-- Compact batch 17/29: rows 801-850

INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES
('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Computational Chemistry & Biology', 'Create a Python CLI that loads a molecular dynamics trajectory of liquid water (XYZ frames plus periodic box dimensions) and computes the O–O radial distribution function g(r), its first minimum, and coordination number (integral to the first minimum), as well as the self-diffusion coefficient from the mean-squared displacement under periodic boundaries. Write g(r) to /app/gofr.csv and a JSON report with the first-minimum position, coordination number, and diffusion coefficient to /app/results.json, verifying normalization and minimum image handling.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Computational Chemistry & Biology', 'Using COBRApy, load the provided SBML metabolic network, configure exchange reactions to model aerobic minimal media with glucose, and maximize biomass to compute the optimal growth rate. Then perform a single-gene deletion screen to identify essential genes under these conditions and write the growth rate and the sorted essential gene IDs to output files.', NULL, NULL),
('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Build a 1D compressible gas dynamics solver for the Sod shock tube using a conservative finite-volume scheme (MUSCL-Hancock with HLLC flux and CFL control) from Riemann initial data, and write density/velocity/pressure profiles at specified times. Include a check that total mass and total energy are conserved to within a small tolerance.', NULL, NULL),
('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Implement a 1D compressible Euler solver to simulate the Sod shock tube using a finite-volume Godunov scheme (e.g., HLLC) with CFL-controlled timestepping and positivity preservation. Output density, velocity, and pressure profiles at specified times and report L1 error against the analytic solution.', NULL, NULL),
('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Implement a 1D finite-volume solver for the compressible Euler equations to simulate the Sod shock tube using an HLLC Riemann solver with a TVD slope limiter, exposing a CLI to set grid size and CFL and writing CSV profiles of density, velocity, and pressure at a target time. Validate conservation of mass/momentum/energy and achieve a small L1 error versus an exact Riemann solution computed by a provided routine.', NULL, NULL),
('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Implement a 1D time-dependent Schrödinger equation solver using the split-operator Fourier method to simulate a Gaussian wavepacket scattering from a rectangular potential barrier. The CLI should sweep incident energies, compute reflection/transmission probabilities with norm conservation, and validate against the analytic transmission coefficient.', NULL, NULL),
('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Implement an Euler–Bernoulli beam finite element solver for a uniform clamped–clamped beam that assembles mass and stiffness matrices and computes the first three natural frequencies and mode shapes. Validate the frequencies against closed-form solutions within 2% and save frequencies and mode shapes to specified output files.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Implement a CLI tool that loads a dense or sparse matrix (CSV or Matrix Market) and computes a rank-k approximation using randomized SVD with configurable oversampling and power iterations, writing U, S, and V^T to standardized output files. Include a verification mode that compares top-k singular values and relative reconstruction error against SciPy’s svds on small matrices, enforcing a ≤1% gap in Frobenius-norm error to the reference.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Implement a Python CLI that loads A, B, C from /app/*.npy and solves A X B = C for X using factorization-based linear solves without forming the Kronecker product (e.g., via LU/QR and column/row reshaping), with an option for Tikhonov regularization. Save X to /app/output/X.npy and a metrics JSON including relative residual (target ≤ 1e-8) and simple condition estimates.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Implement a randomized SVD (Halko algorithm) with configurable rank, oversampling, and power iterations to compute a low-rank approximation of a large dense or sparse matrix loaded from disk. Compare to a deterministic truncated SVD by reporting singular values, relative Frobenius reconstruction errors, and timings in a results JSON, also saving the U,S,V factors.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Implement a randomized low-rank SVD with oversampling and configurable power iterations to compute the top-k singular values and vectors for large dense or sparse matrices via a CLI, benchmarking accuracy and runtime against NumPy/SciPy baselines. Validate orthonormality of U and V and relative reconstruction error, writing standardized outputs to files.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Write a Python script that loads a sparse SPD matrix A from /app/A.mtx and a vector b from /app/b.npy, then solves Ax=b using preconditioned conjugate gradients with an incomplete factorization (ILU/IC) or Jacobi fallback. Save x to /app/x.npy and a JSON with iteration count, final relative residual, and wall time, ensuring ||A x − b||2 / ||b||2 ≤ 1e-8.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Build a Python CLI that integrates systems of ODEs defined by a JSON spec using an adaptive Dormand–Prince 5(4) solver with dense output and event/root detection, automatically switching to an implicit BDF method when stiffness is detected via step-rejection heuristics. The tool should write solution snapshots and event times to files and include a test harness that verifies accuracy and performance against SciPy.integrate on provided nonstiff and stiff problems.', NULL, ARRAY['python', 'performance']),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Implement a Python CLI that performs 1D integration using tanh-sinh (double-exponential) quadrature with adaptive node refinement and error control to handle endpoint singularities. Use it to evaluate the integral of x^(-1/2) * log(x) over [0, 1] to at least 12 correct digits and write both the result and the function-evaluation count to /app/answer.json.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Implement a Python tool that loads a parameterized ODE and scalar loss from a problem module, integrates forward to produce state samples at given eval_ts, then computes dL/dθ via a reverse-time continuous adjoint solve with accurate interpolation of the forward trajectory. Output the trajectory and gradient along with a verification report that checks the adjoint gradient against central finite differences within a specified tolerance.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Implement an adaptive Gauss–Kronrod 21/10 quadrature with a best-first error priority queue that handles infinite limits and endpoint algebraic/log singularities via variable transformations, enforcing absolute/relative tolerances and a cap on function evaluations. The CLI loads an integrand from /app/integrand.py and a JSON spec of intervals and tolerances, then writes the integral, error estimate, and evaluation statistics to /app/output.json.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Implement an adaptive tanh-sinh (double-exponential) quadrature that handles endpoint singularities and infinite limits, returning integrals to specified absolute/relative tolerances while tracking function-evaluation counts. Provide a CLI that reads multiple integrals and intervals from input, computes results without external integration libraries, and writes both values and convergence traces.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Build a Jacobian-free Newton-Krylov solver with backtracking line search to find the steady state of the 2D Bratu (nonlinear Poisson) equation on an N×N grid. The CLI should accept N and lambda, converge to a specified residual tolerance using GMRES with simple preconditioning, and write the solution field and an iteration/residual log to disk.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Build a sparse primal–dual interior-point solver for linear programs in standard form (Mehrotra predictor–corrector with adaptive step and iterative refinement) that loads A, b, c from /app/lp.npz and solves to ≤1e-7 KKT residuals. Write the optimal x, primal/dual residual norms, and objective to /app/output.json, and report infeasible/unbounded cases via a homogeneous self-dual start.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Build a terminal tool that solves a system of nonlinear equations using a Jacobian-free Newton–Krylov method (Newton-GMRES with backtracking line search), loading residual(x) and an initial guess from /app/problem.py. Stop when the 2-norm of the residual is ≤1e-8 or the time budget is hit, and write the solution vector plus iteration and GMRES stats to /app/solution.json.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Implement a command-line tool that computes the minimax (L-infinity) polynomial approximation of a given function on [a,b] using the Remez exchange algorithm, with optional weighting. Output the polynomial coefficients, the achieved uniform error, and the final set of alternation points to a results file.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Implement a primal-dual interior-point solver (Mehrotra predictor–corrector) for dense convex quadratic programs that reads H, f, A, b, G, h, and bound vectors from /app/problem.npz, uses a safeguarded line search with regularization, and drives the KKT residual below 1e-6. Output the primal and dual solutions, final duality gap, and residual norms to /app/output/solution.json.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Build a CLI tool that estimates logdet(A) for large sparse SPD matrices via randomized trace estimation of log(A) (Hutch++ with Chebyshev/Lanczos polynomial approximation), using reproducible seeds and batched probes to deliver a 95% confidence interval within a target relative error. The program must read Matrix Market files, validate against exact small cases, and emit a JSON report with estimate, CI, probe count, and timings.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Create a terminal script that loads a symmetric positive-definite matrix from /app/A.npz and estimates log(det(A)) by approximating trace(log A) via stochastic Lanczos quadrature with Hutchinson (Rademacher) probes using a reproducible RNG seed. The tool should adaptively increase probes to meet a target confidence interval and write the estimate, probe count, and CI to /app/answer.json within a time budget.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Implement a CLI tool that, given a symmetric positive definite sparse matrix A (Matrix Market), estimates trace(log A) via stochastic Lanczos quadrature with Hutchinson probes, supporting Rademacher, Gaussian, and Owen‑scrambled Sobol sequences. The tool adaptively increases probes to hit a target relative 95% CI, reports estimate/CI/probe count/RNG/timing to /app/results.json, and validates on small cases against a Cholesky-based exact computation.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Implement a program that estimates the log-determinant of a large sparse SPD matrix using stochastic trace estimation (Hutchinson with Rademacher probes) combined with Lanczos quadrature, adaptively increasing probes until a 95% confidence interval is within ±1% relative error. Output the estimate, confidence interval, and the number of probes used to a results file.', NULL, NULL),
('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Implement a stochastic Lanczos quadrature estimator for trace(log(A)) (i.e., log det A) of a large sparse SPD matrix using Hutchinson probes (Rademacher with optional antithetic pairing), reporting the mean, standard error, and 95% CI as functions of probe count and Lanczos steps. Provide a CLI that loads a Matrix Market .mtx, runs with a reproducible seed, and writes per-probe estimates and the final summary to CSV.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Build a CLI that reads a YAML parameter grid, generates and submits a resilient SLURM array job with a launcher mapping SLURM_ARRAY_TASK_ID to parameters, and monitors progress via squeue/sacct until completion. It must auto-requeue failed indices with increased time/memory, throttle or add dependencies based on pending reasons, and produce a CSV with per-index status, exit code, runtime, and MaxRSS.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Build a SLURM workflow manager that submits a 3‑stage pipeline (preprocess → job array → reduction) with dependency chaining, monitors via squeue/sacct, and automatically requeues only failed array tasks (e.g., preempted or OOM) with adjusted resources and retry limits. It must handle SIGTERM for checkpointing and produce a final JSON/CSV report of exit status, retries, elapsed time, and MaxRSS per task.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Build a SLURM-driven workflow that launches a job array for a parameter sweep, enforces job dependencies (build -> stage data -> array -> postreduce), detects and auto-recovers preempted/failed tasks via sacct, and aggregates per-task elapsed time and GPU allocation into results.json. Provide scripts to submit, monitor, and checkpoint outputs so requeued runs resume without redoing completed work.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Create a SLURM workflow that runs a parameter sweep as a job array reading /app/params.csv, stages per-task inputs to node-local scratch, and records stdout/stderr per index. Implement automatic failure handling that requeues only failed array tasks once with doubled time/memory and a dependent postprocessing job that uses sacct to write state, runtime, and MaxRSS for all indices to /app/output/summary.csv only after all tasks succeed.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Create a SLURM workflow that shards a large input into 200 parts, submits a fault-tolerant job array with per-task time/memory requests that traps SIGTERM to checkpoint and automatically retries failed elements, then resumes from partial results upon requeue. Monitor progress via squeue/sacct and submit an afterok aggregation job that verifies all shards, computes per-task runtime/memory statistics, and writes a consolidated JSON report to /app/summary.json.', 'hard', NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Build an MPI-based distributed PageRank solver for sparse graphs that partitions the adjacency matrix by rows, performs power iteration with teleportation and dangling-mass handling via collective reductions, and outputs the top-k ranked nodes and convergence metrics. Provide a CLI to read an edge list, configure alpha/tolerance, verify correctness by matching NetworkX PageRank on small graphs within 1e-6, and report weak-scaling efficiency.', NULL, ARRAY['distributed']),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Implement a distributed 2D Poisson/heat equation solver using MPI with domain decomposition and ghost-cell halo exchanges alongside a serial baseline sharing a common CLI to control grid size, iterations, and tolerance. Save residual history and the final field to standardized outputs, validate convergence and agreement with the serial solution within a set error, and demonstrate strong-scaling across process counts.', NULL, ARRAY['distributed']),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Implement a distributed Conjugate Gradient solver for large sparse SPD matrices using MPI (mpi4py) with row-wise partitioning and halo exchanges for sparse matrix–vector products; solve Ax=b from provided Matrix Market and NumPy inputs and write the solution residual, iterations, and per-rank timing to files. Validate against a serial SciPy reference on small cases and demonstrate strong scaling across multiple processes.', NULL, ARRAY['distributed']),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Implement an MPI-based 3D Poisson solver on a structured grid using domain decomposition and a conjugate gradient method with Jacobi preconditioning, with each rank maintaining ghost cells and performing halo exchanges each iteration. Validate against an analytical solution by reporting L2 error and residual reduction, and write per-rank timing/scaling metrics and a representative solution slice to output files.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Implement an MPI-based 3D Poisson solver on a uniform grid using 3D Cartesian domain decomposition with nonblocking halo exchanges and Jacobi/CG iteration, writing per-iteration residuals, timings, and a central solution slice to standardized outputs. The harness runs at 1, 2, and 4 ranks to validate against a manufactured sinusoidal solution (error threshold), ensure monotonic residual decrease, and assess near-ideal weak scaling.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'GPU & Accelerator Utilization', 'Create a GPU-accelerated 3D FFT-based Poisson solver using CuPy that computes the potential from a density field under periodic boundary conditions, with a CPU fallback using NumPy/SciPy. The CLI should load a .npy volume, compute potential and total energy, verify relative error ≤1e-6 vs CPU on a test case, and print device info and achieved GPU speedup.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'GPU & Accelerator Utilization', 'Implement a 3D FFT-based Poisson solver with periodic boundaries accelerated on GPU using CuPy/cuFFT, supporting batched right-hand sides and single/double precision. Provide a CLI that validates against a manufactured analytic solution and reports accuracy plus speedup versus a NumPy/FFTW CPU baseline.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'GPU & Accelerator Utilization', 'Implement a 3D heat diffusion solver using CuPy with a custom CUDA RawKernel (7-point stencil) alongside a NumPy CPU reference, then run both on provided initial conditions to the same final time and validate the GPU field against CPU within 1e-6 max error while saving the final array, device name, and per-backend timings/speedup. Enforce the stability constraint dt <= dx^2/(6*alpha) and use shared-memory tiling with coalesced accesses in the GPU kernel.', NULL, ARRAY['backend']),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'GPU & Accelerator Utilization', 'Implement a GPU-accelerated 2D Poisson solver on a large grid using a CuPy/Numba-CUDA stencil (Jacobi or Red–Black Gauss–Seidel), and compare its runtime to a NumPy CPU baseline. The script must reach a specified residual tolerance, validate against an analytic solution, and write residual, iterations, and GPU speedup to /app/metrics.json.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Build a multi-threaded Smith–Waterman local sequence alignment engine that parallelizes anti-diagonals (wavefront) with OpenMP alongside a serial baseline, exposing a CLI to align FASTA pairs and emit alignment score and traceback. Include correctness checks against a known-good implementation and a benchmark that reports GCUPS and thread-scaling.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Implement a 2D steady-state Poisson solver on a large grid using Jacobi iterations, providing both a single-threaded baseline and a multi-threaded version (OpenMP or multiprocessing). The CLI must accept grid size and thread count, iterate until a residual threshold, and write the final field plus a convergence/timing summary that demonstrates speedup with ≥4 threads.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Implement a Conjugate Gradient solver for large SPD sparse matrices in CSR format with both serial and OpenMP-threaded paths for SpMV and vector reductions, selectable via a CLI. Load a provided matrix/vector, solve to a tolerance, and output solution, residual norm, and per-iteration timing to validate correctness and speedup across thread counts.', NULL, NULL),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Implement serial and OpenMP-parallelized Conjugate Gradient for large SPD sparse matrices in CSR loaded from Matrix Market files, with optional Jacobi preconditioning and fused parallel reductions. Provide a common CLI to solve Ax=b, write residual histories and solution summaries, verify the parallel solution matches serial within tolerance, and report timing-based speedups across thread counts.', NULL, ARRAY['parallel']),
('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Implement serial and shared-memory parallel PageRank for a large sparse graph loaded from disk, using thread-partitioned sparse matvec and residual-based convergence. Output the top-ranked nodes and detailed timings to demonstrate speedup over the serial baseline.', NULL, ARRAY['parallel']),
('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Data Versioning & Dependency Control', 'Build a DVC-backed pipeline (local remote) with dvc.yaml stages to fetch, preprocess, and analyze a dataset while pinning Python dependencies with pip-tools to a requirements.lock. Prove reproducibility by switching between two Git tags and using dvc checkout so that metrics.json and output file checksums exactly match each tag’s recorded state.', NULL, ARRAY['python', 'git']),
('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Data Versioning & Dependency Control', 'Build a DVC-managed analysis pipeline that versions two dataset revisions in a local DVC remote and runs a metrics script inside a conda-lock pinned environment. The run must write /app/results.json with metrics and provenance (dataset DVC hash, lockfile digest, git commit, script checksum) and reproduce bit-for-bit identical outputs across reruns.', NULL, ARRAY['git']),
('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Data Versioning & Dependency Control', 'Create a reproducible time-travel runner that checks out dataset revisions (e.g., tags data/v1 and data/v2) with DVC, resolves the exact environment via conda-lock, executes a Snakemake pipeline, and writes a provenance manifest listing git SHAs, DVC object IDs, lockfile hash, and output checksums. Generate a metric-drift report comparing the two runs and fail if any data or dependency is not pinned.', NULL, ARRAY['git']),
('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Data Versioning & Dependency Control', 'Implement a DVC-managed pipeline (preprocess → train → evaluate) with two local dataset versions and lock Python dependencies via pip-tools so reproducing on v1 yields identical artifact and metrics hashes across runs, while switching to v2 triggers only minimal stage recomputation. The run must emit an output manifest with dataset version, DVC stage checksums, and exact pip freeze, and validate at startup that installed packages match the lockfile.', NULL, ARRAY['python']);
