-- Batch 1 of 8: Inserting tasks 1 to 200

INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Build Profiling & Benchmarking', 'Benchmark a CMake/Ninja C++ project across linkers (ld.bfd vs lld) and with/without LTO, capturing compile vs link phase durations and Clang -ftime-trace to identify the five slowest translation units. Produce a JSON report comparing full and incremental rebuild times (after touching a common header) and recommend the fastest configuration.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Build Profiling & Benchmarking', 'Instrument a CMake-based C++ project to build with Ninja and Clang using -ftime-trace, aggregating the emitted JSON traces to identify the five slowest translation units and the link step. Add CMake options for precompiled headers and unity builds, run baseline and optimized clean builds, and emit /app/metrics.json with total wall times, per-step timings, and percent improvement.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Build Profiling & Benchmarking', 'Instrument a provided CMake/Ninja C++ project with clang’s -ftime-trace and Ninja -d stats to profile cold and incremental builds, reporting the slowest translation units and link steps. Enable ccache and a precompiled header via CMake, then re-benchmark and output a before/after summary of total build time, parallelism, and cache hit rates.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Build Profiling & Benchmarking', 'Profile a CMake+Ninja C++ project by enabling Clang -ftime-trace and Ninja -d stats to collect per-file compile/link timings and parallelism, then benchmark clean vs. incremental builds across -j values with and without ccache/PCH and using GNU ld vs. ld.lld. Emit a JSON summary ranking configurations by wall time, flag the two slowest targets, and apply minimal flag tweaks to achieve at least a 30% speedup over the baseline.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Build Profiling & Benchmarking', 'Profile a medium C++ CMake/Ninja project by collecting compile and link timings (e.g., clang -ftime-trace and ninja -d stats), then identify the worst-offending translation units and headers. Introduce a precompiled header and an optional unity-build mode, rebuild, and emit a metrics.json comparing baseline vs optimized total build time, longest TU time, and percent improvement.', 'medium', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Incremental Builds & Caching', 'Configure a Bazel workspace to use a local HTTP remote cache (bazel-remote) persisted under /cache, build a mixed C++/Java project to prime the cache, then simulate a fresh checkout and rebuild. Verify the second build achieves >95% remote cache hits with no compile actions executed, based on Bazel’s build event summary.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Incremental Builds & Caching', 'Configure sccache as a unified compiler cache for a mixed Rust (Cargo) + C (CMake) workspace, routing rustc, CC, and CXX through sccache with stable flags. Verify incremental behavior by performing back-to-back builds to record cache hits, then modifying a single Rust crate so only that crate recompiles while C targets are served from cache, as shown by sccache stats and build logs.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Incremental Builds & Caching', 'Configure sccache as the compiler wrapper for a mixed Rust + C++ workspace (Cargo + CMake) so both toolchains share a persistent cache and clean rebuilds are served from it. Validate by building twice and then after a targeted source edit, reporting sccache stats showing cache hits for unchanged targets and minimal recompilation for the modified component.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Incremental Builds & Caching', 'Configure sccache for a Rust workspace and wire cargo to use it with rustc, enabling incremental compilation with a shared on-disk cache. Build twice across two clean worktrees, then modify a single crate to demonstrate minimal rebuilds and record timings plus sccache hit/miss stats to /app/metrics.json.', NULL, ARRAY['rust', 'compilation']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Incremental Builds & Caching', 'Provision a local Bazel remote cache (bazel-remote) and configure a polyglot Bazel workspace (C++, Java, Python) to use it, then perform two clean builds to prove incremental and remote cache hits. Parse the Bazel Build Event Protocol to write a summary of action counts, cache-hit ratios, and elapsed time improvements.', NULL, ARRAY['java', 'python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Parallelization & Resource Utilization', 'Configure distributed, parallel compilation for a medium-size CMake+Ninja C/C++ project using distcc by launching multiple local distccd workers and wiring CC/CXX and DISTCC_HOSTS, then build with -j$(nproc). Validate by parsing distcc logs to confirm a majority of object files were compiled remotely and that total parallel jobs respect the configured CPU quota without oversubscription.', 'medium', ARRAY['distributed', 'parallel', 'compilation']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Parallelization & Resource Utilization', 'Convert the provided CMake-based C++ project to use Ninja with CMake Unity builds and ccache, and enable ThinLTO to parallelize the link stage. Auto-detect available cores, run a cold and warm build with -j$(nproc), and output a report showing wall-time improvement and cache hits on the second build.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Parallelization & Resource Utilization', 'Reconfigure a CMake-based C++ monorepo to use the Ninja generator with CMAKE_JOB_POOLS/CMAKE_JOB_POOL_LINK to fully parallelize compilation while capping memory-heavy link jobs, and enable ccache for reuse across repeated builds. Run a baseline (Unix Makefiles, -j1) and the optimized build, then emit /app/parallel_metrics.json with cores utilized, wall-time speedup, and cache hit rate.', NULL, ARRAY['compilation']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Parallelization & Resource Utilization', 'Refactor a multi-module Gradle project to build and test in parallel by enabling org.gradle.parallel, tuning workers and test forks based on available CPU/memory, and enabling the local build cache. Capture baseline single-threaded vs optimized build times and emit a metrics JSON with speedup while ensuring produced JARs and test outcomes remain identical.', NULL, ARRAY['parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Optimization & Performance', 'Parallelization & Resource Utilization', 'Refactor a recursive Makefile-based C/C++ project to be jobserver-aware and compile in parallel via distcc with ccache, spawning multiple local distccd agents to simulate a distributed build. Ensure sub-makes share the jobserver tokens, utilize all CPU cores, and emit a build log proving compilation fanned out across the agents.', NULL, ARRAY['parallel', 'distributed', 'compilation']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Build Output Validation', 'Diagnose and correct a Go (1.22) project''s build settings so it outputs a fully static, reproducible binary. Validate by ensuring ldd reports ''not a dynamic executable'', readelf shows no INTERP or NEEDED entries, and two builds with identical SOURCE_DATE_EPOCH have identical SHA-256 hashes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Build Output Validation', 'Fix a CMake-based project that embeds absolute RPATHs causing the installed executable to fail when moved. Reconfigure and rebuild to emit $ORIGIN-relative RUNPATH for bundled shared libraries, then validate by relocating the install tree, executing the binary, and confirming via readelf/ldd that no absolute paths remain.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Build Output Validation', 'Repair a CMake-based C shared library that leaks internal symbols and lacks proper SONAME/versioning by enforcing hidden visibility and a GNU ld version script. Validate that the built lib has SONAME libfoo.so.1 and exports only the intended API symbols under version FOO_1.0 (checked via nm/readelf) and that a minimal client links and runs successfully.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Build Output Validation', 'Repair a CMake-based build so the produced shared library is libvector.so.3 with an exact exported symbol set matching /app/exports.txt, no undefined symbols, no RUNPATH/RPATH, and the correct SONAME. Validate by diffing nm -D --defined-only against the reference, checking readelf -d for SONAME/RPATH, and building a tiny client that links dynamically and prints a known checksum to confirm ABI correctness.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Build Output Validation', 'Repair a failing CMake build of a versioned shared library (libimagelib) by fixing PIC/visibility flags and defining a proper SONAME and symlink chain. Validate by ensuring libimagelib.so.2 resolves via ldd, nm -D exposes only intended symbols, a tiny consumer links and runs, and a sample transform output matches an expected SHA256.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Compiler & Linker Errors', 'Fix a CMake-based C++ project where building a shared plugin fails to link due to a vendored static library compiled without -fPIC (relocation against .text/.rodata). Reconfigure the build to rebuild that static library with POSITION_INDEPENDENT_CODE and correct link interface so the plugin links and a provided dlopen smoke test runs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Compiler & Linker Errors', 'Repair a CMake-based C++ project that links a shared library against a bundled static archive and currently fails with R_X86_64_32 relocation errors and undefined references to dlopen/pthread/clock_gettime. Rebuild the static archive with -fPIC and correct the CMake link configuration (Threads::Threads, dl, rt) so the library links cleanly and the demo executable runs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Compiler & Linker Errors', 'Repair a CMake-based C++17 project that fails to link a shared library due to non-PIC static dependencies and missing OpenMP/filesystem linkage. Rebuild static libs with -fPIC (or use shared), enable OpenMP via CMake and conditionally link stdc++fs for older GCC, set $ORIGIN rpath, and validate by running a threaded test that dlopens the library.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Compiler & Linker Errors', 'Repair a failing JNI native library build by fixing missing jni.h includes, enabling position-independent code, and linking against the correct libjvm with proper RPATH in the build configuration. Verify by producing a loadable libnative.so that the provided Java class can load and call to print an expected message.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Configuration & Environment Issues', 'Diagnose and fix a Meson-based C project that fails to detect SDL2 because it is installed under a non-standard prefix (/opt/sdl2). Configure environment variables (e.g., PKG_CONFIG_PATH and LD_LIBRARY_PATH) and, if needed, a Meson cross file so the project configures, builds, and the resulting binary links against /opt/sdl2 as verified by ldd.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Configuration & Environment Issues', 'Diagnose and repair a Rust crate build that fails to compile openssl-sys and bindgen by installing the proper system tools and correctly setting PKG_CONFIG_PATH/OPENSSL_DIR and LIBCLANG_PATH/LD_LIBRARY_PATH so Cargo can find OpenSSL and libclang. Verify by building in release mode and running a provided HTTPS client example to confirm TLS works end-to-end.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Configuration & Environment Issues', 'Repair a Java Maven project that fails because it requires JDK 11 via the maven-toolchains-plugin but the environment defaults to JDK 17, by installing/selecting the correct JDK and configuring ~/.m2/toolchains.xml plus JAVA_HOME/PATH so mvn -B -DskipTests package succeeds without changing pom.xml. Verify by printing the javac -version used and running the built JAR to confirm it targets Java 11.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Configuration & Environment Issues', 'Repair a failing Maven Java build caused by an incorrect JDK and unset JAVA_HOME by installing the required JDK 21, setting JAVA_HOME/PATH, and configuring a Maven toolchains.xml so the compiler uses the correct toolchain. Verify by running mvn -DskipTests package to produce the expected JAR at a specified path without changing dependency declarations.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Dependency & Compatibility Issues', 'Diagnose a CMake C++ project that fails to build and link because the protoc used for code generation does not match the installed libprotobuf runtime version. Install or build a matching protobuf toolchain, update PATH and CMAKE_PREFIX_PATH so generation and linking use the same version, then rebuild to produce a binary that runs and prints a provided test message.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Dependency & Compatibility Issues', 'Diagnose a Rust Cargo build failing on Linux due to an OpenSSL headers/library version mismatch (openssl-sys expecting OpenSSL 3 while the OS provides 1.1). Resolve by only modifying Cargo.toml (pin compatible crate versions or enable the vendored OpenSSL feature) and installing minimal build tools so cargo build --release succeeds and the produced binary runs and prints "TLS: OK".', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Dependency & Compatibility Issues', 'Diagnose and fix a Rust CLI project that fails to compile because the openssl-sys crate expects OpenSSL 1.1 while the system only provides OpenSSL 3. Adjust Cargo features and environment (e.g., enable the vendored feature or point pkg-config to the correct libs), rebuild successfully, and verify with a TLS request plus ldd showing the intended libssl linkage.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Dependency & Compatibility Issues', 'Diagnose and repair a Node.js project failing to build because the sharp native addon is incompatible with the installed Node.js version and the required libvips system libraries are missing. Align the Node/ABI and dependency versions (or rebuild sharp from source) and install the OS-level libraries so npm install completes and the test suite passes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Build Troubleshooting & Repair', 'Dependency & Compatibility Issues', 'Repair a Maven-based Java project that fails to build on JDK 21 due to incompatible plugin/dependency versions (maven-compiler-plugin, animal-sniffer) and javax→jakarta namespace conflicts. Update version pins and dependency exclusions so mvn -DskipTests=false verify succeeds and the assembled Spring Boot jar launches and responds on /actuator/health.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Artifact Publishing & Deployment', 'Build a multi-arch OCI image for the provided service using Docker Buildx, push it to a local registry, then sign it with a locally generated cosign key and attach an SPDX SBOM as an OCI artifact. Verify by pulling the manifest list to confirm both architectures, validating the signature against the public key, reading the SBOM from the registry, and deploying via a digest-pinned Docker Compose file.', NULL, ARRAY['docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Artifact Publishing & Deployment', 'Create a CI-style release pipeline that cross-compiles a Go CLI for linux/amd64 and linux/arm64, packages deterministic tarballs with embedded build metadata, generates SBOM and checksums, signs the artifacts, and publishes them to a local “release” store; verify by installing from that store and validating the signature.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Artifact Publishing & Deployment', 'Package a small CLI tool as a Debian .deb and publish it to a locally hosted APT repository served over HTTP. Generate and sign repository metadata, add the repo to sources.list, install the package via apt by name, and verify the installed binary runs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Build Script Development', 'Create a Bash build script that compiles a small CMake-based library and a Python extension wheel using a fixed SOURCE_DATE_EPOCH and deterministic toolchain/linker flags, then packages outputs into a tarball with a manifest of checksums and build metadata. The script must run tests, reuse a local cache across invocations, and verify reproducibility by proving two consecutive runs produce identical tarball checksums.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Build Script Development', 'Create a deterministic Bash build script and accompanying CI YAML that build a Rust-backed Python extension (PyO3) into manylinux wheels for CPython 3.11 and 3.12 using maturin, cache Cargo/pip artifacts, run pytest, and place wheels in /app/dist. The pipeline must honor SOURCE_DATE_EPOCH, run in a matrix for linux/amd64 and linux/arm64 via QEMU, and fail on formatting or type-check violations (cargo fmt --check, ruff, mypy).', NULL, ARRAY['rust', 'python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Build Script Development', 'Create a portable build.sh and CI workflow (YAML) that build, audit, and test manylinux wheels for a PyO3-based Rust extension across CPython 3.9–3.12 using maturin/auditwheel with Cargo and pip caches, then install each wheel in fresh venvs to run smoke/unit tests. The script must run locally and in CI, emit a dist/ manifest with checksums, and fail if any wheel is non-manylinux-compliant or import tests fail.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Build Script Development', 'Write a portable Bash build script for a CMake-based C/C++ repo that runs a compiler×sanitizer matrix (gcc/clang × none/ASan/UBSan), executes ctest for each, and emits JUnit XML plus Cobertura coverage (gcovr) for gcc builds. The script must read a coverage threshold from a config file, fail the build if unmet, cache builds with ccache, and place all artifacts under /app/artifacts.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Build Verification & Reproducibility', 'Build a provided Go CLI twice in separate working directories and with different PATH orders while enforcing hermetic, reproducible outputs (e.g., -trimpath, -buildid=, vendor-only modules, fixed SOURCE_DATE_EPOCH), then assert the two binaries have identical SHA256 hashes. Only adjust build scripts/configuration without modifying source code, and the task fails on any network access or hash mismatch.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Build Verification & Reproducibility', 'Configure a Gradle multi-module Java project to produce bit-for-bit reproducible artifacts (JARs and a shaded fat JAR) by normalizing file order, timestamps, and manifest fields, and pinning plugin/wrapper versions. Add a CI shell script that builds twice in isolated workspaces and fails if any artifact checksums differ.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Build Verification & Reproducibility', 'Convert a multi-module Maven Java project to produce bit-for-bit reproducible JARs by configuring project.build.outputTimestamp from SOURCE_DATE_EPOCH, normalizing MANIFEST entries, and locking dependency versions, then perform two clean builds to verify identical SHA256s for every artifact. The task should fail if any JAR differs or includes non-deterministic metadata such as timestamps, build paths, or environment-specific fields.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Build Verification & Reproducibility', 'Create a hermetic CI-style script that builds a provided Go CLI twice in separate directories with different GOPATHs, using -trimpath, -buildvcs=false, and SOURCE_DATE_EPOCH to eliminate path and timestamp leakage, then asserts identical SHA-256 hashes of the binaries. On success, emit a brief reproducibility report and a minimal provenance JSON; on failure, output a targeted diff (e.g., cmp/strings) to highlight remaining non-determinism.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'Build Verification & Reproducibility', 'Transform the provided Python package into a bit-for-bit reproducible wheel by normalizing zip entry timestamps, ordering, and metadata, eliminating VCS-derived version noise, and honoring SOURCE_DATE_EPOCH. Perform two clean builds in different build paths and verify identical SHA256 of the .whl, then install it and run a supplied test script to confirm functionality.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'CI Configuration & Maintenance', 'Configure a GitHub Actions workflow that builds and tests a Rust project in a matrix (Linux and macOS) with sccache and dependency caching, then on tags performs two clean release builds and asserts the binaries are bit-for-bit identical before uploading them as artifacts. The pipeline must also generate and upload an SBOM for each artifact and fail if reproducibility or SBOM generation checks fail.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'CI Configuration & Maintenance', 'Create a GitHub Actions configuration for a monorepo containing a Python package and a Rust crate using a reusable workflow and two caller workflows with path filters so only relevant jobs run, with pip/cargo caching and cross-job artifact sharing. Validate locally (e.g., with act) that pytest and cargo test execute when their respective directories change and are skipped otherwise.', NULL, ARRAY['python', 'rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'CI Configuration & Maintenance', 'Create a GitHub Actions workflow for a Python/Node monorepo that uses path filters to trigger language-specific jobs, caches pip and pnpm, provisions a Postgres service for integration tests, and builds manylinux wheels with cibuildwheel and auditwheel; on tags, publish release artifacts with checksums. Validate locally with act by ensuring all jobs pass and expected wheels plus a merged coverage report are uploaded as artifacts.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'CI Configuration & Maintenance', 'Fix and harden a GitHub Actions workflow for a CMake-based C project by pinning actions to SHAs, enabling ccache with cache restore/save across a gcc/clang matrix, and splitting build/test/release with minimal permissions and concurrency cancellation. Validate locally with act that pushes run build+test across the matrix and that tagging v* produces an uploaded release artifact.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Continuous Integration & Automation', 'CI Configuration & Maintenance', 'Repair a failing GitHub Actions workflow by migrating deprecated features (set-output, add-path, old v1 actions) to current best practices: pin actions by commit SHA, upgrade to setup-node v4 with Node 20, switch to upload-artifact v4, add proper caching and a concurrency group. Validate locally with act that the workflow installs with npm ci, runs tests, and successfully uploads a build artifact.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Installation & Version Control', 'Convert a Rust Cargo workspace into a fully pinned, offline build by replacing loose version requirements with exact pins, generating a deterministic Cargo.lock, and vendoring all crates with cargo vendor while wiring .cargo/config.toml to the vendor directory. Verify success by clearing the Cargo registry/cache and building and testing the workspace with cargo --offline to demonstrate no network access is needed.', NULL, ARRAY['rust', 'testing']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Installation & Version Control', 'Diagnose and fix a Go module dependency graph that fails to resolve due to mixed v1/v2+ module paths and a transitive break. Update only go.mod by pinning compatible versions and adding replace directives (including a local path for a provided fork) so that go mod tidy and go build ./... succeed.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Installation & Version Control', 'In a Rust workspace, resolve a security advisory by pinning a transitive crate to a specific commit via [patch.crates-io], regenerate Cargo.lock, and vendor all dependencies so the project builds strictly offline. Verify by compiling with cargo build -Z offline using only the vendored directory and running the binary to print its version.', NULL, ARRAY['rust', 'security']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Installation & Version Control', 'Migrate a JavaScript monorepo to pnpm workspaces and resolve conflicting peerDependencies (e.g., React 18 and TypeScript 5) by editing package.json ranges and adding pnpm.overrides to pin a single compatible set. Generate a deterministic pnpm-lock.yaml, install with a frozen lockfile, and validate by building all packages and running a provided cross-package integration script.', NULL, ARRAY['javascript', 'typescript']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Installation & Version Control', 'Resolve peerDependency conflicts in a Yarn v3 Plug''n''Play monorepo by using resolutions and packageExtensions to align versions of React, Webpack loaders, and ESLint plugins. Produce a reproducible install (yarn.lock) and verify the workspace builds and lints successfully under Node 20.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Resolution & Conflict Fixing', 'Diagnose and fix a Rust project’s build failure caused by a dependency tree pulling in both native-tls (openssl-sys) and rustls while the host OpenSSL version is incompatible. Align Cargo features and versions (e.g., select rustls-tls, enable vendored OpenSSL, or install the correct libssl-dev) so cargo build and the test suite complete successfully.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Resolution & Conflict Fixing', 'Fix a Rust Cargo workspace that fails to build due to conflicting versions and feature flags among tokio, hyper, and reqwest by aligning version pins and enabling compatible features in Cargo.toml without adding or removing dependencies. Ensure cargo build --locked succeeds across all workspace members with the provided toolchain.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Resolution & Conflict Fixing', 'In a Rust Cargo workspace, diagnose and resolve a build failure caused by conflicting serde/serde_json versions and incompatible feature requirements across multiple member crates and a pinned transitive dependency. Modify only Cargo.toml constraints (workspace dependency versions, [patch.crates-io], and feature flags) so that cargo build completes without changing source code or removing dependencies.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Resolution & Conflict Fixing', 'Resolve a Rust Cargo workspace that fails to compile due to transitive version/feature conflicts between reqwest, openssl-sys, and tokio plus a system OpenSSL 1.1 vs 3.0 mismatch. Pin compatible crate versions, adjust features and Cargo patches, configure pkg-config to link the intended OpenSSL, vendor dependencies for offline build, and validate by building and running a CLI that performs an HTTPS request.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Dependency Resolution & Conflict Fixing', 'Resolve a Rust Cargo workspace where crates pull in incompatible TLS stacks (native-tls via openssl-sys pinned for OpenSSL 1.1 vs rustls) causing builds to fail against system OpenSSL 3.x. Unify feature flags and version pins (or enable openssl "vendored") so cargo build --workspace succeeds and the provided HTTPS CLI test runs successfully.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Lockfile & Manifest Maintenance', 'In a Rust workspace with crates using branch-based git and wildcard semver dependencies, pin each to exact versions and commit SHAs in Cargo.toml and regenerate a deterministic Cargo.lock. Verify reproducibility by building with cargo build --frozen in a clean state, ensuring no yanked or platform-specific mismatches remain in the lockfile.', NULL, ARRAY['rust', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Lockfile & Manifest Maintenance', 'Regenerate deterministic lockfiles for a polyglot monorepo—Python (pip-compile with --generate-hashes), Node (npm@10 package-lock v3), and Rust (Cargo.lock)—replacing version ranges with exact pins and eliminating platform-specific drift. Verify by performing two clean, offline installs that yield byte-for-byte identical dependency trees and checksums.', NULL, ARRAY['python', 'rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Lockfile & Manifest Maintenance', 'Regenerate fully hashed requirements.txt and requirements-dev.txt from a pyproject.toml that includes extras and environment markers, using pip-tools pinned to Python 3.11 and honoring an existing constraints.txt without pulling in optional extras. Verify that pip install --require-hashes succeeds entirely offline from the provided wheelhouse and fails if any dependency would need the network.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Lockfile & Manifest Maintenance', 'Regenerate reproducible Python lockfiles (with hashes) from a pyproject.toml that includes extras, environment markers, a VCS-pinned dependency, and a local path package using pip-tools, updating the manifest as needed for Python 3.12 on Debian bookworm. Validate by installing offline from a provided wheelhouse with pip --require-hashes and verifying that re-locking with the same SOURCE_DATE_EPOCH produces identical files.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'Lockfile & Manifest Maintenance', 'Resolve peerDependency conflicts in a Yarn v3 workspaces monorepo by aligning manifest ranges and regenerating a deterministic yarn.lock with Corepack enabled so yarn install --immutable succeeds on Linux. Prove reproducibility by performing two clean installs that yield identical resolved versions and an unchanged install-state file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'System vs. Project Dependency Isolation', 'Build OpenSSL 1.1.x from source into a project-local prefix and compile a provided C utility to link exclusively against it (not the system OpenSSL), embedding an rpath to the local lib directory. Prove isolation by showing ldd resolves libssl/libcrypto from the project prefix and the program prints the 1.1.x version while the system ''openssl version'' remains unchanged.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'System vs. Project Dependency Isolation', 'Create a Python project-local virtual environment at /app/.venv and use pip-tools to lock dependencies so the project installs NumPy 1.24.x and a compatible SciPy while the system Python retains NumPy 2.x. Prove isolation by printing NumPy versions from both interpreters and successfully running a bundled script that relies on APIs removed in NumPy 2.0.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'System vs. Project Dependency Isolation', 'Initialize an R project with renv to create a project-local library and lockfile, installing specific versions of data.table and ggplot2 that differ from the system-wide packages. Run the provided R script using the isolated library and verify at runtime that .libPaths()[1] resolves to the renv project path, not the system library.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Dependency Management', 'System vs. Project Dependency Isolation', 'Pin a per-project Rust toolchain via rust-toolchain.toml and vendor all Cargo dependencies into ./vendor, configuring .cargo/config.toml so the crate builds fully offline without touching global cargo/rustup caches. Verify isolation by clearing ~/.cargo and ~/.rustup, setting CARGO_HOME to a temp dir, disabling network, and successfully building and running the tests.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'C/C++ & Systems Builds', 'Build a versioned shared library (e.g., libmathshim.so.1.0) with a proper SONAME and install a matching pkg-config file, then compile a consumer executable that discovers it via pkg-config and embeds a $ORIGIN-based RUNPATH for relocatable execution. Verify by relocating the bin and lib into a new directory tree and demonstrating the program runs and ldd shows RUNPATH without needing LD_LIBRARY_PATH.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'C/C++ & Systems Builds', 'Configure a CMake-based C project to produce bit-for-bit reproducible builds by enabling deterministic archives and stripping build paths (e.g., SOURCE_DATE_EPOCH, ar D, -ffile-prefix-map/-fdebug-prefix-map) with split DWARF. Build twice in different directories and verify identical SHA-256 digests while ensuring no absolute build paths remain in the binary.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'C/C++ & Systems Builds', 'Create a CMake superbuild that compiles vendored zlib and libpng via ExternalProject_Add and then builds a C++ CLI (pngdim) that links them. Ensure correct SONAME and RUNPATH so the produced binary runs in the sandbox and transforms a provided PNG to /app/out.png with an expected SHA256.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'C/C++ & Systems Builds', 'Create and install a C shared library with GNU symbol versioning and proper SONAME/symlink layout (e.g., libcalc.so.2) plus a pkg-config file, exporting both v1 and v2 of an API via a linker version script. Build two test programs (one expecting v1, one v2) and verify via readelf/nm and runtime execution that both resolve correctly against the single installed library.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'C/C++ & Systems Builds', 'Refactor a small C library to use modern CMake, installing both shared and static variants along with a FooConfig.cmake export and a pkg-config foo.pc that correctly express include and link interfaces. Build a separate consumer in a clean environment using find_package(Foo CONFIG) and pkg-config, run it to generate /app/out.txt, and verify correct SONAME and RPATH on the linked binary.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Java & JVM-Based Builds', 'Build a Java 17 multi-module Maven project (app, core, provider) as JPMS modules, configuring the compiler and JAR plugins to produce modular artifacts and using jlink to assemble a custom runtime image at /app/dist. Validate that the image’s launcher runs the CLI and that ServiceLoader discovers the provider implementation at runtime.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Java & JVM-Based Builds', 'Configure a multi-module Gradle (Kotlin DSL) Java/Kotlin project to build offline against a pre-seeded local Maven repository, enable dependency locking and verification, and produce a deterministic shaded fat JAR targeting JDK 17. Verify by building twice with the same SOURCE_DATE_EPOCH to obtain identical SHA256 sums and by running the JAR to print its git-derived version.', NULL, ARRAY['java', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Java & JVM-Based Builds', 'Configure and build a mixed-language (Java + Kotlin) multi-module Maven project using toolchains to compile one legacy module with JDK 8 and the rest with JDK 17, wiring Lombok and MapStruct as annotation processors on the correct processor path. Produce a deterministic, shaded CLI artifact with relocated dependencies and attached sources/javadoc, publish to the local Maven repository, and verify by building and running a tiny consumer project that imports the library and executes the CLI.', NULL, ARRAY['java', 'rest']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Java & JVM-Based Builds', 'Create a Gradle multi-module Java build that replaces a transitive dependency with a local fork via dependency substitution, then produces a reproducible shaded (relocated) fat JAR with deterministic timestamps and entry order. Validate that unit tests pass, the runnable JAR executes without classpath conflicts, and two builds with the same SOURCE_DATE_EPOCH are bit-for-bit identical.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Java & JVM-Based Builds', 'Refactor a Maven multi-module Java project to use a Bill of Materials (BOM) and the Maven Enforcer plugin to resolve transitive version conflicts, then configure the maven-shade-plugin to build a reproducible, executable app JAR with relocated Guava classes and a proper Main-Class manifest. Validate by running the JAR to produce the expected output and by proving two consecutive builds are byte-identical (same SHA256) when SOURCE_DATE_EPOCH is set.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'JavaScript & Frontend Builds', 'Convert a TypeScript library to a dual-module build that emits ESM and CommonJS bundles with Rollup or tsup, generating declaration files and source maps, and configure package.json exports/typings so both import and require work. Verify by running two provided consumers (Node ESM and CJS) and by ensuring the ESM bundle is tree-shakeable and under a specified size budget.', NULL, ARRAY['typescript']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'JavaScript & Frontend Builds', 'Create a Yarn 3 Plug''n''Play workspace that builds a TypeScript library and a Node.js CLI via Rollup, emitting dual ESM/CJS outputs plus .d.ts, with zero node_modules on disk. Validate by running the CLI through the PnP loader to consume the workspace library and by proving two builds are byte-for-byte identical when SOURCE_DATE_EPOCH is fixed.', NULL, ARRAY['typescript']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'JavaScript & Frontend Builds', 'Migrate a legacy CommonJS React app to an ESM-based toolchain using Vite and TypeScript, resolving peer dependency/version conflicts and tsconfig path aliasing so the project compiles and runs. Produce an optimized, code-split production build with hashed filenames and verify that tree-shaking removed a specified debug utility from the final bundles.', NULL, ARRAY['typescript']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Python Builds & Packaging', 'Package a Python project containing a C extension into a manylinux2014 wheel using PEP 517 (pyproject.toml with setuptools), statically linking its vendored C library and repairing the artifact with auditwheel to be self-contained. Build sdist and wheel to dist/, then install from those artifacts in a fresh virtualenv and verify both module import and a console_script entry point’s expected output.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Python Builds & Packaging', 'Refactor a Cython-based Python project to a PEP 517 build with setuptools, ensuring generated C sources are included in the sdist so pip install from the sdist works without Cython present. Build reproducible sdist and wheel (respecting SOURCE_DATE_EPOCH), then verify in a clean virtualenv by installing only from the sdist and running the provided import/CLI smoke tests.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Rust/Go/Other Modern Toolchains', 'Convert a Rust workspace to build fully offline by vendoring all dependencies and configuring Cargo source replacement, pinning a git-sourced crate via [patch.crates-io] to a specific commit to resolve a version conflict. Build for both the host target and wasm32-wasi, run native tests, and produce reproducible artifacts with a locked Cargo.lock.', NULL, ARRAY['rust', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Rust/Go/Other Modern Toolchains', 'Create a reproducible offline build for a Rust workspace by using cargo vendor and [patch.crates-io] to pin a dependency to a specific git revision, then compile the project for both x86_64-unknown-linux-gnu and wasm32-unknown-unknown using wasm-bindgen with TypeScript bindings emitted to fixed output paths. Validate by running native cargo tests and a Node.js script that loads the generated WebAssembly to confirm an exported function returns the expected value.', NULL, ARRAY['rust', 'git', 'typescript']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Rust/Go/Other Modern Toolchains', 'Refactor a provided multi-crate Rust project into a Cargo workspace, vendor all dependencies with cargo vendor, and configure .cargo/config.toml so the project builds fully offline. Cross-compile a static x86_64-unknown-linux-musl release binary with feature "cli" (default-features=false) and verify by running cargo test --workspace and executing the binary to emit a deterministic SHA256.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Rust/Go/Other Modern Toolchains', 'Vendor all Cargo dependencies for the provided Rust CLI, switch TLS features from OpenSSL to rustls, and cross-compile a fully static x86_64-unknown-linux-musl binary in strict offline mode. Validate by proving no network access during build, ldd reports it is not a dynamic executable, and repeated builds with the same SOURCE_DATE_EPOCH produce identical SHA256 sums.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Language & Ecosystem-Specific Build Management', 'Rust/Go/Other Modern Toolchains', 'Vendor all crates for a multi-crate Rust workspace and configure Cargo for a fully offline build using a provided local registry mirror; resolve a feature-induced dependency graph conflict without adding or removing crates, then cross-compile the workspace for x86_64-unknown-linux-gnu and wasm32-wasi. Run tests for the native target, execute the WASI binary with wasmtime to verify expected stdout, and write artifact sizes and resolved crate versions to /app/build-metadata.json.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Branch-Based Build Rules', 'Create a Git-aware build pipeline for a small CMake project where branch names control behavior: main builds produce a reproducible, stripped, LTO-enabled tarball with SBOM and version from the latest tag; release/* builds append -rcN; feature/* builds are debug, include an experimental module, and are blocked from publish. Validate by switching branches/tags to confirm artifact names, embedded --version/--info metadata, and that publish is refused on feature/*.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Branch-Based Build Rules', 'Create a Git-backed project whose Makefile/build script alters outputs by branch/tag: main and tags v* produce stripped, versioned release tarballs; staging builds include debug symbols and a visible STAGING banner; feature/* builds emit -SNAPSHOT artifacts and block the release target. Enforce these rules via branch-aware build logic and lightweight Git hooks/CI entrypoints, with tests that checkout branches/tags and verify artifact names, flags, and refusal behavior.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Branch-Based Build Rules', 'Create a branch-aware build script for a small Go CLI that enforces different behaviors per branch: main builds are stripped and versioned from the latest tag, feature/* builds enable -race and debug info with a -canary+<shortSHA> suffix, and release/* builds require a matching CHANGELOG entry and emit both a SHA256SUMS file and a CycloneDX SBOM. Validate by creating and checking out branches and running the script to produce and verify the expected artifacts and metadata.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Branch-Based Build Rules', 'Implement a Git-aware Makefile for a Rust CLI that enforces branch-specific builds: main produces a stripped LTO release with version from the latest tag and a sha256 checksums.txt; staging enables a telemetry-staging feature and adds an -rc suffix; feature/* appends +branch.sha and writes to /app/dist/feature, while release/* fails if Cargo.toml version doesn’t match the tag. The harness will check out different branches and verify artifact names, --version output, and the presence of checksums only on main.', NULL, ARRAY['git', 'rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Branch-Based Build Rules', 'Implement a Git-aware build script that enforces branch-specific rules: feature/* runs tests only and emits a -SNAPSHOT artifact, staging builds produce debug binaries with embedded staging config, and main requires an annotated tag to create a stripped release tarball with semver from the tag and a SHA256 checksum in /app/dist. Validate by creating branches and tags and showing the correct artifacts and version strings are generated for each branch.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Signed & Verified Builds', 'Create an offline release pipeline that signs a Git tag for a provided source tree, builds a normalized tar.gz and binary, and generates SHA256SUMS along with both GPG (.asc) and minisign signatures for the artifacts. Provide a verify.sh that validates the tag signature against a supplied public key, checks checksums and signatures, and confirms the binary’s embedded commit hash matches the signed tag.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Signed & Verified Builds', 'Implement a release pipeline that signs the vX.Y.Z Git tag and a SHA256SUMS file with GPG, builds a binary embedding git describe/commit hash, and provides verify.sh to validate the tag signature, the embedded version against the tag, the checksum signature, and the artifact hashes. The task must detect and fail on any tampering with either artifacts or checksums.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Signed & Verified Builds', 'Implement a release workflow for a small Rust CLI where an annotated, signed Git tag triggers building a deterministic static binary, packaging it into a tar.gz, generating SHA256SUMS, and creating detached GPG signatures for both the tag and checksum file in a temporary GNUPGHOME. Provide a verify-release.sh that, from a clean clone, validates the tag signature, checksums, and that the binary prints the tagged version; the release must fail if HEAD is not a signed tag or any verification step fails.', NULL, ARRAY['rust', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Signed & Verified Builds', 'Implement a release workflow that only builds from an annotated, GPG-signed git tag: produce a deterministic git-archive tar.gz, compute SHA256SUMS, and create detached ASCII-armored signatures for both the tarball and the checksum file using a provided maintainer key. Import only the supplied public key to verify the tag signature and both artifact signatures; emit to /app/dist only if all verifications succeed and the archive reproduces bit-for-bit under a fixed SOURCE_DATE_EPOCH.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Signed & Verified Builds', 'Implement an offline release workflow that builds a Go project at a signed git tag, produces a deterministic tar.gz of the binary, emits SHA256SUMS, and creates detached GPG signatures for the tag, the tarball, and the checksum file. Provide a verification script that imports the public key, verifies the tag and artifact signatures, validates the checksums, and checks an in-toto provenance attestation proving the tarball was produced from the tagged commit with the specified build command.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Version Tagging & Release Automation', 'Create a POSIX shell release script that parses Conventional Commits since the last tag to compute the next semantic version, updates a version file, generates/updates CHANGELOG.md, creates an annotated git tag, and pushes tags to a provided local bare remote. Validate by running the script twice on a seeded repo to produce v1.1.0 then v1.1.1 and confirm the tags, changelog sections, and versioned build artifact output match the computed versions.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Version Tagging & Release Automation', 'Create a portable release script that parses Conventional Commits since the last git tag to compute the next semver (major/minor/patch), updates a VERSION file and CHANGELOG.md, then creates an annotated tag (vX.Y.Z). On success, build the project to dist/, archive it as project-vX.Y.Z.tar.gz with SHA256SUMS, and refuse to run on a dirty tree while verifying the changelog covers exactly the tagged commit range.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Version Tagging & Release Automation', 'Implement a release pipeline for a two-package monorepo (Python lib at libs/pycalc and Go CLI at apps/gocalc) that reads Conventional Commits since each package’s last namespaced tag to compute the next semantic version per package. Update pyproject.toml/go.mod, generate a combined CHANGELOG.md with per-package sections, create annotated tags pycalc-vX.Y.Z and gocalc-vA.B.C only for changed packages, and place built artifacts plus SHA256 checksums in dist/.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Version Tagging & Release Automation', 'Implement a repo-local release automation that, using Conventional Commits, calculates the next semantic version since the last git tag, updates version fields in both package.json and pyproject.toml, regenerates CHANGELOG.md, creates an annotated tag, and produces tarball artifacts with a SHA256SUMS file. Validate by seeding example commits, invoking the release script twice, and asserting that tags, changelog sections, and checksums match expected outputs.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Release Engineering & Version Control Integration', 'Version Tagging & Release Automation', 'In a Git monorepo with a Rust workspace of multiple crates, implement a release script that parses Conventional Commits since the last per‑crate tag, bumps versions in Cargo.toml/Cargo.lock with dependency propagation, writes per‑crate and aggregate changelogs, and creates annotated tags (v{crate}-{version}) plus a workspace tag. The run must support dry‑run vs apply, handle prerelease channels (e.g., -beta) and BREAKING CHANGE semantics, be idempotent on a second run, and leave the workspace building successfully at the new versions.', NULL, ARRAY['git', 'rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Artifact Generation & Packaging', 'Build the provided C++ library into both a versioned shared object (with correct SONAME symlinks) and a static archive, and generate pkg-config and CMake package config files while staging headers and licenses under a prefix. Package the staged tree into a relocatable tar.gz release and verify by compiling a tiny consumer that locates the library via pkg-config and find_package.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Artifact Generation & Packaging', 'Configure a CMake project and use CPack to produce both .deb and .rpm packages for a small C/C++ CLI, including /usr/bin binary, a man(1) page, bash completion, and a separate -dbg package with split debug symbols. Validate package metadata (version from git tag), ownership/permissions, dependencies, and contents via dpkg-deb and rpm queries, and by extracting to a temporary root to confirm correct install paths.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Artifact Generation & Packaging', 'Convert the provided Java library into an OSGi-compliant bundle and produce reproducible release artifacts: the main .jar with correct Bundle-* MANIFEST headers plus -sources.jar and -javadoc.jar. Publish them to a local Maven repository and verify a sample consumer project resolves the bundle and that bnd/osgi-info validates the metadata.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Artifact Generation & Packaging', 'Develop a small C library using CMake with correct SONAME/versioned symlinks and a pkg-config .pc file, then produce release artifacts: a tar.gz containing headers and the shared library and distribution packages (.deb and .rpm) splitting runtime and -dev contents. Validate by building and running a tiny consumer program that uses pkg-config to link against the installed package and confirms the correct SONAME is loaded at runtime.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Artifact Generation & Packaging', 'Package a small C library built with CMake into two Debian packages: a versioned runtime shared library with correct SONAME (e.g., libfoo2) and a -dev package containing headers and a pkg-config file, using debhelper and dpkg-buildpackage. Install the .debs and verify by compiling and running a tiny consumer that links via pkg-config against the installed library.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Build System Configuration', 'Configure a CMake superbuild that fetches and builds pinned zlib and libpng from source via FetchContent/ExternalProject, then builds a small C/C++ image utility that links to them. Install targets with an exported CMake package (MyImgToolConfig.cmake), verify find_package works from a separate minimal project, and run the utility on a provided PNG sample.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Build System Configuration', 'Configure a CMake-based build for /app/engine using Ninja, CMakePresets.json, and a cross-compiling toolchain file to produce both native (x86_64) and ARMv7 binaries with an ENABLE_SIMD option that toggles sources and compile definitions. The workflow must emit compile_commands.json, run ctest, and generate relocatable cpack TGZ packages for each configuration, verifying the ARM artifact is an ARM ELF and the native build links against system zlib via find_package(ZLIB).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Build System Configuration', 'Configure a CMake/Ninja project to run a two-stage Profile-Guided Optimization workflow: first build instrumented binaries and execute a provided training script to generate profiles, then rebuild using those profiles to emit an optimized executable at a fixed path. Verify that the profile was consumed (via build logs/artifacts) and that the optimized binary demonstrates a measurable runtime improvement over a baseline build.', NULL, ARRAY['optimization']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Build System Configuration', 'Create a CMake superbuild using ExternalProject_Add to compile vendored zlib and libpng from local tarballs with Ninja, then build a top-level C++ library and CLI that link them and install to /opt/app with correct RPATH. Emit pkg-config and CMake export targets, and verify by running the CLI to convert a provided PNG into a raw byte dump without network access.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Build System Configuration', 'Replace the project''s Autotools build with Meson + Ninja, adding a subproject wrap for a missing dependency, installing headers, and generating a pkg-config file, and then add a Meson cross file to support armv7hf cross-compilation with hard-float. Verify by building native and cross variants, running the native tests, and using qemu-arm to execute a sample program linked against the cross-built shared library while pkg-config resolves the correct paths.', 'hard', ARRAY['compilation']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Cross-Compilation & Multi-Platform Builds', 'Cross-compile a CGO-based Go CLI that embeds SQLite into static binaries for linux/amd64, linux/arm64, linux/riscv64, and windows/amd64 using zig as the cross C compiler/linker. Verify by running the riscv64 binary under qemu-user to execute a SQL query and confirming the Windows PE binary via wine or PE header inspection outputs the exact expected result.', NULL, ARRAY['sql']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Cross-Compilation & Multi-Platform Builds', 'Cross-compile a provided C/C++ utility into static aarch64 and riscv64 Linux binaries using a musl-based toolchain (e.g., Zig as cc). Validate by running both under qemu-user to process the same input and write matching SHA256 output hashes to a verification file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Cross-Compilation & Multi-Platform Builds', 'Cross-compile a provided Rust CLI into x86_64-unknown-linux-musl and aarch64-unknown-linux-musl static binaries plus an x86_64-pc-windows-gnu .exe using cargo with the appropriate cross-linkers. Verify outputs by running the native binary directly, the aarch64 binary under qemu-aarch64, and the Windows .exe under wine, asserting exact stdout including the embedded target triplet in --version.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Cross-Compilation & Multi-Platform Builds', 'Cross-compile the provided CMake-based CLI to produce three artifacts: x86_64-linux-musl (fully static), aarch64-linux-gnu, and x86_64-w64-mingw32. Verify correctness by inspecting ELF/PE headers and running the ARM64 build under qemu-aarch64 and the Windows build under wine, ensuring the musl binary has no glibc dependency and all builds honor a fixed SOURCE_DATE_EPOCH.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Cross-Compilation & Multi-Platform Builds', 'Cross-compile the ripgrep Rust project into statically-linked binaries for x86_64-unknown-linux-musl and aarch64-unknown-linux-musl from an x86_64 host, packaging each artifact with a LICENSE file and SHA256 checksum. Validate the ARM64 build by executing it under qemu-aarch64 on a provided test corpus and verifying the expected grep results.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Manual Compilation', 'Implement and manually compile a Java+JNI demo: generate headers with javac -h, compile the C code into libnativeops.so using gcc -fPIC -shared with the correct JDK include paths, and compile the Java class. Verify by running the Java harness with -Djava.library.path to confirm correct native results and by inspecting exported JNI symbols with nm/objdump.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Manual Compilation', 'Manually compile a C shared library and a Java program that calls it via JNI using only javac/java and gcc/clang, correctly setting include paths, -fPIC/-shared, and runtime library paths (java.library.path or LD_LIBRARY_PATH). Execute the Java program to verify the native method loads and returns an exact computed result.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Manual Compilation', 'Manually compile a modular Java application using javac, then assemble a minimized custom runtime image with jlink that runs the app without relying on a system JRE. Validate the image by launching the program and confirming only required modules are included with debug symbols and locales stripped.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Manual Compilation', 'Manually compile a small Java project into a multi‑release executable JAR: build base classes with javac --release 8, compile alternate implementations for Java 11 into META-INF/versions/11, and assemble with a manifest declaring Multi-Release: true and Main-Class using only javac and jar. Verify by running the JAR to see Java‑11‑specific behavior and by listing the archive to confirm versioned entries.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Build & Dependency Management', 'Source Compilation & Build Systems', 'Manual Compilation', 'Perform a two-phase profile-guided optimization build of the C program in /app/pgotask: first compile with -fprofile-generate and run it over the input corpus in /app/corpus to emit profiles, then recompile with -fprofile-use to produce /app/bin/app_pgo. Verify by timing both pre- and post-PGO binaries on the same workload and writing the speedup and file sizes to /app/pgo_report.txt.', NULL, ARRAY['optimization']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'ETL (Extract-Transform-Load) Workflows', 'Build a pipeline that scans /app/logs for mixed-format Apache/Nginx logs (plain, .gz, .bz2, .zst), parses into a normalized schema, enriches with country and ASN via provided lookup CSVs, applies prefix-preserving IP anonymization, and outputs a SQLite database plus per-day aggregates (CSV and Parquet).', NULL, ARRAY['database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'ETL (Extract-Transform-Load) Workflows', 'Create a script that ingests a mixed drop folder of .csv.gz, newline-delimited .json, and .xlsx transaction files, normalizes columns and timestamps to UTC, converts currencies using /app/rates.toml, and de-identifies emails by hashing with a SALT env var. Load the cleaned data into a SQLite database with indexes and emit per-day partitioned CSVs under /app/out plus a manifest.json of row counts and SHA256 checksums.', NULL, ARRAY['database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'ETL (Extract-Transform-Load) Workflows', 'Create a script that ingests mixed Apache/Nginx logs under /app/logs, normalizes timestamps to UTC, de-duplicates requests, and stitches events into user sessions using IP+User-Agent with a 30-minute inactivity threshold. Load results into /app/sessions.db (SQLite) with sessions and events tables, and write /app/landing_pages.csv listing the top 10 landing pages with session counts and bounce rate.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'ETL (Extract-Transform-Load) Workflows', 'Create a script that ingests mixed-format web server access logs from /app/logs (plain .log, .gz, .bz2 in Common/Combined Log Format), parses and normalizes timestamps to ISO-8601 UTC, enriches with country via /app/GeoLite2-Country.mmdb, and de-duplicates by (ip, timestamp, request). Write partitioned, snappy-compressed Parquet files with a fixed schema to /app/out/year=YYYY/month=MM/day=DD.', NULL, ARRAY['web']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'ETL (Extract-Transform-Load) Workflows', 'Implement an idempotent incremental ETL that extracts customer transactions from CSV files in /app/inbox/, newline-delimited JSON in /app/stream/, and a local mock REST endpoint, normalizes timestamps/timezones and converts currencies to USD using a provided FX rates file, and de-duplicates near-duplicates. Load results into a SQLite star schema, persist a checkpoint so only new or changed data is processed on re-run, and write a data-quality report of nulls, duplicate keys, and outliers to /app/reports/.', NULL, ARRAY['rest']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Pipeline Orchestration', 'Build a Makefile-driven ETL that ingests JSONL.gz logs from /app/raw, validates/normalizes them, partitions to date-based Parquet, aggregates per-endpoint metrics, and emits a CSV plus HTML report. The DAG must be incrementally rebuildable using checksum stamps so only affected partitions and downstream artifacts are recomputed, with targets for full run, incremental update, and clean.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Pipeline Orchestration', 'Create a Makefile-driven ETL that reads a manifest of resources (URL, filename, sha256), downloads and verifies them, normalizes mixed CSV/TSV/JSONL into a common JSONL schema, merges/deduplicates by timestamp, and outputs final.jsonl plus a machine-readable provenance report. The workflow must use stamp files and checksum-based invalidation so reruns are no-ops when inputs are unchanged, and touching any single source triggers only the necessary downstream steps.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Pipeline Orchestration', 'Create a Makefile-driven ETL that verifies and decompresses /app/logs/*.log.gz, normalizes records to JSONL, partitions by day, and generates daily summaries plus a SHA256 manifest of inputs/outputs. The DAG must be idempotent and incremental (reruns only when dependencies change) and provide targets all, day-YYYYMMDD, and clean.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Pipeline Orchestration', 'Create a tiny DAG runner that reads /app/dag.yaml and executes a 5-stage local ETL (extract, normalize, dedupe, aggregate, report) with dependency-aware incremental rebuilds using content hashes, per-task timeouts/retries, max-parallelism, and a dry-run mode. The harness mutates a single source file and expects only downstream nodes to re-run, emitting updated outputs plus a provenance log and a DOT graph of the executed sub-DAG.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Pipeline Orchestration', 'Implement a lightweight DAG runner that reads /app/pipeline.yml (tasks with command, inputs, outputs, and depends) and executes them in topological order with a max concurrency of 2, skipping tasks whose outputs are up-to-date and retrying failures once. Write an execution log to /app/run.log and concatenate the outputs of all leaf tasks into /app/build/summary.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Python/Perl/Ruby Scripting', 'Implement a Python CLI that reads /app/pipeline.yaml to run a small DAG-based ETL over mixed CSV/JSON/TSV in /app/data: normalize schemas and timestamps to UTC, join with /app/exchange_rates.json to convert currencies to USD, and write a partitioned Parquet dataset to /app/warehouse plus a Markdown summary report. The runner must compute content hashes to skip unchanged steps, execute dependencies in parallel, and emit a reproducibility manifest of inputs/outputs at /app/manifest.json.', NULL, ARRAY['python', 'parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Python/Perl/Ruby Scripting', 'Implement a Python tool that scans /app/config for JSON, YAML, TOML, and INI files, expands ${ENV_VAR:-default} and ${config.some.path} references with type-aware coercions (e.g., durations like 5m, sizes like 1.5GB), merges them by a specified priority, and validates against /app/schema.json (JSON Schema). Output a normalized config.json and a resolution_report.json detailing per-key source precedence, coercions, defaults applied, and any unresolved references.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Python/Perl/Ruby Scripting', 'Write a Python script that reads a workflow YAML at /app/workflow.yaml defining tasks (id, command, deps, env, max_retries, timeout), executes the DAG in dependency order with retries/timeouts, and captures per-task stdout/stderr to /app/logs/<id>.log. Output /app/report.json summarizing each task’s status (success/failed/skipped), attempt count, start/end timestamps, exit code, and a topologically sorted execution list.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Shell Scripting & CLI Automation', 'Create two Bash scripts: backup.sh performs idempotent, incremental backups of /app/data into date-stamped snapshots using rsync --link-dest with per-snapshot SHA256 manifests and a flock-based lock; prune.sh enforces a configurable GFS retention policy, verifies snapshot integrity before deletion, and writes a JSON report of kept/removed snapshots and verification results.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Shell Scripting & CLI Automation', 'Write a Bash script that organizes media files from /app/photos into a date-based library at /app/library/YYYY/MM/DD by reading capture timestamps from EXIF/QuickTime metadata (fall back to file mtime), renames files to timestamp_shortsha.ext, and de-duplicates exact content by SHA-256. Produce /app/manifest.csv with header original_path,new_path,taken_at,sha256,mime and make the workflow idempotent so re-running makes no changes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Task Scheduling & Cron Jobs', 'Create two cron jobs: one runs every 10 minutes to promote ''stable'' CSVs from /app/incoming to /app/staging (unchanged for ≥90s), the other runs at 00:05 UTC to consolidate all staged CSVs into a deduplicated, timestamp-sorted daily report at /app/reports/YYYY-MM-DD.csv.gz. Use flock to prevent overlaps, write last-run metadata as JSON to /app/status.json, and provide a one-shot script to trigger both jobs immediately for verification.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Task Scheduling & Cron Jobs', 'Set up a cron-orchestrated ETL with three scripts: every 2 minutes ingest and idempotently upsert JSON files from /app/inbox into SQLite, hourly export a rolling 24h metrics CSV to /app/out/report.csv and prune old rows, and daily rotate/compress processed inputs to /app/archive. Enforce flock-based locking, CRON_TZ=UTC, and a catch-up mechanism that detects downtime and replays missed windows.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Automation & Workflow Scripting', 'Task Scheduling & Cron Jobs', 'Write a backup script that snapshots /app/db.sqlite to /app/backups as timestamped compressed files, retaining the last 7 daily and last 4 Sunday weekly backups. Install a cron.d entry to run it at 02:17 UTC daily with flock-based locking and append-only logging to /app/backup.log.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Aggregation & Reduction', 'Build a script that ingests mixed-format web access logs (CSV and JSONL), normalizes them to a single schema, sessionizes requests per client with a 30-minute inactivity timeout, and computes per-session aggregates (request count, duration, total bytes). Output a compact session table and a brief text summary with top landing paths and percentile session lengths.', NULL, ARRAY['web']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Aggregation & Reduction', 'Create a command-line script that scans /app/logs for web access logs (plain or .gz), normalizes URLs by collapsing numeric IDs/UUIDs to placeholders, and aggregates per-normalized-endpoint metrics (request count, total bytes, median/p95/p99 latency, and 5xx error rate) for a specified UTC day. Output a 2-space-indented JSON array sorted by descending request count to /app/endpoint_metrics.json.', NULL, ARRAY['web']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Aggregation & Reduction', 'Create a script that ingests a directory of mixed-format telemetry files (CSV and JSONL) with heterogeneous timestamp formats, normalizes them to UTC minute buckets, and deduplicates events by (device_id, metric, ts). Aggregate per device and metric to produce hourly stats (count, mean, median, p95, min, max) and write aggregates.parquet plus a concise anomalies.csv listing hours with data coverage <80%.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Aggregation & Reduction', 'Create a script that reads /app/points.parquet of GPS pings, converts timestamps to UTC and rounds to 15-minute buckets, and bins lat/lon into 7-character geohashes. Remove per-cell daily outliers using median absolute deviation and write /app/aggregates.csv with rows (bucket_start, geohash7, count, distinct_src, mean_value, min_value, max_value) sorted by bucket then geohash.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Aggregation & Reduction', 'Create a terminal pipeline that scans /app/logs for web-event files in CSV, JSONL, and .jsonl.gz, normalizes fields (utc_ts, user_id, url, status, bytes), and computes 5-minute rollups with totals, distinct users, bytes p50/p95/p99, and the top-3 URLs by count. Write /app/rollup.parquet and /app/top_urls.csv, and support an incremental mode that updates only new windows using /app/watermark.txt.', NULL, ARRAY['web']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Data Merging & Joins', 'Create a script that merges a product catalog CSV (product_id, sku, upc), a price events NDJSON (sku, price, timestamp), and a UPC alias TSV by normalizing UPCs and resolving aliases to canonical IDs, then joining on sku/upc. Output a consolidated CSV per product_id with latest price and count of price events, plus an unmatched.csv listing any price events that could not be linked.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Data Merging & Joins', 'Create a script that merges an Apache access_log (CLF/combined) and an application event stream (JSON Lines) into a single CSV by first joining on a shared request_id when available; if absent, fall back to the nearest timestamp within ±2 seconds for the same client IP and URL path, and mark which join strategy was used. Output must contain one row per web request with selected fields from both sources and unmatched records discarded.', NULL, ARRAY['web']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Data Merging & Joins', 'Create a script that merges three datasets—orders.csv, refunds.csv, and chargebacks.jsonl—into a single per-order report by joining on order_id (exact) and de-duping conflicting events by the latest event_timestamp. Compute each order’s final_status (Pending/Fulfilled/Refunded/Chargeback) and net_amount, and write a sorted CSV with a fixed header.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Data Merging & Joins', 'Create a script that performs a temporal as-of join across three datasets—ad impressions (CSV), clicks (JSONL), and conversions (Parquet)—to attribute each conversion to the most recent prior click (≤7 days) and impression (≤24 hours before the click) for the same user_id with deterministic tie-breaking. Write a unified Parquet with attribution fields and a JSON report listing conversions with ambiguous or missing joins.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Data Merging & Joins', 'Join network event logs with IP ownership datasets by performing longest-prefix-match containment over IPv4/IPv6 CIDR ranges, resolving overlaps via most-specific prefix and source priority. Produce an enriched events output annotated with org/asn and a summary report of per-org counts and unmatched coverage.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Filtering & Selection', 'Create a command-line script that streams a gzip-compressed NDJSON file at /app/events.ndjson.gz, selecting only records within a given UTC time window whose URL host appears in /app/allowlist.txt while enforcing a per-user cap K (discarding excess events per user in-window). Output the retained events as a stable-order, 2-space-indented JSON array to /app/filtered.json, preserving original key order.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Filtering & Selection', 'Create a streaming CLI that scans /app/events for newline-delimited JSON files (.jsonl, .jsonl.gz, .jsonl.zst), filters records by a UTC time window, a regex on event_type, and an email-domain whitelist from /app/allowed_domains.txt, and outputs filtered.jsonl with only selected fields in input order. Also write rejected.jsonl logging each discarded record’s id and machine-readable reason, ensuring constant-memory processing without loading entire files.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Filtering & Selection', 'Implement a command-line tool that reads one or more COCO-format annotation JSONs in /app/dataset and filters annotations to categories listed in /app/categories.txt while enforcing bbox area and score thresholds from /app/filter.yaml, dropping any now-orphaned images. Output a pruned COCO JSON with deterministically ordered, remapped contiguous ids and a newline manifest of kept image file paths.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Filtering & Selection', 'Write a script that scans /app/logs for Apache/Nginx access logs (plain text and .gz), filters entries whose client IP falls within any CIDR in /app/eu_cidrs.txt, whose request path matches any pattern in /app/paths.txt, and whose status is 2xx. Output /app/filtered.csv with ISO8601 timestamp, ip, method, and path, deduplicated per ip+path within rolling 10‑minute windows.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Normalization & Standardization', 'Build a CLI that scans /app/datasets for CSV/TSV and JSONL files with mixed encodings, delimiters, header spellings, and timestamp/number formats; auto-detects encoding and delimiter, canonicalizes Unicode (NFKC), maps header synonyms to a target schema (user_id, event, ts_utc, amount), and standardizes timestamps to ISO 8601 UTC and numbers to dot-decimal, writing RFC4180 UTF-8 CSVs to /app/normalized. Emit /app/audit.json summarizing per-file detection results, header mappings, and counts of fixed/dropped rows with a small before/after sample of transformed values.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Normalization & Standardization', 'Create a script that ingests a mixed-format coordinate dataset (DMS strings, decimal degrees with hemisphere letters, and UTM zones) and normalizes all positions to WGS84 latitude/longitude in signed decimal degrees with fixed precision. Validate ranges, correct common notations (e.g., stray hemisphere suffixes), and emit a clean, standardized output with a report of any unresolvable rows.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Normalization & Standardization', 'Create a script that ingests mixed CSV/JSON sensor datasets from /app/data where numeric values include heterogeneous units and localized formats (e.g., 72F, 21.1 °C, 55 mph, 24,6 m/s, 1 234.5). Normalize all measurements to SI units with canonical float types and ISO 8601 UTC timestamps, then emit a unified standardized Parquet and a normalization report summarizing per-field conversions, unit assumptions, and any imputations or drops.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Normalization & Standardization', 'Create a script that scans /app/data for CSV/TSV/JSON product records and outputs /app/normalized.csv with sku, weight_g, length_mm, width_mm, height_mm, price_usd, and updated_at (UTC ISO-8601). It must normalize unit‑labeled values (g/kg/lb/oz; mm/cm/in/ft), localized numbers (commas, spaces), and currencies (using /app/rates.json), converting all timestamps to UTC and writing irrecoverable rows with reasons to /app/errors.csv.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Normalization & Standardization', 'Create a script that scans /app/logs for mixed-format logs (Apache, syslog, JSON), normalizes all timestamps (including timezone and epoch forms) to ISO 8601 UTC (Z) and standardizes severity to a fixed set [DEBUG, INFO, WARN, ERROR, FATAL] while lowercasing hostnames. Emit a single JSON Lines file at /app/normalized_logs.jsonl with a consistent schema and entries sorted strictly by timestamp.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Outlier & Error Detection', 'Create a command-line script that ingests time-series CSV files in /app/sensors, normalizes ISO-8601 timestamps, and detects per-sensor outliers using median absolute deviation plus sanity checks (negative values where forbidden, duplicated timestamps, and sudden step changes). Output cleaned CSVs to /app/cleaned, append all flagged rows with reason codes to /app/anomalies.csv, and write a per-file summary to /app/report.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Outlier & Error Detection', 'Create a script that ingests /app/readings.csv of IoT telemetry and writes /app/clean.csv plus /app/anomalies.csv, flagging schema/plausibility errors (invalid UTF-8, column count, status not in {OK,WARN,FAIL}, out-of-range temp/humidity/battery, duplicate device_id+timestamp, and non-monotonic timestamps per device). Additionally, mark statistical outliers in temperature per device using a 1-hour rolling median with MAD-based thresholds and annotate anomalies with semicolon-separated reason codes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Outlier & Error Detection', 'Create a script that ingests GPX/CSV GPS tracks, normalizes timestamps and coordinate formats, and flags/removes points that imply impossible speeds, large teleports, or non-monotonic time. Output cleaned tracks and an anomalies report summarizing each file’s discarded points and reasons.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Outlier & Error Detection', 'Create a script that ingests heterogeneous service logs from /app/logs (Apache/Nginx, JSONL app logs, and syslog), normalizes timestamps to UTC, correlates entries by request_id when present, and flags anomalies including unparsable lines, clock-skew/causal-order violations, negative durations, and latency outliers via median absolute deviation. Output a CSV of anomalies with standardized fields and a cleaned, time-ordered normalized JSONL stream for downstream use.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Cleaning & Transformation', 'Outlier & Error Detection', 'Write a script that scans /app/trips/*.csv (columns: trip_id, device_id, timestamp, lat, lon, odometer_km) to detect geospatial and temporal anomalies such as impossible speeds via haversine distance/time, out-of-bounds coordinates, non-monotonic timestamps per device, duplicate trip_ids, and odometer regressions. Output anomalies.jsonl with one record per issue (including a machine-readable reason and fields) and cleaned_trips.parquet with all offending rows removed.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Descriptive Statistics & Summaries', 'Build a CLI tool that scans /app/data for CSV, JSONL, or Parquet files and writes profile.json containing per-column summaries (type, non-null count, distinct≈HLL, min/max, mean, median, std, p5/p25/p50/p75/p95) and fixed-bin histograms for numeric fields; if a timestamp column exists, also output hourly counts. Emit a stratified 1% sample that preserves rare categories to /app/sample.ndjson.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Descriptive Statistics & Summaries', 'Create a CLI that streams over all .jsonl and .jsonl.gz files in /app/events, filters by a UTC date range, and computes overall and per-endpoint latency summaries: count, distinct_user_ids, mean, median, std, p90, p99, and error_rate. Output a 2-space-indented JSON report to /app/latency_summary.json, sorted by descending count and excluding non-numeric or missing latencies from calculations.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Descriptive Statistics & Summaries', 'Create a streaming profiler that scans all CSV and JSONL (including .gz) files under /app/data and produces per-column summaries: non-null count, distinct count (case-insensitive), min, max, mean, median, and p95 for numeric fields, and top 5 categories with frequencies for non-numeric fields. Write a consolidated report to /app/profile.csv and a machine-readable /app/profile.json, handling mixed schemas across files and locale-formatted numbers (commas and decimals).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Descriptive Statistics & Summaries', 'Implement a streaming profiler for /app/data.csv (optionally gzipped) that infers column types from a sample and then computes per-column summaries without loading the entire file: numeric -> count, nulls, mean, std, min, max, median, p95 (approx via P^2), categorical -> count, nulls, distinct count, top-3 modes with counts. Write a single JSON report to /app/profile.json containing total rows, file size, and a per-column section with the computed statistics.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Descriptive Statistics & Summaries', 'Implement a streaming profiler that scans /app/data for CSV/TSV/JSONL files (optionally .gz) and writes profile.json with per-column stats: total rows, non-null count, min/max, mean, std, quartiles/median, top-3 frequent values, and distinct counts (exact below a threshold, HyperLogLog otherwise). For timestamp columns also emit rolls.csv with per-hour counts and, if a user_id column exists, approximate hourly unique users.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Sampling & Subsetting', 'Build a CLI that reads arbitrarily large, multi-file clickstream data (CSV and JSONL) and emits a fixed-size, user-level stratified reservoir sample that preserves the hourly traffic curve and the joint distribution of country×device within ±5% of the original. The tool must stream in one pass, be seed-reproducible, and write the selected records and a manifest to /app/sample/.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Sampling & Subsetting', 'Create a CLI script that, given customers.csv, orders.csv, and order_items.csv, produces a reproducible 1% per-month stratified sample of orders via deterministic hashing, then emits subsetted CSVs for all three tables that include only rows linked to sampled orders while preserving referential integrity and original column order. Additionally, write a summary manifest reporting per-month sample rates and total rows kept per table.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Sampling & Subsetting', 'Create a reproducible, referentially consistent subset of a two-table dataset by selecting a 1% hash-based sample of users (seeded) from /app/data/users.parquet and including all their related events from /app/data/events/*.parquet within an optional --since time window. Output sampled users and events Parquet files plus a summary verifying that the users’ country distribution deviates by no more than ±1% from the full dataset, and a manifest listing sampled user_ids.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Sampling & Subsetting', 'Create a script that builds a deterministic, stratified sample of a normalized CSV dataset in /app/data (e.g., users, orders, order_items, events) by selecting users proportionally across country and signup cohort using a seed from /app/seed.txt and including only their related rows. Output referentially complete subset CSVs to /app/sample and a manifest with per-stratum counts and basic distribution checks.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Sampling & Subsetting', 'Create a script that reads a large time-series CSV at /app/timeseries.csv (columns: series_id,timestamp,value) and produces a representative subset at /app/timeseries_sample.csv by applying Largest-Triangle-Three-Buckets (LTTB) downsampling to keep at most 2,000 points per series while preserving chronological order and the original header. Also emit /app/summary.json with the algorithm parameters, per-series retained counts, and a SHA256 of the sample for reproducibility.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Visualization & Reporting (CLI-based)', 'Create a CLI that profiles missing-data patterns in a large CSV/JSONL via streaming with reservoir sampling, then renders an ASCII heatmap (rows=sampled records, columns=fields) using dense/light characters for present vs missing alongside per-field summaries. Write a human-readable report to /app/report.txt including missingness rates, longest present/missing streaks, and the top co-missing field pairs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Visualization & Reporting (CLI-based)', 'Create a command-line script that reads /app/events.ndjson of user event logs, computes a five-step conversion funnel (visit → view → add_to_cart → checkout → purchase) with counts and stage-to-stage rates per day and overall. Output a human-readable ASCII report to /app/funnel_report.txt including a monospaced funnel chart, a histogram of daily purchases, and annotations flagging anomalous days using a 3-sigma rule.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Visualization & Reporting (CLI-based)', 'Implement a script that reads /app/events.csv with timestamps and categories, performs stratified reservoir sampling to bound memory, and generates an ASCII calendar heatmap of daily activity for the last month plus a per-category horizontal bar chart of counts. Write a single human-readable report to /app/report.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Sampling & Exploration', 'Visualization & Reporting (CLI-based)', 'Write a script that profiles a mixed dataset directory (CSV, JSONL, Parquet), performs deterministic sampling, infers column types, and generates a single CLI report with ASCII histograms for numeric columns, a character-based missingness heatmap by column, and top-k value tables for categoricals. Output the human-readable report to /app/profile.txt with sections per file and columns sorted by variability.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Integrity Checks & Diffs', 'Build a tool that compares two release artifacts (e.g., .tar.gz vs .zip) for content-equivalence by extracting, normalizing metadata (timestamps, owners, entry order), and normalizing text EOL for .txt/.md before computing per-file hashes and a directory Merkle root. Emit a machine-readable JSON report of added/removed/changed/renamed files and permission-only changes, optionally validating against a provided manifest.json and exiting nonzero on drift.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Integrity Checks & Diffs', 'Create a CLI that compares two mixed-format dataset snapshots at /app/v1 and /app/v2 using rules from /app/rules.yaml: JSON compared semantically (ignoring key order/whitespace), CSV diffed by declared primary keys, text normalized for EOL/encoding, and binaries by SHA256. Emit a single /app/diff_report.json summarizing added/removed/modified records/files and exit non‑zero if any change violates the allowlist rules.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Integrity Checks & Diffs', 'Create a script that compares dataset snapshots at /app/stage_a and /app/stage_b by canonicalizing contents (CSV normalized by a configured primary key from /app/diff_config.toml; JSON/JSONL with sorted keys) and computing content checksums per file. Write /app/diff_report.json listing added/removed files, checksum mismatches, and for changed CSVs counts of added/removed/modified rows keyed by the primary key.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Integrity Checks & Diffs', 'Create a script that compares two tar.gz filesystem snapshots at /app/snapshots/v1.tar.gz and v2.tar.gz entirely in-stream (no full extraction), computing SHA256s to report added/removed/changed files and detecting renames by matching content hashes while distinguishing content vs metadata-only changes. It must also validate v2 against /app/manifest.csv of expected paths, sizes, and hashes and emit a concise diff report.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Integrity Checks & Diffs', 'Implement a CLI that compares two dataset snapshots in /app/snap_a and /app/snap_b, verifies SHA-256 integrity, and classifies per-table differences as identical, row-reordered-only, or content-changed across CSV and Parquet files. Detect renamed files by matching content hashes and write /app/changes.json (added/removed/modified/moved with reasons) and /app/violations.txt (checksum failures).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Missing & Duplicate Detection', 'Create a script that merges CSV enrollment files in /app/enrollments and validates against /app/students.csv, deduplicating repeated registrations (same student_id, course_id, term) and flagging registrations with missing or unknown student_ids. Output a cleaned /app/enrollments_clean.csv plus /app/duplicates.csv (grouped duplicate sets with source filenames) and /app/missing.csv (rows with null or unmatched keys).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Missing & Duplicate Detection', 'Create a script that scans all NDJSON user records under /app/incoming and /app/archive, flags rows with missing required keys (id, email, last_name) or malformed emails/phones, and deduplicates users across files by case-insensitive email or normalized phone or Levenshtein-1 full-name match with identical birth_date. Write /app/clean.ndjson containing one canonical record per user and /app/anomalies.csv listing file:line, record_id (if present), and the reason for each missing/duplicate/inconsistent record.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Missing & Duplicate Detection', 'Implement a script that scans mixed-format contact datasets in /app/data (CSV and JSONL), normalizes them to a common schema, detects duplicates via canonicalized emails plus approximate name matching, and flags rows with missing required fields. Output a deduplicated clean_contacts.csv, a duplicates_report.json with cluster details and chosen canonical records, and a missing_summary.csv of per-column missing counts.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Missing & Duplicate Detection', 'Write a script that ingests all headered CSVs in /app/logs/daily with fields sensor_id,timestamp,value, deduplicates rows by the (sensor_id,timestamp) key across files, and emits a consolidated /app/clean.csv sorted by sensor_id then timestamp. For each sensor, detect missing 1-minute intervals between its min and max timestamp, insert placeholder rows with empty value for gaps, and produce /app/quality_report.json summarizing per-sensor duplicates removed and gaps inserted.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Regression Testing for Data Outputs', 'Create a CLI regression harness that compares a baseline and candidate directory of mixed CSV/JSON/Parquet outputs by canonicalizing record/order, normalizing floats (1e-6), and keying rows by a provided primary key to detect schema drift, added/removed records, and numeric deltas beyond a tolerance. Write a structured diff to /app/report.json and PASS/FAIL to /app/result.txt using zero-drift for schema and 0.1% relative tolerance for numeric fields.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Regression Testing for Data Outputs', 'Create a CLI regression harness that runs data transformation scripts declared in /app/tasks.yaml, writes outputs (CSV, JSONL, Parquet) to /app/out, and compares them to goldens in /app/golden using canonicalization (deterministic row ordering, normalized JSON keys) and configurable numeric tolerances. Support per-file ignore/remap rules (e.g., timestamps) via config and emit both a JUnit XML report and a concise text diff summary of mismatches.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Regression Testing for Data Outputs', 'Create a regression harness that compares two pipeline outputs in /app/run_prev/ and /app/run_new/ (CSV or Parquet): verify identical table set, column order and types against /app/schema.json, per-partition row counts and key-level checksums match, and numeric aggregates stay within tolerances from /app/thresholds.toml. Emit a JUnit-style XML report to /app/results.xml and exit non-zero on any failure.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Regression Testing for Data Outputs', 'Create a script that compares /app/baseline and /app/candidate outputs across matching CSV or NDJSON files by joining records on id (order-insensitive), enforcing schema compatibility (no removed columns) and comparing numeric fields within a configurable tolerance while ignoring volatile fields like updated_at. Write a summary to /app/regression_report.txt and exit non-zero on missing/extra rows, type changes, or values outside tolerance.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Regression Testing for Data Outputs', 'Implement a CLI that compares new aggregation outputs in /app/current/*.parquet to golden snapshots in /app/baseline/*.parquet using /app/spec.yaml to define composite key columns and per-column rules (exact for categoricals, relative/absolute tolerances for numerics, allowed new columns). Align by keys, flag missing/extra keys, schema narrowing, null-rate increases, and tolerance violations; write /app/report.txt and /app/report.json and exit non-zero on any failure.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Schema & Type Validation', 'Build a CLI script that validates all NDJSON event files in /app/events against /app/schema.json (JSON Schema draft-2020-12), enforcing required fields, types, enum values, and custom formats (uuid, email, RFC 3339 timestamps). Coerce only lossless type fixes (e.g., numeric strings to numbers), write all valid records to /app/validated/merged.ndjson, emit a line-level error report to /app/invalid_report.json for rejects, and exit non-zero if any record fails.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Schema & Type Validation', 'Build a validator that reads a JSON Schema from /app/schema.json and validates user records aggregated from three sources (CSV, JSONL, and a SQLite table), performing strict type/format checks (email, uuid, URI, timezone-aware date-time) and conditional rules (e.g., if country == ''US'' then state is a 2-letter code; if status == ''ACTIVE'' then deactivated_at is null). Produce /app/validation_report.json summarizing per-rule violations and global uniqueness errors (id and case-insensitive email), and write a normalized /app/valid_merged.jsonl containing only valid, de-duplicated records with extra fields stripped.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Schema & Type Validation', 'Create a CLI validator that reads a versioned schema.yaml and validates mixed-format ''orders'' datasets (CSV, NDJSON, Parquet) for strict type adherence, including decimal precision/scale, UUID/email formats, UTC datetimes, nested objects/arrays, required fields, enums, and ranges. Produce a machine-readable JSON violations report per file and emit a Parquet containing only the records that pass validation.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Schema & Type Validation', 'Create a script that validates all NDJSON event records in /app/events against /app/schema.json, enforcing cross-record constraints (globally unique event_id, per-session non-decreasing ISO‑8601 timestamps) and conditional typing based on event_type (e.g., purchase requires a positive numeric amount, view must not include amount). Write valid, normalized records (timestamps coerced to RFC3339 Z, safe numeric coercions) to /app/valid.ndjson and emit a machine-readable /app/errors.csv with file, line, and codes for every rejected record.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Data Validation & Quality Assurance', 'Schema & Type Validation', 'Create a script that validates all records in /app/events/*.ndjson against /app/schema.json plus extra rules (user_id must be UUIDv4, timestamp ISO 8601 and not in the future, amount nonnegative with currency-specific decimal precision). Output /app/validation_report.csv with line_number,error_code,field,message for all failures and /app/valid.ndjson containing only canonicalized, schema-conforming records.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Encoding & Compression', 'Create a CLI that recursively scans /app/input for text files, auto-detects encoding (e.g., UTF-8/UTF-16/Windows-1252/Shift-JIS), converts them to UTF-8 with LF newlines in /app/normalized, then builds a reproducible tar.zst archive with sorted entries and fixed metadata. Output a manifest.csv listing original path, detected encoding, original/normalized sizes and SHA256 hashes, and support a verify mode that extracts the archive and validates checksums against the manifest.', NULL, NULL);
