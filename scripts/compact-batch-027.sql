-- Compact batch 27/29: rows 1301-1350

INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES
('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Unit & Integration Test Implementation', 'Implement unit and integration tests with pytest, pytest-asyncio, and Hypothesis for an asyncio WebSocket chat server skeleton, verifying message routing, rate limiting, heartbeat timeouts, and graceful disconnects. Tests must spin up the server on localhost, connect multiple clients concurrently, assert broadcast ordering and backpressure handling, and run deterministically without external network access.', NULL, NULL),
('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Unit & Integration Test Implementation', 'Implement unit tests for a timezone-aware recurring event scheduler to verify next_occurrence and occurrences_between across DST forward/back transitions, month-end rollovers, and timezone changes using IANA zoneinfo and frozen time. Add integration tests that run the provided CLI against a fixtures.yaml of recurrence rules to assert deterministic outputs and round-trip serialization across multiple timezones.', NULL, NULL),
('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Unit & Integration Test Implementation', 'Write a comprehensive pytest + Hypothesis suite for an existing Python CRDT library (e.g., LWW-Element-Set and OR-Map) that verifies merge algebra (commutativity, associativity, idempotence), serialization round-trips, and tombstone semantics. Tests should generate randomized concurrent operation sequences across multiple replicas, simulate partitions and merges, and assert eventual consistency and order-independence in end-to-end scenarios.', NULL, ARRAY['python']),
('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Unit & Integration Test Implementation', 'Write unit and integration tests for an existing Python resumable chunked downloader and its `fetch` CLI using pytest (and pytest-asyncio), mocking filesystem and network layers and spinning up a local HTTP server for end-to-end flows. Verify checksum validation, HTTP range-request handling, resume-after-interrupt via SIGINT/SIGTERM, and atomic file moves, enforcing at least 90% coverage.', NULL, ARRAY['python']),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Configure the AWS CLI to use a named profile that obtains credentials via credential_process from a local Python helper and auto-assumes a role, with region/output defaults set. Point S3 and STS to LocalStack endpoints so offline aws sts get-caller-identity and aws s3api list-buckets work using that profile.', NULL, ARRAY['aws', 'python']),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Install Google Cloud SDK and create two named gcloud configurations (dev and prod) using provided service account key files in /app/keys, setting distinct default project IDs and compute regions/zones for each. Activate each config in turn, initialize Application Default Credentials from its key, and verify the active account, project, and ADC source switch correctly between dev and prod.', NULL, ARRAY['cloud']),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Install and configure AWS CLI, gcloud SDK, and Azure CLI to target local emulators (LocalStack for AWS, fake-gcs-server for GCP, and Azurite for Azure), creating named profiles and endpoint overrides so storage commands work offline. Verify by creating a bucket/container in each emulator and listing them via the respective CLIs using the configured profiles.', NULL, ARRAY['aws', 'azure', 'gcp', 'container']),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Install and configure AWS CLI, gcloud, and Azure CLI to target local emulators (LocalStack for AWS, Pub/Sub emulator for GCP, and Azurite for Azure) with offline credentials, named profiles/projects/subscriptions, and endpoint overrides so basic list/describe commands succeed without internet. Ensure defaults (region/output) are set and all configs reside in the standard dot-directories for each CLI.', NULL, ARRAY['aws', 'azure', 'gcp']),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Install and configure AWS CLI, gcloud, and Azure CLI to use local emulators (LocalStack, gcloud Pub/Sub emulator, and Azurite) with isolated named profiles and custom endpoints, persisting settings in the standard credential/config files. Validate by switching profiles and creating a test S3 bucket, Pub/Sub topic/subscription, and Azure Blob container, then listing them to confirm connectivity.', NULL, ARRAY['aws', 'azure', 'container']),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Provision a bastion and an internal SSH service, create OpenSSH user and host CAs, and configure both servers to accept only CA-signed keys (password auth off), installing host certificates and @cert-authority entries in known_hosts. Add a client ~/.ssh/config with ProxyJump so ''ssh internal-via-bastion'' works, verify scp through the jump, and demonstrate a local port forward (15432 -> internal:5432) established via the bastion.', NULL, NULL),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Provision two OpenSSH servers (bastion and private) on an isolated network and configure the client to reach the private host only via the bastion using ProxyJump with per-host identities in ~/.ssh/config. Disable password authentication, hash and pin host keys in known_hosts, block direct access to the private host, and verify by copying a file and executing a remote command through the jump while confirming direct SSH to the private host fails.', NULL, NULL),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Provision two local OpenSSH daemons as a bastion (port 2222) and an internal host (port 2223), create an SSH CA, sign both host keys and a user certificate, and configure the servers to accept only CA-signed certs (no passwords or raw public keys). Configure the client with @cert-authority and hashed known_hosts plus a ~/.ssh/config using ProxyJump and ControlMaster to reach the internal host via the bastion, verifying SSH and SCP work with StrictHostKeyChecking=yes.', NULL, NULL),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Provision two local OpenSSH servers representing a bastion (port 2222) and an internal host (port 2223). Configure certificate-based SSH using a user CA and a host CA, disable passwords, require ProxyJump through the bastion, pre-populate known_hosts with @cert-authority entries, and verify that a single ssh command using the signed client key reaches the internal host via the bastion and creates /tmp/ok.', NULL, NULL),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Stand up two local sshd instances (bastion on one port, app on another), configure ProxyJump through the bastion, and implement OpenSSH certificate-based auth by creating a user CA to sign the client key and a host CA to sign the app host key; configure sshd and the client with hashed known_hosts using @cert-authority for non-interactive trust. Verify that connecting to the app via the bastion works passwordlessly without host-key prompts and that access breaks when certs expire or principals don’t match.', NULL, NULL),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Launch a LocalStack instance and use Terraform to provision an S3 bucket, an SQS queue, and a least-privilege IAM user/policy, wiring S3 ObjectCreated notifications to the queue. Configure awscli with the issued credentials, upload a test object, and consume the resulting queue message to validate the end-to-end flow.', NULL, NULL),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Provision an AWS-like event ingestion pipeline on LocalStack via CLI/IaC: create an S3 bucket (versioning + SSE), an SNS topic, an SQS queue with DLQ, and an IAM user restricted to a specific S3 prefix. Wire S3 ObjectCreated notifications S3→SNS→SQS and verify by uploading with the new credentials and receiving the resulting queue message.', NULL, ARRAY['aws']),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Provision an AWS-like stack on LocalStack using Terraform: an S3 bucket with versioning and SSE, an SNS topic, and an SQS queue subscribed to the topic via least-privilege IAM policies and resource tags. Configure AWS CLI to target LocalStack and demonstrate end-to-end by uploading to S3, publishing to SNS, verifying the message in SQS, and exporting a JSON summary of created ARNs.', NULL, ARRAY['aws']),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Start a LocalStack container and use Terraform to provision an SNS topic, an SQS queue with a dead-letter queue, and a subscription connecting the topic to the queue. Publish a test message and verify delivery by consuming it from the queue via the AWS CLI.', NULL, ARRAY['container', 'aws']),
('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Use Terraform against LocalStack to provision an S3→SNS→SQS event pipeline: a versioned bucket that publishes object-created events to an SNS topic with an SQS subscription and a dead-letter queue. Validate by uploading a test object via awscli, reading the event from SQS, and demonstrating DLQ redrive behavior.', NULL, NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Create an LVM volume group on a loopback disk with an ext4 logical volume mounted at /mnt/data, and implement consistent backups by taking read-only LVM snapshots before each run. Configure a systemd service/timer that uses rsync --link-dest to maintain 7 rotating daily backups in /srv/backups, then demonstrate recovery by restoring a file from a previous snapshot.', NULL, NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Deploy a local MinIO S3 service and configure restic with repository encryption to back up /app/data using exclude patterns, tags, and a scheduled cron job enforcing a retention policy (keep 7 daily, 4 weekly, 12 monthly). Perform initial and follow-up backups with file changes, run forget/prune, then restore a specific snapshot to /app/restore verifying checksums and that no plaintext filenames exist in the repository.', NULL, NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Install and configure BorgBackup to create encrypted, deduplicated snapshots of /data into a local repository at /backups/borg with an hourly systemd timer and a retention policy of 7 daily, 4 weekly, and 6 monthly snapshots, followed by a repository integrity check. Demonstrate correctness by modifying and deleting sample files, restoring a chosen snapshot to /restore, and verifying contents and that prune retained the requested generations.', NULL, NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Install and configure rsnapshot to perform rotating, hard-link-based backups of /etc and /srv/data to /backup/rsnapshot with retentions hourly:6, daily:7, weekly:4 and excludes for logs/cache, scheduled via cron. Verify by modifying files, running backups, confirming deduplication through hard-link counts across snapshots, and restoring a deleted file to its original location.', 'hard', NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Set up two loopback-backed btrfs filesystems mounted at /srv/src and /srv/backup, create a /srv/src/data subvolume, and automate hourly read-only snapshots named snap-YYYYMMDDHH with pruning to the latest 6 plus incremental btrfs send/receive mirroring to /srv/backup, logging to /var/log/btrfs-backup.log. Verify recovery by deleting a file in /srv/src/data and restoring it from the newest snapshot on the backup target.', NULL, ARRAY['logging']),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Create a 3 GiB sparse file as a loop device, partition it with GPT into two volumes (512 MiB ext4 labeled DATA and the remainder as a LUKS-encrypted XFS labeled SECRET) and set proper labels/UUIDs. Configure /etc/crypttab and /etc/fstab to unlock and mount them at /mnt/data and /mnt/secret by UUID, then verify persistence by detaching/reattaching the loop device and remounting without using device paths.', NULL, NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Create a 3GB sparse disk image, attach it as a loop device, and partition it with GPT into a small unencrypted FAT32 partition and a LUKS2-encrypted data partition containing an LVM PV/VG/LV formatted as ext4. Mount the LV at /mnt/secure with restrictive options and persist the configuration via /etc/crypttab and /etc/fstab using UUIDs/labels, verifying it remounts correctly after detaching and reattaching the loop device.', NULL, NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Create a GPT-partitioned loopback disk, build an LVM-on-LUKS stack on one partition, and mount the decrypted logical volume at /srv/secure with persistent /etc/crypttab and /etc/fstab entries using UUIDs and a root-only keyfile. Demonstrate that after detaching and reattaching the loop device the volume auto-opens and mounts non-interactively, preserving data.', NULL, NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Provision a 3 GiB loopback disk image and partition it with GPT into: 512 MiB EFI System (vfat, label EFI), 2 GiB Linux filesystem (ext4, label DATA), and the remainder as Linux swap. Format and label each partition, mount EFI at /mnt/efi and DATA at /mnt/data, enable swap, and persist the setup using PARTUUID-based entries in /etc/fstab so all mounts reattach correctly after unmounting and remounting.', NULL, NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Provision an encrypted LVM-on-LUKS volume backed by a sparse loop device: create a GPT partition on the loop device, initialize it with LUKS using a keyfile, build a VG with two LVs (data and logs), format, and mount at /srv/secure/{data,logs}. Persist the setup via /etc/crypttab and /etc/fstab using UUIDs so it can be unlocked and mounted non-interactively and verified with mount -a after reattaching the loop device.', NULL, NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Create a loopback-backed XFS filesystem mounted at /mnt/projects with pquota enabled and configure project quotas for two directories (/mnt/projects/build-cache and /mnt/projects/datasets) via /etc/projid and /etc/projects, setting soft/hard limits of 500MB and 1GB with a 7-day grace period. Apply setgid and default ACLs so group ''research'' has rwx on both trees, then verify quota enforcement with xfs_quota reports and writes that exceed the limits.', 'hard', NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Create a loopback-backed XFS filesystem mounted at /srv/projects with project quotas (prjquota) enabled, defining two directory-scoped projects via /etc/projects and /etc/projid with distinct soft/hard limits, and configuring setgid plus default ACLs for collaborative inheritance. Verify enforcement by filling each project until soft/hard limits and grace periods trigger, confirming with xfs_quota reports and observed EDQUOT failures.', 'hard', NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Create a loopback-backed XFS volume mounted at /mnt/projects with project quotas enabled, defining project IDs for team-a (200 MiB) and scratch (50 MiB) and enforcing hard limits. Configure a shared dir with setgid and default POSIX ACLs for group inheritance, a scratch dropbox with the sticky bit, and a logs dir marked append-only via chattr, then verify quota and permission behavior with automated writes.', 'hard', NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Provision a loopback-mounted XFS filesystem at /mnt/projects with prjquota enabled, bind project ''projA'' to /mnt/projects/projA via /etc/projid and /etc/projects, and enforce an 80MB soft/100MB hard project quota (7-minute grace) using xfs_quota with persistence in /etc/fstab. Validate enforcement by writing data as multiple users and confirming over-limit writes are denied.', 'hard', NULL),
('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Provision an XFS filesystem on a loopback device mounted at /mnt/studio with prjquota enabled, configure a project quota that caps /mnt/studio/assets at 1 GiB via /etc/projects and xfs_quota, and set per-user soft/hard quotas for alice and bob. Enforce collaborative permissions by applying setgid, sticky bit, and default ACLs for the ''artists'' group, demonstrate chattr +i on a file, and verify quota/permission enforcement with xfs_quota and failed writes.', 'hard', NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure a host-wide nftables firewall with default-drop policy using inet and ip6 tables: allow established/related, loopback, necessary ICMP/ICMPv6 (ND, RA, RS, PTB), and open SSH (22) and HTTP (8080) only on IPv4, with rate-limited new connections. Make the rules persistent across reboots and enable logging of dropped packets to /var/log/nftables-drop.log; verify IPv4 HTTP works while IPv6 HTTP is blocked and ICMPv6 neighbor discovery still functions.', NULL, ARRAY['logging']),
('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure iptables to implement a three-step port knocking sequence (4001 → 4002 → 4003 within 10s) that temporarily opens SSH (port 22) only for the knocking source, while default-denying inbound and allowing established/related traffic. Persist the rules across reboots and verify SSH is blocked before knocking, opens after the sequence, and relocks after a timeout.', NULL, NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure iptables-based port knocking that keeps SSH (port 22) closed by default and opens it for 60 seconds only to the knocking client after a correct sequence on three high ports. Enforce a default-deny inbound policy, add logging for knock attempts, and verify both denial without knocking and successful SSH after the sequence.', NULL, ARRAY['logging']),
('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure nftables to enforce a default-deny host firewall with stateful rules. Allow loopback/established traffic, port-forward 80→8080 to a local service, restrict SSH on 2222 to 10.0.0.0/24 with rate limiting, block outbound SMTP except to smtp.example.net, log drops with prefix TB-FW, ensure persistence across reboots, and verify behavior over IPv4/IPv6 with curl/nc tests.', NULL, NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure nftables to enforce a host firewall with default drop on inbound traffic, allowing established/related and loopback, permitting HTTP/HTTPS to a local nginx, and opening SSH only after a correct 3-step UDP port-knock (1111→2222→3333 within 10s) with rate-limited access. Make the rules persistent across reboots and include a verification script that demonstrates SSH is closed before knocking, opens for 30 seconds after the sequence, then automatically closes again.', NULL, NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Interface & IP Configuration', 'Configure a dual-homed Linux host where eth0 uses DHCP and eth1 has a static 192.168.50.2/24; add policy-based routing so traffic sourced from 192.168.50.0/24 uses gateway 192.168.50.1 while all other traffic uses the DHCP default route. Set per-domain DNS with systemd-resolved so queries to corp.local use 192.168.50.53 via eth1, ensuring settings persist across reboots with netplan.', NULL, NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Interface & IP Configuration', 'Using iproute2 and network namespaces, build a routed lab with three namespaces (hostA, router, hostB): create veth links, assign static IPv4/IPv6, configure per-namespace DNS via a dnsmasq bound to the router, add policy-based routing and default routes, enable IPv4 forwarding/NAT on the router, and verify end-to-end connectivity and name resolution.', NULL, NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Build a three-namespace topology (client–router–server) with mismatched MTUs and ICMP “Fragmentation Needed” filtered, then diagnose a stalled TCP connection using tracepath/ping and tcpdump to pinpoint a PMTU blackhole. Fix the issue by permitting ICMP or enabling TCP MSS clamping and verify successful HTTP transfer end-to-end.', NULL, NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Create a three-namespace topology (client-router-server) where the router drops ICMP Fragmentation Needed, producing a PMTU blackhole that causes HTTPS requests to hang. Use ping with DF, traceroute, and tcpdump to confirm the issue, then fix it by enabling TCP MSS clamping (or lowering MTU) on the router and verify curl completes successfully.', NULL, NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Create three network namespaces (client, router, server) linked by veth; drop ICMP ''Fragmentation Needed'' on the router to simulate a PMTU black hole that causes HTTP transfers to hang. Diagnose with ping -M do, traceroute, ss, and tcpdump, then fix by enabling TCP MSS clamping on the router and verify a large curl from client to server succeeds.', NULL, NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Diagnose and fix stalled large file downloads caused by PMTU blackholing: use tcpdump, tracepath, and curl to confirm ICMP “Fragmentation Needed” is being dropped and that the interface MTU is misconfigured. Restore connectivity by allowing the required ICMP through iptables and/or clamping TCP MSS, then verify the transfer completes.', NULL, NULL),
('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Simulate and diagnose a path MTU black hole using Linux network namespaces by creating a multi-hop topology with mismatched MTUs and blocking ICMP “Fragmentation Needed,” causing large TCP transfers to stall. Use ping with DF, traceroute, tcpdump, and curl to pinpoint the issue, then fix it by allowing ICMP or applying TCP MSS clamping and verify sustained transfers succeed.', NULL, NULL),
('System Setup & Configuration', 'Operating System Configuration', 'Environment Variables & Profiles', 'Create a layered cross-shell environment configuration that defines APP_ENV=staging and prepends /opt/tools/bin to PATH without duplicates via /etc/profile.d/bench.sh (interactive shells) and ~/.config/environment.d/bench.conf (session-wide). Ensure these variables appear in login and non-login shells, ssh commands, a cron job for user ''bench'', and a systemd --user service, while interactive-only prompt changes do not affect scripts.', NULL, NULL),
('System Setup & Configuration', 'Operating System Configuration', 'Environment Variables & Profiles', 'Create a unified environment manager that reads variables and PATH entries from ~/.config/envvars.yaml and generates shell-agnostic snippets sourced by both Bash and Zsh for login, non-login, interactive, and non-interactive sessions. Provide an envsync command to rebuild the snippets and verify PATH precedence, LANG/LC_ALL, and HTTP(S)_PROXY/NO_PROXY persist across new shells and subprocesses.', NULL, NULL),
('System Setup & Configuration', 'Operating System Configuration', 'Environment Variables & Profiles', 'Install and configure direnv for both bash and zsh by adding the required shell hooks to the correct profile files so it runs in interactive sessions. Create a project directory with an .envrc that exports custom variables (e.g., APP_ENV, LOG_LEVEL), prepends ./bin to PATH, optionally activates a Python virtualenv if present, and verify the environment loads only inside the directory after direnv allow and unloads on exit.', NULL, ARRAY['python']),
('System Setup & Configuration', 'Operating System Configuration', 'Environment Variables & Profiles', 'Install and configure direnv globally for bash and zsh, then create /app/project with an .envrc that adds /app/bin to PATH, sets APP_ENV=dev and API_URL, and activates a Python virtualenv via layout python. Verify that entering and leaving /app/project automatically loads/unloads the environment in both shells after direnv allow, while non-project shells remain unaffected.', NULL, ARRAY['python']);
