-- Batch 7 of 8: Inserting tasks 1201 to 1400

INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Build Tool Configuration', 'Configure a Meson+Ninja build for a small C library and CLI that builds shared and static variants, generates a pkg-config file, and embeds a git-derived version string. Add debug/release options toggling sanitizers, wire up unit tests, and ensure `meson dist` produces a bit-for-bit reproducible source tarball with fixed timestamps and sorted file order.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Build Tool Configuration', 'Create a CMake build for a C++ library that generates a version header from git metadata, fetches fmt via FetchContent, and installs exportable targets with both a CMake package config and a pkg-config .pc file for downstream consumption. The harness should build out-of-tree, run ctest, install to /app/dist, then compile a separate consumer using find_package or pkg-config, and verify incremental builds are no-ops and the reported version matches the latest git tag.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Continuous Integration (CI) Pipelines', 'Create a GitHub Actions workflow for a Python+Node monorepo that uses path filters to generate a dynamic job matrix, caches pip/npm, provisions a Postgres service with health checks, shards pytest across 3 parallel jobs, runs jest with coverage, and publishes a combined coverage summary. On semantic-version tags, build a multi-arch Docker image with buildx, sign it via OIDC/cosign with an attached SBOM, and upload release artifacts while skipping release steps on other pushes.', 'hard', ARRAY['python', 'parallel', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Continuous Integration (CI) Pipelines', 'Create a GitHub Actions workflow for a monorepo that uses path filters and a matrix to run Python and Node.js tests (with a Postgres service), caching dependencies, and on failure triggers an automatic git-bisect job that posts the first bad commit as a PR comment. On tagged releases, build and push a signed multi-arch Docker image to GHCR with Buildx, generate CycloneDX SBOMs for both components, and fail if the vulnerability scan reports high-severity issues.', NULL, ARRAY['python', 'git', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Continuous Integration (CI) Pipelines', 'Create a GitHub Actions workflow for a polyglot monorepo (server/ Python API, web/ Node frontend) that conditionally runs by path, uses a matrix, caches dependencies, and hands off built web artifacts to backend integration tests. The pipeline should start Postgres and Redis services, merge coverage to Cobertura, and on v* tags build and push a Docker image to a local registry.', NULL, ARRAY['python', 'api', 'web', 'frontend', 'backend', 'redis', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Continuous Integration (CI) Pipelines', 'Create a reusable GitHub Actions workflow (invoked via workflow_call) that builds a dynamic matrix from changed subdirectories to lint/test polyglot components (Go, Node, Python) with dependency caching, provisions PostgreSQL and MinIO services for integration tests, and builds multi-arch Docker images via buildx. On version tags, sign the image using keyless cosign via OIDC, generate an SBOM and SLSA provenance, and publish artifacts to GitHub Releases and the container registry.', NULL, ARRAY['python', 'postgresql', 'docker', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Continuous Integration (CI) Pipelines', 'Implement a GitHub Actions workflow for a polyglot monorepo (Python package, Node library, and Go CLI) that uses path-based change detection to run only impacted jobs, caches per-language dependencies, runs a version/OS matrix, aggregates JUnit and coverage artifacts, and produces a versioned release bundle only on annotated tags. The pipeline must use reusable workflows, pinned action SHAs with actionlint validation, concurrency to cancel superseded runs, and artifact handoff between jobs without re-installing dependencies.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Developer Environment Setup', 'Create a hermetic polyglot developer environment using Nix Flakes that exposes a dev shell with pinned Python (Poetry), Rust (cargo), and Node (pnpm), plus pre-commit and reproducible caches. Provide flake.nix and a Justfile so `nix develop` drops into a non-root shell where `just lint` and `just test` execute the configured tooling.', NULL, ARRAY['python', 'rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Developer Environment Setup', 'Create a reproducible VS Code devcontainer for a polyglot repo (FastAPI backend + Next.js frontend) with hot-reload debugging, pre-commit hooks, and Postgres/Redis services started via docker-compose, exposing ports 8000 and 3000. Include a non-VS Code bootstrap script and health checks so the task passes only when both apps, databases, and lint hooks are active.', NULL, ARRAY['backend', 'frontend', 'debugging', 'redis', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Developer Environment Setup', 'Create a reproducible polyglot developer environment using Nix flakes and direnv for a repo combining Python 3.11, Rust 1.75, and Node 20, with a matching Docker image generated from the same flake. Pin all toolchains, wire pre-commit hooks, and ensure `make test` runs identically inside `nix develop` and `docker run`.', NULL, ARRAY['python', 'rust', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Developer Environment Setup', 'Set up a Nix flake-powered VS Code devcontainer that provides a hermetic polyglot toolchain (Rust, Python, Node.js, Go) with pinned versions, LSPs, and pre-commit hooks via direnv integration. Enable Docker Buildx/QEMU multi-arch and ccache/sccache so the same make bootstrap and make test targets work identically on x86_64 and arm64.', NULL, ARRAY['rust', 'python', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Developer Environment Setup', 'Set up a VS Code Dev Container backed by Docker Compose that provisions Python 3.11 (via uv), Node.js 20, and Rust stable, with Postgres 15 and Redis 7 as sidecar services. Include bootstrap scripts and pre-commit so that entering the container pins tool versions and a single make verify command builds a sample Rust crate, runs npm install, and executes pytest integration tests that talk to the databases.', NULL, ARRAY['container', 'docker', 'python', 'rust', 'redis']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Toolchain Customization & Extensions', 'Build a custom clang-tidy module that implements a check (e.g., modernize-avoid-raw-new) to flag and auto-fix uses of new/delete by suggesting std::make_unique/make_shared, and integrate it into a CMake project with a .clang-tidy config and a script to run it on the codebase. Include unit tests for the check and ensure the plugin builds and runs entirely within the sandbox.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Toolchain Customization & Extensions', 'Build an ESLint plugin that adds a rule ''no-unbounded-fetch'' to detect fetch/axios calls without an AbortController or timeout, including an autofix to wrap calls with a cancellable pattern. Integrate it into a sample TypeScript project via .eslintrc, npm scripts, and a pre-commit hook, with RuleTester tests covering both reports and fixes.', NULL, ARRAY['typescript']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Toolchain Customization & Extensions', 'Implement a Prettier plugin for a simple INI-like key=value DSL with sections and comments, adding a custom parser and printer that preserves comments, normalizes indentation, and alphabetically sorts keys within each section while remaining idempotent. Provide a CLI that formats all .conf files in a directory and verifies byte-for-byte equality with expected outputs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Toolchain Customization & Extensions', 'Implement an ESLint plugin that adds a custom rule with autofix to enforce import hygiene: group imports as [node builtins, external, internal ''@app/*'', relative], keep one blank line between groups, alphabetize within groups, and place side-effect-only imports last. Provide fixtures and a test CLI so running npm test verifies exact diagnostics pre-fix and that the autofixed output matches a golden file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Toolchain Customization & Extensions', 'Implement an ESLint plugin with a rule that bans direct fetch/axios usage and enforces routing HTTP calls through a project-specific client API, including a robust AST-based autofixer. Provide CLI tests that lint and auto-fix sample files to verify correct detection, messages, and transformations.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Version Control & Branching', 'Implement and register a Git custom merge driver that performs a deterministic, key-aware three-way merge for JSON files, with .gitattributes routing *.json through it. Create two feature branches that introduce overlapping edits to the same JSON documents, merge them back to main without manual conflicts, and leave a verifiable merged state and commit history.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Version Control & Branching', 'Locate a regression by automating git bisect with a script that runs the project’s tests to identify the first bad commit, then create a hotfix branch with the minimal fix. Cherry-pick the fix onto the latest release branch and create a GPG-signed annotated patch-release tag, ensuring linear history and passing tests on both branches.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Version Control & Branching', 'Migrate a repository from using a submodule at libs/foo to using a git subtree, preserving the submodule’s commit history within libs/foo/ across main and release branches. Then remove all blobs >5MB via history rewrite, rebase feature/* branches onto the cleaned main resolving conflicts (enable rerere), and push to a bare origin with a specified branch/tag layout and verifiable commit graph with no large blobs.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Version Control & Branching', 'Migrate a repository that uses two submodules into a monorepo via git subtree, preserving complete history and retagging releases with component-prefixed tags. Then merge three diverging feature branches with an octopus merge, resolving JSON conflicts via a custom merge driver configured through .gitattributes.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Development Tooling & Workflow Automation', 'Version Control & Branching', 'Split a provided monorepo’s frontend/ and backend/ histories into two standalone repositories using git subtree split while preserving commit history and tags, then re-integrate them into the original monorepo as subtrees wired to remotes. Demonstrate a subsequent upstream sync by pulling new commits from both remotes and merging into main as fast-forwards with no content drift.', NULL, ARRAY['frontend', 'backend', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'API Design & Integration', 'Create a WebSocket-to-MQTT bridge that authenticates clients via JWT and implements a JSON protocol for subscribe, unsubscribe, and publish operations, translating them to MQTT with QoS1 and retained message support. Expose an HTTP endpoint to list active client sessions and subscriptions, and ensure clean mapping of error states between WebSocket frames and MQTT acknowledgments.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'API Design & Integration', 'Implement a Go-based gRPC↔HTTP JSON transcoding gateway that exposes REST endpoints (including a Server-Sent Events stream) mapped to methods in a provided .proto, translating errors/metadata and supporting bidirectional streaming via WebSockets. The gateway must validate incoming JWTs using a remote JWKS (with caching/rotation) and inject verified claims into gRPC metadata for the upstream service.', NULL, ARRAY['grpc', 'rest']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'API Design & Integration', 'Implement a minimal S3-compatible object storage server that supports AWS Signature v4 auth and interoperates with aws-cli for CreateBucket/ListBuckets, PutObject/GetObject/DeleteObject, and presigned GET URLs; persist objects to /data and return AWS-style XML responses. Include ETag/If-None-Match handling and ensure requests with invalid signatures return the correct S3 error codes.', NULL, ARRAY['aws']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'API Design & Integration', 'Implement an HTTP gateway that exposes a REST+SSE API on localhost:8080 and transparently bridges to a local gRPC service at 127.0.0.1:50051, translating unary and streaming RPCs into JSON and server-sent events. Ensure consistent gRPC→HTTP error mapping, request deadlines via headers, idempotency keys for POSTs, and auto-generate an OpenAPI spec for the REST facade.', NULL, ARRAY['rest', 'api', 'grpc']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'API Design & Integration', 'Implement an HTTP-to-gRPC gateway that reads a provided OpenAPI spec and matching .proto, translating REST requests into gRPC calls (including server-streaming exposed as Server-Sent Events) and mapping errors to correct HTTP codes. The gateway must validate requests/responses against OpenAPI, support path/query/header mapping, and preserve backward compatibility for both v1 and v1beta routes.', NULL, ARRAY['grpc', 'rest']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Algorithm Implementation', 'Implement a KLL streaming quantile sketch with configurable error (epsilon) that supports insert, merge, serialize/deserialize, and percentile queries, exposing both a small library and a CLI that reads floats from stdin and returns requested quantiles. Provide deterministic tests verifying accuracy bounds against exact quantiles on synthetic and adversarial streams.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Algorithm Implementation', 'Implement a single-pass streaming quantile estimator using the Greenwald–Khanna algorithm with guaranteed epsilon-approximate quantiles. Expose a CLI that ingests an arbitrary-length numeric stream and outputs requested quantiles deterministically for a given epsilon.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Algorithm Implementation', 'Implement a succinct trie using the LOUDS representation with bit-level rank/select to support exact lookup, prefix enumeration, and lexicographic k-th word queries. Provide a CLI to build from a newline-delimited dictionary and answer mixed queries from stdin efficiently.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Algorithm Implementation', 'Implement an exact 64-bit integer convolution using Number Theoretic Transforms: compute convolutions modulo multiple NTT-friendly primes and recombine via the Chinese Remainder Theorem (or Garner’s algorithm) to match Python big-integer results. Provide a CLI that reads two integer sequences from stdin and outputs their full convolution, running in O(n log n) for n up to 200,000.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Code Generation & Automation Utilities', 'Build a CLI that reads a JSON Schema (Draft 7) from /app/schema.json and generates a Rust crate at /app/gen with idiomatic serde-annotated structs/enums, correctly handling oneOf/anyOf/allOf, defaults, optional fields, and safe field/enum naming. Emit and compile a validator binary that uses the generated types to validate all /app/samples/*.json inputs and writes a summary JSON reporting per-file validity and human-readable errors.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Code Generation & Automation Utilities', 'Build a CLI that scans a polyglot monorepo (Python, Node.js, Go) to detect service roots and generate optimized multi-stage Dockerfiles and matching .dockerignore files using lockfiles for deterministic caching and stable layer ordering. Provide a validate subcommand that builds each image and outputs a summary of image sizes, cache efficiency, and hadolint violations.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Code Generation & Automation Utilities', 'Create a CLI tool that scans a repository for Dockerfiles and generates a GitHub Actions workflow YAML that builds and pushes a multi-architecture image matrix for each Dockerfile (respecting ARG defaults and build contexts). The tool must validate the YAML, support dry-run and overwrite modes, and output both the workflow at .github/workflows/build.yml and a machine-readable summary report.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Code Generation & Automation Utilities', 'Implement a CLI that converts a docker-compose.yml into a Helm chart (Chart.yaml, values.yaml, and templates/*) and auto-generates a GitHub Actions workflow for chart linting and release. The tool (/app/compose2helm.py) supports multiple compose files and environment interpolation, and tests verify the rendered manifests on a sample project.', NULL, ARRAY['docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Code Generation & Automation Utilities', 'Implement a Python AST-based codemod (using LibCST) that migrates a codebase in /app/src from requests to httpx, updating imports, call sites, Sessions/Clients, timeouts, redirect flags, and exception types. Apply changes in-place while also writing a unified patch to /app/patch.diff and a machine-readable /app/report.json summarizing per-file edits.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Feature Extension & Enhancement', 'Extend a minimal HTTP JSON TODO service by adding optimistic concurrency via ETag/If-Match on PUT/PATCH, stable cursor-based pagination for GET /todos, and a /metrics endpoint exporting request counts and p95 latency. Ensure thread-safe handling under concurrent clients and persistence across restarts using a write-ahead log.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Feature Extension & Enhancement', 'Extend an existing Node.js Express REST API backed by SQLite by adding optimistic concurrency (ETags/If-Match), soft deletes with a restore endpoint, and full-text search over titles/descriptions using SQLite FTS5. Introduce /search and /items/:id/restore routes, apply schema migrations, and update the OpenAPI spec to reflect the new behavior and error codes.', NULL, ARRAY['rest', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Feature Extension & Enhancement', 'Extend an existing Python CLI notes/todo app by adding a `search` subcommand backed by SQLite FTS5 that queries titles and bodies with ranked results and optional --limit/--offset/--json output. Implement a migration to create and keep the FTS index in sync, update the data layer, and add tests covering ranking, pagination, no-match behavior, and Unicode tokenization.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Feature Extension & Enhancement', 'Extend an existing Python CLI that reads NDJSON logs to support a SQL-like query engine (SELECT fields, WHERE, ORDER BY, LIMIT/OFFSET, GROUP BY with count/sum/avg) and a --follow mode that processes streaming input in constant memory. Add a plugin system for custom aggregate functions discovered at runtime and a plugins subcommand to list/validate them with robust error reporting.', NULL, ARRAY['python', 'sql']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Feature Implementation & Algorithm Development', 'Feature Extension & Enhancement', 'Extend the provided Python static site generator by adding an incremental build cache and a `watch` subcommand. Track per-page dependencies via content hashes (templates, partials, assets) so only affected outputs are rebuilt on change, and write a manifest proving cache hits/misses for each build.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Code Signing & Verification', 'Build a CLI tool that verifies a release artifact by validating a signed checksums manifest (detached OpenPGP signature against a pinned keyring) and, if present, a Minisign/Signify signature, confirming digests across multiple algorithms (SHA-256/512, BLAKE2b), and emitting a fail-closed JSON report with signer identities, algorithms, and timestamps. Handle revoked/expired keys, ambiguous filenames, and newline/whitespace normalization, and return non-zero on any verification failure.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Code Signing & Verification', 'Build a minimal TUF-secured release flow: generate root, targets, snapshot, and timestamp metadata with a 2-of-3 threshold for targets, sign a target artifact, and implement a client that downloads and verifies the artifact enforcing expiry and key rotation. The verifier must fail on expired metadata, insufficient signature threshold, or tampered targets, and exit 0 only when all checks pass.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Code Signing & Verification', 'Build an offline CLI that signs deployment tarballs with Ed25519 and emits a DSSE JSON attestation (including SHA-256, builder ID, and timestamp), with a keygen and public keyring export. Implement a verifier that enforces a JSON trust policy (allowed keys per release channel, expiry window, and revocation list) and fails on any tampering or policy violation.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Code Signing & Verification', 'Implement a Git pre-receive hook and verifier script that require any refs/tags/release/* update to be an annotated, GPG-signed tag by a key in .ci/trusted.gpg and that all commits reachable from the tag since the previous release are signed by trusted, non-expired, non-revoked keys. The verifier must also build a git archive of the tagged tree, compare its SHA256 to a checksums.json tracked in the tag, and output a JSON report listing verification results and any offending objects, exiting non-zero on failure.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Code Signing & Verification', 'Implement a pair of CLIs that produce and verify a signed release manifest: the signer walks /app/build, generates a reproducible SHA-256 manifest, wraps it in a DSSE JSON envelope, and signs it with an Ed25519 key derived from a passphrase. The verifier must validate the signature with the public key, detect tampering or missing files via the manifest, and only copy artifacts to /app/deploy upon successful verification.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Dependency & License Compliance', 'Build a CLI that ingests a polyglot repo (npm, pip, and Cargo), parses their lockfiles to map dependencies to SPDX license IDs, and emits a unified SPDX 2.3 SBOM at /app/sbom.spdx.json. Enforce a policy.yaml with allow/deny lists and per-package exceptions plus OSV vulnerability thresholds, verify each dependency’s LICENSE presence or resolvable URL, produce /app/compliance_report.json with remediation suggestions, and exit non-zero on any violation.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Dependency & License Compliance', 'Build a CLI that scans a polyglot monorepo (Python/Poetry, Node/pnpm, and Go modules), resolves all transitive dependencies, normalizes their SPDX license expressions, and enforces an allowlist/denylist with per-package exceptions. The tool must output an SPDX 2.3 SBOM and a deterministic THIRD_PARTY_NOTICES.md with license texts and source URLs, run offline from lockfiles, and ship a CI workflow that fails the build on violations.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Dependency & License Compliance', 'Create a CLI that compares two dependency lockfiles (npm, Poetry/pip-tools, and Go modules), resolves each dependency’s license (including transitives), and writes a policy-checked diff report to /app/license_diff.json. It must detect license changes, dual-licensing nuances, and missing metadata, consult OSV for disallowed packages, and exit non-zero on violations.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Dependency & License Compliance', 'Implement a CLI that audits a polyglot repo (Python/Node/Rust) by parsing poetry.lock, package-lock.json, and Cargo.lock to resolve all transitive dependencies offline, extracting SPDX license identifiers from local metadata. It must generate a CycloneDX SBOM and a consolidated THIRD_PARTY_NOTICES.txt, enforce a policy forbidding AGPL/SSPL/GPL-3.0-only and unknown licenses unless explicitly allowlisted, and exit non-zero on violations.', NULL, ARRAY['python', 'rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Dependency & License Compliance', 'Set up a polyglot repo (Python, Node.js, Rust) with a CI-like script that generates an SPDX SBOM, scans for CVEs and license terms, enforces a policy banning copyleft licenses and high-severity vulnerabilities, and fails if violations are found. Remediate by pinning or replacing flagged dependencies, regenerate lockfiles, and produce a machine-readable compliance report under /app/compliance/report.json.', NULL, ARRAY['python', 'rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Reliability & Fault Tolerance', 'Create a resilient HTTP proxy that fronts multiple flaky upstreams, implementing bounded retries with exponential backoff and jitter, a circuit breaker with half-open recovery, and request hedging; when all upstreams fail, serve stale cache entries (cache-aside) and surface structured errors. Add idempotency-key handling for POST requests and a /metrics endpoint exposing success/failure counts so tests can inject chaos and verify graceful degradation and self-healing.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Reliability & Fault Tolerance', 'Implement a Redis-backed job worker that guarantees at-least-once delivery with idempotent processing, exponential backoff with jitter, a dead-letter queue, and crash-safe recovery via a transactional outbox. Provide a chaos test harness that kills the worker mid-task and injects duplicate deliveries to verify no duplicate side effects, eventual completion, and correct quarantining of permanently failing jobs.', NULL, ARRAY['redis']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Reliability & Fault Tolerance', 'Implement a crash-safe transactional outbox for a toy Orders service using SQLite and a background dispatcher: persist orders and outbox records atomically, then reliably deliver them to an append-only mock broker with idempotency keys, exponential backoff with jitter, and a retry budget. After simulated crashes and restarts, the system must guarantee at-least-once delivery without duplicate observable publishes and reconcile any in-flight work.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Reliability & Fault Tolerance', 'Implement a local SQS-like durable task queue with visibility timeouts, exponential backoff with jitter, idempotency-key deduplication, and a dead-letter queue; provide a worker that can be killed mid-run and must resume without double-processing. The harness injects crashes, network-like delays, and duplicates to verify eventual processing and no duplicate side effects via a persisted checksum ledger.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Reliability & Fault Tolerance', 'Implement a resilient webhook relay daemon that reads events from /app/queue.jsonl and delivers them to a flaky HTTP endpoint using capped exponential backoff with jitter, a circuit breaker (with half-open probing), and a token-bucket rate limiter. On persistent failure it must dead-letter events, serve stale-but-valid cached results, and guarantee idempotent, exactly-once visible delivery across restarts via checkpointed offsets and idempotency keys.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Secure Coding Practices', 'Audit and harden a Python backup/restore utility that creates and extracts tar archives, currently vulnerable to Zip Slip path traversal and a --post-hook command injection via shell=True. Constrain extraction to a specified base directory, sanitize tar members, replace shell execution with safe subprocess invocation and an allowlist, and add tests that confirm malicious archives cannot escape the sandbox while preserving normal behavior.', 'hard', ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Secure Coding Practices', 'Given an intentionally vulnerable Node.js microservice/CLI in /app, remediate prototype pollution in JSON merging, command injection in child_process usage, and ReDoS in a user-supplied regex. Replace unsafe patterns with secure alternatives, add regression tests, and ensure npm audit reports no high/critical issues.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Secure Coding Practices', 'Harden a Python FastAPI file-processing service that currently uses shell=True and trusts filenames by replacing unsafe subprocess calls with argument lists, adding strict input validation and path whitelisting to prevent command injection and directory traversal, and moving credentials out of source into an .env file with parameterized loading. Add automated tests that demonstrate exploit payloads are blocked (command injection, path traversal) while valid operations still pass.', 'hard', ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Secure Coding Practices', 'Harden a deliberately vulnerable FastAPI microservice that fetches URLs and converts images by eliminating SSRF, path traversal, and command injection—replace shell calls with safe libraries, enforce allowlists/timeouts/size limits, canonicalize paths, and validate inputs with Pydantic. Rotate any leaked secrets into environment variables, add a pre-commit secret scanner and CI SAST step, and provide tests proving malicious payloads are blocked while legitimate requests still succeed.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Security, Compliance & Reliability Engineering', 'Secure Coding Practices', 'Harden a vulnerable Python Flask file-processing API by replacing unsafe YAML loading, removing shell=True subprocess usage to prevent command injection, and blocking path traversal/symlink attacks on uploads. Add tests proving malicious payloads are neutralized while preserving intended functionality.', 'hard', ARRAY['python', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Codebase Architecture Documentation', 'Build a CLI that analyzes a polyglot monorepo (Python, Go, Node) to generate a cross-language dependency graph and a C4 Container diagram, writing docs/architecture.md and SVG diagrams with components annotated by primary git authorship and service boundaries. Include a CI mode that fails on new dependency cycles or components missing ADR links, and provide a deterministic make target to regenerate all artifacts.', NULL, ARRAY['python', 'container', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Codebase Architecture Documentation', 'Build a CLI that scans a polyglot monorepo (Python, Go, Node.js) and its docker-compose.yml to produce C4 Container/Component diagrams, a module import matrix, and a cross-service topology, exporting PlantUML/SVG and Markdown docs. The tool must enforce layer rules from a config by failing on forbidden imports and append an ADR entry whenever dependency topology changes are detected.', NULL, ARRAY['python', 'docker', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Codebase Architecture Documentation', 'Create a script that scans a polyglot repo (Python and Node) to generate /app/docs containing a C4-style container diagram inferred from docker-compose.yml, per-service module dependency graphs, and a consolidated architecture README. The script must be idempotent, detect and list circular dependencies, and output diagrams in both Mermaid and PlantUML formats.', NULL, ARRAY['python', 'container', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Codebase Architecture Documentation', 'Given a polyglot microservices monorepo with docker-compose, build a tool that parses source imports and compose files to generate a cross-service architecture diagram and per-language package dependency graph, emitting Graphviz artifacts and a Markdown overview. The tool must detect cycles and boundary violations and fail CI when found, with tests verifying required nodes/edges and report contents.', NULL, ARRAY['docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Design Pattern Implementation', 'Build a Unix-style streaming log processor CLI where pipeline stages share a common Stream interface and are composed using Chain of Responsibility, with cross-cutting concerns (timing, retries, metrics) applied via Decorator. Support dynamic stage discovery and instantiation through an Abstract Factory that loads plugins from a plugins/ directory and a config file describing the pipeline.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Design Pattern Implementation', 'Implement a Python CLI task runner that uses the Command pattern for actions, Memento for undo/redo, and an Abstract Factory to load pluggable commands from /app/commands at runtime. The tool must support run, undo, redo, and macro commands (Composite) without modifying the core engine when new commands are added.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Design Pattern Implementation', 'Implement a mini rule-engine that parses and evaluates a boolean filtering DSL over JSON records using the Interpreter and Composite patterns. Provide a CLI that reads NDJSON from stdin, prints matching lines, and supports adding new operators via pluggable terminals without modifying the core parser.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Design Pattern Implementation', 'Refactor a monolithic log-processing tool into a pluggable pipeline that uses Chain of Responsibility for filter stages, Strategy for parse/format variants, and an Abstract Factory to construct pipelines from a YAML config. Discover processors from /app/plugins without modifying core code and verify correctness by producing byte-identical outputs on provided fixtures before and after the refactor.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Design Pattern Implementation', 'Refactor a provided Python CLI to-do app into a modular design that applies Command (with undo/redo), Strategy (pluggable storage backends: in-memory, JSON file, SQLite), and Observer (event hooks for sync/logging). Implement dynamic plugin discovery for new Strategy backends and a test suite validating persistence, undo/redo semantics across restarts, and event notifications.', NULL, ARRAY['python', 'logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Refactoring for Maintainability', 'Refactor a Node.js Express REST API that uses module-scoped singletons and inline SQL into a layered design (controllers/services/repositories) with dependency injection and repository interfaces so side effects are isolated and components are easily testable. Preserve all route paths and JSON responses exactly, and ensure the existing test suite passes unchanged.', NULL, ARRAY['rest', 'api', 'sql']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Refactoring for Maintainability', 'Refactor a Python Flask service in /app/app.py that currently intertwines routing, SQL queries, and business rules into a hexagonal architecture: extract domain logic into /app/core with ports, implement adapters for HTTP and SQLite, and wire dependencies at a composition root. Preserve all HTTP routes and JSON schemas exactly; tests will assert identical responses while enabling unit tests of the core via an in-memory adapter.', NULL, ARRAY['python', 'sql']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Refactoring for Maintainability', 'Refactor a monolithic Go HTTP service that directly accesses PostgreSQL and global singletons into a hexagonal (ports/adapters) architecture with domain, application, and infrastructure layers, explicit interfaces, and constructor-based dependency injection. Preserve all HTTP routes, response schemas, environment variables, and logging formats, and add golden tests to verify identical behavior before and after.', NULL, ARRAY['postgresql', 'logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'Refactoring for Maintainability', 'Refactor a small Flask microservice in /app to a ports-and-adapters (hexagonal) architecture by extracting domain logic into pure modules, introducing repository/service interfaces, and isolating framework/infrastructure behind adapters. Preserve the exact REST API and CLI behavior and response formats while removing global state and adding dependency injection seams for testability.', NULL, ARRAY['rest', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'System & Module Design', 'Design a hexagonal architecture (ports and adapters) for a feature-flag evaluation service. Define the domain module and interfaces (FlagStore, TargetingRuleEngine, Evaluator), implement separate adapters for JSON-file persistence and an HTTP query endpoint, and a composition root that wires dependencies while keeping the domain free of I/O or framework dependencies.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'System & Module Design', 'Design a minimal CQRS + event-sourcing Todo service with strict module boundaries: define interfaces for CommandBus, EventStore, AggregateRoot, Projector, and ReadModelRepository, and implement swappable in-memory and SQLite adapters via dependency injection. Expose a thin write-only REST for commands and a separate read-model API, with contract tests that validate the command→event→projection flow and enforce no cross-dependencies between write and read modules.', NULL, ARRAY['rest', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'System & Module Design', 'Design a pluggable feature-flag evaluation engine with clean module boundaries: Strategy (targeting/rollout), Store (flag/state persistence), and AuditSink (decision logging) wired via dependency inversion. Define interfaces and data flow, load implementations from a TOML config at runtime, and provide a CLI that evaluates flags for user contexts without the core depending on concrete classes.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'System & Module Design', 'Design a plugin-based data pipeline with strict layering (domain: Stage/DAG interfaces, application: orchestrator, infrastructure: adapters) where stages are discovered dynamically and wired from a YAML-defined DAG. Implement CSVReader, Filter, Aggregate, and JSONWriter stages and provide a static dependency check that fails if any stage module imports the orchestrator or adapters.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Software Architecture & Design Patterns', 'System & Module Design', 'Design and implement a hexagonal architecture for an inventory reservations system: define domain entities and ports for commands, queries, time, and event publishing, keeping the core framework-agnostic. Provide interchangeable adapters for persistence (SQLite and in-memory) and I/O (HTTP and CLI) wired via a lightweight DI container so tests can swap adapters without modifying the domain.', NULL, ARRAY['container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Continuous Testing Integration', 'Configure a GitHub Actions workflow runnable locally via act that builds a Python project, starts a Postgres service with docker-compose, and runs tox-based unit, integration, type (mypy), and security (bandit) tests across a Python version matrix with pip caching, sharded pytest execution, and flaky-test retries while enforcing a 90% coverage gate. The pipeline must upload JUnit XML and coverage reports as artifacts to /app/ci_artifacts and pass end-to-end locally.', 'hard', ARRAY['python', 'docker', 'security']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Continuous Testing Integration', 'Create a GitHub Actions pipeline for a polyglot monorepo (Python, Node.js, and Go) that runs unit and Dockerized integration tests in a matrix, spins up Postgres/Redis services, caches dependencies, splits and retries tests, enforces per-language coverage thresholds, and uploads JUnit/Cobertura artifacts. Add path-based change filters to skip unaffected jobs, lock down secrets, require status checks, and schedule a nightly run that aggregates flaky-test statistics.', NULL, ARRAY['python', 'redis']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Continuous Testing Integration', 'Create a GitHub Actions workflow for a polyglot monorepo (Python, Node.js, and Go) that caches dependencies, runs unit and integration tests (integration via docker-compose Postgres), aggregates JUnit and coverage across languages into a single report, and fails if combined coverage is below 85% while uploading artifacts. Implement a sharding-and-retry runner that splits slow tests across two matrix shards and retries failures once, marking the job as unstable via an output file when a retry passes.', 'hard', ARRAY['python', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Continuous Testing Integration', 'Implement a local CI harness that reads a ci.yml, spins up required services via Docker Compose (e.g., PostgreSQL), shards tests across N parallel workers for Python and Node subprojects, and retries failures once to classify flakiness. The pipeline must produce merged JUnit XML and coverage reports, enforce coverage thresholds during the build stage, and output a summary.json with pass/fail, flake counts, and artifacts paths.', 'hard', ARRAY['docker', 'postgresql', 'parallel', 'python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Continuous Testing Integration', 'Integrate mutation testing and coverage gating into a tox-driven pipeline that runs unit and integration tests across Python 3.10–3.12, emitting JUnit and coverage XML to /app/artifacts and merging per-environment results. Implement path-aware test selection and dependency caching so only affected tests run on changes, and fail the pipeline if mutation score < 85% or coverage < 90%.', NULL, ARRAY['testing', 'python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'End-to-End (E2E) & Regression Testing', 'Build a Dockerized E2E and regression test harness that launches a three-service sample app (frontend, API, Postgres) via docker-compose, seeds test data, and runs headless Playwright tests against localhost. Include golden JSON and visual snapshot assertions, collect screenshots/HAR/logs on failure, and provide a single CI-friendly script that exits nonzero on any diff.', NULL, ARRAY['frontend', 'api', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'End-to-End (E2E) & Regression Testing', 'Create a migration regression harness that spins up a temporary PostgreSQL instance, applies upgrade/downgrade paths across a set of SQL migrations, seeds data, and verifies invariants by comparing normalized query results and schema digests to golden snapshots. Include a CLI to run the full matrix (all from→to versions), detect drift and irreversibility, and optionally update snapshots.', NULL, ARRAY['postgresql', 'sql']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'End-to-End (E2E) & Regression Testing', 'Create a regression harness that runs the same Playwright E2E suite against two app versions (baseline vs candidate) via docker-compose, capturing API response snapshots and page screenshots, then producing semantic diffs and visual diffs in /app/artifacts. Implement retry-based flake detection with automatic quarantine list generation and emit a JUnit XML summary suitable for CI.', NULL, ARRAY['docker', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'End-to-End (E2E) & Regression Testing', 'Design an automated cross-version E2E regression harness that spins up vN and vN-1 of a sample service (HTTP + gRPC) with docker-compose, replays recorded interactions, and validates API responses, protobuf/JSON schemas, DB state, and log invariants. Integrate OpenAPI/Buf breaking-change checks and emit JUnit and HTML reports to fail the pipeline on incompatibilities.', NULL, ARRAY['grpc', 'docker', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'End-to-End (E2E) & Regression Testing', 'Implement an E2E regression harness that launches two Dockerized versions (v1 and v2) of a FastAPI service against a fresh Postgres, applies Alembic migrations, seeds fixtures, replays a recorded HTTP trace, and diffs normalized JSON responses to detect behavior drift. The runner must produce JUnit XML and a readable diff, ignoring nondeterministic fields (ids/timestamps/order), and exit nonzero on any semantic mismatch.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Mocking & Test Data Simulation', 'Build a cassette-driven GraphQL mock server that captures live queries/responses, redacts secrets, and replays them offline with deterministic seeding. Include a CLI to inject schema drift, latency/jitter, and controlled error rates so client tests can verify resilience and schema-compatibility via golden snapshots.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Mocking & Test Data Simulation', 'Build a minimal mock OpenID Connect provider that serves a .well-known discovery document and a rotating RS256 JWKS, and generates signed ID tokens for a set of fixture users. Include a verifier script that fetches the JWKS over HTTP and validates tokens before and after a key rotation, ensuring expired/old-key tokens fail and newly issued tokens pass.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Mocking & Test Data Simulation', 'Create a spec-driven mock HTTP service that reads an OpenAPI 3.0 spec from /app/spec.yaml and deterministically generates synthetic responses from schema examples and constraints, with toggles for error injection, pagination, and rate limits. Include fixtures and a test harness that validate a client’s handling of boundary values, idempotency keys, and retry/backoff behavior using only the mock service.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Mocking & Test Data Simulation', 'Implement a local S3-compatible mock server that supports CreateBucket, PutObject, GetObject, and ListObjects while simulating eventual consistency and fault injection (configurable latency, transient 500s, and delayed listings). Provide fixtures that generate synthetic objects with edge-case keys and varied payload sizes, and emit structured logs to validate client retry/backoff and read-after-write behavior.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Mocking & Test Data Simulation', 'Implement a local mock payment gateway and webhook relay that mimics Stripe-style semantics: create/confirm payment intents, idempotency-key enforcement, HMAC-signed webhooks with rotating secrets, and deterministic fake card numbers that trigger specific error paths. Provide a seedable synthetic data generator and runtime toggles to simulate latency, network flakiness, 3DS challenge flows, rate limits, and partial outages to validate client robustness.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Static Analysis & Linting', 'Configure a Python+TypeScript monorepo to enforce strict static analysis: mypy --strict (with custom stub packages for a vendored library), flake8 with a custom plugin forbidding naive datetime usage, and ESLint/TypeScript rules requiring explicit return types. Refactor the codebase to eliminate all violations, wire the tools into pre-commit and a CI script that produces /app/lint_report.json and fails on any new issues.', NULL, ARRAY['python', 'typescript']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Static Analysis & Linting', 'Create and integrate a custom Flake8 plugin that flags timezone-naive datetime usage, mutable default arguments, and broad exception handlers in a small Python repo. Configure pyproject.toml so flake8 (with the plugin) and mypy --strict both run clean after refactoring the code to satisfy all checks.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Static Analysis & Linting', 'Implement a custom Flake8 plugin that flags calls where the return value of any function decorated with @must_use is ignored, emitting code MUU100 at the call site. Register the plugin and provide a script that runs flake8 on /app/src and writes a SARIF report to /app/lint.sarif.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Static Analysis & Linting', 'Implement a custom flake8 plugin that flags functions and methods using mutable default arguments (lists, dicts, sets, and comprehensions), supporting per-line noqa and exemptions for dataclasses field(default_factory=...). Integrate it via setup.cfg, run it over a small Python package with seeded violations, and make the codebase pass with a combination of fixes and justified ignores.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Static Analysis & Linting', 'Set up a cross-language lint/type pipeline for a Python+TypeScript monorepo using mypy (strict), flake8, and ESLint with typescript-eslint, plus custom analyzers that compare an OpenAPI spec to implemented HTTP routes to flag missing or undocumented endpoints. Integrate via pre-commit and a make lint target that emits a single consolidated JSON report and exits nonzero on any violations.', NULL, ARRAY['python', 'typescript']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Unit & Integration Test Implementation', 'Create a comprehensive pytest test suite for a cron expression parser and scheduler, including unit tests for ranges/steps/lists, W/L/# modifiers, invalid inputs, and timezone/DST edge cases, plus property-based tests that verify monotonic and gap-free next_run sequences. Add integration tests that exercise the CLI with stdin/files to validate output formatting, error messages, and exit codes, targeting at least 90% line and branch coverage.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Unit & Integration Test Implementation', 'Implement unit and integration tests with pytest, pytest-asyncio, and Hypothesis for an asyncio WebSocket chat server skeleton, verifying message routing, rate limiting, heartbeat timeouts, and graceful disconnects. Tests must spin up the server on localhost, connect multiple clients concurrently, assert broadcast ordering and backpressure handling, and run deterministically without external network access.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Unit & Integration Test Implementation', 'Implement unit tests for a timezone-aware recurring event scheduler to verify next_occurrence and occurrences_between across DST forward/back transitions, month-end rollovers, and timezone changes using IANA zoneinfo and frozen time. Add integration tests that run the provided CLI against a fixtures.yaml of recurrence rules to assert deterministic outputs and round-trip serialization across multiple timezones.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Unit & Integration Test Implementation', 'Write a comprehensive pytest + Hypothesis suite for an existing Python CRDT library (e.g., LWW-Element-Set and OR-Map) that verifies merge algebra (commutativity, associativity, idempotence), serialization round-trips, and tombstone semantics. Tests should generate randomized concurrent operation sequences across multiple replicas, simulate partitions and merges, and assert eventual consistency and order-independence in end-to-end scenarios.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Software Engineering & Development', 'Testing, Validation & Quality Assurance', 'Unit & Integration Test Implementation', 'Write unit and integration tests for an existing Python resumable chunked downloader and its `fetch` CLI using pytest (and pytest-asyncio), mocking filesystem and network layers and spinning up a local HTTP server for end-to-end flows. Verify checksum validation, HTTP range-request handling, resume-after-interrupt via SIGINT/SIGTERM, and atomic file moves, enforcing at least 90% coverage.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Configure the AWS CLI to use a named profile that obtains credentials via credential_process from a local Python helper and auto-assumes a role, with region/output defaults set. Point S3 and STS to LocalStack endpoints so offline aws sts get-caller-identity and aws s3api list-buckets work using that profile.', NULL, ARRAY['aws', 'python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Install Google Cloud SDK and create two named gcloud configurations (dev and prod) using provided service account key files in /app/keys, setting distinct default project IDs and compute regions/zones for each. Activate each config in turn, initialize Application Default Credentials from its key, and verify the active account, project, and ADC source switch correctly between dev and prod.', NULL, ARRAY['cloud']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Install and configure AWS CLI, gcloud SDK, and Azure CLI to target local emulators (LocalStack for AWS, fake-gcs-server for GCP, and Azurite for Azure), creating named profiles and endpoint overrides so storage commands work offline. Verify by creating a bucket/container in each emulator and listing them via the respective CLIs using the configured profiles.', NULL, ARRAY['aws', 'azure', 'gcp', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Install and configure AWS CLI, gcloud, and Azure CLI to target local emulators (LocalStack for AWS, Pub/Sub emulator for GCP, and Azurite for Azure) with offline credentials, named profiles/projects/subscriptions, and endpoint overrides so basic list/describe commands succeed without internet. Ensure defaults (region/output) are set and all configs reside in the standard dot-directories for each CLI.', NULL, ARRAY['aws', 'azure', 'gcp']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Cloud CLI Setup', 'Install and configure AWS CLI, gcloud, and Azure CLI to use local emulators (LocalStack, gcloud Pub/Sub emulator, and Azurite) with isolated named profiles and custom endpoints, persisting settings in the standard credential/config files. Validate by switching profiles and creating a test S3 bucket, Pub/Sub topic/subscription, and Azure Blob container, then listing them to confirm connectivity.', NULL, ARRAY['aws', 'azure', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Provision a bastion and an internal SSH service, create OpenSSH user and host CAs, and configure both servers to accept only CA-signed keys (password auth off), installing host certificates and @cert-authority entries in known_hosts. Add a client ~/.ssh/config with ProxyJump so ''ssh internal-via-bastion'' works, verify scp through the jump, and demonstrate a local port forward (15432 -> internal:5432) established via the bastion.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Provision two OpenSSH servers (bastion and private) on an isolated network and configure the client to reach the private host only via the bastion using ProxyJump with per-host identities in ~/.ssh/config. Disable password authentication, hash and pin host keys in known_hosts, block direct access to the private host, and verify by copying a file and executing a remote command through the jump while confirming direct SSH to the private host fails.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Provision two local OpenSSH daemons as a bastion (port 2222) and an internal host (port 2223), create an SSH CA, sign both host keys and a user certificate, and configure the servers to accept only CA-signed certs (no passwords or raw public keys). Configure the client with @cert-authority and hashed known_hosts plus a ~/.ssh/config using ProxyJump and ControlMaster to reach the internal host via the bastion, verifying SSH and SCP work with StrictHostKeyChecking=yes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Provision two local OpenSSH servers representing a bastion (port 2222) and an internal host (port 2223). Configure certificate-based SSH using a user CA and a host CA, disable passwords, require ProxyJump through the bastion, pre-populate known_hosts with @cert-authority entries, and verify that a single ssh command using the signed client key reaches the internal host via the bastion and creates /tmp/ok.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Remote Session & SSH Configuration', 'Stand up two local sshd instances (bastion on one port, app on another), configure ProxyJump through the bastion, and implement OpenSSH certificate-based auth by creating a user CA to sign the client key and a host CA to sign the app host key; configure sshd and the client with hashed known_hosts using @cert-authority for non-interactive trust. Verify that connecting to the app via the bastion works passwordlessly without host-key prompts and that access breaks when certs expire or principals don’t match.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Launch a LocalStack instance and use Terraform to provision an S3 bucket, an SQS queue, and a least-privilege IAM user/policy, wiring S3 ObjectCreated notifications to the queue. Configure awscli with the issued credentials, upload a test object, and consume the resulting queue message to validate the end-to-end flow.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Provision an AWS-like event ingestion pipeline on LocalStack via CLI/IaC: create an S3 bucket (versioning + SSE), an SNS topic, an SQS queue with DLQ, and an IAM user restricted to a specific S3 prefix. Wire S3 ObjectCreated notifications S3→SNS→SQS and verify by uploading with the new credentials and receiving the resulting queue message.', NULL, ARRAY['aws']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Provision an AWS-like stack on LocalStack using Terraform: an S3 bucket with versioning and SSE, an SNS topic, and an SQS queue subscribed to the topic via least-privilege IAM policies and resource tags. Configure AWS CLI to target LocalStack and demonstrate end-to-end by uploading to S3, publishing to SNS, verifying the message in SQS, and exporting a JSON summary of created ARNs.', NULL, ARRAY['aws']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Start a LocalStack container and use Terraform to provision an SNS topic, an SQS queue with a dead-letter queue, and a subscription connecting the topic to the queue. Publish a test message and verify delivery by consuming it from the queue via the AWS CLI.', NULL, ARRAY['container', 'aws']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Cloud & Remote Environment Configuration', 'Resource Provisioning & Management', 'Use Terraform against LocalStack to provision an S3→SNS→SQS event pipeline: a versioned bucket that publishes object-created events to an SNS topic with an SQS subscription and a dead-letter queue. Validate by uploading a test object via awscli, reading the event from SQS, and demonstrating DLQ redrive behavior.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Create an LVM volume group on a loopback disk with an ext4 logical volume mounted at /mnt/data, and implement consistent backups by taking read-only LVM snapshots before each run. Configure a systemd service/timer that uses rsync --link-dest to maintain 7 rotating daily backups in /srv/backups, then demonstrate recovery by restoring a file from a previous snapshot.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Deploy a local MinIO S3 service and configure restic with repository encryption to back up /app/data using exclude patterns, tags, and a scheduled cron job enforcing a retention policy (keep 7 daily, 4 weekly, 12 monthly). Perform initial and follow-up backups with file changes, run forget/prune, then restore a specific snapshot to /app/restore verifying checksums and that no plaintext filenames exist in the repository.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Install and configure BorgBackup to create encrypted, deduplicated snapshots of /data into a local repository at /backups/borg with an hourly systemd timer and a retention policy of 7 daily, 4 weekly, and 6 monthly snapshots, followed by a repository integrity check. Demonstrate correctness by modifying and deleting sample files, restoring a chosen snapshot to /restore, and verifying contents and that prune retained the requested generations.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Install and configure rsnapshot to perform rotating, hard-link-based backups of /etc and /srv/data to /backup/rsnapshot with retentions hourly:6, daily:7, weekly:4 and excludes for logs/cache, scheduled via cron. Verify by modifying files, running backups, confirming deduplication through hard-link counts across snapshots, and restoring a deleted file to its original location.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Backup & Snapshot Management', 'Set up two loopback-backed btrfs filesystems mounted at /srv/src and /srv/backup, create a /srv/src/data subvolume, and automate hourly read-only snapshots named snap-YYYYMMDDHH with pruning to the latest 6 plus incremental btrfs send/receive mirroring to /srv/backup, logging to /var/log/btrfs-backup.log. Verify recovery by deleting a file in /srv/src/data and restoring it from the newest snapshot on the backup target.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Create a 3 GiB sparse file as a loop device, partition it with GPT into two volumes (512 MiB ext4 labeled DATA and the remainder as a LUKS-encrypted XFS labeled SECRET) and set proper labels/UUIDs. Configure /etc/crypttab and /etc/fstab to unlock and mount them at /mnt/data and /mnt/secret by UUID, then verify persistence by detaching/reattaching the loop device and remounting without using device paths.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Create a 3GB sparse disk image, attach it as a loop device, and partition it with GPT into a small unencrypted FAT32 partition and a LUKS2-encrypted data partition containing an LVM PV/VG/LV formatted as ext4. Mount the LV at /mnt/secure with restrictive options and persist the configuration via /etc/crypttab and /etc/fstab using UUIDs/labels, verifying it remounts correctly after detaching and reattaching the loop device.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Create a GPT-partitioned loopback disk, build an LVM-on-LUKS stack on one partition, and mount the decrypted logical volume at /srv/secure with persistent /etc/crypttab and /etc/fstab entries using UUIDs and a root-only keyfile. Demonstrate that after detaching and reattaching the loop device the volume auto-opens and mounts non-interactively, preserving data.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Provision a 3 GiB loopback disk image and partition it with GPT into: 512 MiB EFI System (vfat, label EFI), 2 GiB Linux filesystem (ext4, label DATA), and the remainder as Linux swap. Format and label each partition, mount EFI at /mnt/efi and DATA at /mnt/data, enable swap, and persist the setup using PARTUUID-based entries in /etc/fstab so all mounts reattach correctly after unmounting and remounting.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Disk Partitioning & Mounting', 'Provision an encrypted LVM-on-LUKS volume backed by a sparse loop device: create a GPT partition on the loop device, initialize it with LUKS using a keyfile, build a VG with two LVs (data and logs), format, and mount at /srv/secure/{data,logs}. Persist the setup via /etc/crypttab and /etc/fstab using UUIDs so it can be unlocked and mounted non-interactively and verified with mount -a after reattaching the loop device.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Create a loopback-backed XFS filesystem mounted at /mnt/projects with pquota enabled and configure project quotas for two directories (/mnt/projects/build-cache and /mnt/projects/datasets) via /etc/projid and /etc/projects, setting soft/hard limits of 500MB and 1GB with a 7-day grace period. Apply setgid and default ACLs so group ''research'' has rwx on both trees, then verify quota enforcement with xfs_quota reports and writes that exceed the limits.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Create a loopback-backed XFS filesystem mounted at /srv/projects with project quotas (prjquota) enabled, defining two directory-scoped projects via /etc/projects and /etc/projid with distinct soft/hard limits, and configuring setgid plus default ACLs for collaborative inheritance. Verify enforcement by filling each project until soft/hard limits and grace periods trigger, confirming with xfs_quota reports and observed EDQUOT failures.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Create a loopback-backed XFS volume mounted at /mnt/projects with project quotas enabled, defining project IDs for team-a (200 MiB) and scratch (50 MiB) and enforcing hard limits. Configure a shared dir with setgid and default POSIX ACLs for group inheritance, a scratch dropbox with the sticky bit, and a logs dir marked append-only via chattr, then verify quota and permission behavior with automated writes.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Provision a loopback-mounted XFS filesystem at /mnt/projects with prjquota enabled, bind project ''projA'' to /mnt/projects/projA via /etc/projid and /etc/projects, and enforce an 80MB soft/100MB hard project quota (7-minute grace) using xfs_quota with persistence in /etc/fstab. Validate enforcement by writing data as multiple users and confirming over-limit writes are denied.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Filesystem & Storage Management', 'Filesystem Permissions & Quotas', 'Provision an XFS filesystem on a loopback device mounted at /mnt/studio with prjquota enabled, configure a project quota that caps /mnt/studio/assets at 1 GiB via /etc/projects and xfs_quota, and set per-user soft/hard quotas for alice and bob. Enforce collaborative permissions by applying setgid, sticky bit, and default ACLs for the ''artists'' group, demonstrate chattr +i on a file, and verify quota/permission enforcement with xfs_quota and failed writes.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure a host-wide nftables firewall with default-drop policy using inet and ip6 tables: allow established/related, loopback, necessary ICMP/ICMPv6 (ND, RA, RS, PTB), and open SSH (22) and HTTP (8080) only on IPv4, with rate-limited new connections. Make the rules persistent across reboots and enable logging of dropped packets to /var/log/nftables-drop.log; verify IPv4 HTTP works while IPv6 HTTP is blocked and ICMPv6 neighbor discovery still functions.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure iptables to implement a three-step port knocking sequence (4001 → 4002 → 4003 within 10s) that temporarily opens SSH (port 22) only for the knocking source, while default-denying inbound and allowing established/related traffic. Persist the rules across reboots and verify SSH is blocked before knocking, opens after the sequence, and relocks after a timeout.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure iptables-based port knocking that keeps SSH (port 22) closed by default and opens it for 60 seconds only to the knocking client after a correct sequence on three high ports. Enforce a default-deny inbound policy, add logging for knock attempts, and verify both denial without knocking and successful SSH after the sequence.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure nftables to enforce a default-deny host firewall with stateful rules. Allow loopback/established traffic, port-forward 80→8080 to a local service, restrict SSH on 2222 to 10.0.0.0/24 with rate limiting, block outbound SMTP except to smtp.example.net, log drops with prefix TB-FW, ensure persistence across reboots, and verify behavior over IPv4/IPv6 with curl/nc tests.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Firewall & Security Rules', 'Configure nftables to enforce a host firewall with default drop on inbound traffic, allowing established/related and loopback, permitting HTTP/HTTPS to a local nginx, and opening SSH only after a correct 3-step UDP port-knock (1111→2222→3333 within 10s) with rate-limited access. Make the rules persistent across reboots and include a verification script that demonstrates SSH is closed before knocking, opens for 30 seconds after the sequence, then automatically closes again.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Interface & IP Configuration', 'Configure a dual-homed Linux host where eth0 uses DHCP and eth1 has a static 192.168.50.2/24; add policy-based routing so traffic sourced from 192.168.50.0/24 uses gateway 192.168.50.1 while all other traffic uses the DHCP default route. Set per-domain DNS with systemd-resolved so queries to corp.local use 192.168.50.53 via eth1, ensuring settings persist across reboots with netplan.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Interface & IP Configuration', 'Using iproute2 and network namespaces, build a routed lab with three namespaces (hostA, router, hostB): create veth links, assign static IPv4/IPv6, configure per-namespace DNS via a dnsmasq bound to the router, add policy-based routing and default routes, enable IPv4 forwarding/NAT on the router, and verify end-to-end connectivity and name resolution.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Build a three-namespace topology (client–router–server) with mismatched MTUs and ICMP “Fragmentation Needed” filtered, then diagnose a stalled TCP connection using tracepath/ping and tcpdump to pinpoint a PMTU blackhole. Fix the issue by permitting ICMP or enabling TCP MSS clamping and verify successful HTTP transfer end-to-end.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Create a three-namespace topology (client-router-server) where the router drops ICMP Fragmentation Needed, producing a PMTU blackhole that causes HTTPS requests to hang. Use ping with DF, traceroute, and tcpdump to confirm the issue, then fix it by enabling TCP MSS clamping (or lowering MTU) on the router and verify curl completes successfully.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Create three network namespaces (client, router, server) linked by veth; drop ICMP ''Fragmentation Needed'' on the router to simulate a PMTU black hole that causes HTTP transfers to hang. Diagnose with ping -M do, traceroute, ss, and tcpdump, then fix by enabling TCP MSS clamping on the router and verify a large curl from client to server succeeds.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Diagnose and fix stalled large file downloads caused by PMTU blackholing: use tcpdump, tracepath, and curl to confirm ICMP “Fragmentation Needed” is being dropped and that the interface MTU is misconfigured. Restore connectivity by allowing the required ICMP through iptables and/or clamping TCP MSS, then verify the transfer completes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Networking & Connectivity', 'Network Diagnostics & Debugging', 'Simulate and diagnose a path MTU black hole using Linux network namespaces by creating a multi-hop topology with mismatched MTUs and blocking ICMP “Fragmentation Needed,” causing large TCP transfers to stall. Use ping with DF, traceroute, tcpdump, and curl to pinpoint the issue, then fix it by allowing ICMP or applying TCP MSS clamping and verify sustained transfers succeed.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Environment Variables & Profiles', 'Create a layered cross-shell environment configuration that defines APP_ENV=staging and prepends /opt/tools/bin to PATH without duplicates via /etc/profile.d/bench.sh (interactive shells) and ~/.config/environment.d/bench.conf (session-wide). Ensure these variables appear in login and non-login shells, ssh commands, a cron job for user ''bench'', and a systemd --user service, while interactive-only prompt changes do not affect scripts.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Environment Variables & Profiles', 'Create a unified environment manager that reads variables and PATH entries from ~/.config/envvars.yaml and generates shell-agnostic snippets sourced by both Bash and Zsh for login, non-login, interactive, and non-interactive sessions. Provide an envsync command to rebuild the snippets and verify PATH precedence, LANG/LC_ALL, and HTTP(S)_PROXY/NO_PROXY persist across new shells and subprocesses.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Environment Variables & Profiles', 'Install and configure direnv for both bash and zsh by adding the required shell hooks to the correct profile files so it runs in interactive sessions. Create a project directory with an .envrc that exports custom variables (e.g., APP_ENV, LOG_LEVEL), prepends ./bin to PATH, optionally activates a Python virtualenv if present, and verify the environment loads only inside the directory after direnv allow and unloads on exit.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Environment Variables & Profiles', 'Install and configure direnv globally for bash and zsh, then create /app/project with an .envrc that adds /app/bin to PATH, sets APP_ENV=dev and API_URL, and activates a Python virtualenv via layout python. Verify that entering and leaving /app/project automatically loads/unloads the environment in both shells after direnv allow, while non-project shells remain unaffected.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Environment Variables & Profiles', 'Install direnv and integrate it system-wide for both bash and zsh via /etc/profile.d so it loads automatically for all users. Create /srv/project with a .envrc that exports APP_ENV=staging, prepends /opt/tools/bin to PATH, sets PYTHONPATH, and verify as user dev that entering/leaving the directory auto-loads/unloads these variables.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Process & Resource Management', 'Create a cgroups v2-backed systemd slice (tb-limited.slice) enforcing CPUQuota and MemoryMax, run a resource-hungry service (e.g., stress-ng via tb-hog.service) within it, and schedule it with a systemd timer that adds a randomized delay. Verify enforcement by observing throttling/OOM-kill behavior, automatic restarts, and corroborating logs via journald and systemd-cgtop.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Process & Resource Management', 'Create a dedicated cgroup v2 slice (batch.slice) and a templated systemd service (batch@.service) that runs a CPU/memory-intensive script under strict limits (CPUAffinity to specific cores, CPUQuota=25%, MemoryMax=150M, TasksMax=32) with automatic restart on OOM. Trigger it via a systemd timer every 2 minutes and verify via cpu.stat/memory.events that throttling and OOM handling occurred, with logs persisted to /var/log/batch/.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Process & Resource Management', 'Create a sandboxed systemd service and timer that runs a worker script under cgroups v2 with CPUQuota=40%, MemoryMax=200M, CPUAffinity pinned to one core, TasksMax, and hardening options (NoNewPrivileges, PrivateTmp, ProtectSystem=strict), logging to both the journal and /var/log/worker.log. Enable and verify the limits by starting the unit, inspecting cgroup metrics, and demonstrating the timer’s persistence and randomized delay.', 'hard', ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Process & Resource Management', 'Create a systemd slice and templated service constrained by cgroup v2 (e.g., CPUQuota and MemoryMax) and trigger it via a Persistent=true systemd timer to run periodic batch jobs. Verify scheduled execution, enforced resource limits, automatic restart-on-failure behavior, and logs accessible with journalctl.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'Process & Resource Management', 'Define and enable a custom systemd slice (bench.slice) with cgroup v2 limits (CPUQuota=40%, MemoryMax=512M) and a service (bench-workload.service) bound to it that runs a CPU/memory stress script with Restart=always and hardened sandboxing. Add a systemd timer to schedule the workload every 5 minutes, log output to /var/log/bench-workload.log, and verify enforcement by inspecting cgroup stats for CPU throttling and memory limits.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'System Parameters & Kernel Settings', 'Configure persistent kernel core dump handling by setting kernel.core_pattern to pipe to a custom collector script that stores and compresses cores under /var/lib/cores with metadata. Create and enable a systemd service that runs a small crashing test binary with LimitCORE=infinity to verify capture and persistence across reboots.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'System Parameters & Kernel Settings', 'Configure system-wide core dump handling by setting kernel.core_pattern to pipe crashes into a custom /usr/local/bin/core_collector that compresses dumps under /var/cores with metadata, and disable systemd-coredump while enforcing fs.suid_dumpable=0. Persist ulimit core=0 for all users except a dedicated systemd service that overrides to unlimited, then verify by crashing a test binary from both contexts and confirming only the service produces a compressed core in /var/cores.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'System Parameters & Kernel Settings', 'Enable compressed swap-on-RAM (zram) with a persistent swap device sized to 50% of system memory, tune vm.swappiness=80 and vm.vfs_cache_pressure=200 via /etc/sysctl.d, and disable Transparent Huge Pages at boot. Verify the settings persist and that zram is active in /proc/swaps and THP shows "never" in sysfs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Operating System Configuration', 'System Parameters & Kernel Settings', 'Persistently harden and tune the kernel by setting sysctl values via /etc/sysctl.d (disable unprivileged user namespaces and BPF, restrict dmesg, enable TCP syncookies, increase somaxconn and inotify limits) and raise per-user nofile/nproc ulimits via /etc/security/limits.d. Verify live and persistent effect with sysctl and ulimit checks after reloading settings and starting a fresh shell.', 'hard', ARRAY['security']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Log Monitoring & Service Debugging', 'Create a socket-activated systemd service (myapp.socket/myapp.service) for a simple HTTP server that initially fails to start, enable persistent journald storage, and use journalctl to pinpoint the root causes (bad WorkingDirectory and missing RuntimeDirectory). Correct the unit (User/Group, WorkingDirectory, RuntimeDirectory, LimitNOFILE), set journald rate limiting, and verify the socket serves 127.0.0.1:8080 with clean, non-repeating logs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Log Monitoring & Service Debugging', 'Create a systemd service and timer that runs a backup script every minute, where the initial run fails due to a missing WorkingDirectory and permission errors. Use journalctl to diagnose the failures, fix the unit (User/Group, WorkingDirectory/RuntimeDirectory, ExecStart), and verify via logs that subsequent timer invocations complete successfully with stdout/stderr captured in journald.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Log Monitoring & Service Debugging', 'Debug a crash-looping systemd service ''img-resizer.service'' by inspecting journald and its app logs to pinpoint failures caused by PrivateTmp and a missing RuntimeDirectory (socket at /tmp/img.sock and unwritable log path). Fix the unit to use /run/img-resizer via RuntimeDirectory=, correct User/Group and dependencies, reload systemd, and confirm the service stays active and the UNIX socket handles a test request.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Log Monitoring & Service Debugging', 'Debug a systemd unit ''imgsvc.service'' that crash-loops on startup: journald reveals ''listen tcp :80: bind: permission denied'' and write failures due to DynamicUser=yes. Update the unit to grant AmbientCapabilities=CAP_NET_BIND_SERVICE and define a RuntimeDirectory with correct permissions, then verify it binds to 0.0.0.0:80 and runs cleanly with logs visible in journald.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Log Monitoring & Service Debugging', 'Investigate a failing systemd unit (myapp.service) for a Gunicorn-backed Python web app that repeatedly restarts; use journalctl and the app’s error logs to identify an invalid WorkingDirectory and a missing EnvironmentFile. Fix the unit via a systemd drop-in (correct ExecStart/WorkingDirectory, EnvironmentFile, User, Restart policy), enable persistent journald with size limits, then verify with curl that the service stays active and logs show a 200 response without rate-limit warnings.', NULL, ARRAY['python', 'web']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Service Installation & Setup', 'Install Prometheus and node_exporter as system services, configure Prometheus to scrape node_exporter and itself on localhost, and ensure both start on boot. Verify successful scraping by querying Prometheus’s HTTP API for the up metric and confirm it returns 1 for both targets.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Service Installation & Setup', 'Install Prometheus and node_exporter as systemd services, configure Prometheus (/etc/prometheus/prometheus.yml) to scrape node_exporter on localhost:9100 every 5s with a custom external_label and 1h retention. Enable and start both services, then verify the target is UP via the Prometheus HTTP API and that metrics are served at http://localhost:9100/metrics.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Service Installation & Setup', 'Install and configure MinIO as an S3-compatible object storage service with a self-signed TLS certificate, listening on 0.0.0.0:9443 and managed via systemd. Create an admin user and a test bucket with a read-only policy, configure AWS CLI to use the endpoint, and verify by uploading and retrieving a file.', NULL, ARRAY['aws']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Service Installation & Setup', 'Install and configure OpenLDAP (slapd) with a base DN (dc=tb,dc=local), enabling StartTLS on 389 and LDAPS on 636 with a self-signed certificate, plus the memberOf/refint overlays and proper indexing. Create an OU and a test user with a salted hashed password, run slapd in the background, and verify authenticated ldapsearch/ldapmodify operations over TLS return expected entries.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Service Installation & Setup', 'Install and configure the Mosquitto MQTT broker with plaintext (1883) and TLS (8883) listeners, password-based authentication, and persistence managed via systemd. Generate a self-signed certificate, enable the service on boot, and verify pub/sub functionality using mosquitto_pub and mosquitto_sub over both transports.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Systemd & Init Configuration', 'Create a socket-activated, templated systemd service (echo@.service) that spawns per-connection Python echo handlers from echo.socket on 127.0.0.1:9999 (Accept=yes), running under DynamicUser with hardening and network-online dependencies. Add a non-root user-level timer (with lingering enabled) that health-checks the socket every minute and configure persistent journald logs to verify on-demand startup and successful checks.', 'hard', ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Systemd & Init Configuration', 'Create a socket-activated, templated systemd service (echo@.socket/echo@.service) for a tiny Python HTTP echo server that runs as an unprivileged user and starts on-demand when connections arrive, with instances bound to ports via the instance name. Enable sockets for ports 8081 and 9091, ensure After=network-online.target with basic hardening, and verify curl requests trigger the service and return a response while logs appear in journald.', 'hard', ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Systemd & Init Configuration', 'Create a socket-activated, templated systemd service that spawns per-connection instances of a tiny Python HTTP responder via Accept=yes on port 8080 using the inherited socket (fd 3). Verify on-demand activation with curl, that each instance exits after one request, and enable the socket to start at boot.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Systemd & Init Configuration', 'Implement a socket-activated, per-connection systemd service (using a .socket and a templated .service) that runs a minimal HTTP echo server bound to 127.0.0.1:8085 with DynamicUser and strict sandboxing. Validate that a curl request triggers on-demand startup, serves a response, then the service stops after an idle timeout while the socket remains listening.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Service & Daemon Management', 'Systemd & Init Configuration', 'Implement a systemd socket-activated, per-connection echo service: echo.socket listens on 127.0.0.1:12345 with Accept=yes, and echo@.service (Type=simple, StandardInput/Output=socket) runs /bin/cat with DynamicUser and strict sandboxing. Enable the socket, verify with nc 127.0.0.1 12345 that input is echoed, and confirm each connection spawns and exits a separate instance recorded in the journal.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Dependency Verification & Repair', 'Diagnose and repair a system with corrupted shared libraries and an interrupted apt/dpkg transaction by verifying package integrity with debsums and fixing the broken package state. Reinstall only the affected packages, refresh the dynamic linker cache, and verify the repair with a successful HTTPS curl and a Python ssl import.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Dependency Verification & Repair', 'Diagnose and repair missing 32-bit runtime libraries for a provided 32-bit ELF binary (/app/bin/hello32) by enabling i386 multiarch on Debian/Ubuntu, installing required :i386 packages (e.g., libc6, libstdc++6, libgcc-s1), and refreshing the linker cache. Prove the fix by ensuring ldd shows no "not found" entries, the binary executes successfully, and saving the resolved ldd map to /app/output/ldd-hello32.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Dependency Verification & Repair', 'In a Debian-based container with mixed-release APT sources and a corrupted dpkg status (half-installed/half-configured packages), restore the package manager to a healthy, consistent ''stable'' state by fixing the dpkg database, correcting sources, resolving pinned/held packages, and repairing dependency conflicts. Validate by achieving a clean apt-get check/apt-get -f install run and successfully using curl to fetch an HTTPS URL with system OpenSSL.', NULL, ARRAY['container', 'database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Dependency Verification & Repair', 'Recover a Debian/Ubuntu system from an interrupted apt upgrade that left dpkg in a broken state by repairing the package database, clearing partial installs, and resolving held/unmet dependencies with correct version pinning. Validate the fix by installing and running a provided CLI that initially fails due to missing libssl/libffi SONAMEs, ensuring compatibility libraries are installed properly without manual symlinks.', NULL, ARRAY['database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Dependency Verification & Repair', 'Resolve a C++ runtime symbol version mismatch by installing a compatible libstdc++ (e.g., GLIBCXX_3.4.26+) on a Debian-based system where a precompiled binary fails with ''version GLIBCXX_3.4.26 not found''. Configure apt pinning/backports to upgrade only libstdc++6 and required dependencies without a full dist-upgrade, then validate the binary runs and ldd shows no unresolved symbols.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Package Installation & Removal', 'Configure APT pinning to add Debian testing with low priority, then install only neovim (>=0.9) from testing while keeping the rest of the system on stable, removing any vim* packages and setting nvim as the default vi/editor via update-alternatives. Place neovim on hold to prevent unintended upgrades and verify pinning/hold status with apt-cache policy and apt-mark.', NULL, ARRAY['testing', 'rest']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Package Installation & Removal', 'Create a GPG-signed local APT repository served over HTTP, build and publish a hello-terminal-bench .deb to it, add the repository to sources.list with its key, then install the package using apt. Finally, remove and purge the package and verify its maintainer scripts executed by logging to a known file.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Package Installation & Removal', 'Create a signed local APT repository under /srv/apt (using apt-ftparchive or reprepro), add it to sources.list.d with its GPG key, and install a provided custom .deb from it. Then remove the package, revoke the repo by removing the key and source, run apt clean/update, and verify the package is no longer available.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Package Installation & Removal', 'Enable multiarch on a Debian/Ubuntu system to install side-by-side i386 and amd64 variants of selected libraries (e.g., libssl and zlib), pin the exact versions, and validate via dpkg-query that both architectures are present. Then purge the i386 variants, remove the version holds, disable multiarch, and confirm apt autoremove leaves no residual dependencies.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Package Installation & Removal', 'Set up a signed local APT repository hosting a dummy hello-bench .deb and configure apt to trust and prefer it via pinning. Install hello-bench from the local repo, then remove and purge it, verifying with apt-cache policy and dpkg status that the correct source and state transitions occurred.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Repository Configuration', 'Build and serve a local APT repository containing a trivial hello-world .deb; generate a GPG key, sign the Release, and add a deb822 .sources entry using signed-by in /usr/share/keyrings. Pin priorities so only hello-world resolves from the local repo while all other packages come from the default sources, and verify via apt-cache policy and installation.', NULL, ARRAY['installation']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Repository Configuration', 'Create a custom DNF/YUM repository from a local directory, generate a new GPG key, sign both RPMs and repodata, and publish it via nginx. Add the repo with repo_gpgcheck=1, gpgcheck=1, and a dedicated keyring, set repo priority to prefer only one named package from it, then verify installs succeed only when signatures are valid and the unsigned variant is rejected.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Repository Configuration', 'Create a local APT repository at /repo, serve it over HTTPS via nginx, and sign its Release/InRelease files with a newly generated GPG key; publish and index a minimal hello-world .deb. Add the repo to apt sources using signed-by, confirm apt update and package installation succeed, then demonstrate that altering the signed metadata causes apt to refuse the repo until the correct signature/key is restored.', NULL, ARRAY['installation']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Repository Configuration', 'Create a locally hosted, GPG-signed APT repository (served on localhost) containing a provided .deb, add it to sources using the signed-by option with a keyring in /usr/share/keyrings, and install the package from it. Demonstrate that apt rejects the repo before the key is configured and succeeds after the correct keyring is installed and referenced.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'Software & Package Management', 'Repository Configuration', 'Create a private, HTTPS APT repository on localhost using reprepro and nginx, sign it with a dedicated GPG key exported to /etc/apt/keyrings/bench-archive.gpg, and protect it with HTTP Basic Auth. Add a sources.list.d entry that uses signed-by and credentials from /etc/apt/auth.conf.d plus APT pinning to prefer this origin, then verify apt update and installing a test package come only from the signed repo.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Log Analysis & Troubleshooting', 'Create a CLI that parses /var/log (syslog, auth.log, kern.log, and rotated files) for the last 24h, normalizes PIDs/IPs/hex to cluster messages into error signatures, and ranks them by frequency. Produce /app/log_report.json and /app/log_report.txt summarizing each cluster with count, first/last timestamps, and inferred service to aid rapid fault isolation.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Log Analysis & Troubleshooting', 'Create a log-analysis utility that scans /var/log (including rotated *.1 and *.gz files) and journalctl for the last 24h to detect recurring SSH auth failures per IP, systemd crash/restart loops, kernel OOM/I/O/EXT4 warnings, and SMART/disk errors, outputting counts and first/last timestamps to /var/log/health/report.json. Schedule it via cron to run every 15 minutes, keep a 7-day rolling archive under /var/log/health/history/, and exit non-zero when thresholds are exceeded to flag incidents.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Log Analysis & Troubleshooting', 'Enable persistent journald storage and implement a CLI tool that scans the last 24 hours of logs (journalctl and /var/log/*) to produce /app/output/log_health.json summarizing recurring errors by service, kernel disk I/O/EXT4/SMART warnings, and top IPs for SSH auth failures. Add a systemd service+timer that streams logs and appends an alert to /app/output/alerts.log whenever more than 10 ''Failed password'' messages from the same IP occur within 5 minutes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Log Analysis & Troubleshooting', 'Enable persistent journald storage and implement a tool that parses the last 24h of system logs to detect flapping systemd services (restarts), recurring kernel I/O errors, and repeated SSH auth failures, aggregating them into /app/incident_report.json with counts and first/last timestamps. The tool must also emit a remediation checklist to /app/remediation.txt with per-issue hints (e.g., identify the failing unit, suggest RestartSec, highlight suspect devices/IPs).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Log Analysis & Troubleshooting', 'Enable persistent systemd-journal storage and implement a CLI tool that scans /var/log and journalctl for the last 24 hours, normalizes messages into signatures by stripping volatile fields, and ranks recurring errors while flagging previously unseen error types. Produce both a machine-readable JSON report and a concise human summary to guide troubleshooting of the top offenders.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Performance Tuning', 'Deploy Nginx to serve a large static file and record a baseline using a load generator (e.g., wrk). Tune worker and I/O settings (epoll, worker_processes auto, worker_connections, sendfile/tcp_nopush, open_file_cache, reuseport, directio for large files) to achieve at least a 50% throughput increase while keeping 99th percentile latency under a set target.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Performance Tuning', 'Implement PSI-aware memory tuning by enabling zram swap and adjusting vm.swappiness, min_free_kbytes, and dirty writeback thresholds to reduce contention under load. Drive concurrent memory pressure with stress-ng alongside a lightweight HTTP service and demonstrate improved p95/p99 latency and zero OOMs versus a baseline configuration.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Performance Tuning', 'Optimize a localhost Nginx static-file server for high concurrency and low latency by tuning Linux TCP/sysctl (e.g., somaxconn, tcp_max_syn_backlog, ip_local_port_range), file-descriptor limits, and Nginx worker settings (worker_processes, worker_connections, reuseport, sendfile). Provide a repeatable wrk/ab benchmark that records before/after throughput and p99 latency, demonstrating measurable improvement and saving results to /app/perf/results.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Performance Tuning', 'Use cgroup v2 (via systemd) to isolate a foreground web service from background CPU and disk contention by tuning cpu.max/cpu.weight, io.weight, and memory.high/memory.min. Induce load with stress-ng/fio and demonstrate improved p99 latency under wrk after tuning compared to a baseline.', NULL, ARRAY['web']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('System Setup & Configuration', 'System Monitoring & Diagnostics', 'Performance Tuning', 'Use cgroups v2 (via systemd slices) to constrain a CPU/memory‑intensive background workload while prioritizing a latency‑sensitive HTTP server, and tune kernel networking sysctls (somaxconn, tcp_fastopen) to improve accept throughput. Verify under sustained stress that the server maintains sub‑50 ms p95 latency over 1000 requests and that the batch workload cannot exceed its CPU/memory quotas.', NULL, ARRAY['networking']);
