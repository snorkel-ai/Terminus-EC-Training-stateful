-- Batch 5 of 8: Inserting tasks 801 to 1000

INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Computational Chemistry & Biology', 'Create a Python CLI that loads a molecular dynamics trajectory of liquid water (XYZ frames plus periodic box dimensions) and computes the O–O radial distribution function g(r), its first minimum, and coordination number (integral to the first minimum), as well as the self-diffusion coefficient from the mean-squared displacement under periodic boundaries. Write g(r) to /app/gofr.csv and a JSON report with the first-minimum position, coordination number, and diffusion coefficient to /app/results.json, verifying normalization and minimum image handling.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Computational Chemistry & Biology', 'Using COBRApy, load the provided SBML metabolic network, configure exchange reactions to model aerobic minimal media with glucose, and maximize biomass to compute the optimal growth rate. Then perform a single-gene deletion screen to identify essential genes under these conditions and write the growth rate and the sorted essential gene IDs to output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Build a 1D compressible gas dynamics solver for the Sod shock tube using a conservative finite-volume scheme (MUSCL-Hancock with HLLC flux and CFL control) from Riemann initial data, and write density/velocity/pressure profiles at specified times. Include a check that total mass and total energy are conserved to within a small tolerance.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Implement a 1D compressible Euler solver to simulate the Sod shock tube using a finite-volume Godunov scheme (e.g., HLLC) with CFL-controlled timestepping and positivity preservation. Output density, velocity, and pressure profiles at specified times and report L1 error against the analytic solution.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Implement a 1D finite-volume solver for the compressible Euler equations to simulate the Sod shock tube using an HLLC Riemann solver with a TVD slope limiter, exposing a CLI to set grid size and CFL and writing CSV profiles of density, velocity, and pressure at a target time. Validate conservation of mass/momentum/energy and achieve a small L1 error versus an exact Riemann solution computed by a provided routine.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Implement a 1D time-dependent Schrödinger equation solver using the split-operator Fourier method to simulate a Gaussian wavepacket scattering from a rectangular potential barrier. The CLI should sweep incident energies, compute reflection/transmission probabilities with norm conservation, and validate against the analytic transmission coefficient.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Physics & Engineering Simulation', 'Implement an Euler–Bernoulli beam finite element solver for a uniform clamped–clamped beam that assembles mass and stiffness matrices and computes the first three natural frequencies and mode shapes. Validate the frequencies against closed-form solutions within 2% and save frequencies and mode shapes to specified output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Implement a CLI tool that loads a dense or sparse matrix (CSV or Matrix Market) and computes a rank-k approximation using randomized SVD with configurable oversampling and power iterations, writing U, S, and V^T to standardized output files. Include a verification mode that compares top-k singular values and relative reconstruction error against SciPy’s svds on small matrices, enforcing a ≤1% gap in Frobenius-norm error to the reference.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Implement a Python CLI that loads A, B, C from /app/*.npy and solves A X B = C for X using factorization-based linear solves without forming the Kronecker product (e.g., via LU/QR and column/row reshaping), with an option for Tikhonov regularization. Save X to /app/output/X.npy and a metrics JSON including relative residual (target ≤ 1e-8) and simple condition estimates.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Implement a randomized SVD (Halko algorithm) with configurable rank, oversampling, and power iterations to compute a low-rank approximation of a large dense or sparse matrix loaded from disk. Compare to a deterministic truncated SVD by reporting singular values, relative Frobenius reconstruction errors, and timings in a results JSON, also saving the U,S,V factors.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Implement a randomized low-rank SVD with oversampling and configurable power iterations to compute the top-k singular values and vectors for large dense or sparse matrices via a CLI, benchmarking accuracy and runtime against NumPy/SciPy baselines. Validate orthonormality of U and V and relative reconstruction error, writing standardized outputs to files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Matrix & Vector Operations', 'Write a Python script that loads a sparse SPD matrix A from /app/A.mtx and a vector b from /app/b.npy, then solves Ax=b using preconditioned conjugate gradients with an incomplete factorization (ILU/IC) or Jacobi fallback. Save x to /app/x.npy and a JSON with iteration count, final relative residual, and wall time, ensuring ||A x − b||2 / ||b||2 ≤ 1e-8.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Build a Python CLI that integrates systems of ODEs defined by a JSON spec using an adaptive Dormand–Prince 5(4) solver with dense output and event/root detection, automatically switching to an implicit BDF method when stiffness is detected via step-rejection heuristics. The tool should write solution snapshots and event times to files and include a test harness that verifies accuracy and performance against SciPy.integrate on provided nonstiff and stiff problems.', NULL, ARRAY['python', 'performance']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Implement a Python CLI that performs 1D integration using tanh-sinh (double-exponential) quadrature with adaptive node refinement and error control to handle endpoint singularities. Use it to evaluate the integral of x^(-1/2) * log(x) over [0, 1] to at least 12 correct digits and write both the result and the function-evaluation count to /app/answer.json.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Implement a Python tool that loads a parameterized ODE and scalar loss from a problem module, integrates forward to produce state samples at given eval_ts, then computes dL/dθ via a reverse-time continuous adjoint solve with accurate interpolation of the forward trajectory. Output the trajectory and gradient along with a verification report that checks the adjoint gradient against central finite differences within a specified tolerance.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Implement an adaptive Gauss–Kronrod 21/10 quadrature with a best-first error priority queue that handles infinite limits and endpoint algebraic/log singularities via variable transformations, enforcing absolute/relative tolerances and a cap on function evaluations. The CLI loads an integrand from /app/integrand.py and a JSON spec of intervals and tolerances, then writes the integral, error estimate, and evaluation statistics to /app/output.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Numerical Integration & Differentiation', 'Implement an adaptive tanh-sinh (double-exponential) quadrature that handles endpoint singularities and infinite limits, returning integrals to specified absolute/relative tolerances while tracking function-evaluation counts. Provide a CLI that reads multiple integrals and intervals from input, computes results without external integration libraries, and writes both values and convergence traces.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Build a Jacobian-free Newton-Krylov solver with backtracking line search to find the steady state of the 2D Bratu (nonlinear Poisson) equation on an N×N grid. The CLI should accept N and lambda, converge to a specified residual tolerance using GMRES with simple preconditioning, and write the solution field and an iteration/residual log to disk.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Build a sparse primal–dual interior-point solver for linear programs in standard form (Mehrotra predictor–corrector with adaptive step and iterative refinement) that loads A, b, c from /app/lp.npz and solves to ≤1e-7 KKT residuals. Write the optimal x, primal/dual residual norms, and objective to /app/output.json, and report infeasible/unbounded cases via a homogeneous self-dual start.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Build a terminal tool that solves a system of nonlinear equations using a Jacobian-free Newton–Krylov method (Newton-GMRES with backtracking line search), loading residual(x) and an initial guess from /app/problem.py. Stop when the 2-norm of the residual is ≤1e-8 or the time budget is hit, and write the solution vector plus iteration and GMRES stats to /app/solution.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Implement a command-line tool that computes the minimax (L-infinity) polynomial approximation of a given function on [a,b] using the Remez exchange algorithm, with optional weighting. Output the polynomial coefficients, the achieved uniform error, and the final set of alternation points to a results file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Optimization & Root Finding', 'Implement a primal-dual interior-point solver (Mehrotra predictor–corrector) for dense convex quadratic programs that reads H, f, A, b, G, h, and bound vectors from /app/problem.npz, uses a safeguarded line search with regularization, and drives the KKT residual below 1e-6. Output the primal and dual solutions, final duality gap, and residual norms to /app/output/solution.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Build a CLI tool that estimates logdet(A) for large sparse SPD matrices via randomized trace estimation of log(A) (Hutch++ with Chebyshev/Lanczos polynomial approximation), using reproducible seeds and batched probes to deliver a 95% confidence interval within a target relative error. The program must read Matrix Market files, validate against exact small cases, and emit a JSON report with estimate, CI, probe count, and timings.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Create a terminal script that loads a symmetric positive-definite matrix from /app/A.npz and estimates log(det(A)) by approximating trace(log A) via stochastic Lanczos quadrature with Hutchinson (Rademacher) probes using a reproducible RNG seed. The tool should adaptively increase probes to meet a target confidence interval and write the estimate, probe count, and CI to /app/answer.json within a time budget.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Implement a CLI tool that, given a symmetric positive definite sparse matrix A (Matrix Market), estimates trace(log A) via stochastic Lanczos quadrature with Hutchinson probes, supporting Rademacher, Gaussian, and Owen‑scrambled Sobol sequences. The tool adaptively increases probes to hit a target relative 95% CI, reports estimate/CI/probe count/RNG/timing to /app/results.json, and validates on small cases against a Cholesky-based exact computation.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Implement a program that estimates the log-determinant of a large sparse SPD matrix using stochastic trace estimation (Hutchinson with Rademacher probes) combined with Lanczos quadrature, adaptively increasing probes until a 95% confidence interval is within ±1% relative error. Output the estimate, confidence interval, and the number of probes used to a results file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Numerical Computation & Linear Algebra', 'Random Number Generation & Monte Carlo Methods', 'Implement a stochastic Lanczos quadrature estimator for trace(log(A)) (i.e., log det A) of a large sparse SPD matrix using Hutchinson probes (Rademacher with optional antithetic pairing), reporting the mean, standard error, and 95% CI as functions of probe count and Lanczos steps. Provide a CLI that loads a Matrix Market .mtx, runs with a reproducible seed, and writes per-probe estimates and the final summary to CSV.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Build a CLI that reads a YAML parameter grid, generates and submits a resilient SLURM array job with a launcher mapping SLURM_ARRAY_TASK_ID to parameters, and monitors progress via squeue/sacct until completion. It must auto-requeue failed indices with increased time/memory, throttle or add dependencies based on pending reasons, and produce a CSV with per-index status, exit code, runtime, and MaxRSS.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Build a SLURM workflow manager that submits a 3‑stage pipeline (preprocess → job array → reduction) with dependency chaining, monitors via squeue/sacct, and automatically requeues only failed array tasks (e.g., preempted or OOM) with adjusted resources and retry limits. It must handle SIGTERM for checkpointing and produce a final JSON/CSV report of exit status, retries, elapsed time, and MaxRSS per task.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Build a SLURM-driven workflow that launches a job array for a parameter sweep, enforces job dependencies (build -> stage data -> array -> postreduce), detects and auto-recovers preempted/failed tasks via sacct, and aggregates per-task elapsed time and GPU allocation into results.json. Provide scripts to submit, monitor, and checkpoint outputs so requeued runs resume without redoing completed work.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Create a SLURM workflow that runs a parameter sweep as a job array reading /app/params.csv, stages per-task inputs to node-local scratch, and records stdout/stderr per index. Implement automatic failure handling that requeues only failed array tasks once with doubled time/memory and a dependent postprocessing job that uses sacct to write state, runtime, and MaxRSS for all indices to /app/output/summary.csv only after all tasks succeed.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Cluster & Batch Job Management', 'Create a SLURM workflow that shards a large input into 200 parts, submits a fault-tolerant job array with per-task time/memory requests that traps SIGTERM to checkpoint and automatically retries failed elements, then resumes from partial results upon requeue. Monitor progress via squeue/sacct and submit an afterok aggregation job that verifies all shards, computes per-task runtime/memory statistics, and writes a consolidated JSON report to /app/summary.json.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Build an MPI-based distributed PageRank solver for sparse graphs that partitions the adjacency matrix by rows, performs power iteration with teleportation and dangling-mass handling via collective reductions, and outputs the top-k ranked nodes and convergence metrics. Provide a CLI to read an edge list, configure alpha/tolerance, verify correctness by matching NetworkX PageRank on small graphs within 1e-6, and report weak-scaling efficiency.', NULL, ARRAY['distributed']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Implement a distributed 2D Poisson/heat equation solver using MPI with domain decomposition and ghost-cell halo exchanges alongside a serial baseline sharing a common CLI to control grid size, iterations, and tolerance. Save residual history and the final field to standardized outputs, validate convergence and agreement with the serial solution within a set error, and demonstrate strong-scaling across process counts.', NULL, ARRAY['distributed']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Implement a distributed Conjugate Gradient solver for large sparse SPD matrices using MPI (mpi4py) with row-wise partitioning and halo exchanges for sparse matrix–vector products; solve Ax=b from provided Matrix Market and NumPy inputs and write the solution residual, iterations, and per-rank timing to files. Validate against a serial SciPy reference on small cases and demonstrate strong scaling across multiple processes.', NULL, ARRAY['distributed']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Implement an MPI-based 3D Poisson solver on a structured grid using domain decomposition and a conjugate gradient method with Jacobi preconditioning, with each rank maintaining ghost cells and performing halo exchanges each iteration. Validate against an analytical solution by reporting L2 error and residual reduction, and write per-rank timing/scaling metrics and a representative solution slice to output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Distributed Numerical Computation', 'Implement an MPI-based 3D Poisson solver on a uniform grid using 3D Cartesian domain decomposition with nonblocking halo exchanges and Jacobi/CG iteration, writing per-iteration residuals, timings, and a central solution slice to standardized outputs. The harness runs at 1, 2, and 4 ranks to validate against a manufactured sinusoidal solution (error threshold), ensure monotonic residual decrease, and assess near-ideal weak scaling.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'GPU & Accelerator Utilization', 'Create a GPU-accelerated 3D FFT-based Poisson solver using CuPy that computes the potential from a density field under periodic boundary conditions, with a CPU fallback using NumPy/SciPy. The CLI should load a .npy volume, compute potential and total energy, verify relative error ≤1e-6 vs CPU on a test case, and print device info and achieved GPU speedup.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'GPU & Accelerator Utilization', 'Implement a 3D FFT-based Poisson solver with periodic boundaries accelerated on GPU using CuPy/cuFFT, supporting batched right-hand sides and single/double precision. Provide a CLI that validates against a manufactured analytic solution and reports accuracy plus speedup versus a NumPy/FFTW CPU baseline.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'GPU & Accelerator Utilization', 'Implement a 3D heat diffusion solver using CuPy with a custom CUDA RawKernel (7-point stencil) alongside a NumPy CPU reference, then run both on provided initial conditions to the same final time and validate the GPU field against CPU within 1e-6 max error while saving the final array, device name, and per-backend timings/speedup. Enforce the stability constraint dt <= dx^2/(6*alpha) and use shared-memory tiling with coalesced accesses in the GPU kernel.', NULL, ARRAY['backend']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'GPU & Accelerator Utilization', 'Implement a GPU-accelerated 2D Poisson solver on a large grid using a CuPy/Numba-CUDA stencil (Jacobi or Red–Black Gauss–Seidel), and compare its runtime to a NumPy CPU baseline. The script must reach a specified residual tolerance, validate against an analytic solution, and write residual, iterations, and GPU speedup to /app/metrics.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Build a multi-threaded Smith–Waterman local sequence alignment engine that parallelizes anti-diagonals (wavefront) with OpenMP alongside a serial baseline, exposing a CLI to align FASTA pairs and emit alignment score and traceback. Include correctness checks against a known-good implementation and a benchmark that reports GCUPS and thread-scaling.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Implement a 2D steady-state Poisson solver on a large grid using Jacobi iterations, providing both a single-threaded baseline and a multi-threaded version (OpenMP or multiprocessing). The CLI must accept grid size and thread count, iterate until a residual threshold, and write the final field plus a convergence/timing summary that demonstrates speedup with ≥4 threads.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Implement a Conjugate Gradient solver for large SPD sparse matrices in CSR format with both serial and OpenMP-threaded paths for SpMV and vector reductions, selectable via a CLI. Load a provided matrix/vector, solve to a tolerance, and output solution, residual norm, and per-iteration timing to validate correctness and speedup across thread counts.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Implement serial and OpenMP-parallelized Conjugate Gradient for large SPD sparse matrices in CSR loaded from Matrix Market files, with optional Jacobi preconditioning and fused parallel reductions. Provide a common CLI to solve Ax=b, write residual histories and solution summaries, verify the parallel solution matches serial within tolerance, and report timing-based speedups across thread counts.', NULL, ARRAY['parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Parallel & High-Performance Computing (HPC)', 'Multi-Threaded & Parallel Programming', 'Implement serial and shared-memory parallel PageRank for a large sparse graph loaded from disk, using thread-partitioned sparse matvec and residual-based convergence. Output the top-ranked nodes and detailed timings to demonstrate speedup over the serial baseline.', NULL, ARRAY['parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Data Versioning & Dependency Control', 'Build a DVC-backed pipeline (local remote) with dvc.yaml stages to fetch, preprocess, and analyze a dataset while pinning Python dependencies with pip-tools to a requirements.lock. Prove reproducibility by switching between two Git tags and using dvc checkout so that metrics.json and output file checksums exactly match each tag’s recorded state.', NULL, ARRAY['python', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Data Versioning & Dependency Control', 'Build a DVC-managed analysis pipeline that versions two dataset revisions in a local DVC remote and runs a metrics script inside a conda-lock pinned environment. The run must write /app/results.json with metrics and provenance (dataset DVC hash, lockfile digest, git commit, script checksum) and reproduce bit-for-bit identical outputs across reruns.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Data Versioning & Dependency Control', 'Create a reproducible time-travel runner that checks out dataset revisions (e.g., tags data/v1 and data/v2) with DVC, resolves the exact environment via conda-lock, executes a Snakemake pipeline, and writes a provenance manifest listing git SHAs, DVC object IDs, lockfile hash, and output checksums. Generate a metric-drift report comparing the two runs and fail if any data or dependency is not pinned.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Data Versioning & Dependency Control', 'Implement a DVC-managed pipeline (preprocess → train → evaluate) with two local dataset versions and lock Python dependencies via pip-tools so reproducing on v1 yields identical artifact and metrics hashes across runs, while switching to v2 triggers only minimal stage recomputation. The run must emit an output manifest with dataset version, DVC stage checksums, and exact pip freeze, and validate at startup that installed packages match the lockfile.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Data Versioning & Dependency Control', 'Initialize a Git+DVC project tracking /app/data.csv with a local remote and a two-stage, params.yaml-driven pipeline (preprocess -> analysis) that produces metrics.json and commits the resulting dvc.lock. Pin Python dependencies via a generated lockfile (e.g., pip-tools) and run in a fresh venv; then modify the data to create a second version, check out the original DVC tag to reproduce identical metrics and checksums, and write the original data hash and metric to /app/answer.json.', NULL, ARRAY['git', 'python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Experiment Logging & Provenance Tracking', 'Build a deterministic three-stage pipeline (preprocess → train → evaluate) that versions data and intermediates with DVC and logs every run to a local MLflow backend, capturing git commit, parameter values, dataset checksums, metrics, and artifacts. Provide a CLI that reads params.yaml (supports sweeps) and writes /app/provenance.json summarizing the latest run’s lineage (stage order, input/output file hashes, DVC stage IDs, MLflow run IDs), reproducing identical metrics on rerun unless inputs or parameters change.', NULL, ARRAY['backend', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Experiment Logging & Provenance Tracking', 'Build a small ML experiment pipeline (data → preprocess → train → eval) that uses DVC to version data and stages and MLflow (file backend) to log params, metrics, artifacts, code version, and environment. Provide a CLI to run a parameter sweep and emit a single provenance.json that links each produced model and report to its DVC hash, MLflow run ID, Git commit, code diff, and random seed, enabling exact reruns.', NULL, ARRAY['backend', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Experiment Logging & Provenance Tracking', 'Create a DVC-driven workflow (data → preprocess → model) that logs parameters, metrics, and artifacts to MLflow, and emits a provenance.json capturing dataset checksums, code commit, DVC stage graph, environment snapshot, and MLflow run IDs. Provide a CLI to reproduce any past run from only an MLflow run ID by restoring DVC versions and the environment, then verify artifact byte equality and write a reproducibility report.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Experiment Logging & Provenance Tracking', 'Create a DVC-tracked pipeline (preprocess → train → evaluate) for a small scikit-learn task, and instrument each run with MLflow to log parameters, metrics, artifacts, git commit, and DVC data hashes. Prove reproducibility by rerunning dvc repro to obtain byte-identical outputs and emit a provenance report linking MLflow run IDs to the exact DVC stage versions used to produce the final metrics.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Experiment Logging & Provenance Tracking', 'Create an MLflow Project that runs a parameterized training pipeline on /app/data.csv, logging parameters, metrics, model artifacts, the Git commit SHA, and an input data checksum for each run. Implement a CLI sweep that launches multiple runs and writes the best run_id and its recorded git_commit to /app/answer.txt, with fixed seeding to make reruns reproduce the same metrics and artifacts.', NULL, ARRAY['logging', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Notebook & Script Reproducibility', 'Convert a geospatial analysis notebook that reprojects a provided shapefile and computes polygon areas under two CRSs into a headless, reproducible CLI executed via papermill/nbconvert, pinning GDAL/PROJ and setting deterministic env vars (e.g., PROJ network/grid settings and single-threaded BLAS). The run must produce identical CSV/PNG artifacts and a results.json with area summaries and SHA256 hashes across repeated clean-container executions.', NULL, ARRAY['container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Notebook & Script Reproducibility', 'Convert a provided Jupyter notebook into a deterministic, headless analysis pipeline by parameterizing randomness, extracting it to a Python script, and orchestrating execution with a Makefile that builds a fully pinned, hashed environment (e.g., pip-tools) and runs papermill to regenerate results. The pipeline must yield byte-identical CSV/PNG outputs across reruns and emit a manifest.json capturing package lock hashes, data checksums, seeds, and system info for verification.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Notebook & Script Reproducibility', 'Create a CLI pipeline that executes /app/analysis.ipynb with papermill using explicit parameters (including a fixed RNG seed), producing deterministic metrics, tables, and plots in /app/outputs and verifying bit-for-bit identical artifacts across two consecutive runs via SHA256 checksums. The run must also emit a locked requirements file and environment manifest (Python, OS, and package versions) alongside the outputs to ensure re-execution fidelity.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Notebook & Script Reproducibility', 'Create a CLI that executes /app/analysis.ipynb via papermill with user parameters, seeds all RNGs (random, NumPy, pandas, and torch if present) and forces single-threaded BLAS for determinism, then exports CSV outputs and a deterministic HTML report. The tool must write a manifest with parameters, pip-freeze, and SHA256 checksums of artifacts and provide a verify mode that re-runs and asserts bitwise identity for identical parameters.', NULL, ARRAY['pandas']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Notebook & Script Reproducibility', 'Refactor a provided Jupyter notebook with stochastic analyses into a deterministic, parameterized workflow that runs in a locked Python environment and produces byte-for-byte identical outputs on repeated runs. Expose a single terminal entrypoint that pins dependencies, executes the notebook (via papermill or a jupytext-converted script) with fixed seeds and constrained BLAS threads, and writes results.json plus a reproducibility checksum.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Report Generation & Automation', 'Build a CLI pipeline that performs a seeded analysis on a provided dataset, exports figures and tables, and assembles a fully self-contained HTML report (embedded images, no external assets) plus a manifest with SHA256 checksums and environment metadata. Orchestrate with Makefile/Snakemake so unchanged inputs trigger cached steps and reruns produce byte-identical outputs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Report Generation & Automation', 'Build a Makefile-driven pipeline that ingests experiment CSVs, computes grouped summaries with bootstrap CIs, renders figures/tables, and compiles a templated Markdown into a standalone HTML (and optional PDF) report via Pandoc with embedded assets. The workflow must support incremental rebuilds and include a provenance appendix (git commit, CLI args, pip freeze), writing /app/report/index.html and a machine-readable /app/results.json.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Report Generation & Automation', 'Build a Snakemake pipeline that parameterizes and executes a Jupyter notebook (via Papermill) across rows in a config CSV, aggregates outputs into figures and tables, and compiles a Quarto/Pandoc HTML+PDF report with embedded provenance (input checksums, software versions) and a run manifest. The workflow must be fully incremental (no re-execution on unchanged inputs), produce deterministic artifacts, and write the final reports and exported assets to a versioned /app/report directory.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Report Generation & Automation', 'Build a Snakemake pipeline that runs a parameterized Monte Carlo study, exports figures and summary tables, and renders a Quarto report to both HTML and PDF. The workflow must record seeds, config, and dependency versions into a manifest to ensure exact reproducibility across runs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Reproducible Research & Workflow Automation', 'Report Generation & Automation', 'Build a reproducible, Makefile-driven pipeline that reads a provided CSV, computes summary statistics and bootstrap 95% CIs in Python, saves tables/figures, and renders a self-contained HTML report from a Jinja2 template under /app/report. The build must be deterministic with a fixed seed and incremental (only re-running steps when inputs or templates change).', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Data Cleaning & Transformation', 'Build a CLI that ingests a directory of environmental sensor CSV/TSV files with mixed time zones and units, converts all measurements to SI using declared metadata, aligns timestamps to UTC, resamples to uniform 1-minute intervals, flags/removes outliers, and imputes short gaps. Write a single tidy, columnar Parquet dataset with standardized NaNs and stable column order, plus a JSON file summarizing QC metrics and unit conversions applied.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Data Cleaning & Transformation', 'Build a CLI that ingests a folder of heterogeneous NetCDF climate model files, maps variables to CF-standard names, converts units to SI, reprojects to a target grid, and aligns time onto a unified daily calendar with gap filling. Output a consolidated chunked Zarr store and a manifest CSV documenting provenance, unit conversions, and optional baseline-normalized anomaly fields.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Data Cleaning & Transformation', 'Create a CLI that ingests a directory of daily CF-netCDF climate files, harmonizes units (e.g., K→°C), decodes mixed time units/calendars, merges along time, masks fill values, removes outliers, and resamples to monthly means. Compute 1991–2020 per-gridcell climatology and z-score anomalies, then export a chunked, compressed Zarr dataset with consolidated metadata and a Parquet summary index.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Data Cleaning & Transformation', 'Create a CLI tool that ingests a DICOM CT series, converts pixel data to Hounsfield Units via RescaleSlope/Intercept (handling per-slice calibration), clips to [-1024, 3071], and resamples to 1 mm isotropic voxels while preserving spatial metadata. Write a single 3D NIfTI (.nii.gz) with correct RAS affine and a JSON summary of original/resampled spacings, dimensions, and any slices skipped due to corruption.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Data Cleaning & Transformation', 'Create a Python CLI that ingests a directory of daily CF-NetCDF climate files, harmonizes variable names/attributes, converts units to a specified target, stitches a continuous time axis over a given range, and repairs single-day gaps via flagged interpolation. Compute per-calendar-month climatology over a baseline and standardized anomalies, then write a CF-compliant compressed NetCDF of the cleaned series plus a CSV of the monthly climatology.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Image & Geospatial Data Handling', 'Build a Python CLI that ingests a multi-band satellite GeoTIFF (with NIR and Red), computes NDVI with nodata handling, reprojects to EPSG:3857, and writes a colorized XYZ tile pyramid into an MBTiles database with correct bounds and metadata. Additionally, vectorize pixels where NDVI exceeds a threshold into simplified GeoJSON polygons and export a PNG quicklook map.', NULL, ARRAY['python', 'database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Image & Geospatial Data Handling', 'Build a Python CLI that ingests a time-series of multispectral GeoTIFFs and a polygon ROI, decodes per-pixel cloud masks from QA bands, harmonizes projection/resolution, and computes a cloud-free median NDVI composite. Output a cloud-optimized GeoTIFF with overviews, a quicklook PNG with ROI outline and scale bar, and a CSV of per-ROI summary statistics.', NULL, ARRAY['python', 'cloud']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Image & Geospatial Data Handling', 'Create a CLI that georectifies an unreferenced aerial image using provided ground control points (pixel ↔ lon/lat), warps to a target CRS, and outputs a tiled, compressed Cloud-Optimized GeoTIFF with correct nodata and overviews. Also produce a quicklook PNG, a GeoJSON footprint of the warped image, and a JSON report of per-point residuals and overall RMSE.', NULL, ARRAY['cloud']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Image & Geospatial Data Handling', 'Create a Python CLI that mosaics multispectral GeoTIFF tiles, reprojects to EPSG:3857, clips to polygons in a GeoJSON ROI, computes NDVI from specified Red/NIR bands while honoring nodata and an optional cloud mask, and saves a color-mapped NDVI PNG plus a Cloud-Optimized GeoTIFF. Also compute per-polygon zonal statistics (mean, median, std, pixel count) and write them to a GeoJSON output.', NULL, ARRAY['python', 'cloud']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Image & Geospatial Data Handling', 'Create a Python tool that reads a folder of multi-date satellite GeoTIFFs with varying CRSs and resolutions plus an AOI polygon, reprojects and clips them to a common grid, and builds a cloud-robust medoid mosaic across dates using RGB+NIR bands. Write the mosaic as a Cloud-Optimized GeoTIFF, a PNG quicklook with AOI overlay, and a JSON report of per-band mean/std and fraction of valid pixels.', NULL, ARRAY['python', 'cloud']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Spectral & Signal Processing', 'Build a CLI tool that loads an irregularly sampled light curve from /app/lightcurve.csv (t, flux, sigma), computes a generalized Lomb–Scargle periodogram to identify the top periodicities with false-alarm probabilities, and produces publication-quality periodogram and phase-folded plots. Refine each candidate via weighted sinusoid fitting and write a summary CSV of frequency, period, semi-amplitude, phase, and FAP.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Spectral & Signal Processing', 'Create a CLI tool that computes a multitaper (DPSS) power spectral density of a 1-D signal and automatically detects narrowband line components above a robust noise floor. Apply notch filtering at detected lines and save the cleaned signal, PSD before/after, and a figure highlighting the peaks removed.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Spectral & Signal Processing', 'Create a CLI tool that computes power spectral density estimates for multichannel signals using both Welch and multitaper (DPSS) methods, saving PSDs and 95% confidence intervals to CSV plus comparison plots. Validate normalization via Parseval’s theorem by requiring the PSD-integrated variance to match the time-domain variance within 2% and report any channels that fail.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Spectral & Signal Processing', 'Implement a Python CLI that loads a multichannel time series, applies adaptive notch filtering at mains and harmonics plus a zero-phase bandpass, then computes multitaper PSDs and magnitude-squared coherence; it must detect and report dominant peaks, band powers, spectral entropy, and a coherence matrix to /app/results.json and save publication-quality PSD/coherence plots. Include a test mode that synthesizes known signals to validate peak frequencies within ±0.2 Hz and coherence above 0.9.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Spectral & Signal Processing', 'Implement a matched-filter detector for transient chirp signals: read a 1D noisy time series and a template waveform, estimate the noise PSD via Welch, whiten both, and compute the matched-filter SNR time series using FFT-based convolution. Write the peak detection time and SNR to a results JSON and save plots of amplitude spectral density (pre/post whitening) and the SNR time series.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Visualization & Plotting', 'Build a Python CLI that loads a gridded NetCDF atmospheric dataset (temperature on lat–lon–pressure), computes a zonal-mean latitude–pressure cross-section and derives the tropopause pressure using the WMO lapse-rate criterion, then plots a publication-quality contour/contourf figure with an inverted log-pressure axis, labeled isotherms, and an overlaid tropopause line using Matplotlib. Save both PNG and SVG figures and export the zonal-mean fields and tropopause profile to specified output files.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Visualization & Plotting', 'Build a Python tool that loads a gridded NetCDF climate dataset, computes a 1981–2010 monthly climatology and anomalies for a chosen year, and generates a publication-quality, three-panel figure: (1) a global Robinson-projection contour map of annual-mean anomaly with coastlines and significance hatching, (2) an equatorial Hovmöller diagram (time vs longitude), and (3) a zonal-mean anomaly profile, all using a shared color normalization. Save both PNG and PDF outputs with consistent, colorblind-safe styling and embedded metadata.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Visualization & Plotting', 'Create a Python CLI that reads a NetCDF surface temperature dataset, computes a 1981–2010 monthly climatology and 2016 anomalies, and produces a publication-quality multi-panel figure: a global anomaly map (Robinson projection with coastlines), a latitude–time Hovmöller, an area-weighted global-mean time series, and an anomaly histogram. Save both PNG and vector PDF with colorblind-safe palettes, labeled colorbars, and consistent typography.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Visualization & Plotting', 'Create a Python script that loads a 2D velocity field (u, v) from /app/velocity.npy, computes speed and vorticity, and generates a two-panel Matplotlib figure: left panel shows a pseudocolor speed heatmap with overlaid streamlines and a sparsified quiver; right panel shows filled vorticity contours with contour lines. Save the figure as /app/flow_figure.png and /app/flow_figure.pdf with labeled colorbars, equal aspect ratio, consistent fonts, and grid-aligned axes.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Data Processing & Visualization', 'Visualization & Plotting', 'Write a Python CLI that loads gridded geophysical data (lat, lon, time, variable) from a NetCDF file, computes a 30-year climatology and anomalies for a target month, and generates a 3-panel publication figure: global anomaly map with coastlines, zonal-mean latitude–anomaly cross-section, and a time series with rolling mean and confidence band. Use Matplotlib (and Cartopy for maps) with a symmetric, colorblind-safe diverging colormap centered at zero and fixed normalization across panels, saving the figure PNG and a JSON with summary statistics.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Algorithm Implementation & Validation', 'Implement a 1D finite-volume solver for the linear advection equation u_t + a u_x = 0 on [0,1] with periodic boundaries, supporting both first-order upwind and second-order MUSCL-Hancock schemes with CFL-controlled time stepping and CLI selection. Validate against the exact traveling-wave solution for a smooth periodic initial condition by outputting solutions at requested times and reporting L1/L2 errors that demonstrate first- vs second-order convergence over at least three uniform grid refinements.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Algorithm Implementation & Validation', 'Implement a 1D heat equation solver using the Crank–Nicolson scheme with a Thomas tridiagonal solver on a uniform grid with Dirichlet boundaries. Validate by comparing to the analytical solution u(x,t)=exp(-pi^2*t)*sin(pi*x) (alpha=1), reporting max and L2 errors at specified times and demonstrating near second-order convergence under grid refinement.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Algorithm Implementation & Validation', 'Implement a 2D Poisson solver on the unit square using a geometric multigrid V-cycle with red-black Gauss–Seidel smoothing and second-order finite differences, with CLI options for grid size and cycle parameters. Validate via a manufactured solution (e.g., u(x,y)=sin(pi x) sin(pi y)) to demonstrate O(h^2) convergence and quantify residual reduction per cycle versus a plain Gauss–Seidel baseline.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Algorithm Implementation & Validation', 'Implement a 2D Poisson solver on the unit square with Dirichlet boundaries using second-order finite differences with at least two solvers (e.g., Gauss-Seidel and Conjugate Gradient) exposed via a CLI. Validate against the analytical solution u(x,y)=sin(pi x)sin(pi y) by grid refinement (e.g., N=32,64,128), reporting L2/L∞ errors and observed order to a results file and failing if order < 1.9 or residual tolerances are unmet.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Algorithm Implementation & Validation', 'Implement a Gauss–Legendre quadrature generator using the Golub–Welsch algorithm to compute nodes and weights for arbitrary n (e.g., up to 2048) and provide a CLI to write them to disk. Validate by integrating polynomials up to degree 2n−1 over [-1, 1] and reporting the maximum absolute error against exact values, ensuring it stays below a specified tolerance.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Code Optimization & Profiling', 'Optimize a naive Python finite-element stiffness matrix assembly for a 2D Poisson problem that performs incremental CSR updates inside nested loops by profiling hotspots and refactoring to a vectorized batch COO (I,J,V) build with a single CSR conversion. Verify numerical equivalence of the assembled matrix and improved end-to-end solve time, and emit a JSON report of timings and speedups.', NULL, ARRAY['python', 'profiling']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Code Optimization & Profiling', 'Profile a naive finite-element stiffness-matrix assembly for a 2D Poisson problem on triangular meshes and optimize the hotspot by vectorizing element computations and constructing the global matrix in CSR with preallocated buffers or Numba. Validate numerical equivalence within tolerance across provided meshes and emit timing and speedup metrics.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Code Optimization & Profiling', 'Profile a naive nested-loop Python implementation of pairwise Euclidean distances between two sets of 128D vectors and replace the hotspot with a vectorized formulation and/or a Numba/Cython kernel using cache-friendly memory access and preallocation. Validate numerical equivalence (≤1e-8), emit before/after profiles and timing summaries, and achieve at least a 20x speedup on inputs of size Q=5000, D=50000.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Code Optimization & Profiling', 'Profile a naive pure-Python 3D heat equation explicit solver stepping 100 iterations on a 128^3 grid, then vectorize the stencil update, optimize memory access, and accelerate with Numba (parallel) to achieve ≥10× speedup while keeping max absolute error ≤1e-6 versus the baseline. Provide a CLI benchmark that runs pre/post-optimization versions, captures timing and max error, and writes a JSON report to /app/bench.json.', NULL, ARRAY['python', 'parallel', 'optimization']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Code Optimization & Profiling', 'Profile and optimize a naive 3D 7-point Jacobi solver for the Poisson equation on a uniform grid, transforming a triple-nested loop baseline into a high-performance version via cache blocking/tiling, vectorized memory access, and optional Numba or OpenMP. The CLI should run solves on several grid sizes, verify residual reduction against a reference solution with fixed boundary conditions, and print a profiling report that shows at least a 5× speedup over the baseline.', NULL, ARRAY['performance', 'profiling']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Library Development & Documentation', 'Design and package a Python library for uncertainty propagation offering linearized (Jacobian-based) and Monte Carlo estimators for vector-valued functions, with interchangeable NumPy and JAX backends. Ship a type-hinted API, Sphinx docs with runnable examples, unit tests with finite-difference validation, a CLI that evaluates models from JSON, and a wheel for local installation.', NULL, ARRAY['python', 'api', 'installation']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Library Development & Documentation', 'Develop a Python interval arithmetic library that guarantees enclosure for elementary functions using outward rounding and vectorized NumPy operations, with a clean API, type hints, and Sphinx docs driven by doctests. Include a CLI to evaluate expressions over named intervals and a test suite that verifies inclusion properties and monotonicity on randomized cases.', NULL, ARRAY['python', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Library Development & Documentation', 'Develop a Python library for lazy linear operators (matrix-free) that supports composition, adjoints, and iterative solvers (CG/LSQR) with NumPy/SciPy backends. Package it with pyproject.toml, Sphinx docs with examples and autodoc, a small CLI to apply/solve from JSON input, and unit tests verifying algebraic identities and solver accuracy.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Library Development & Documentation', 'Develop a Python library that implements polynomial chaos expansion (PCE) for uncertainty propagation with Legendre/Hermite bases, supporting coefficient fitting from samples, surrogate evaluation, and moment estimation. Package it with a CLI to build/evaluate PCEs from CSV data, comprehensive unit tests, and Sphinx-based API/user docs with examples.', NULL, ARRAY['python', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Library Development & Documentation', 'Develop a typed Python library for uncertainty propagation via Polynomial Chaos Expansions, supporting Gaussian/Uniform inputs, sparse regression and quadrature fitting, and computing means/variances plus first/total Sobol indices. Provide a CLI that loads a black-box model from a Python module and a JSON distribution spec to write a results JSON, and include unit tests and Sphinx docs with API and examples.', NULL, ARRAY['python', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Build a metamorphic and differential testing framework for FFT/IFFT routines that auto-generates random and structured signals, validates Parseval’s theorem, round-trip fidelity, and the convolution theorem, and cross-checks outputs between numpy.fft and an FFTW-based CLI tool within set tolerances. Integrate deterministic seeding, tolerance budgets, and performance regression guards into a CI pipeline that fails on numerical drift or speed regressions.', NULL, ARRAY['testing', 'performance']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Build a metamorphic and property-based test harness for a 2D Poisson solver that generates randomized periodic RHS fields, asserts exact recovery on single Fourier modes, checks symmetry/conservation invariants, and differential-tests against an independent finite-difference reference with convergence and error thresholds. Provide a CLI to run the suite and a CI workflow that records metrics and fails on tolerance regressions.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Build a pytest + Hypothesis metamorphic testing suite for a time-integration library (explicit/implicit Runge–Kutta) that verifies order of accuracy via step-halving, checks conserved quantities on canonical systems (harmonic oscillator, Kepler), and validates A-stability on the Dahlquist test equation. Provide a CLI to run the suite with numeric tolerance gates, enforce coverage thresholds, and emit JUnit XML and coverage artifacts suitable for CI.', NULL, ARRAY['testing']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Create a pytest + Hypothesis test harness that ingests a finite-difference PDE solver and verifies second-order accuracy via manufactured solutions, conservation and boundary-condition compliance, and monotonic error reduction under grid refinement. The suite must emit JUnit XML and a JSON convergence report and fail if the estimated order falls below 1.8 on any tested problem.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Create an automated test/CI harness that runs a provided 1D PDE solver across successively refined grids on manufactured solutions, computes L2 errors, fits the empirical convergence order, and fails if it falls below a set tolerance. Include metamorphic tests for boundary-condition transformations and a discrete conservation check, and emit JSON and JUnit XML summaries.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Build a Python CLI that performs adjoint-based parameter estimation for an ODE by integrating both the forward system and its continuous-time adjoint to obtain exact gradients of a least-squares misfit. Apply it to fit the Lorenz system’s (sigma, rho, beta) to a provided noisy trajectory, and report recovered parameters along with adjoint–finite-difference gradient agreement.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Build a Python CLI that solves the Lane–Emden boundary-value problem y'''' + (2/x) y'' + y^n = 0 with y(0)=1, y''(0)=0 using a shooting method and SciPy''s solve_ivp, seeding near x=0 from a SymPy-derived series expansion. Write the sampled solution and the first zero-crossing radius to output files and report max error versus the closed-form solutions for n=0 and n=1.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Implement a 1D Fisher–KPP reaction–diffusion simulator using FiPy that, given D and r, initializes a step profile, advances to a traveling-wave regime, and estimates the wavefront speed from threshold crossings over time. Save positions and the speed estimate to outputs and verify the speed is within 5% of the theoretical 2*sqrt(D*r).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Implement a 1D heat-equation solver with time-dependent source and mixed (Robin) boundary conditions using second-order finite differences in space and Crank–Nicolson time stepping, solving the per-step tridiagonal system via the Thomas algorithm. The CLI should ingest problem parameters and output snapshots at requested times to CSV and additionally run a mesh-refinement check to confirm ~O(Δx^2 + Δt^2) convergence.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Implement a Python CLI that solves the 1D Fisher–KPP reaction–diffusion PDE on [0, L] with Neumann boundaries via method-of-lines (finite differences) using SciPy’s stiff integrator from a compact initial condition. Estimate the traveling wave speed from the simulation and verify it is within 5% of the theoretical minimum 2*sqrt(D*r), writing the estimated speed and error to /app/answer.json.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a 1D discontinuous Galerkin solver for linear advection with periodic boundaries, selectable numerical flux (upwind/Rusanov), and SSPRK time stepping; expose CLI options for polynomial order, CFL, and final time. Output field snapshots and L2 error versus the exact shifted solution, and verify k+1 convergence across mesh refinements.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a 2D finite element solver for -∇·(k∇u)=f on a Gmsh triangular mesh with mixed Dirichlet/Neumann boundaries, assembling a sparse system and solving with Conjugate Gradient and a basic preconditioner. Validate via a manufactured solution by reporting L2 and H1-seminorm errors across at least two mesh refinements, and write both the nodal field and error summary to output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a 2D linear-elasticity finite element solver using first-order (P1) triangular elements that reads a Gmsh (.msh) cantilever beam mesh, assembles the global system with mixed Dirichlet–Neumann boundary conditions, and solves for displacements. Output nodal displacements and von Mises stress (VTK/CSV) and write total strain energy and tip deflection to /app/answer.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a Python finite element solver for 2D linear elasticity on an L-shaped domain using P1 triangles from a provided Gmsh mesh, enforcing Dirichlet and traction boundary conditions and computing von Mises stress. Include a Zienkiewicz–Zhu a posteriori error estimator with Doerfler marking to drive three adaptive refinement cycles, writing VTK field outputs and a JSON convergence summary (DOFs, ||u||_H1 error, observed rate).', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a sparse finite element modal analysis tool for 2D trusses: parse nodes and bar elements with A, E, and ρ, assemble global stiffness and consistent mass matrices, apply fixed DOFs, and compute the first k natural frequencies and mode shapes via eigsh. Write frequencies to an output text file and mode shapes to a mesh-compatible format (e.g., VTK/CSV).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Build a 1D heat-equation simulator (explicit FTCS with Dirichlet boundaries) that sweeps spatial resolution and timestep to explore CFL stability and convergence, comparing against an analytic solution. For each (dx, dt), record stability, L2 error at a fixed final time, and estimate order-of-accuracy across resolutions in a summary CSV.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Build a CLI tool that runs a stochastic SIR epidemic simulation (Gillespie SSA) and performs a Sobol global sensitivity analysis over R0, mean infectious period, and initial infected fraction, reporting first- and total-order indices for peak prevalence, time-to-peak, and final size. Use Saltelli sampling with a fixed seed, parallelize simulations, and write indices and summary metrics to CSV/text outputs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Build a Monte Carlo simulator for the 2D Ising model with periodic boundaries, sweeping temperature across a range and multiple lattice sizes to compute ensemble magnetization, energy, specific heat, susceptibility, and Binder cumulant. Estimate the critical temperature by locating the susceptibility peak and Binder cumulant crossing, saving the full per-temperature statistics and Tc estimate to outputs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Build a Python CLI that simulates the Lotka–Volterra predator–prey ODE across thousands of parameter samples (birth, predation, mortality, efficiency) drawn via Sobol or Latin hypercube designs, recording summary metrics such as final populations, peak amplitudes, and oscillation period per run. Compute and save first-order and total Sobol sensitivity indices for each metric, along with a CSV of runs and a JSON report of indices.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Implement a Python CLI that integrates the Lorenz ''63 system and, for a grid of (sigma, rho) values at fixed beta, computes the largest Lyapunov exponent to map chaotic vs non-chaotic regions, writing a CSV heatmap and the estimated boundary. Assess numerical sensitivity by rerunning a subset with stricter solver tolerances and reporting deviations in the exponent.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Build a discrete-event simulator for an M/M/c/K queue with balking at full capacity and exponential reneging, using a fixed RNG seed and automatic warm-up detection before collecting statistics across multiple replications. Output per-replication and aggregated 95% CI estimates for throughput, loss probability, mean queue length, and waiting time to standardized CSV/JSON files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Implement a discrete-event simulation of a priority M/M/c/K queue with balking and reneging, reading parameters from /app/scenario.yaml, and run batched replications with fixed RNG seeds to estimate per-class throughput, mean wait, and server utilization with 95% CIs to /app/results.json. Include a test mode that sets K→∞ and a single class to validate against the analytical M/M/c steady-state formulas within a specified tolerance.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Implement a discrete-event simulator for an M(t)/M/c/K queue with two priority classes (preemptive-resume) and impatient customers (reneging), supporting reproducible random seeds and multi-run parameter sweeps via CLI. For each run, write CSVs with time-series queue lengths and per-class summary metrics (utilization, mean/95th-percentile wait, abandonment rate).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Implement a discrete-event simulator for an open Jackson queueing network (2–4 M/M/1 nodes) with configurable arrival/service rates and routing probabilities, running multiple replications with independent RNG seeds to estimate steady-state throughput, utilization, mean queue lengths, and waiting times. For provided test cases, compare simulated metrics and 95% CIs to analytic formulas and fail if discrepancies exceed 5%, writing standardized CSV/JSON outputs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Implement a stochastic chemical kinetics simulator that loads a reaction network from a simple JSON schema and runs both exact Gillespie SSA and an adaptive tau-leaping variant across multiple random seeds. Save ensemble trajectories and checkpointed means/variances, and report agreement metrics between the two methods within specified tolerances.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Descriptive Statistics & Summarization', 'Build a memory-bounded CLI that streams a large (possibly gzipped) CSV to compute per-column descriptive stats (count, mean, std, min/max, skewness, kurtosis) and approximate quantiles (1,5,25,50,75,95,99) using online algorithms (e.g., Welford + KLL), with NA handling and optional group-by by a categorical field. Write a JSON report including equal-width histograms per column and enforce quantile approximation error ≤0.005 while keeping peak RAM ≤200 MB.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Descriptive Statistics & Summarization', 'Build a streaming command-line tool that ingests large CSV shards with columns group, value, weight and outputs per-group weighted descriptive summaries (count, mean, unbiased variance, MAD, IQR), approximate quantiles (p5, p50, p95) via a quantile sketch, and 20-bin histograms using a Freedman–Diaconis rule under a fixed memory cap. Write deterministic summaries to /app/output/summary.csv and /app/output/histograms.json suitable for automated tolerance-based checks.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Descriptive Statistics & Summarization', 'Implement a streaming CLI that computes per-column (and optional group-by) descriptive stats—count, mean, variance, min/max, skewness, kurtosis—and approximate quantiles (p1, p5, p25, p50, p75, p95, p99) from a large CSV using a memory-bounded quantile sketch (e.g., t-digest/P^2), outputting a compact JSON summary and fixed-bin histograms. The tool must handle missing values and optional weights while operating on datasets larger than RAM.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Descriptive Statistics & Summarization', 'Implement a streaming CLI that reads a potentially multi-GB CSV at /app/data.csv and computes per-group descriptive statistics (count, mean, variance, min, max) and approximate quantiles (p10, p50, p90) using numerically stable online methods (e.g., Welford plus a GK or t-digest sketch), writing a compact JSON report to /app/summary.json. The tool must ignore NaNs, support optional observation weights, and complete under a strict memory cap and time budget.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Build a CLI that reads a CSV with group labels and a numeric outcome, performs equivalence testing via two one-sided t-tests (TOST) for independent or paired samples with user-specified equivalence bounds, and reports 90% CIs, effect sizes, and decisions. Automatically choose Welch variants when variances differ and apply Benjamini–Hochberg correction when testing multiple endpoints, writing a concise results table to /app/output/results.csv.', NULL, ARRAY['testing']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Build a CLI that reads a CSV with outcome, binary treatment, and optional covariates/strata and conducts a stratified permutation test of zero treatment effect using Freedman–Lane residualization. Compute an exact p-value when permutations are enumerable (or Monte Carlo otherwise) and report a 95% confidence interval for the ATE via test inversion to a JSON file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Build a CLI tool that performs permutation-based ANCOVA (Freedman–Lane) to test a binary treatment effect while adjusting for a continuous covariate, optionally within blocking factors. Output the permutation p-value, partial R², and 95% bootstrap CI, and apply Benjamini–Hochberg correction if multiple outcomes are tested.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Create a CLI tool that ingests per-study effect sizes and standard errors, runs a random-effects meta-analysis (DerSimonian–Laird with optional Hartung–Knapp adjustment), and tests for overall effect and heterogeneity (Cochran’s Q, I²). Write combined estimates, p-values, per-study weights, and a leave-one-out influence summary to standardized output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Create a script that ingests stratified 2x2 contingency data (A/B by success/failure with a stratum identifier), performs a Cochran–Mantel–Haenszel test to estimate a common odds ratio with 95% CI, and reports its p-value. Additionally run the Breslow–Day test for homogeneity across strata and write the common OR, CI, and both p-values to an output JSON file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Build a CLI tool that fits an errors-in-variables Deming regression for method-comparison data, estimating the error variance ratio from replicate measurements and optionally applying Huber M-estimation to orthogonal residuals for robustness. Output slope, intercept, their 95% CIs (bootstrap), the variance ratio estimate, and a CSV of fitted values and orthogonal residuals.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Build a CLI tool that fits piecewise linear (segmented) regression with an unknown number of change-points on a noisy 1D dataset, selecting the number and locations via BIC-penalized dynamic programming (e.g., PELT). Save breakpoint positions, segment slopes/intercepts, fitted values and residuals, and bootstrap confidence intervals for parameters to standardized output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Build a terminal script that reads /app/series.csv (time,y) and fits a piecewise linear regression with 1–3 unknown changepoints under Huber loss using dynamic programming (or equivalent), selecting the segment count by BIC. Output /app/results.json with changepoint times, segment slopes/intercepts, BIC per model, and residual diagnostics.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Create a CLI tool that fits a bi-exponential decay model y(t)=a1*exp(-k1 t)+a2*exp(-k2 t) using the variable-projection method: optimize k1,k2 via nonlinear search while solving a1,a2 by linear least squares at each step, enforcing a1,a2>=0 and k1,k2>0. Report parameter estimates, bootstrap 95% CIs, and predicted values at specified eval times without using high-level curve-fitting helpers.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Fit Planck''s law to a measured spectral radiance dataset (wavelength vs intensity), jointly estimating temperature and a gray-body emissivity factor with bounds and optional instrument-response correction from a calibration file. Save parameter estimates with bootstrap confidence intervals and residual diagnostics to standardized output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Build a CLI tool that ingests an irregularly timestamped sensor series, resamples to hourly, and fits a Basic Structural Model (local level + local trend + 24-hour seasonality) using a from-scratch Kalman filter/smoother with maximum-likelihood estimation of noise variances while natively handling missing points. Output the decomposed components, the seasonally adjusted series, and 48-hour forecast quantiles (5/50/95%).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Create a CLI that ingests an irregularly sampled multivariate time series, estimates dominant seasonal periods via Lomb–Scargle and multitaper spectral analysis, then fits a seasonal state-space/SARIMAX model with Fourier terms to forecast a specified horizon. The tool must impute missing values, run rolling-origin backtesting, and write forecasts with 80/95% intervals and per-horizon error metrics to standardized output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Create a CLI tool that ingests an irregularly sampled time series with gaps, detects dominant seasonal periods via a Lomb–Scargle periodogram, and performs robust STL decomposition after appropriate resampling/imputation. Fit an ARIMA model to the seasonally adjusted component to generate a 7-day forecast with 95% intervals, and write the detected periods, decomposition components, and forecast to standardized CSV outputs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Create a CLI tool that ingests an irregularly sampled univariate time series with optional exogenous variables, resamples to a target frequency, applies a Box–Cox transform, and selects a SARIMAX model via stepwise AIC under stationarity/invertibility constraints. Perform multi-fold rolling-origin backtesting and output n-step forecasts with 95% intervals, residual Ljung–Box diagnostics, selected (p,d,q)(P,D,Q)s, and MASE/sMAPE metrics to standardized files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Implement a CLI that ingests an irregularly sampled univariate time series, estimates dominant seasonal periods via Lomb–Scargle spectral analysis, and performs STL decomposition using those periods. Fit a SARIMA model to the deseasonalized component to generate 30-step forecasts with 95% intervals, saving detected periods, decomposition components, and forecasts to disk.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Build a CLI tool that performs Bayesian inference for a stochastic SIR model using ABC-SMC to estimate transmission and recovery rates from observed daily case counts with an adaptive tolerance schedule. The program outputs weighted posterior samples and posterior predictive simulations for a fixed forecast horizon as standardized CSV files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Build a CLI tool that performs hierarchical Bayesian calibration of a Michaelis–Menten kinetics model across multiple temperatures, linking Vmax(T) via an Arrhenius law to jointly infer activation energy, pre-exponential factor, Km, and per-experiment noise with MCMC. Write posterior parameter summaries and posterior predictive trajectories with 95% credible intervals for each experiment to designated output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Calibrate an SIR epidemic ODE model to noisy incidence data using Bayesian inference (e.g., PyMC/NumPyro with NUTS), estimating transmission and recovery rates and R0. Run multi-chain MCMC to produce posterior credible intervals and posterior predictive trajectories and save a concise summary artifact.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Create a Python tool that fits a stochastic SIR model to a provided daily incidence CSV using Particle Marginal Metropolis–Hastings with a bootstrap particle filter, jointly inferring β, γ, initial I0, and a reporting rate under Negative Binomial observation noise. Output posterior samples and 95% credible intervals for parameters plus posterior predictive incidence trajectories to standardized JSON/CSV files.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Implement a CLI tool that calibrates an SIR ODE model to noisy daily incidence via Bayesian inference (PyMC NUTS), estimating beta, gamma, initial infections, and a reporting rate under a Negative Binomial likelihood. The program must run MCMC, compute R0 and posterior predictive trajectories with coverage metrics, and write diagnostics and posterior summaries to standardized output files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Error Analysis & Confidence Intervals', 'Create a Python CLI that loads mean and covariance for parameters [a,b,c] of the model y(x)=a*exp(b x)+c and a grid of x, and computes 95% confidence bands for y(x) via both first-order delta-method propagation and Monte Carlo sampling (Cholesky, fixed seed). Write the bands and propagated standard errors to /app/output/bands.csv and a summary JSON, and verify the two methods’ bounds agree within 3% at each x.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Error Analysis & Confidence Intervals', 'Create a Python script that estimates a 95% confidence interval for the half-life parameter in an exponential decay experiment by fitting a non-linear model with heteroscedastic Gaussian noise and performing both profile likelihood and parametric bootstrap, then propagates the parameter uncertainty to predicted counts at specified times. Load data from /app/data/decay.csv and write a JSON summary with the CI endpoints, bootstrap distribution diagnostics, and predicted interval bands to /app/output/results.json.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Error Analysis & Confidence Intervals', 'Fit a nonlinear Michaelis–Menten model to concentration–rate data and compute 95% confidence intervals for Vmax and Km using both an asymptotic (Fisher information/delta) method and a residual bootstrap. Propagate uncertainty to a prediction at a specified substrate level and write point estimates and interval bounds to a standardized results file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Error Analysis & Confidence Intervals', 'Fit a nonlinear Michaelis–Menten model with weighted least squares to enzyme kinetics data, then compute 95% profile-likelihood confidence intervals for Km and Vmax. Propagate parameter uncertainty to a specified substrate level to produce a 95% prediction interval for the reaction rate and emit all interval endpoints in a results file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Error Analysis & Confidence Intervals', 'Implement a CLI tool that propagates uncertainty in Steinhart–Hart temperature estimation: given correlated coefficient estimates (A,B,C with covariance) and a CSV of resistance readings with standard uncertainties, compute 68%/95% confidence intervals for T using both the delta method and Monte Carlo sampling with correlation, and write per-sample intervals plus a JSON summary. Include a simulation mode that generates synthetic datasets from a known ground truth to estimate empirical coverage for both methods.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Sensitivity Metrics & Ranking', 'Build a CLI tool that computes first- and total-order Sobol indices (Jansen estimator with Saltelli sampling) for a stochastic black-box model f(x, seed) in /app/model.py under independent Uniform priors, using replicate runs and bootstrap CIs to produce a ranked list of influential parameters. The script must be robust to NaNs/infs in model outputs, respect a configurable time budget, and write both the indices with 95% intervals (JSON) and the parameter ranking (TXT).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Sensitivity Metrics & Ranking', 'Create a CLI tool that loads a black-box model f(x) from /app/model.py (optionally stochastic via a seed argument) and computes first- and total-order Sobol’ indices using a Saltelli design with Owen-scrambled Sobol sequences and common random numbers under a fixed evaluation budget. Output a CSV of indices with bootstrap 95% CIs and a parameter ranking by total-order effect, and include an automated self-test that recovers Ishigami indices within ±0.02.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Sensitivity Metrics & Ranking', 'Create a CLI tool that loads a black-box model from /app/model.py and input distributions from /app/inputs.json, then computes first-order and total Sobol indices via Saltelli sampling and performs Morris screening for comparison. Output a ranked CSV of parameters by influence with bootstrap 95% confidence intervals, and save the exact sample matrices and RNG seed to /app/artifacts.npz for reproducibility.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Sensitivity Metrics & Ranking', 'Create a Python CLI that loads a black-box model f(x) from model.py and parameter bounds from bounds.json, then computes Sobol first- and total-order indices via Saltelli sampling alongside derivative-based global sensitivity measures (DGSM) via finite-difference gradients. The tool should adaptively increase samples until 95% bootstrap CI widths for S_i fall below a threshold and write indices, CIs, and a consolidated parameter ranking to /app/results.json.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Sensitivity Metrics & Ranking', 'Implement a Python CLI that loads a differentiable JAX model f: R^d -> R, computes derivative-based global sensitivity measures (DGSM) via automatic differentiation on quasi–Monte Carlo samples, and converts them into provable upper bounds on total Sobol indices using Poincaré constants for Uniform/Normal inputs. Write a JSON file with per-parameter DGSM, total-effect bounds, and a ranking by the bounds.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Uncertainty Propagation', 'Build a CLI that propagates uncertainty in a deterministic SIR ODE model with uncertain β, γ, and I0, computing the distributions of peak infected fraction and time-to-peak via both Monte Carlo (with variance reduction) and non-intrusive polynomial chaos. The tool must read input distributions from a config file and output summary statistics and method agreement diagnostics.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Uncertainty Propagation', 'Build a CLI tool that loads a black‑box Python model and a JSON of input uncertainties (marginals plus optional correlation) and propagates them to outputs using both Latin Hypercube Monte Carlo and a sparse Polynomial Chaos Expansion. Report mean, variance, 5th/95th percentiles, and KL divergence between methods, and save the fitted PCE surrogate for reuse.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Uncertainty Propagation', 'Build a polynomial chaos expansion (total order 3) using Smolyak sparse Gauss-Hermite quadrature to propagate a 5-D Gaussian input uncertainty through a provided black-box function, returning mean/variance estimates and a surrogate evaluator. Compare the PCE estimates against a Sobol low-discrepancy Monte Carlo reference and report relative errors and sample efficiency.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Uncertainty Propagation', 'Create a script that reads a JSON file describing correlated lognormal uncertainties for R and C in an RC circuit, then propagates them through the step-response V(t)=V0*(1-exp(-t/(R*C))) to estimate the mean and variance of V(t) over a given time grid using both Monte Carlo sampling and a third-order polynomial chaos expansion. Write per-time statistics and the maximum absolute discrepancy between the two methods to /app/results.json with a fixed random seed for reproducibility.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Uncertainty Propagation', 'Implement a non-intrusive polynomial chaos pipeline that reads a YAML describing independent input distributions and a black-box model CLI, then builds a sparse Legendre/Hermite PCE via stochastic collocation to propagate uncertainty and estimate the output mean, variance, and 5th/95th percentiles. Validate the PCE by comparing its moments against a fixed-seed Monte Carlo baseline and report relative errors.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Cipher Cracking & Weak Encryption Analysis', 'Crack a corpus of hex-encoded messages encrypted with the same unknown repeating-key XOR by estimating key length via normalized Hamming distance and recovering the key using English frequency scoring. Decrypt all files and write the plaintext of a specified target message to /app/output/target.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Cipher Cracking & Weak Encryption Analysis', 'Exploit AES-CTR nonce reuse across many hex-encoded ciphertexts to reconstruct the keystream via multi-time-pad techniques (pairwise XOR and crib-dragging) and decrypt a designated target message. Write the exact recovered plaintext to /app/secret.txt and the keystream to /app/keystream.hex.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Cipher Cracking & Weak Encryption Analysis', 'Exploit AES-CTR nonce reuse across multiple ciphertexts by using XOR analysis with known file headers and crib-dragging to recover the keystream and decrypt a target message containing SECRET{...}. Write the recovered secret to /app/secret.txt without modifying other files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Cipher Cracking & Weak Encryption Analysis', 'Recover plaintexts from multiple files encrypted with the same repeating-key XOR (many-time pad) by estimating key length with Hamming distances, crib-dragging using known file headers, and reconstructing the key to decrypt all messages.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Cipher Cracking & Weak Encryption Analysis', 'Recover the seed and decrypt files that were XOR-encrypted with a keystream from Python’s Mersenne Twister (random.Random) seeded by a 32-bit Unix timestamp, using magic headers (e.g., PNG/ZIP) and file mtimes to constrain the search. Implement a CLI that identifies the correct seed, reconstructs the keystream, decrypts all files losslessly, and outputs the recovered seed plus SHA-256 hashes of plaintexts.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Password Hash Cracking', 'Build a command-line cracker that parses a mixed credential dump containing unsalted MD5, SHA-1, and NTLM hashes alongside bcrypt entries, auto-detects the hash type per record, and recovers plaintexts for only the weak/unsalted hashes using a provided wordlist plus simple mutation rules. Output cracked username→password pairs in deterministic order to /app/output/cracked.json and leave bcrypt entries untouched.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Password Hash Cracking', 'Extract mixed-format password hashes from a legacy CMS SQLite dump, fingerprint each hash type (unsalted MD5, apr1-crypt, and phpass), and crack only accounts labeled tier=low using a hybrid wordlist+mask attack derived from a provided policy hint file. Output a validated username:plaintext list and a summary indicating which algorithms were cracked and which were skipped.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Password Hash Cracking', 'Given /app/data/users.txt containing username:hash entries in mixed formats (unsalted MD5 hex, SHA-1 hex, and MySQL 4.1 double-SHA1), write a script that auto-detects each scheme and cracks passwords using the provided dictionaries plus a ?d?d mask for numeric suffixes. Output recovered pairs as username:password, sorted lexicographically by username, to /app/cracked.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Password Hash Cracking', 'Given a mixed-format hash dump at /app/hashes.txt containing LM+NTLM (unsalted), raw MD5, and SHA-1, create a workflow that auto-detects each hash type, cracks them via dictionary+rules and targeted mask attacks (including LM half-cracking and recombination), and verifies candidates. Write username:password pairs to /app/cracked.txt and a brief per-hash-type success summary to /app/stats.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Password Hash Cracking', 'Recover plaintext passwords from a SQLite database where each user’s hash is the hex-encoded MD5 of lowercase(email)+":"+password (no salt). Reverse-engineer the format from a provided hint script, then use a dictionary+mask attack to crack all accounts and write user_id,email,password to /app/cracked.csv.', NULL, ARRAY['database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Protocol Analysis & Exploit Detection', 'Analyze SMTP traffic to detect a STARTTLS stripping downgrade that exposes credentials, reproduce the attack using standard CLI tools, and write the recovered username:password to /app/creds.txt. Reconfigure the mail server to require TLS (reject plaintext AUTH without STARTTLS) and verify via a captured session that downgrade attempts no longer leak credentials.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Protocol Analysis & Exploit Detection', 'Analyze a TLS-enabled internal service and an accompanying PCAP to detect reuse of a static TLS session ticket encryption key. Extract the ticket key from the service (e.g., config/env/memory) and use it to decrypt the captured session, recovering a secret and writing it to /app/recovered_secret.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Protocol Analysis & Exploit Detection', 'Analyze a reverse-proxy setup (HTTP/2 frontend to HTTP/1.1 backend) to detect H2-to-H1 request smuggling caused by improper forwarding of Connection/TE headers. Craft a single HTTP/2 request to smuggle an internal GET /admin/flag to the backend, extract FLAG{...}, and write it to /app/flag.txt.', NULL, ARRAY['frontend', 'backend']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Protocol Analysis & Exploit Detection', 'Build a CLI that parses a provided pcap of SMTP/IMAP/POP3 sessions to detect STARTTLS downgrade/misuse and plaintext credential exposure. For each session, report server capabilities, whether TLS was negotiated, and any extracted usernames/passwords in a machine-readable summary.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Protocol Analysis & Exploit Detection', 'Given a TLS 1.2 packet capture and the server’s RSA private key, decrypt and reconstruct the HTTP conversation to extract a leaked bearer token. Replay the token against the local service to obtain a protected secret and persist the result to a specified file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Reverse Engineering Binary Artifacts', 'Analyze a stripped ELF that reconstructs an AES-128 key at runtime from scattered lookup tables and uses it to decrypt an embedded data blob. Recreate the key derivation and decryption in a standalone script to recover the original JSON config and write it to /app/config.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Reverse Engineering Binary Artifacts', 'Analyze a stripped x86-64 ELF that embeds a custom bytecode virtual machine for license verification; extract the bytecode and reimplement the VM in Python to compute the correct license without running the binary, writing it to /app/license.txt.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Reverse Engineering Binary Artifacts', 'Analyze a stripped x86-64 ELF that validates input using a custom stack-based bytecode VM and simple anti-debug checks. Reconstruct or emulate the VM to recover the exact passphrase that yields ''ACCESS GRANTED'' and write it to /app/flag.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Reverse Engineering Binary Artifacts', 'Reverse engineer a stripped x86_64 ELF that decrypts a payload using AES-CTR, where the key and nonce are constructed at runtime from several obfuscated constants. Recover the exact key/nonce and write a CLI tool that decrypts /app/secret.enc to /app/secret.txt without modifying the binary.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Applied Cryptanalysis & Reverse Engineering', 'Reverse Engineering Binary Artifacts', 'Reverse-engineer a stripped Linux ELF that embeds a WebAssembly module inside a custom section and validates input by interpreting that WASM; locate and extract the module, reconstruct the check algorithm from its bytecode, and compute the input that makes the program reveal FLAG{...}. Write the recovered flag to /app/secret.txt and note the byte offsets used for the extraction.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Multi-Factor & Token-Based Authentication', 'Configure OpenSSH in the sandbox to require dual authentication: Ed25519 public key plus a TOTP code derived from /app/mfa_seed.txt via keyboard-interactive PAM. Implement a non-interactive client script that computes the current TOTP and successfully scp’s /secure/flag.txt to /app/result.txt as proof of access.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Multi-Factor & Token-Based Authentication', 'Configure an OpenSSH server to require dual authentication: a CA-signed user certificate and a TOTP code via PAM. Generate a user keypair, sign it with a provided SSH CA, seed a TOTP secret for the test user, and prove that SSH access succeeds only with a valid cert plus current OTP while plain keys or incorrect codes are rejected.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Multi-Factor & Token-Based Authentication', 'Implement a minimal OAuth 2.0 device authorization flow that issues RS256 JWT access tokens backed by a rotating JWKS, where user approval requires a TOTP code generated from a provisioned per-user secret. Provide a CLI client that enrolls the TOTP secret, completes the device flow while handling authorization_pending/slow_down, and accesses a protected API; tests validate TOTP windowing, key rotation via kid, and strict audience/issuer checks.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Multi-Factor & Token-Based Authentication', 'Patch a vulnerable web API that currently accepts JWTs with alg=none and HS/RS key confusion by enforcing strict RS256 verification against a local JWKS endpoint, validating iss/aud/exp, and implementing key rotation with cache invalidation. Provide CLI scripts that mint a valid token to access a protected endpoint and demonstrate that forged tokens (none, HS-using-public-key, wrong aud/iss, expired) are rejected, writing results to /app/verification.txt.', NULL, ARRAY['web', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Password Management & Hashing', 'Create a CLI shadow-upgrader that reads a users.json containing mixed legacy password formats (plaintext, SHA-1 hex, salted SHA-256, bcrypt), authenticates a batch of login attempts, and transparently rehashes verified passwords to Argon2id with per-user random salts and a file-based pepper (/app/pepper.key) in PHC format. Use constant-time verification, enforce target Argon2 parameters, write updates atomically with upgraded_at timestamps, and leave unverifiable entries unchanged.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Password Management & Hashing', 'Create a CLI tool that migrates a legacy user database containing mixed bcrypt/SHA-1 password hashes to Argon2id with per-user salts and a global pepper from an environment variable, encoding hashes in PHC string format. Implement transparent verification that accepts old hashes, rehashes on successful login using constant-time comparisons, and outputs an audit report listing upgraded accounts and any remaining non-compliant entries.', NULL, ARRAY['database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Password Management & Hashing', 'Given a SQLite users.db containing mixed password schemes (md5, sha256-crypt, and bcrypt), implement a CLI that verifies logins against the current scheme and transparently upgrades accounts to Argon2id in PHC format with per-user random salts and tuned parameters. Provide a dry-run audit mode that reports counts by scheme and flags records requiring rehash due to weak algorithms or sub-threshold cost factors.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Password Management & Hashing', 'Implement a login-and-migrate utility that validates users from a legacy SQLite users.db storing unsalted SHA-1 password hashes using constant-time comparison, and on successful authentication rehashes the password to Argon2id with per-user 16-byte random salt and a global pepper from /run/secrets/pepper, storing a PHC-formatted hash and schema version. Output a machine-readable /app/migration_report.json summarizing upgraded accounts, skipped/locked users, and the Argon2 parameters used.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Password Management & Hashing', 'Refactor a legacy Flask-style auth service that stores unsalted SHA-1 password hashes to use Argon2id with per-user random salts and configurable memory/time parameters, including automatic rehash-on-login when parameters are outdated. Provide a CLI to bulk-migrate users by validating credentials from a provided login_attempts.csv, updating hashes in-place, and emit an /app/audit.json listing any accounts that could not be migrated.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Role-Based & Policy Enforcement', 'Configure PostgreSQL with role-based and row-level security: create tenant-scoped roles, enable RLS on a table using tenant_id policies, and expose a masked view so analysts can only SELECT non-PII while ingesters can INSERT but not read. Verify cross-tenant reads are denied and admins retain full access via psql tests.', NULL, ARRAY['postgresql', 'security']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Role-Based & Policy Enforcement', 'Configure an SSH-based Git service that enforces role-based access using authorized_keys restrictions and server-side hooks: create ci and maintainer roles where ci can only perform read-only git-upload-pack on /srv/repoA.git, while maintainer can push to repoA.git but not to repoB.git. Disable interactive shells and all forwarding features for both roles, and verify that unauthorized operations are denied while allowed ones succeed.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Role-Based & Policy Enforcement', 'Create Unix roles via groups ''analyst'' and ''operator'' and enforce POSIX ACLs (including default ACLs) so analysts have read-only access to /app/data/reports (present and future files) while operators can modify /app/data/ops but cannot read reports. Lock down sudoers so only operators may run `/usr/bin/systemctl restart metrics-agent.service` without a password and cannot execute any other command or escalate to a shell, and provide a script that proves both allowed and denied behaviors.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Role-Based & Policy Enforcement', 'Implement UNIX RBAC for a project workspace by creating dev, qa, and ops roles, enforcing a permission matrix with POSIX ACLs (including default ACL inheritance), and adding a sudoers.d rule that lets only ops run a specific appctl restart command without enabling shell escapes or env-based escalation. Provide a verifier that impersonates sample users to confirm read/write/execute behavior, ACL inheritance on new files, and denials for unauthorized sudo or file operations.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Role-Based & Policy Enforcement', 'Provision role-based access on a Linux host by creating dev, ops, and audit roles with UNIX groups, POSIX ACLs, and sudoers.d policy. Enforce that devs can write to /srv/app/releases but cannot restart services, ops may only sudo systemctl restart app@* without shell escapes or env-based escalation, and auditors can read /var/log/app but not secrets, with default ACLs applied to new files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Security & Cryptography', 'Authentication & Access Control', 'Session Management & Revocation', 'Augment a JWT-based API to use short-lived access tokens and refresh-token rotation with reuse detection backed by a persistent token-family store; presenting any previously rotated refresh token must revoke the entire family and add active access-token JTIs to a denylist. Provide an admin CLI/endpoint to revoke all sessions for a user and verify with curl that compromised tokens are rejected across multiple app processes while other users remain authenticated.', NULL, ARRAY['api']);
