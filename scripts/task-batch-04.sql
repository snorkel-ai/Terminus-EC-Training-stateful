-- Batch 4 of 8: Inserting tasks 601 to 800

INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Interactive Challenges & Games', 'Tool & CLI Mastery Challenges', 'Shell Puzzle Games', 'Starting at /app/maze/start, traverse a symlink-based filesystem maze where each encountered file contains JSON giving a regex for the next filename plus a token fragment and sequence number. Using only shell tools (find, sed/awk, jq, sort), detect and avoid cycles, collect and order fragments, then base64-decode and gunzip the concatenated string to plaintext and write it to /app/answer.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Interactive Challenges & Games', 'Tool & CLI Mastery Challenges', 'Shell Puzzle Games', 'Traverse a directory tree containing mixed-format event fragments (logs, JSON, CSV, and filename-encoded timestamps), some nested in unlabeled archives, and normalize their heterogeneous timestamps (RFC3339, epoch ms/nanos, DOY, base36) using shell tools. After deduping by event id and globally sorting, extract one character per event to reconstruct the hidden message and write it to /app/message.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Interactive Challenges & Games', 'Tool & CLI Mastery Challenges', 'TUI (Text User Interface) Interaction', 'Open lazygit in the provided Git repo and resolve a pending merge by choosing “theirs” for config/app.yml and accepting only the first two conflicting hunks from “ours” in src/core.py, then finalize the merge with the supplied message and exit. After leaving the TUI, write the resulting HEAD commit SHA and the total count of remaining conflict markers (<<< or >>>) in the repo to /app/answer.txt.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Interactive Challenges & Games', 'Tool & CLI Mastery Challenges', 'TUI (Text User Interface) Interaction', 'Open the provided mixed CSV/JSONL dataset in the VisiData TUI, interactively filter to completed EMEA orders in Q3 2024, join users to orders, group by user, compute total spend, sort descending, and export a 2‑column TSV to /app/report.tsv. All data manipulation must be performed inside VisiData via keyboard-driven operations, then exit cleanly.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Interactive Challenges & Games', 'Tool & CLI Mastery Challenges', 'TUI (Text User Interface) Interaction', 'Use the tig ncurses Git interface to locate the first commit that introduced a target function signature and determine the first tag that contains it by navigating log, search, and blame views. Record the exact commit SHA and tag name to /app/results.txt as ''SHA TAG'' after exiting the TUI.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Interactive Challenges & Games', 'Tool & CLI Mastery Challenges', 'TUI (Text User Interface) Interaction', 'Using the lazygit TUI, resolve a prepared merge conflict by selectively staging hunks to restore a passing implementation, commit with the exact message ''merge-fix: OK'', and push to the provided local bare remote. After the test suite passes, write the resulting commit SHA to /app/result.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Interactive Challenges & Games', 'Tool & CLI Mastery Challenges', 'TUI (Text User Interface) Interaction', 'Using the visidata TUI, open /app/orders.csv and interactively create a pivot grouped by region and product_category for orders in 2023-Q4, calculating total_revenue and order_count, then sort by total_revenue descending and export the result to /app/summary.tsv. Also write the single top row of that pivot (tab-separated) to /app/top.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Augmentation & Synthesis', 'Build a CLI that ingests a labeled multivariate time-series CSV, slices it into fixed windows, and generates augmented samples using jitter, scaling, time-warp, permutation, and magnitude-warp with deterministic seeds while preserving label alignment. Save the augmented dataset and a per-sample transform manifest, and produce a small DTW-based diversity report.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Augmentation & Synthesis', 'Build a CPU-only Python CLI that reads WAV files from /app/speech, impulse responses from /app/rir, and noise from /app/noise, and synthesizes an augmented set by convolving speech with a chosen RIR and mixing noise at randomized target SNRs, resampling as needed and peak-normalizing to -1 dBFS without clipping. Save 16-bit PCM WAVs under /app/aug deterministically given a --seed and write /app/aug/metadata.csv listing source paths, chosen RIR/noise, SNR, RT60 estimate of the RIR, output path, and random seed.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Augmentation & Synthesis', 'Create a CLI that augments multivariate time-series by injecting labeled anomalies—spikes, level shifts, trend changes, and seasonal pattern breaks—under user-controlled prevalence, duration, and SNR, producing /app/aug_series.csv, /app/aug_labels.csv, and a JSONL manifest of per-sample transforms. Include a deterministic seed and a ''validate'' mode that checks non-overlap, exact target prevalence by type, and summarizes augmentation statistics.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Augmentation & Synthesis', 'Create a Python CLI that ingests multivariate IoT sensor readings from /app/sensor.csv, trains a variational autoencoder on normal windows, then synthesizes a balanced dataset with labeled normal and anomalous sequences by sampling and latent-space perturbations plus jitter, scaling, and time-warp augmentations. Save train/val/test Parquet files (fixed-length windows) and a manifest JSONL capturing augmentation provenance to /app.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Augmentation & Synthesis', 'Create a Python CLI that performs class-balanced augmentation of a mixed-type tabular dataset by implementing SMOTE-NC from scratch, honoring per-column constraints (numeric bounds, integer-only, allowed categories) and a fixed RNG seed. Output the augmented CSV and a JSON report with pre/post class ratios and drift metrics (KS for numeric, chi-square for categorical), with tests ensuring constraints are met and no target leakage occurs.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Cleaning & Preprocessing', 'Build a CLI pipeline that ingests a directory of messy CSVs (mixed encodings, delimiters, and locales) and reconciles their schemas, producing a single standardized Parquet dataset and a JSON data-quality report. Handle Unicode NFC and BOM normalization, locale-aware numeric/currency parsing, ISO-8601 UTC datetime normalization, group-wise imputation, MAD-based outlier capping, MinHash de-duplication on a text column, and optional tokenization to fixed-vocabulary IDs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Cleaning & Preprocessing', 'Build a CLI pipeline that ingests multiple vendor CSVs of product listings with mixed encodings, locale-specific number/currency formats, and heterogeneous timestamp columns, then standardizes them. Normalize text to UTF-8 NFC, parse dates to UTC ISO-8601, harmonize decimal/thousand separators, convert currencies via a provided FX table, impute missing numeric fields per-category with robust medians, remove outliers via MAD, deduplicate by SKU/title similarity, and write a cleaned Parquet plus a data-quality summary JSON.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Cleaning & Preprocessing', 'Build a chunked, streaming CLI that consolidates heterogeneous CSV/TSV/JSON sources with mixed encodings into a single cleaned Parquet: auto-detect encoding/delimiters, coerce to a target schema from schema.json, normalize booleans/numerics, parse and UTC-normalize datetimes, impute missing values, cap outliers via MAD, and deduplicate by composite keys. Emit data_quality.json with per-column nulls/outlier counts/type-coercions and bad-record samples, ensuring determinism (seeded), memory safety on multi-GB files, and resilience to BOMs, malformed rows, and embedded newlines.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Cleaning & Preprocessing', 'Build a streaming CLI that merges multiple CSV shards with mixed encodings and a nested JSON column, infers a unified schema, standardizes datetimes to UTC ISO-8601, normalizes column names, and outputs cleaned Parquet deterministically. Impute missing values (group-wise median for numerics, mode for categoricals, forward-fill within user sessions), cap outliers per group via IQR, tokenize a free-text column while preserving emojis, and generate a data-quality report JSON with validation metrics.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Data Cleaning & Preprocessing', 'Create a CLI that consolidates multi-sensor time-series CSVs with differing time zones and sampling rates: normalize timestamps to UTC, auto-detect and correct per-sensor clock drift via alignment to a shared ''sync'' channel, resample to 1 Hz, impute gaps ≤5s, and flag/remove outliers using robust MAD. Save the cleaned dataset to Parquet and emit a JSON audit of imputations, drift corrections, and outlier statistics to support reproducibility.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Dataset Splitting & Sampling', 'Build a CLI that performs a purged, group-aware time-series split with an adjustable embargo to prevent leakage, using entity_id as the group and preserving chronological order. It must output train/val/test CSVs that maintain marginal and pairwise label co-occurrence within ±2% via iterative multi-label stratification and emit a JSON report of balance and leakage diagnostics.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Dataset Splitting & Sampling', 'Implement a CLI that performs leakage-safe train/val/test splitting for a multi-label text dataset by first clustering near-duplicate documents with MinHash LSH and then applying iterative stratification at the cluster level to match label marginals while assigning whole clusters to a single split. Write split assignments to /app/splits.csv and a duplicate report to /app/dup_report.json with cluster members and pairwise Jaccard estimates.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Dataset Splitting & Sampling', 'Implement a Purged Group Time Series Split that creates train/validation/test indices for timestamped events grouped by an entity_id, enforcing a configurable gap and embargo to prevent temporal leakage while approximately preserving class balance via quantile-based stratification. Provide a CLI that reads /app/events.csv and writes split index files plus a JSON report with leakage checks and per-split label prevalence.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Dataset Splitting & Sampling', 'Implement a deterministic multi-label, group-aware stratified k-fold splitter with an optional time-based embargo to prevent leakage across folds. Provide a CLI that reads id/group_id/timestamp/labels columns and outputs per-fold splits plus a JSON report of label balance, zero group overlap, and temporal ordering, scaling to millions of rows via streaming.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Dataset Splitting & Sampling', 'Implement a spatially stratified data splitter that groups samples by 5-character geohash and assigns whole geohashes to train/val/test to prevent spatial leakage. Maintain class balance for the species label as closely as possible, enforce reproducibility via salted hashing, and write split indices and a summary (per-split label histograms and KL divergence vs overall) to disk.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Feature Extraction & Transformation', 'Build a CLI that performs leakage-safe K-fold target encoding with additive smoothing for multiple categorical columns (including pairwise interactions), producing out-of-fold encodings for train, encodings for test via a holdout, and a serialized mapping for reuse. It must stream-process large CSVs (10M+ rows), be deterministic, and robustly handle missing and unseen categories.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Feature Extraction & Transformation', 'Build a CPU-only Python CLI that loads directed graphs from /app/graphs/*.edgelist and computes reproducible 128-dimensional node2vec embeddings via fixed-seed random walks and skip-gram training, writing /app/embeddings/{graph}.npy and a matching {graph}_nodes.txt listing nodes in row order. Ensure deterministic node ordering across runs, gracefully handle disconnected nodes, and fit any walk/model parameters using only the provided train split to prevent leakage.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Feature Extraction & Transformation', 'Build a Python CLI that performs leakage-safe out-of-fold target encoding and frequency encoding for multiple high-cardinality categorical columns on a time-stamped dataset using chronological folds with smoothing and optional noise regularization. Output transformed train/test Parquet files and a reusable encoder artifact to ensure consistent application on future data.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Feature Extraction & Transformation', 'Create a Python CLI that reads an edge list from /app/graph.csv and computes per-node features including node2vec embeddings and structural metrics (degree, betweenness, clustering coefficient, PageRank), then standardizes and writes a single feature table with a node_id column to /app/node_features.parquet. Ensure deterministic results with fixed RNG seeds and correct handling of isolated nodes and disconnected components.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Data Preparation & Feature Engineering', 'Feature Extraction & Transformation', 'Implement a leakage-safe categorical target encoder that computes out-of-fold, James-Stein–smoothed means for high-cardinality features (and selected feature crosses), augments with count/frequency stats, and uses a hashed fallback for unseen categories at inference. Provide a CLI that fits on train.csv and transforms both train/test into /app/processed/*.csv in chunked mode with deterministic seeds and memory bounds.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Architecture Design & Implementation', 'Implement a Mixture-of-Experts Transformer feed-forward block in PyTorch with top-2 gating, capacity-based token dispatch (including overflow handling), and an auxiliary load-balancing loss. Integrate it into a small decoder-only model and provide tests for routing correctness, gradient flow, and equivalence to a dense FFN when num_experts=1.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Architecture Design & Implementation', 'Implement a PyTorch LoRA adapter system that injects low‑rank adapters into a vanilla Transformer’s attention (Q, K, V, and output) and MLP projections, with per-module rank/alpha settings, freezing of base weights, and precise merge/unmerge of adapters into the backbone. Provide a CLI that trains only the adapters on a tiny language-modeling corpus and verifies identical logits pre/post-merge within a tight tolerance while confirming no non-adapter parameters changed.', NULL, ARRAY['pytorch', 'modeling']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Architecture Design & Implementation', 'Implement a PyTorch Mixture-of-Experts Transformer block with top-2 routing, per-expert capacity with token dropping, and an auxiliary load-balancing loss, supporting variable sequence lengths and attention masks. Ensure numerically stable, deterministic routing and gradient flow across dtypes on CPU, and include a small CLI to verify balanced expert utilization on synthetic data.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Architecture Design & Implementation', 'Implement a PyTorch decoder-only Transformer block with grouped-query attention (GQA), rotary position embeddings (RoPE), pre-norm RMSNorm, and an efficient KV cache that supports incremental autoregressive generation with a stable fallback when scaled_dot_product_attention is unavailable. Ensure correct causal masking, mixed-precision stability, variable-length batch handling, and robust cache updates during token appends and sequence reordering.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Architecture Design & Implementation', 'Implement a minimal decoder-only Transformer in PyTorch that supports rotary positional embeddings (RoPE) and grouped-query attention (GQA) from first principles (no Transformers/timm), with a flag to fall back to standard multi-head attention. Train CPU-only on TinyShakespeare for a short run, then generate a deterministic 200-character sample and save model.pt and a config.json to /app.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Loss Function Design & Custom Layers', 'Implement a PyTorch MonotonicLinear layer that enforces non-negative weights on selected features and a pairwise monotonicity loss that penalizes order violations, then train an MLP on a tabular regression dataset with specified monotone inputs. Report test MAE and the fraction of monotonicity violations versus an unconstrained baseline.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Loss Function Design & Custom Layers', 'Implement a PyTorch Soft-DTW loss with numerically stable forward/backward that supports batched variable-length sequences via padding masks, per-sample Sakoe–Chiba windows, and mixed precision. Provide a TemporalAlignment layer that uses the expected alignment matrix to differentiably warp sequences for downstream models.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Loss Function Design & Custom Layers', 'Implement a batched Soft-DTW loss with padding masks and an optional Sakoe–Chiba band for variable-length time-series, plus a custom temporal attention pooling layer that uses differentiable DTW alignment scores as attention weights. The components must run on CPU/GPU, support mixed precision, and be memory-efficient enough to handle sequences up to length 10k.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Loss Function Design & Custom Layers', 'Implement a custom TokenDropAttention layer for a tiny Transformer that learns to stochastically drop uninformative tokens via Gumbel-Softmax gates, paired with a sparsity-consistent KL loss enforcing a user-specified target keep-rate with temperature annealing and mixed-precision safety. Train on a synthetic sequence classification dataset and verify via tests that the achieved keep-rate is within tolerance and that accuracy drop versus a vanilla attention baseline stays below a threshold.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Loss Function Design & Custom Layers', 'Implement a differentiable sorting-based Top-k pooling layer (NeuralSort/SoftSort) and a listwise NDCG surrogate loss in PyTorch to train a ranking model on variable-length item lists with padding masks. The layer and loss must be numerically stable in fp16/fp32, efficient on long lists, and include gradient checks and input validation.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Training Stabilization Techniques', 'Build a CPU-only PyTorch character-level LSTM language model on TinyShakespeare that stays stable on long sequences via dropout, LayerNorm on recurrent outputs, global-norm gradient clipping, gradient accumulation, and a warmup+cosine learning-rate schedule. Log per-step gradient norms and effective LR, and save a final model plus JSON metrics proving clipping occurred and the scheduler advanced.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Training Stabilization Techniques', 'Implement a PyTorch character-level LSTM trained on Tiny Shakespeare with two runs: an unstable baseline and a stabilized variant using dropout, gradient clipping, label-smoothed cross-entropy, and a warmup+cosine learning rate schedule. Log gradient norms and NaN/Inf checks, and verify the stabilized run achieves a target perplexity while the baseline shows exploding gradients or divergence.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Training Stabilization Techniques', 'Retrofit an unstable DCGAN training script to add spectral normalization to the discriminator, an R1 gradient penalty, adaptive global-norm gradient clipping, EMA of generator weights, and a cosine learning-rate schedule with warmup; train on a provided CIFAR-10 subset and write FID and Inception Score to /app/metrics.json, ensuring no NaNs and FID below a set threshold.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Training Stabilization Techniques', 'Train a compact Transformer for character-level language modeling on long sequences, implementing stabilization features: gradient clipping (by norm and value), warmup+cosine LR scheduling, dropout, label smoothing, and EMA/SWA of weights. Provide a CLI to ablate each component, log per-step gradient norms and NaN/Inf events to /app/stability_log.json, and save the best-perplexity checkpoint.', NULL, ARRAY['modeling']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Training Stabilization Techniques', 'Write a PyTorch training script for CIFAR-10 that stabilizes an intentionally aggressive setup (large LR, small batch) using mixed precision with dynamic loss scaling, adaptive gradient clipping (AGC), linear warmup plus cosine decay scheduling, and EMA of weights with switchable BatchNorm/GroupNorm and dropout. Tests verify no NaNs/Inf, bounded gradient norms, correct LR schedule behavior, and a validation curve that is smoother and at least as good as a baseline without these techniques.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Visualization & Debugging', 'Build a CLI tool that instruments any PyTorch model with forward/backward hooks to record per-layer activation, weight, and gradient statistics during training, automatically flagging saturation, dead ReLUs, and vanishing/exploding gradients while rendering concise PNG plots and a JSON report. The script should run a short CPU-only training of a small CNN on synthetic data and output /app/reports/{grad_flow.png, activations.png, weights_hist.png, anomaly_report.json}.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Visualization & Debugging', 'Build a Python CLI that loads a PyTorch ResNet-18 and, via forward/backward hooks on a small image batch, saves per-layer activation/gradient histograms (PNGs), a gradient-flow plot, and a dead-ReLU heatmap. Write a debug_report.json summarizing per-layer gradient norms and flagging any vanishing/exploding gradients.', NULL, ARRAY['python', 'pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Visualization & Debugging', 'Create a PyTorch script that hooks into a ResNet-18 training on CIFAR-10 to record per-layer activation histograms, activation sparsity, and gradient norms across one epoch, automatically flagging layers with saturation or vanishing/exploding gradients. Produce a self-contained HTML report of these visuals and save Grad-CAM overlays for the top-3 misclassified images.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Visualization & Debugging', 'Create a Python CLI that registers forward/backward hooks on a given PyTorch model to capture per-layer activation histograms, gradient norms, and (if present) attention head entropy/rollout, then writes PNG plots and a single HTML report to /app/vis. The tool should flag vanishing/exploding gradients, NaN/Inf activations, and saturation rates per layer, exiting non-zero if any issue is detected.', NULL, ARRAY['python', 'pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Deep Learning & Neural Network Engineering', 'Visualization & Debugging', 'Implement a Python CLI that loads a provided PyTorch CNN and sample dataset, registers forward/backward hooks to compute per-layer activation stats (mean/std/sparsity) and gradient norms on a minibatch, and produces a gradient-flow plot plus activation histograms. Save a JSON report flagging dead ReLUs and vanishing/exploding gradients, and write all artifacts (JSON and PNGs) to /app/report so tests can verify detection of an intentionally broken layer.', NULL, ARRAY['python', 'pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Data & Model Sharding', 'Build an expert-parallel Mixture-of-Experts layer that shards experts across ranks and routes tokens via top-2 gating with a capacity factor, using all_to_all to dispatch to per-rank experts and recombining to the original order. Provide an unsharded reference and ensure numerical parity and gradient correctness across world_size 1/2/4, with support for dropless/drop policies, variable sequence lengths, and mixed precision.', 'hard', ARRAY['parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Data & Model Sharding', 'Implement 1D tensor-parallel sharding for GPT-style attention and MLP in PyTorch with custom ColumnParallelLinear/RowParallelLinear layers using torch.distributed (Gloo), including forward/backward collectives (all-gather/reduce-scatter) and model-parallel RNG. Provide a test script that trains a tiny Transformer on synthetic data across 2–4 ranks and verifies numerical parity with an unsharded reference, correct gradient synchronization, and that memory per rank drops below a set threshold.', 'hard', ARRAY['parallel', 'pytorch', 'distributed']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Data & Model Sharding', 'Implement CPU-only tensor parallelism for a single Transformer block using torch.distributed (Gloo), sharding QKV and MLP weights across two ranks with column/row-parallel matmuls and the necessary all-reduce/concat steps. Provide a script that verifies forward/backward parity with an unsharded baseline to 1e-5 and reports per-rank parameter and optimizer memory to demonstrate sharding benefits.', 'hard', ARRAY['distributed', 'parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Data & Model Sharding', 'Implement a minimal ZeRO Stage-2 optimizer in PyTorch that shards Adam states and gradients across ranks, using reduce-scatter for gradient partitioning and on-demand all-gather of parameters for forward passes. Train a small model on synthetic data and verify numerical parity with an unsharded baseline, correct save/load of sharded checkpoints, and peak memory reduction for world_size 1, 2, and 4.', 'hard', ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Data & Model Sharding', 'Implement vocabulary-parallel sharding for a tiny Transformer language model in PyTorch by partitioning the token embedding and tied LM head across ranks, producing only local logits and using an all-reduce to compute the global softmax cross-entropy loss. Support world sizes 1, 2, and 4, include sharded checkpoint save/load with resharding across different world sizes, and verify numerical parity with a non-sharded reference model.', 'hard', ARRAY['parallel', 'pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Distributed & Parallel Training Infrastructure', 'Build a CPU-only PyTorch FSDP training pipeline launched via torchrun (world_size=2–4) that auto-wraps a small Transformer, uses DistributedSampler and gradient accumulation to maintain a fixed global batch, and logs rank-local plus aggregated metrics. Save a sharded checkpoint (model and optimizer) and implement resume-on-different-world_size, verifying determinism by matching validation loss and a consolidated state_dict against a single-process baseline.', 'hard', ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Distributed & Parallel Training Infrastructure', 'Build an elastic PyTorch DDP training launcher that tolerates worker failures and dynamic membership (2–4 ranks), re-forming the process group via a rendezvous backend and resuming from rank-0 sharded checkpoints even when world size changes. The test will start/kill workers mid-epoch; the job must continue training to a target accuracy and emit a single consolidated checkpoint at the end.', 'hard', ARRAY['pytorch', 'backend']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Distributed & Parallel Training Infrastructure', 'Launch a CPU-only PyTorch Elastic DDP job (torchrun) with 4 ranks across two localhost ''nodes'' that trains a tiny transformer on synthetic data using the gloo backend, writes sharded per-rank checkpoints, then restarts from the latest checkpoint after simulating a rank failure. Consolidate the shards into a single checkpoint and verify equivalence to a single-process baseline by hashing model parameters.', 'hard', ARRAY['pytorch', 'backend']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Distributed & Parallel Training Infrastructure', 'Launch a PyTorch FSDP training job for a small Transformer on synthetic sequence data across 4 local ranks with torchrun, enabling mixed precision and activation checkpointing, and write sharded checkpoints plus a script to consolidate them into a single state_dict.pt. Provide a baseline DDP run and verify that resuming from the sharded checkpoint reproduces validation loss within tolerance and that peak memory per rank is at least 30% lower than DDP.', 'hard', ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Distributed & Parallel Training Infrastructure', 'Launch an elastic Horovod CPU training run (Gloo backend) on synthetic data that tolerates worker restarts and dynamic scaling, preserving optimizer state and the learning-rate schedule across changes. Begin with 2 workers, add a third after 50 steps, then remove one, and produce a metrics.json with per-step throughput and effective global batch size plus a final saved model.', NULL, ARRAY['backend']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Inference Optimization at Scale', 'Convert a Hugging Face BERT-base classifier to ONNX, build an INT8 static-quantized variant from calibration data, and serve both in an NVIDIA Triton model repository (ONNX Runtime backend, CPU) with dynamic batching and multiple instances. Implement a concurrent client to benchmark p50/p95 latency and throughput at batch sizes 1/8/32 and assert the INT8 model delivers ≥1.4x throughput with ≤1% accuracy delta, saving a metrics.json.', NULL, ARRAY['backend']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Inference Optimization at Scale', 'Deploy a BERT-base encoder in NVIDIA Triton with two TensorRT backends (FP16 and INT8 calibrated from /app/calib), enable dynamic batching and concurrent instance groups, and write a Python client that drives variable-length requests over HTTP to collect p50/p95 latency and throughput. Validate that the INT8 engine achieves at least 1.8x throughput over a PyTorch eager baseline on the same hardware and emit a JSON report to /app/metrics.json.', 'hard', ARRAY['python', 'pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Inference Optimization at Scale', 'Export a BERT-base QA model to ONNX, build both FP16 and INT8 TensorRT engines (with calibration), and deploy them in NVIDIA Triton with dynamic batching and two concurrent instances. Benchmark with perf_analyzer over batch sizes {1, 8, 32} and write a JSON summary of latency/throughput and INT8 vs FP16 speedups to /app/perf_report.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Inference Optimization at Scale', 'Export a HuggingFace BERT-base encoder to ONNX, build FP16 and INT8 TensorRT engines with entropy calibration, and deploy both behind NVIDIA Triton Inference Server with a model repository configured for dynamic batching and multiple concurrent instances. Provide a CLI load generator to send large-batch requests, verify output parity vs. PyTorch within tolerance, and report throughput to demonstrate INT8 speedup over FP16.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Inference Optimization at Scale', 'Stand up a CPU-only Triton Inference Server hosting an INT8-quantized DistilBERT ONNX model via the ONNX Runtime backend, configured with dynamic batching and multiple instances, then load-test batch sizes {1, 8, 32, 128}. Validate outputs against an FP32 baseline within tolerance and write a JSON report summarizing per-batch throughput plus p50/p99 latency scraped from Triton’s /metrics endpoint.', NULL, ARRAY['backend']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Large Model Fine-Tuning & Adaptation', 'Build a CPU-only QLoRA fine-tuning pipeline for a small Hugging Face causal LM that can switch between LoRA and prompt-tuning via a CLI flag, training on /app/data/train.jsonl with sequence packing and evaluating perplexity on /app/data/valid.jsonl. Save adapter weights to /app/adapter and a merged full model to /app/merged, and write the final validation perplexity to /app/perplexity.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Large Model Fine-Tuning & Adaptation', 'Fine-tune a small Hugging Face causal LM using LoRA to produce two domain-specific adapters from tiny corpora, then implement on-the-fly weighted adapter merging and a CLI to evaluate perplexity across domains. Verify that each adapter beats the base model on its domain and that online merged logits match an offline-merged checkpoint within a small tolerance.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Large Model Fine-Tuning & Adaptation', 'Fine-tune a small causal LM (e.g., GPT-2) with PEFT to produce two separate LoRA adapters on two distinct domains (e.g., prose and code) in a CPU-only setting. Implement inference-time weighted composition of the adapters to blend or route behaviors, then save individual/composed adapters and a merged variant, and report a metrics JSON comparing cross-entropy/perplexity across domains and blends.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Large Model Fine-Tuning & Adaptation', 'Implement a soft prompt-tuning pipeline for a decoder-only LLM (e.g., distilgpt2) that learns K virtual tokens while freezing all base weights. Provide scripts to train on data/, save/load the prompt embeddings, verify perplexity improvement on a held-out split, and generate completions for prompts.txt into outputs.jsonl with deterministic seeds.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Foundation Models & Large-Scale Systems', 'Large Model Fine-Tuning & Adaptation', 'Implement soft prompt tuning for a small causal LM (e.g., distilgpt2) to learn k virtual tokens for reversible date format conversion on a tiny synthetic dataset, keeping the base model frozen. Save the learned prompt vectors separately and provide an inference script that attaches them to the base model to generate outputs for test inputs, writing predictions to /app/date_convert.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Experiment Tracking & Logging', 'Build a Python CLI that runs an offline Weights & Biases sweep of 8 trials for a scikit-learn imbalanced binary classifier, performing 5-fold CV per trial and logging per-fold metrics, aggregated results, confusion matrices, and the best model as artifacts under a single grouped sweep. Enable run resumption, and export a self-contained wandb-export.tar.gz with all offline run data to /app/wandb_export plus a best_trial.json summarizing chosen hyperparameters and metrics.', NULL, ARRAY['python', 'logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Experiment Tracking & Logging', 'Configure and execute a Weights & Biases hyperparameter sweep in offline mode that trains a scikit-learn model with StratifiedKFold, logging hyperparameters, per-fold AUC/accuracy, ROC curves, and saving the fitted estimator as a W&B artifact for each run. After the sweep completes, programmatically identify the best run by mean AUC and write its run ID, config, and artifact file path to /app/best_run.json.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Experiment Tracking & Logging', 'Create a Python CLI that runs 5-fold cross-validation with hyperparameter search, using MLflow to record a parent run and nested child runs per trial and fold with parameters, metrics, and artifacts (ROC/PR plots, confusion matrices, and serialized models). The CLI must support resuming by skipping completed child runs, produce an aggregated leaderboard.csv, and register the best model with signature and input example in the Model Registry.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Experiment Tracking & Logging', 'Deploy an MLflow tracking server with a SQLite backend and a MinIO S3 artifact store behind an Nginx reverse proxy on localhost, then build a training pipeline that uses nested runs and autologging for both scikit-learn and PyTorch, logs SHAP artifacts, a model signature, and an input example, and registers two models with stage transitions. Add a script that queries MLflow for the best run by a validation metric, downloads its artifacts to run batch inference, logs predictions as a new artifact, and prints the chosen run_id.', NULL, ARRAY['backend', 'pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Experiment Tracking & Logging', 'Implement a resumable training pipeline that uses MLflow to start a run, log hyperparameters and per-epoch metrics, save checkpoints, then intentionally crashes mid-training. On re-execution it must detect state and resume the exact same run_id (start_run with run_id), continue logging without duplicating epochs, record environment snapshots (pip freeze and git commit) and a learning-curve artifact, and write the run_id to /app/run_id.txt.', NULL, ARRAY['logging', 'git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Model Registry & Versioning', 'Build a local, file-backed model registry with a SQLite metadata store and content-addressable artifact storage, including a CLI to register versions, assign stage aliases (staging/production), and promote or rollback based on evaluation metrics. Provide an inference loader that consumes a lockfile to fetch a pinned version and verifies immutability and lineage.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Model Registry & Versioning', 'Create a Python CLI that publishes trained models as OCI artifacts to a local Docker registry (registry:5000), storing model weights and a metadata.json layer with code/data hashes, metrics, and dependency manifest. Support semver tags and aliases (staging/production), integrity verification by content digest, version comparison by a chosen metric, and atomic promote/rollback of the production alias.', NULL, ARRAY['python', 'docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Model Registry & Versioning', 'Create a schema-aware local model registry that assigns semantic versions (MAJOR/MINOR/PATCH) when registering scikit-learn models by diffing input schema, hyperparameters, and data hashes. Provide a CLI to register, list, and promote versions with stage transitions and a ''champion'' alias, then verify by loading the Production model to score a held-out set.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Model Registry & Versioning', 'Start a local MinIO S3 server on localhost:9000 and configure a DVC remote (s3://model-registry) to serve as a centralized model registry for versioned model artifacts and metrics. Train two scikit-learn models, push both versions with semantic tags (e.g., v0.1.0, v0.2.0), implement a promote.py CLI to label Staging/Production in a bucket-hosted registry.json, and demonstrate a rollback to the prior Production version.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Pipeline Construction & Scheduling', 'Build a Prefect 2.x flow and deployment that orchestrates an end-to-end ML pipeline with ETag-aware data ingestion, feature engineering, model training/evaluation, and conditional promotion; configure retries, result persistence/caching, and a cron schedule, ensuring re-runs skip unchanged tasks. Provide a CLI to register the deployment, start a worker, trigger a run, and emit versioned artifacts plus a run_report.json summarizing cache hits, timings, and the promotion decision.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Pipeline Construction & Scheduling', 'Build an Apache Airflow DAG that watches /app/data/incoming with a FileSensor, validates new CSVs using Great Expectations, then transforms, trains, and evaluates a scikit-learn model on accepted data, writing artifacts and metrics under /app/outputs/{{ ds }}. The DAG must use the TaskFlow API with XCom to pass artifact paths, support backfilling for the past 7 days, and run on a daily 02:00 schedule.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Pipeline Construction & Scheduling', 'Create a Prefect 2 flow and deployment that ingests new CSVs, computes feature drift against a stored baseline, and conditionally runs preprocessing, training, evaluation, and model registration only when drift exceeds a threshold. Enable local caching and retries, add a cron schedule, and persist run artifacts and the chosen model under /app.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Pipeline Construction & Scheduling', 'Create an Apache Airflow DAG that monitors /app/current.csv, computes data drift against /app/reference.csv with Evidently, and branches to either retrain/evaluate a scikit-learn model or skip retraining when drift is below a threshold. The DAG must be scheduled daily with retries and SLAs, use XCom to pass metrics, persist artifacts to /app/, and implement a file-content hash to cache and skip redundant training.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Pipeline Construction & Scheduling', 'Create an Apache Airflow DAG that uses dynamic task mapping to run k-fold cross-validation (download/validate data, per-fold training, metric logging, aggregation) and conditionally register the model only if the averaged score exceeds a threshold. Package it for a local Dockerized Airflow setup, schedule it to run daily, ensure idempotent runs, and persist all artifacts/metrics under /app/artifacts.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Reproducibility & Environment Setup', 'Build a Dockerized ML pipeline that achieves bit-for-bit reproducibility by using a conda-lock lockfile, fixing locale/timezone, seeding all RNGs, and pinning BLAS thread counts, while prefetching wheels and dataset artifacts for fully offline execution. Train a scikit-learn model and write both metrics and a SHA256 of the serialized model; rerunning the container (including offline) must produce identical outputs.', NULL, ARRAY['container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Reproducibility & Environment Setup', 'Build a Dockerized, conda-lock–pinned environment that runs a fully deterministic scikit-learn training pipeline on /app/data.csv, fixing seeds and BLAS threads to yield identical artifacts across runs. The CLI must produce model.pkl, metrics.json, and a reproducibility_report.json capturing package versions, BLAS backend, thread config, and SHA256 checksums of code/lockfile/data, with a make target that verifies bit-for-bit reproducibility.', NULL, ARRAY['backend']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Reproducibility & Environment Setup', 'Build a Dockerized, fully reproducible ML pipeline using DVC stages (data prep → feature extraction → training) with a conda-lock generated environment and pinned pip extras. Verify that running dvc repro in two clean clones yields bit-for-bit identical model and metrics artifacts and emit a manifest with exact package versions and data checksums.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Reproducibility & Environment Setup', 'Build a fully offline, deterministic ML pipeline using DVC stages (data -> features -> train -> eval) and a Dockerized micromamba environment created from a conda-lock lockfile, training a scikit-learn LogisticRegression on synthetic data with fixed seeds. Provide scripts/targets to run dvc repro and verify reproducibility by asserting identical SHA256 checksums of model and metrics artifacts across two consecutive runs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Machine Learning Pipelines & Automation', 'Reproducibility & Environment Setup', 'Create a Nix flake that defines a hermetic Python 3.11 environment with pinned NumPy, pandas, and scikit-learn, plus a CLI that trains a logistic regression on /app/data.csv with fixed seeds. Add a Makefile target that builds the flake and runs the training twice in fresh pure shells, asserting identical SHA256 hashes for model.pkl and metrics.json to confirm bit-for-bit reproducibility.', NULL, ARRAY['python', 'pandas']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Benchmarking & Comparison', 'Build a CPU-only benchmarking CLI that compares FP32, FP16, and INT8 (quantized) variants of a given image classifier on a provided dataset, reporting accuracy, Brier score, and p50/p95 per-sample latency. Output a leaderboard CSV and select the best configuration by maximizing accuracy under a 95th-percentile latency budget, saving the chosen tag to /app/selection.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Benchmarking & Comparison', 'Create a reproducible CLI benchmarking harness that trains and evaluates at least three scikit-learn classifiers on every CSV dataset in /app/data using nested stratified k-fold CV, computing accuracy, ROC-AUC, F1, log-loss, Brier score, and calibration error with 95% bootstrap confidence intervals. Aggregate results across datasets with paired Wilcoxon tests and effect sizes to rank models, also measuring CPU inference latency on fixed batch sizes and exporting a single results.json with per-dataset metrics, CIs, significance, and an accuracy–latency Pareto summary.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Benchmarking & Comparison', 'Create a reproducible benchmarking harness that trains five scikit-learn classifiers across four built-in datasets with repeated stratified k-fold, logging ROC-AUC, log loss, Brier score, per-sample latency, and model size to a results file. Run a Friedman test with Nemenyi post-hoc to rank methods, emit a critical-difference diagram, and pick a champion model that satisfies latency and size thresholds.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Benchmarking & Comparison', 'On an imbalanced binary dataset in /app/data.csv, train two baselines (Logistic Regression and Gradient Boosting) and calibrate each with temperature scaling and isotonic regression using a validation split. Benchmark pre/post-calibration AUROC, AUPRC, accuracy, Brier score, NLL, and ECE with bootstrap 95% CIs, then output a metrics CSV and a JSON naming the best-calibrated variant that keeps accuracy within 1% of the uncalibrated best.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Cross-Validation & Statistical Testing', 'Build a Python CLI that runs repeated StratifiedGroupKFold cross-validation to produce out-of-fold predictions for two classifiers, with options for class-weighting to handle imbalance. Compute ROC-AUC/PR-AUC means and bootstrap CIs, apply the Nadeau–Bengio corrected resampled t-test and McNemar’s test to assess performance differences, and write a summary report to /app/results.json.', NULL, ARRAY['python', 'performance']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Cross-Validation & Statistical Testing', 'Create a Python CLI that loads /app/adult.csv and runs nested stratified 5x2 cross-validation comparing tuned logistic regression and tuned random forest on F1 and PR-AUC, then applies Dietterich''s 5x2cv paired t-test and bootstrap 95% CIs for metric differences, writing /app/fold_predictions.csv and /app/eval_report.json with p-values, effect sizes, and CIs. Use fixed seeds for reproducibility, handle class imbalance, and hard-fail if variance across folds is zero.', 'hard', ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Cross-Validation & Statistical Testing', 'Create a Python CLI that performs nested, stratified GroupKFold cross-validation (outer k=5, inner k=3) to tune a logistic regression on an imbalanced dataset with strict group-leakage prevention, aggregating out-of-fold macro-F1 and BCa bootstrap 95% confidence intervals. Implement the Nadeau–Bengio corrected resampled t-test to compare the tuned model against a majority-class baseline and report Holm–Bonferroni-adjusted p-values.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Cross-Validation & Statistical Testing', 'Implement a CLI that compares two classifiers on /app/data.csv using nested stratified 5x2 cross-validation, reporting ROC-AUC and F1 per fold. Assess significance with Dietterich’s 5x2cv paired t-test and DeLong’s AUC test, and output a reproducible JSON containing fold scores, BCa bootstrap 95% CIs, and overall p-values.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Cross-Validation & Statistical Testing', 'Implement a CLI that runs Dietterich’s 5x2 cross-validation paired t-test to compare LogisticRegression and RandomForest on the scikit-learn breast cancer dataset with stratification and fixed seeds. Aggregate out-of-fold predictions to compute ROC AUC and Average Precision with bootstrap 95% CIs, and write per-fold metrics, the t statistic, p-value, and a significance verdict to results.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Error Analysis & Visualization', 'Build a CLI that ingests a CSV of binary classifier outputs (y_true, y_score, group) and generates reliability diagrams with bootstrap CIs, ROC/PR curves, and score histograms, saving plots to /app/eval. It must choose a decision threshold that minimizes expected cost from user-specified FP/FN costs, then emit per-group confusion matrices and a summary JSON reporting ECE, MCE, Brier, AUROC/AUPRC, and the worst-affected groups.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Error Analysis & Visualization', 'Build a CLI that ingests multiclass predictions (logits or probabilities) and ground-truth labels, computes calibration metrics (ECE/MCE, class-conditional ECE, Brier, NLL) with bootstrap confidence intervals, fits temperature scaling on a validation split, and recomputes metrics post-calibration. Output adaptive-binning reliability diagrams, confidence histograms, and per-class normalized confusion matrices highlighting top confusable pairs, and save a concise markdown report linking all figures.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Error Analysis & Visualization', 'Build a CLI that ingests multiclass softmax predictions and ground-truth labels from CSVs in /app/preds/{train,val,test} (optionally including a ''group'' column) and generates per-group confusion matrices and reliability diagrams. Fit temperature scaling on the validation split, then save before/after ECE and Brier scores, interactive HTML plots, and a JSON metrics summary to /app/report.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Error Analysis & Visualization', 'Create a Python CLI that evaluates multivariate time-series forecasts against ground truth, computing per-horizon sMAPE, MASE, and prediction-interval coverage, and generates horizon-wise error heatmaps plus overlay plots of predictions vs. actuals for the worst 10 series by MASE. Write a metrics.json and PNG plots to /app/output while streaming to handle >1e6 points with numerically stable aggregations.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Error Analysis & Visualization', 'Implement a CLI tool that ingests a CSV of predictions (y_true, y_pred, per-class probabilities) plus optional metadata columns and performs comprehensive error analysis: confusion matrix, per-class PR curves, reliability diagram/ECE, and per-slice metrics for each metadata field. Identify the top-3 statistically significant failure slices via bootstrap, then export PNG plots and a JSON report listing highest-confidence false positives/negatives and an optimal threshold per class.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Metric Computation & Reporting', 'Build a CLI evaluator for named entity recognition that parses BIO/BILOU tag sequences, extracts spans, and computes strict and partial-overlap F1, per-entity-type metrics, and micro/macro aggregates. Handle mismatched sequence lengths and invalid tag transitions with robust decoding, output a metrics.json plus a span_errors.csv highlighting boundary and type confusions.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Metric Computation & Reporting', 'Build a CLI that ingests CSVs of true labels and model logits/probabilities for in-distribution and OOD samples, fits a single temperature on a validation split, and computes accuracy, macro-F1, ROC-AUC, PR-AUC, NLL, Brier score, ECE/MCE (fixed and adaptive bins), and OOD AUROC/AUPR/FPR@95 using MSP and energy scores. Output a metrics.json and per-class.csv plus reliability diagrams and score histograms with strict input validation and numerically stable computations.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Metric Computation & Reporting', 'Create a CLI that ingests a CSV of multiclass prediction probabilities and ground-truth labels, computes macro/micro F1, top-1/top-5 accuracy, per-class precision/recall, confusion matrix, and calibration metrics (ECE with adaptive binning, MCE, Brier), and writes a JSON summary plus per-class CSV. Include 1,000-sample bootstrap confidence intervals for scalar metrics and save a reliability diagram and normalized confusion matrix as PNGs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Metric Computation & Reporting', 'Create a CLI that ingests a Parquet file containing multilabel ground-truth indicators and model score columns, learns per-label thresholds on a validation split to maximize macro-F1, then evaluates the test split with those thresholds. Output a JSON report with per-label precision/recall/F1, micro/macro averages, LRAP, coverage error, Jaccard index, and the chosen thresholds, and write per-label 2x2 confusion matrices to CSV.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Evaluation & Validation', 'Metric Computation & Reporting', 'Ingest /app/logits.csv (Nx5 logits) and /app/labels.csv (N class ids), fit temperature scaling to calibrate probabilities, and compute top-1/top-5 accuracy, NLL, ECE (15 bins), Brier score, and macro-F1 before and after calibration with 95% bootstrap confidence intervals. Write a JSON summary to /app/report.json and save a before/after reliability diagram to /app/reliability.png.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Batch & Online Inference', 'Build a CPU-only FastAPI inference service that loads a scikit-learn model from /app/model.pkl, performs dynamic batching by aggregating requests for up to 50 ms before a single model call, and hot-reloads the model when the file changes without dropping in-flight requests. Provide a batch_infer.py CLI that reads /app/input.csv, runs identical pre/post-processing for batched predictions, and writes results to /app/preds.csv including a model_version column.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Batch & Online Inference', 'Build a dual-mode inference app around an ONNX image classifier using onnxruntime: a CLI that runs batched CPU inference over all images in /app/images and writes predictions.csv, and a lightweight HTTP server exposing /predict for single-image requests with lazy, thread-safe model loading and unified preprocessing. Implement optional dynamic batching on the server (short timeout window) and enable onnxruntime CPU optimizations for consistent, reproducible outputs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Batch & Online Inference', 'Export a pretrained torchvision MobileNetV2 to ONNX, then implement an ONNX Runtime-powered FastAPI endpoint for online top-5 ImageNet predictions and a batch script that scores all images in a directory. Include optional dynamic quantization and write JSONL predictions plus latency/throughput metrics for the batch run.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Batch & Online Inference', 'Export a pretrained torchvision ResNet-18 to ONNX and implement a CPU-only FastAPI service backed by ONNX Runtime that supports single-image and dynamic micro-batched inference (≤50 ms window). Provide a CLI for offline batch predictions over a folder, saving top-5 classes per image and recording throughput and p95 latency to /app/metrics.json for both online and batch modes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Latency & Throughput Optimization', 'Build a CPU-only FastAPI inference server for a torchvision ResNet-18 and implement a background queue that performs dynamic micro-batching (coalesce requests for up to 16 images or 10 ms) with a single forward pass using a TorchScript-compiled model and tuned num_threads. Provide a CLI load generator to compare baseline (no batching) versus micro-batched serving and write p50/p95 latency and requests/sec to /app/results.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Latency & Throughput Optimization', 'Build a CPU-only FastAPI service that serves a DistilBERT sentiment classifier via ONNX Runtime, then add three optimizations: static INT8 quantization with calibration, adaptive micro-batching (max batch 16, 10ms timeout), and an LRU cache of tokenized inputs keyed by content hash. Provide a benchmark script that drives concurrent requests and outputs a JSON report comparing p50/p95 latency and throughput before vs after, with a required ≥1.5× throughput and ≥25% p95 latency improvement to pass.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Latency & Throughput Optimization', 'Build an async Python inference server for a small Hugging Face Transformer that adds micro-batching (time-windowed), dynamic int8 quantization, and a tokenizer cache. Provide a replay benchmark that outputs baseline vs optimized p50/p95 latency and throughput to a JSON report.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Latency & Throughput Optimization', 'Containerize a FastAPI inference service for a small Transformer text classifier that implements a background request queue with dynamic micro-batching and an LRU tokenizer cache, and provide an ONNX Runtime int8-quantized variant. Use a load generator to measure QPS and p50/p95 latencies for fp32, int8, and ''int8+batching+cache'' modes, writing a comparison summary to /app/bench.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Latency & Throughput Optimization', 'Create a CPU-only FastAPI inference server for a pretrained DistilBERT classifier that implements time-windowed dynamic batching, int8 dynamic quantization of Linear layers, and a content-hash response cache; include a short warm-up and pad inputs to multiples of 8 tokens. Supply a load generator that compares baseline vs optimized builds and outputs p50/p95 latency and throughput, with tests requiring at least 1.5x throughput improvement without violating a p95 latency SLA.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Model Export & Serialization', 'Export a PyTorch sequence model to both TorchScript (scripted) and ONNX with dynamic axes and opset 17, saving weights in safetensors with strictly pickle-free serialization. Provide a CLI that loads the exported artifacts on CPU, runs onnxruntime and TorchScript inference on the same inputs, and asserts numerical parity within a tight tolerance.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Model Export & Serialization', 'Export a scikit-learn Pipeline that includes a custom categorical encoder and a RandomForest model to ONNX by implementing a custom converter and shape calculator, then verify output parity against the original pipeline with onnxruntime on a mixed-type dataset. Save the portable ONNX and a small parity report summarizing numerical differences and opset/ir metadata.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Model Export & Serialization', 'Export the ''sentence-transformers/all-MiniLM-L6-v2'' PyTorch encoder to ONNX with dynamic batch and sequence axes and also produce an int8-quantized ONNX using onnxruntime. Provide a CLI that tokenizes sentences from /app/input.txt, runs PyTorch vs ONNX (fp32 and int8), checks cosine-similarity parity (1e-3/1e-2), and writes a JSON report with model sizes and average latency.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Model Export & Serialization', 'Implement a CLI that builds a variable-length batched BiLSTM tagger in PyTorch using PackedSequence, exports it to TorchScript and ONNX (opset 17) with dynamic batch and sequence length, and provides an ONNX-compatible unpacking path. Validate numerical parity across eager PyTorch, TorchScript, and ONNX Runtime on randomized inputs, saving all artifacts and a sample input under /app/export.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Model Export & Serialization', 'Train a scikit-learn mixed-type Pipeline (ColumnTransformer with numeric StandardScaler and categorical OneHotEncoder feeding LogisticRegression), then export it to ONNX (opset ≥17) with a dynamic batch axis, explicit input dtypes, and embedded class-label metadata. Validate with onnxruntime that class probabilities and predictions match scikit-learn within a tight tolerance across a holdout CSV, and save both the ONNX artifact and a JSON parity/latency report.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Serving & Deployment', 'Build a FastAPI microservice that serves a scikit-learn model from /app/models/current.pkl with atomic, zero-downtime hot-reloads on file change via a background watcher and readers–writer lock, exposing /predict (batch), /healthz, /readyz, and /promote endpoints. Include a script that swaps in a new model and demonstrates uninterrupted concurrent requests while logging requests and responses to SQLite.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Serving & Deployment', 'Deploy a FastAPI microservice that serves a small ONNX sentiment classifier via ONNX Runtime with async micro-batching (max batch size and wait time), concurrency-safe tokenization, and pydantic request validation. Provide Dockerfile and startup scripts, expose /predict, /healthz, and /metrics (Prometheus) endpoints, and implement a zero-downtime hot-swap endpoint that atomically loads and switches to a new model file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Serving & Deployment', 'Implement a Python gRPC inference server that loads a CPU-only ONNX Runtime model and performs dynamic micro-batching (bounded by batch size and a 50 ms queue window), exposing the gRPC health checking service and a Prometheus /metrics endpoint. Provide a CLI load generator to issue concurrent requests and write a JSON report comparing latency/QPS in batched vs unbatched modes to /app/bench.json.', NULL, ARRAY['python', 'grpc']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Serving & Deployment', 'Package a CPU-only ResNet18 into a TorchServe .mar with a custom handler that performs torchvision preprocessing and returns top-5 class probabilities as JSON. Launch TorchServe on 0.0.0.0:8080, register the model, support both single and batched image requests at /predictions/resnet18 with proper 400 errors for invalid inputs, and expose /ping and Prometheus /metrics for health and monitoring.', NULL, ARRAY['monitoring']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Inference & Serving', 'Serving & Deployment', 'Package a pre-trained PyTorch ResNet18 into a TorchServe .mar with a custom handler that accepts base64-encoded images, applies preprocessing, and returns top-3 labels with probabilities. Launch TorchServe with dynamic batching (e.g., max_batch_size=8), register the model via the management API, issue batched requests, and write a latency/throughput summary to /app/serve_metrics.json.', NULL, ARRAY['pytorch', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Fine-Tuning Pretrained Models', 'Add LoRA adapters to a pretrained T5-small and fine-tune on a local summarization dataset in /app/data (train.jsonl, val.jsonl) while freezing all base weights, then export both an adapter-only checkpoint and a merged full model. Verify base weights are bitwise-identical pre-merge, that the merged model matches adapter outputs on a fixed prompt, and that ROUGE-L on val improves over the frozen baseline.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Fine-Tuning Pretrained Models', 'Fine-tune T5-small with parameter-efficient prefix tuning to translate English task descriptions into Bash one-liners on a provided dataset; evaluate exact match and BLEU on a held-out split, and save both the prefix adapter and a merged model plus predictions.json to /app.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Fine-Tuning Pretrained Models', 'Fine-tune a pretrained sentence-transformer (e.g., sentence-transformers/all-MiniLM-L6-v2) on provided positive/negative sentence pairs with a contrastive cosine-similarity loss to adapt it for semantic search. Provide a CPU-only CLI that trains, saves the fine-tuned encoder, and reports MRR@10 and Recall@10 on a held-out query set using exact cosine similarity over corpus embeddings.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Fine-Tuning Pretrained Models', 'Implement parameter-efficient fine-tuning by inserting lightweight adapter modules into a pretrained DistilBERT for domain text classification, training only adapters with discriminative layer-wise learning rates and a slanted triangular schedule. Provide a CLI to train/evaluate, export adapter-only weights, verify the frozen base model hash is unchanged, and support hot-swapping different adapter checkpoints at inference.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Hyperparameter Optimization', 'Build a CLI that performs multi-objective hyperparameter optimization with Optuna for a PyTorch CNN on Fashion-MNIST, maximizing validation accuracy while minimizing wall-clock time via ASHA pruning and a SQLite-backed study that can be resumed. After the search, pick the Pareto-optimal trial under a 30s time budget, deterministically retrain on the full training set, and export best_config.json, study.db, metrics.json, and best_model.pt.', NULL, ARRAY['optimization', 'pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Hyperparameter Optimization', 'Build a reproducible Optuna-powered multi-fidelity search (ASHA pruner) that tunes learning rate, weight decay, batch size, and transformer depth for a small text classifier on a provided CSV, persisting the study to SQLite. After the search, retrain the best trial and export the final model along with a Pareto front that balances validation accuracy against measured inference latency.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Hyperparameter Optimization', 'Build an Optuna multi-objective HPO pipeline that trains a tabular classifier (XGBoost if installed, otherwise scikit-learn GradientBoosting) with stratified K-fold CV to jointly minimize validation log loss and 95th-percentile per-sample prediction latency. Implement pruning, class-imbalance handling, and a dynamic search space conditioned on the chosen estimator, then export the selected Pareto-optimal trial’s hyperparameters, a serialized model, and a small report of the Pareto front.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Hyperparameter Optimization', 'Create a reproducible, multi-objective Optuna study that tunes a CPU-only PyTorch tabular classifier (layers, width, dropout, learning rate, weight decay, batch size) to simultaneously maximize ROC-AUC and minimize measured inference latency using ASHA pruning within a fixed time budget. Persist the study to a local SQLite DB, export the Pareto-optimal trials to /app/pareto.json, and save the fastest model meeting a target AUC threshold to /app/best_model.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Hyperparameter Optimization', 'Run a multi-objective Optuna study to tune a CPU-only LightGBM classifier on the UCI Adult income dataset, maximizing ROC-AUC while minimizing p95 inference latency over 10k predictions. Persist the study, write the Pareto front with hyperparameters to JSON, and export the fastest Pareto-optimal model artifact to /app.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Resource Management & Parallel Training', 'Build a PyTorch DDP training harness that runs a small CNN on synthetic data in both single-process and 4-rank torchrun modes, auto-selecting CPU/GPU and gloo/NCCL while pinning one device per rank and using gradient accumulation with optional AMP to keep the effective batch size constant. Log images/sec per rank, global throughput, speedup vs single-process, and (if GPUs exist) per-GPU memory/utilization via nvidia-smi, saving a final JSON/CSV report.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Resource Management & Parallel Training', 'Build a PyTorch training launcher that runs a small CNN under DistributedDataParallel across all available GPUs (falling back to multi-process CPU via gloo), automatically selecting the largest per-device microbatch via OOM-aware binary search and using gradient accumulation to hit a target global batch size. Record per-rank and averaged throughput, communication overlap vs non-overlap timings, and memory usage to a CSV, and support resuming checkpoints when world_size changes.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Resource Management & Parallel Training', 'Implement a CPU-only pipeline-parallel trainer that splits a small Transformer into 2–4 stages across torch.distributed processes with a GPipe-style microbatch schedule, auto-falling back to single-process when world_size=1. Run via torchrun and output a JSON report comparing baseline vs pipeline throughput, per-stage latency, and memory usage.', NULL, ARRAY['parallel', 'distributed']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Resource Management & Parallel Training', 'Implement a PyTorch DistributedDataParallel training launcher that runs on CPU (gloo) but uses CUDA if available, employs ZeroRedundancyOptimizer to shard optimizer state, and supports gradient accumulation with optional mixed precision. It must log per-rank and aggregate throughput and memory usage, save a single rank-0 checkpoint, and verify synchronized weights across ranks after each epoch.', 'hard', ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Resource Management & Parallel Training', 'Implement a PyTorch training launcher that uses torchrun to start DistributedDataParallel across all detected GPUs (falling back to multi-process CPU with Gloo), pins each rank to a device, and enables AMP on CUDA. Log per-rank throughput (images/sec) and memory stats to a shared JSONL and aggregate a final /app/throughput.json confirming that multi-GPU total throughput scales over a single process baseline.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Supervised & Unsupervised Learning', 'Build a semi-supervised pipeline that uses Label Spreading to pseudo-label unlabeled samples, then trains a calibrated LogisticRegression on the union of labeled and high-confidence pseudo-labeled data and benchmarks against a labeled-only baseline. Provide a CLI for labeled fraction, confidence threshold, and seed, and write accuracy/F1/ROC-AUC plus class balance summaries to /app/metrics.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Supervised & Unsupervised Learning', 'Implement a from-scratch Gaussian Mixture Model with EM that supports full/diagonal covariances, K-means++ initialization, and automatic component selection via BIC, then train on a large CSV to output cluster assignments and model parameters. Ensure strong numerical stability (log-sum-exp, covariance regularization) and a streaming-compatible E-step for memory-constrained environments.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Supervised & Unsupervised Learning', 'Implement an EM-based Gaussian Mixture Model trainer (NumPy only) with diagonal covariances that selects the optimal number of components via BIC and enforces monotonic log-likelihood across iterations. Provide a CLI that reads a CSV, runs multiple random restarts per K, and saves the chosen K, parameters, responsibilities, and cluster labels to /app/out.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Supervised & Unsupervised Learning', 'Learn a supervised metric using scikit-learn’s Neighborhood Components Analysis on labeled data, then perform k-means clustering in the learned embedding on the full dataset. Save cluster assignments and evaluate clustering quality with adjusted mutual information and silhouette scores to a metrics file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Supervised & Unsupervised Learning', 'Train a sparse autoencoder in PyTorch on a numeric tabular dataset with early stopping and L1 activation regularization, saving the encoder to /app/encoder.pt. Freeze the encoder to generate embeddings and train a scikit-learn logistic regression on labels, reporting stratified 5-fold ROC-AUC and writing metrics and artifact paths to /app/results.json.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Training Loop Implementation', 'Implement a PyTorch training loop for a stateful RNN that performs truncated backpropagation through time on a streaming text dataset, correctly carrying/detaching hidden states across chunks with global-norm gradient clipping and LR warmup+cosine decay. Add fully resumable mid-epoch checkpoints that capture optimizer/scheduler/RNG/file offsets/per-stream hidden states, plus early stopping on validation perplexity with top-k best checkpoints.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Training Loop Implementation', 'Implement a PyTorch training loop for a tiny character-level language model on a given corpus with truncated BPTT, gradient accumulation, global-norm gradient clipping, and early stopping on validation loss. Support rotating checkpoints (keep N), exact resume of optimizer/scheduler and RNG state after interruption, and deterministic results when a seed is provided.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Training Loop Implementation', 'Implement a PyTorch training loop that supports mixed-precision (AMP) with GradScaler, gradient accumulation, global-norm clipping, cosine LR scheduling, early stopping on validation loss, and checkpointing that rotates top-2 best models plus the latest. The loop must be fully resumable (optimizer/scheduler/AMP scaler/RNG states) after an external SIGTERM or KeyboardInterrupt, skip NaN/Inf batches safely, and produce deterministic metrics given a seed on a tiny synthetic dataset.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Training Loop Implementation', 'Implement a custom PyTorch training loop for SimCLR-style contrastive learning on a small image dataset with mixed precision, gradient accumulation, per-step gradient clipping, cosine warmup+restarts, temperature annealing, EMA weights, and robust checkpointing (best/last with resume). Validate via k-NN on frozen embeddings each epoch and support early stopping on top-1 accuracy.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Model Training & Optimization', 'Training Loop Implementation', 'Implement a pure-PyTorch training loop for a CNN on a synthetic image dataset with gradient accumulation, automatic mixed precision (CPU/GPU fallback), global-norm gradient clipping, cosine-annealing learning-rate scheduling, and early stopping on a validation metric. Add robust checkpointing that saves and restores model/optimizer/scheduler states, best metric, and dataloader progress to resume mid-epoch or after SIGINT/SIGTERM, producing both latest and best artifacts.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Environment Setup & Policy Training', 'Build a CLI that reads a JSON-specified stochastic GridWorld (walls, terminal states, slip probability) and trains a tabular Q-learning agent with epsilon-greedy exploration and learning-rate decay to learn an optimal policy. Support variable map sizes and multiple maps in a folder, ensure deterministic seeding, evaluate the greedy policy to meet a success-rate threshold, and save both the Q-table and a human-readable policy artifact.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Environment Setup & Policy Training', 'Build a PettingZoo AEC multi-agent predator–prey gridworld with optional message-passing actions and invalid-move masking, register it with Gymnasium, and configure RLlib to train decentralized PPO policies with GAE, vectorized rollout workers, and resume-from-checkpoint support. Evaluate on held-out procedurally generated maps (fixed seed) and require a ≥0.70 predator win rate over 100 episodes while logging training metrics to TensorBoard.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Environment Setup & Policy Training', 'Create a custom Gymnasium environment backed by a SimPy discrete-event simulation of a two-station production line with stochastic arrivals and a controllable dispatch/batching policy. Train a Stable-Baselines3 PPO agent on CPU to minimize average job latency, logging learning curves and saving a checkpoint and evaluation report that demonstrates at least a 20% latency reduction versus a fixed-rate heuristic baseline.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Environment Setup & Policy Training', 'Create and register a custom Gymnasium environment ''ThermalControl-v0'' whose dynamics (heat capacity, loss rate, actuator limits, and disturbance sequence) are loaded from /app/dynamics.yaml, and train a Soft Actor-Critic agent with stable-baselines3 (automatic entropy tuning) to keep temperature within a target band via domain-randomized episodes. Save the trained policy to /app/checkpoints and a 100-episode seeded evaluation log (time, state, action, reward) to /app/eval.csv for automated verification.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Environment Setup & Policy Training', 'Install Ray RLlib with PettingZoo and SuperSuit, configure the MPE simple_spread_v3 multi-agent environment, and train a shared-parameter PPO policy using vectorized parallel environments. Export the trained policy to TorchScript and run a seeded evaluation that writes per-agent rewards and coverage metrics to /app/mpe_eval.json.', NULL, ARRAY['parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Multi-Agent & Self-Play Training', 'Implement a PSRO self-play pipeline for the Rock-Paper-Scissors-Lizard-Spock normal-form game, iteratively training best-response policies via no-regret updates against the evolving meta-strategy. After convergence, compute the mixed Nash distribution and exploitability, and write them to /app/solution.json, passing tests by staying below a specified exploitability threshold.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Multi-Agent & Self-Play Training', 'Implement a self-play Counterfactual Regret Minimization trainer for Kuhn Poker with a minimal game engine including chance nodes, information-set caching, and average-strategy export. The script should train to a low-exploitability policy verified by a best-response evaluator, be reproducible via seeding, and finish on CPU within tight time limits.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Multi-Agent & Self-Play Training', 'Implement a self-play training pipeline for Connect Four using OpenSpiel where a PyTorch policy–value network is optimized via AlphaZero-style MCTS. After training, evaluate against a depth-limited minimax baseline over 100 games and save win/draw/loss and Elo metrics to /app/results.json.', NULL, ARRAY['pytorch']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Multi-Agent & Self-Play Training', 'Implement from-scratch CFR+ self-play for Kuhn Poker with a CLI to train for N iterations and compute exploitability via an exact best response. Save the average strategy to /app/kuhn_policy.json and ensure the final policy’s exploitability is ≤0.05 chips.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Multi-Agent & Self-Play Training', 'Train a near-Nash strategy for Kuhn Poker via self-play Counterfactual Regret Minimization (CFR/CFR+) using OpenSpiel (pyspiel), then serialize the average policy and compute exploitability. Produce a policy artifact and a metrics report demonstrating exploitability below a specified threshold.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Reward Design & Evaluation', 'Augment Gymnasium’s LunarLander-v2 with a configurable multi-objective reward balancing landing accuracy, fuel efficiency, and leg-contact stability, then sweep at least 32 coefficient sets where each trains a lightweight PPO agent for a fixed budget. Compute and save the Pareto frontier and knee-point selection with CSV/plots of episodic return, crash rate, and fuel use to verify the chosen reward balances competing objectives.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Reward Design & Evaluation', 'Design and evaluate multi-objective rewards for Gymnasium’s Taxi-v3 by augmenting the sparse reward with penalties for illegal pickup/dropoff and a discomfort cost proportional to action changes, implementing both scalarized (lambda-weighted) and Lagrangian-constrained formulations. Train a tabular Q-learning agent across a sweep of coefficients and report the Pareto frontier between episode length and discomfort with a baseline comparison to the original sparse reward.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Reward Design & Evaluation', 'Implement a Gymnasium-compatible ''Windy Keys-and-Doors'' gridworld and design a potential-based reward shaping function that balances goal completion, energy use, and safety while preserving the optimal policy. Provide a training/evaluation script that compares shaped vs. sparse rewards (e.g., with tabular Q-learning), demonstrating faster learning and fewer collisions, verifying equal optimal returns, and flagging reward-hacking behaviors.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Reward Design & Evaluation', 'Implement a custom Gymnasium GridWorld with a sparse goal reward, time penalty, and stochastic hazard tiles, then compare two rewards: potential-based shaping via Manhattan-distance potential and a naive per-step progress bonus. Train PPO under both and report success rate, hazard contacts, and path optimality gap to highlight shaping invariance vs reward hacking.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Reward Design & Evaluation', 'In a 2D gridworld with a key, a locked door, and a fragile vase, implement and compare three rewards: sparse goal-only, potential-based shaping with step penalty, and a side-effect avoidance term that penalizes action impact relative to an inaction baseline using object-position L1 distance. Train a fixed PPO agent under each reward, detect reward hacking like key pick/drop loops, and produce a summary of goal success, vase collisions, loop frequency, and sample efficiency.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Simulation Rollouts & Replay Buffers', 'Implement a disk-backed prioritized replay buffer daemon that ingests CartPole-v1 transitions from multiple local producer scripts over TCP, computes n-step returns across episode boundaries, and persists state for crash-safe restart. Provide a client to sample mini-batches with PER (alpha/beta) and importance weights, with a test harness that verifies sampling distribution, deterministic checksums for sampled batches, and replay continuity after restart.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Simulation Rollouts & Replay Buffers', 'Implement a goal-conditioned 2D grid environment and generate large-scale rollouts to an on-disk replay buffer supporting Hindsight Experience Replay, n-step returns, and prioritized sampling with importance weights. Train a lightweight DQN for several thousand updates from this buffer and output success-rate curves and sampling diagnostics derived from the stored trajectories.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Simulation Rollouts & Replay Buffers', 'Implement a memory-mapped, Zarr-backed replay buffer for Gymnasium Dict/Box spaces with prioritized experience replay, n-step returns, and sequence sampling for RNN policies (burn-in, overlap, zero-padding). Provide a CLI to run vectorized rollouts to populate the store, then deterministically sample batches under a fixed seed and output a JSON report verifying priority distributions, importance-sampling weights, and crash-safe resume behavior.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Simulation Rollouts & Replay Buffers', 'Implement a multiprocessing rollout + learner system that generates goal-conditioned episodes and stores them in a segment-tree prioritized replay buffer with n-step returns and on-the-fly Hindsight Experience Replay relabeling. The buffer must support batched append/sample/update with importance-sampling weights, be mmap-backed to handle 10M+ transitions, and a training script should reach a target success rate while validating sampling distribution and bias correction.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Reinforcement Learning & Simulation-Based Training', 'Simulation Rollouts & Replay Buffers', 'Implement a prioritized experience replay buffer using a segment tree that supports n-step returns, sequence sampling for recurrent policies, and per-sample importance weights. Provide a CLI to collect rollouts from parallel Gymnasium environments, persist the buffer to disk in chunked files, then reload to verify sampling probabilities, TD-error updates, and n-step target consistency.', NULL, ARRAY['parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Adversarial Robustness & Defense', 'Create a CLI pipeline that attacks a pretrained image classifier with EOT-PGD over random crops, rotations, and Gaussian noise, then reports robust accuracy and worst-case loss. Implement a defense via randomized smoothing with calibrated sigma to compute per-sample certified radii and write a CSV summarizing clean/robust accuracy and certificates for a test subset.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Adversarial Robustness & Defense', 'Implement a CPU-only Python CLI that loads a provided CIFAR-10 model, wraps it with a non-differentiable defense (bit-depth reduction plus randomized resizing), and evaluates robust accuracy under FGSM, PGD, and BPDA+EOT-PGD. Save per-attack metrics to /app/robust_metrics.json and 32 adversarial samples per attack to /app/adv/{attack}/, demonstrating that BPDA+EOT meaningfully reduces reported robustness compared to naive PGD.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Adversarial Robustness & Defense', 'Train a small CNN on MNIST (CPU) and implement FGSM and PGD-Linf attacks. Add a feature-squeezing detector (bit-depth reduction + median smoothing) and an adversarially trained variant, then report clean/robust accuracy at eps=0.3 and ROC-AUC for detection, saving metrics and checkpoints.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Adversarial Robustness & Defense', 'Train a small CNN on MNIST, implement FGSM and multi-step PGD (with Expectation-over-Transformation for stochastic defenses) to craft adversarial examples at multiple L∞ epsilons, and report clean/robust accuracies with saved adversarial image grids. Add PGD adversarial training and a randomized smoothing inference defense, then re-evaluate and output a JSON metrics report plus a file of estimated certified radii for 100 test samples.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Adversarial Robustness & Defense', 'Train a small CNN on a CIFAR-10 subset, wrap it with an L2 randomized smoothing certifier (configurable sigma), and compute per-example certified radii with 95% confidence for 200 test images, writing certificates.csv and a summary JSON. Implement an EOT-PGD attack that accounts for the smoothing noise and report robust vs attacked accuracies across L2 epsilons, verifying certified accuracy lower-bounds are not violated.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Bias Detection & Mitigation', 'Build a CLI pipeline that trains a baseline binary classifier on /app/data.csv, computes demographic parity, equal opportunity, and disparate impact for sex and race, then applies Calibrated Equalized Odds post-processing to the model’s probabilities to reduce violations. Write a before/after report with bootstrap confidence intervals to /app/fairness_report.json and save learned group-specific thresholds/weights to /app/thresholds.json.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Bias Detection & Mitigation', 'Build a CLI that loads /app/loans.csv containing features, a binary label y, and a sensitive attribute S, trains a logistic regression baseline, reports fairness metrics per group (demographic parity difference, equalized odds difference, disparate impact), then applies Kamiran–Calders reweighing and a per-group threshold optimizer to enforce equal opportunity within 2% while minimizing accuracy loss. Save before/after metrics and per-group confusion matrices to /app/fairness_report.json, persist the learned thresholds, and repeat the evaluation under a covariate-shifted test split using importance weighting to verify fairness generalization.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Bias Detection & Mitigation', 'Create a Python CLI that loads /app/data.csv with features, label, and protected_attribute, audits a logistic-regression baseline via demographic parity difference, equalized odds difference, and calibration within groups, then mitigates bias using reweighting plus group-wise threshold optimization. Write a before/after fairness report to /app/fairness_report.json, requiring <2% accuracy drop and at least 50% reduction in each measured disparity.', NULL, ARRAY['python', 'optimization']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Bias Detection & Mitigation', 'Create a Python CLI that trains a binary classifier on a tabular dataset, scans all intersectional subgroups (combinations of up to 3 sensitive attributes) to find the worst demographic parity difference and equalized odds violation, and then applies a per-group threshold optimizer to reduce violations below a target while keeping overall AUC within 2%. Output a before/after fairness report (JSON) and save the calibrated, debiased model and the learned group thresholds.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Bias Detection & Mitigation', 'Create a command-line pipeline that trains a credit-approval classifier, computes subgroup fairness metrics (demographic parity, equalized odds, disparate impact), and then applies reweighing plus threshold optimization to mitigate bias. Save a before/after fairness report JSON, per-group decision thresholds, and the mitigated model artifact.', NULL, ARRAY['optimization']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Ethical & Policy Compliance Validation', 'Build a CLI pipeline that scans a raw text corpus, detects PII (emails, phones, names, addresses) via regex+NER, applies consistent pseudonymization, and produces both a redacted dataset and a provenance ledger with SHA-256 hashes, source URLs, and SPDX license IDs. Then evaluate a fine-tuned text generation model for privacy compliance by running canary extraction and membership inference tests, emitting a JSON report of leakage metrics and pass/fail flags against given thresholds.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Ethical & Policy Compliance Validation', 'Build a CLI that audits a JSONL training dataset and a local text-generation model for policy compliance by verifying data provenance (required source_url and license in an allowed whitelist) and detecting/redacting PII (emails, phones, addresses, SSNs) with deterministic hashing. Run a fixed red-teaming prompt suite against the model to flag PII leakage and disallowed content, then emit a compliance_report.json with per-rule counts, sample snippets, thresholds, overall pass/fail, and a sanitized_data.jsonl output.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Ethical & Policy Compliance Validation', 'Build a Python CLI that scans /app/data/{train,test} and /app/logs/inference.log for PII (names via a bundled dictionary, emails, phones, IPs, street addresses, government IDs) and validates that each record has provenance in /app/metadata.jsonl with a source, timestamp, and SPDX license from an allowed list. Automatically redact violations, emit a tamper-evident audit to /app/compliance_report.json with SHA-256 hashes and a redaction map, and exit non-zero if any unredacted PII or disallowed licenses remain.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Ethical & Policy Compliance Validation', 'Build a streaming Python CLI that ingests a large CSV of free-text training data plus a whitelist of permitted licenses, detects and redacts PII (names, emails, phone numbers, addresses, SSNs) via regex and spaCy NER, and validates each row’s provenance against a provided source-to-license map. Output a JSONL compliance report with SHA-256 hashes of raw and redacted text, per-row PII categories found/redacted, license verdicts, and exit non-zero if any violation exceeds configured thresholds.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Ethical & Policy Compliance Validation', 'Create a terminal CLI that validates a dataset’s licensing and provenance for model training by parsing per-file metadata and SPDX identifiers, verifying cryptographic hashes against a manifest, and checking compatibility with a specified usage policy (e.g., commercial use). The tool should emit a machine-readable compliance report and a symlinked approved/ subset, failing with clear diagnostics for missing, incompatible, or conflicting licenses.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Explainability & Interpretability', 'Build a CPU-only CLI that trains a simple MLP on a tabular dataset and computes per-sample feature attributions using LIME, KernelSHAP, and Integrated Gradients, normalizing outputs into a common schema. Export JSONL attributions, a global feature ranking, and quantitative consistency metrics (additivity/completeness checks, Kendall tau agreement, and deletion/insertion AUCs) to predefined paths.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Explainability & Interpretability', 'Create a CLI tool that trains a scikit-learn tabular classifier on a provided CSV, computes per-sample SHAP (TreeExplainer) and LIME attributions, and writes unified explanations to /app/explanations.json with global summaries. Evaluate faithfulness by producing deletion/insertion curves that mask features by attribution rank, outputting Kendall rank agreement and AUC metrics to /app/faithfulness.csv with deterministic seeding and memory‑efficient batching.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Explainability & Interpretability', 'Create a CPU-only Python CLI that trains a scikit-learn RandomForestClassifier on /app/data/train.csv (binary target column ''y''), computes per-sample feature attributions with SHAP TreeExplainer and LIME TabularExplainer on the test split across 10 random seeds, and quantifies explanation stability via Kendall tau of top-10 feature rankings for each sample. Save per-method global summaries (mean absolute attribution), per-sample top-10 attributions, and a comparison report with median stability and method win-rate to /app/explainability/, and exit with nonzero status if SHAP''s median stability is lower than LIME''s.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Explainability & Interpretability', 'Implement a CLI that explains predictions of a pretrained HuggingFace sentiment model on a text file using both SHAP and LIME, repeating each method over multiple random seeds to quantify stability (Kendall tau of token-importance ranks and top-k Jaccard overlap). Write a JSON summary of stability metrics, a CSV of per-example attributions, and HTML token heatmaps for the most unstable cases.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Machine Learning & AI', 'Responsible AI & Model Robustness', 'Explainability & Interpretability', 'Train a gradient boosting classifier on the UCI Adult dataset and generate local explanations for 20 test instances using both SHAP and LIME. Implement a faithfulness evaluation via deletion/insertion curves over ranked features, report AUC metrics for each method, and save per-instance attributions (JSON) and summary plots to /app/.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Astronomy & Astrophysics Computation', 'Build a CLI tool that ingests a set of NORAD TLEs and a ground-station coordinates file, propagates each orbit with SGP4 over a 24-hour window, and computes visibility passes above a given elevation threshold (AOS/LOS times, max elevation, range). Write per-satellite CSV summaries and an aggregated ICS calendar of visible passes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Astronomy & Astrophysics Computation', 'Build a Python CLI that reads a time–flux light curve from /app/lightcurve.csv, robustly detrends it, and uses a Box Least Squares search to detect the strongest transiting-planet signal. Write the inferred period, transit epoch, depth, duration, and SNR to /app/transit.json and save the phase-folded, binned light curve to /app/phase.csv.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Astronomy & Astrophysics Computation', 'Implement a CLI tool that ingests asteroid astrometric observations in MPC 80-column format, computes a preliminary orbit (e.g., Gauss) and refines it via weighted least-squares differential corrections. Propagate the fitted state to a target UTC with a two-body Kepler solver and write osculating elements, residual RMS, and a topocentric RA/Dec ephemeris from a specified observatory code.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Astronomy & Astrophysics Computation', 'Implement an exoplanet transit search tool that reads a stellar light curve, detrends it, and runs a Box Least Squares period search over a specified grid with careful, unit-aware time handling. Output the best-fit ephemeris (period, epoch, duration, depth) with detection metrics and a phase-folded, binned curve to standardized files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Astronomy & Astrophysics Computation', 'Implement an initial orbit determination and refinement pipeline that reads multi-epoch asteroid astrometry (UTC, RA, Dec, observatory) to compute a heliocentric two-body solution using Gauss’ method followed by nonlinear least-squares differential corrections. Output Keplerian elements at a target epoch, a 6×6 covariance estimate, propagated ephemerides, and postfit residual statistics.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Climate & Environmental Modeling', 'Build a CLI tool that reads CF-compliant NetCDF files of monthly precipitation and potential evapotranspiration, computes the 12-month SPEI per grid cell via log-logistic fitting with robust handling of missing values, and writes a CF-compliant NetCDF of SPEI. Additionally, produce a CSV time series of global land-area fraction in drought (SPEI <= -1) for each month.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Climate & Environmental Modeling', 'Build a zero-dimensional energy balance climate model that ingests historical radiative forcing and GMST series, estimates the climate feedback and effective heat capacity via constrained least squares, then projects global-mean temperature through 2100 under provided forcing scenarios. Output the fitted parameters, hindcast skill metrics, and scenario trajectories to standardized files.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Climate & Environmental Modeling', 'Create a Python CLI that reads daily gridded NetCDF temperature and precipitation and computes three ETCCDI indices—TX90p, CDD, and PRCPTOT—per grid cell for a user-specified baseline, honoring CF calendars, masks, and leap years, and writes CF-compliant NetCDF outputs. Also compute area-weighted global and region-mean time series using cell areas and save a summary CSV.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Climate & Environmental Modeling', 'Implement a two-box global energy balance model (mixed-layer plus deep ocean) driven by a provided radiative forcing time series to simulate global-mean temperature and ocean heat uptake. Calibrate feedback, heat capacities, and exchange parameters against historical GMST and OHC data, then output ECS, TCR, fitted parameters, and scenario projections.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Computational Chemistry & Biology', 'Build a Python CLI that loads an SBML metabolic model and uses COBRApy with a GLPK solver to perform FBA, then evaluates growth under multiple media conditions and all single-gene knockouts to identify essential genes. Save growth rates per condition and the essential gene list to standardized JSON/CSV outputs.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Computational Chemistry & Biology', 'Create a BioPython-based tool that reads a coding DNA sequence and a list of restriction enzymes, then computes the minimal set of synonymous mutations needed to remove all listed recognition sites while preserving the protein sequence. Ensure no new listed sites are created, favor host-preferred codons to keep GC content within ±5% of the original, and output the mutated sequence and a CSV change log.', NULL, ARRAY['coding']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Scientific Computing & Analysis', 'Domain-Specific Computation', 'Computational Chemistry & Biology', 'Create a Python CLI that loads a metabolic network SBML (/app/model.xml), builds the stoichiometric matrix, and performs flux balance analysis to maximize a specified biomass reaction using linear programming. Validate mass balance and bounds, identify exchange reactions, then write the optimal flux vector and dual shadow prices to CSV files.', NULL, ARRAY['python']);
