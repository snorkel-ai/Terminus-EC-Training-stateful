-- Compact batch 19/29: rows 901-950

INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES
('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Library Development & Documentation', 'Develop a typed Python library for uncertainty propagation via Polynomial Chaos Expansions, supporting Gaussian/Uniform inputs, sparse regression and quadrature fitting, and computing means/variances plus first/total Sobol indices. Provide a CLI that loads a black-box model from a Python module and a JSON distribution spec to write a results JSON, and include unit tests and Sphinx docs with API and examples.', NULL, ARRAY['python', 'api']),
('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Build a metamorphic and differential testing framework for FFT/IFFT routines that auto-generates random and structured signals, validates Parseval’s theorem, round-trip fidelity, and the convolution theorem, and cross-checks outputs between numpy.fft and an FFTW-based CLI tool within set tolerances. Integrate deterministic seeding, tolerance budgets, and performance regression guards into a CI pipeline that fails on numerical drift or speed regressions.', NULL, ARRAY['testing', 'performance']),
('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Build a metamorphic and property-based test harness for a 2D Poisson solver that generates randomized periodic RHS fields, asserts exact recovery on single Fourier modes, checks symmetry/conservation invariants, and differential-tests against an independent finite-difference reference with convergence and error thresholds. Provide a CLI to run the suite and a CI workflow that records metrics and fails on tolerance regressions.', NULL, NULL),
('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Build a pytest + Hypothesis metamorphic testing suite for a time-integration library (explicit/implicit Runge–Kutta) that verifies order of accuracy via step-halving, checks conserved quantities on canonical systems (harmonic oscillator, Kepler), and validates A-stability on the Dahlquist test equation. Provide a CLI to run the suite with numeric tolerance gates, enforce coverage thresholds, and emit JUnit XML and coverage artifacts suitable for CI.', NULL, ARRAY['testing']),
('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Create a pytest + Hypothesis test harness that ingests a finite-difference PDE solver and verifies second-order accuracy via manufactured solutions, conservation and boundary-condition compliance, and monotonic error reduction under grid refinement. The suite must emit JUnit XML and a JSON convergence report and fail if the estimated order falls below 1.8 on any tested problem.', NULL, NULL),
('Scientific Computing & Analysis', 'Scientific Software Engineering', 'Testing & Verification Frameworks', 'Create an automated test/CI harness that runs a provided 1D PDE solver across successively refined grids on manufactured solutions, computes L2 errors, fits the empirical convergence order, and fails if it falls below a set tolerance. Include metamorphic tests for boundary-condition transformations and a discrete conservation check, and emit JSON and JUnit XML summaries.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Build a Python CLI that performs adjoint-based parameter estimation for an ODE by integrating both the forward system and its continuous-time adjoint to obtain exact gradients of a least-squares misfit. Apply it to fit the Lorenz system’s (sigma, rho, beta) to a provided noisy trajectory, and report recovered parameters along with adjoint–finite-difference gradient agreement.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Build a Python CLI that solves the Lane–Emden boundary-value problem y'''' + (2/x) y'' + y^n = 0 with y(0)=1, y''(0)=0 using a shooting method and SciPy''s solve_ivp, seeding near x=0 from a SymPy-derived series expansion. Write the sampled solution and the first zero-crossing radius to output files and report max error versus the closed-form solutions for n=0 and n=1.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Implement a 1D Fisher–KPP reaction–diffusion simulator using FiPy that, given D and r, initializes a step profile, advances to a traveling-wave regime, and estimates the wavefront speed from threshold crossings over time. Save positions and the speed estimate to outputs and verify the speed is within 5% of the theoretical 2*sqrt(D*r).', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Implement a 1D heat-equation solver with time-dependent source and mixed (Robin) boundary conditions using second-order finite differences in space and Crank–Nicolson time stepping, solving the per-step tridiagonal system via the Thomas algorithm. The CLI should ingest problem parameters and output snapshots at requested times to CSV and additionally run a mesh-refinement check to confirm ~O(Δx^2 + Δt^2) convergence.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Differential Equation Solvers', 'Implement a Python CLI that solves the 1D Fisher–KPP reaction–diffusion PDE on [0, L] with Neumann boundaries via method-of-lines (finite differences) using SciPy’s stiff integrator from a compact initial condition. Estimate the traveling wave speed from the simulation and verify it is within 5% of the theoretical minimum 2*sqrt(D*r), writing the estimated speed and error to /app/answer.json.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a 1D discontinuous Galerkin solver for linear advection with periodic boundaries, selectable numerical flux (upwind/Rusanov), and SSPRK time stepping; expose CLI options for polynomial order, CFL, and final time. Output field snapshots and L2 error versus the exact shifted solution, and verify k+1 convergence across mesh refinements.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a 2D finite element solver for -∇·(k∇u)=f on a Gmsh triangular mesh with mixed Dirichlet/Neumann boundaries, assembling a sparse system and solving with Conjugate Gradient and a basic preconditioner. Validate via a manufactured solution by reporting L2 and H1-seminorm errors across at least two mesh refinements, and write both the nodal field and error summary to output files.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a 2D linear-elasticity finite element solver using first-order (P1) triangular elements that reads a Gmsh (.msh) cantilever beam mesh, assembles the global system with mixed Dirichlet–Neumann boundary conditions, and solves for displacements. Output nodal displacements and von Mises stress (VTK/CSV) and write total strain energy and tip deflection to /app/answer.json.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a Python finite element solver for 2D linear elasticity on an L-shaped domain using P1 triangles from a provided Gmsh mesh, enforcing Dirichlet and traction boundary conditions and computing von Mises stress. Include a Zienkiewicz–Zhu a posteriori error estimator with Doerfler marking to drive three adaptive refinement cycles, writing VTK field outputs and a JSON convergence summary (DOFs, ||u||_H1 error, observed rate).', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Finite Element & Numerical Methods', 'Implement a sparse finite element modal analysis tool for 2D trusses: parse nodes and bar elements with A, E, and ρ, assemble global stiffness and consistent mass matrices, apply fixed DOFs, and compute the first k natural frequencies and mode shapes via eigsh. Write frequencies to an output text file and mode shapes to a mesh-compatible format (e.g., VTK/CSV).', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Build a 1D heat-equation simulator (explicit FTCS with Dirichlet boundaries) that sweeps spatial resolution and timestep to explore CFL stability and convergence, comparing against an analytic solution. For each (dx, dt), record stability, L2 error at a fixed final time, and estimate order-of-accuracy across resolutions in a summary CSV.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Build a CLI tool that runs a stochastic SIR epidemic simulation (Gillespie SSA) and performs a Sobol global sensitivity analysis over R0, mean infectious period, and initial infected fraction, reporting first- and total-order indices for peak prevalence, time-to-peak, and final size. Use Saltelli sampling with a fixed seed, parallelize simulations, and write indices and summary metrics to CSV/text outputs.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Build a Monte Carlo simulator for the 2D Ising model with periodic boundaries, sweeping temperature across a range and multiple lattice sizes to compute ensemble magnetization, energy, specific heat, susceptibility, and Binder cumulant. Estimate the critical temperature by locating the susceptibility peak and Binder cumulant crossing, saving the full per-temperature statistics and Tc estimate to outputs.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Build a Python CLI that simulates the Lotka–Volterra predator–prey ODE across thousands of parameter samples (birth, predation, mortality, efficiency) drawn via Sobol or Latin hypercube designs, recording summary metrics such as final populations, peak amplitudes, and oscillation period per run. Compute and save first-order and total Sobol sensitivity indices for each metric, along with a CSV of runs and a JSON report of indices.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Parameter Sweeps & Sensitivity Analysis', 'Implement a Python CLI that integrates the Lorenz ''63 system and, for a grid of (sigma, rho) values at fixed beta, computes the largest Lyapunov exponent to map chaotic vs non-chaotic regions, writing a CSV heatmap and the estimated boundary. Assess numerical sensitivity by rerunning a subset with stricter solver tolerances and reporting deviations in the exponent.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Build a discrete-event simulator for an M/M/c/K queue with balking at full capacity and exponential reneging, using a fixed RNG seed and automatic warm-up detection before collecting statistics across multiple replications. Output per-replication and aggregated 95% CI estimates for throughput, loss probability, mean queue length, and waiting time to standardized CSV/JSON files.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Implement a discrete-event simulation of a priority M/M/c/K queue with balking and reneging, reading parameters from /app/scenario.yaml, and run batched replications with fixed RNG seeds to estimate per-class throughput, mean wait, and server utilization with 95% CIs to /app/results.json. Include a test mode that sets K→∞ and a single class to validate against the analytical M/M/c steady-state formulas within a specified tolerance.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Implement a discrete-event simulator for an M(t)/M/c/K queue with two priority classes (preemptive-resume) and impatient customers (reneging), supporting reproducible random seeds and multi-run parameter sweeps via CLI. For each run, write CSVs with time-series queue lengths and per-class summary metrics (utilization, mean/95th-percentile wait, abandonment rate).', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Implement a discrete-event simulator for an open Jackson queueing network (2–4 M/M/1 nodes) with configurable arrival/service rates and routing probabilities, running multiple replications with independent RNG seeds to estimate steady-state throughput, utilization, mean queue lengths, and waiting times. For provided test cases, compare simulated metrics and 95% CIs to analytic formulas and fail if discrepancies exceed 5%, writing standardized CSV/JSON outputs.', NULL, NULL),
('Scientific Computing & Analysis', 'Simulation & Modeling', 'Stochastic or Agent-Based Simulations', 'Implement a stochastic chemical kinetics simulator that loads a reaction network from a simple JSON schema and runs both exact Gillespie SSA and an adaptive tau-leaping variant across multiple random seeds. Save ensemble trajectories and checkpointed means/variances, and report agreement metrics between the two methods within specified tolerances.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Descriptive Statistics & Summarization', 'Build a memory-bounded CLI that streams a large (possibly gzipped) CSV to compute per-column descriptive stats (count, mean, std, min/max, skewness, kurtosis) and approximate quantiles (1,5,25,50,75,95,99) using online algorithms (e.g., Welford + KLL), with NA handling and optional group-by by a categorical field. Write a JSON report including equal-width histograms per column and enforce quantile approximation error ≤0.005 while keeping peak RAM ≤200 MB.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Descriptive Statistics & Summarization', 'Build a streaming command-line tool that ingests large CSV shards with columns group, value, weight and outputs per-group weighted descriptive summaries (count, mean, unbiased variance, MAD, IQR), approximate quantiles (p5, p50, p95) via a quantile sketch, and 20-bin histograms using a Freedman–Diaconis rule under a fixed memory cap. Write deterministic summaries to /app/output/summary.csv and /app/output/histograms.json suitable for automated tolerance-based checks.', 'hard', NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Descriptive Statistics & Summarization', 'Implement a streaming CLI that computes per-column (and optional group-by) descriptive stats—count, mean, variance, min/max, skewness, kurtosis—and approximate quantiles (p1, p5, p25, p50, p75, p95, p99) from a large CSV using a memory-bounded quantile sketch (e.g., t-digest/P^2), outputting a compact JSON summary and fixed-bin histograms. The tool must handle missing values and optional weights while operating on datasets larger than RAM.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Descriptive Statistics & Summarization', 'Implement a streaming CLI that reads a potentially multi-GB CSV at /app/data.csv and computes per-group descriptive statistics (count, mean, variance, min, max) and approximate quantiles (p10, p50, p90) using numerically stable online methods (e.g., Welford plus a GK or t-digest sketch), writing a compact JSON report to /app/summary.json. The tool must ignore NaNs, support optional observation weights, and complete under a strict memory cap and time budget.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Build a CLI that reads a CSV with group labels and a numeric outcome, performs equivalence testing via two one-sided t-tests (TOST) for independent or paired samples with user-specified equivalence bounds, and reports 90% CIs, effect sizes, and decisions. Automatically choose Welch variants when variances differ and apply Benjamini–Hochberg correction when testing multiple endpoints, writing a concise results table to /app/output/results.csv.', NULL, ARRAY['testing']),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Build a CLI that reads a CSV with outcome, binary treatment, and optional covariates/strata and conducts a stratified permutation test of zero treatment effect using Freedman–Lane residualization. Compute an exact p-value when permutations are enumerable (or Monte Carlo otherwise) and report a 95% confidence interval for the ATE via test inversion to a JSON file.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Build a CLI tool that performs permutation-based ANCOVA (Freedman–Lane) to test a binary treatment effect while adjusting for a continuous covariate, optionally within blocking factors. Output the permutation p-value, partial R², and 95% bootstrap CI, and apply Benjamini–Hochberg correction if multiple outcomes are tested.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Create a CLI tool that ingests per-study effect sizes and standard errors, runs a random-effects meta-analysis (DerSimonian–Laird with optional Hartung–Knapp adjustment), and tests for overall effect and heterogeneity (Cochran’s Q, I²). Write combined estimates, p-values, per-study weights, and a leave-one-out influence summary to standardized output files.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Hypothesis Testing & Inference', 'Create a script that ingests stratified 2x2 contingency data (A/B by success/failure with a stratum identifier), performs a Cochran–Mantel–Haenszel test to estimate a common odds ratio with 95% CI, and reports its p-value. Additionally run the Breslow–Day test for homogeneity across strata and write the common OR, CI, and both p-values to an output JSON file.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Build a CLI tool that fits an errors-in-variables Deming regression for method-comparison data, estimating the error variance ratio from replicate measurements and optionally applying Huber M-estimation to orthogonal residuals for robustness. Output slope, intercept, their 95% CIs (bootstrap), the variance ratio estimate, and a CSV of fitted values and orthogonal residuals.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Build a CLI tool that fits piecewise linear (segmented) regression with an unknown number of change-points on a noisy 1D dataset, selecting the number and locations via BIC-penalized dynamic programming (e.g., PELT). Save breakpoint positions, segment slopes/intercepts, fitted values and residuals, and bootstrap confidence intervals for parameters to standardized output files.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Build a terminal script that reads /app/series.csv (time,y) and fits a piecewise linear regression with 1–3 unknown changepoints under Huber loss using dynamic programming (or equivalent), selecting the segment count by BIC. Output /app/results.json with changepoint times, segment slopes/intercepts, BIC per model, and residual diagnostics.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Create a CLI tool that fits a bi-exponential decay model y(t)=a1*exp(-k1 t)+a2*exp(-k2 t) using the variable-projection method: optimize k1,k2 via nonlinear search while solving a1,a2 by linear least squares at each step, enforcing a1,a2>=0 and k1,k2>0. Report parameter estimates, bootstrap 95% CIs, and predicted values at specified eval times without using high-level curve-fitting helpers.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Regression & Curve Fitting', 'Fit Planck''s law to a measured spectral radiance dataset (wavelength vs intensity), jointly estimating temperature and a gray-body emissivity factor with bounds and optional instrument-response correction from a calibration file. Save parameter estimates with bootstrap confidence intervals and residual diagnostics to standardized output files.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Build a CLI tool that ingests an irregularly timestamped sensor series, resamples to hourly, and fits a Basic Structural Model (local level + local trend + 24-hour seasonality) using a from-scratch Kalman filter/smoother with maximum-likelihood estimation of noise variances while natively handling missing points. Output the decomposed components, the seasonally adjusted series, and 48-hour forecast quantiles (5/50/95%).', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Create a CLI that ingests an irregularly sampled multivariate time series, estimates dominant seasonal periods via Lomb–Scargle and multitaper spectral analysis, then fits a seasonal state-space/SARIMAX model with Fourier terms to forecast a specified horizon. The tool must impute missing values, run rolling-origin backtesting, and write forecasts with 80/95% intervals and per-horizon error metrics to standardized output files.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Create a CLI tool that ingests an irregularly sampled time series with gaps, detects dominant seasonal periods via a Lomb–Scargle periodogram, and performs robust STL decomposition after appropriate resampling/imputation. Fit an ARIMA model to the seasonally adjusted component to generate a 7-day forecast with 95% intervals, and write the detected periods, decomposition components, and forecast to standardized CSV outputs.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Create a CLI tool that ingests an irregularly sampled univariate time series with optional exogenous variables, resamples to a target frequency, applies a Box–Cox transform, and selects a SARIMAX model via stepwise AIC under stationarity/invertibility constraints. Perform multi-fold rolling-origin backtesting and output n-step forecasts with 95% intervals, residual Ljung–Box diagnostics, selected (p,d,q)(P,D,Q)s, and MASE/sMAPE metrics to standardized files.', NULL, NULL),
('Scientific Computing & Analysis', 'Statistical Analysis & Data Modeling', 'Time Series Analysis', 'Implement a CLI that ingests an irregularly sampled univariate time series, estimates dominant seasonal periods via Lomb–Scargle spectral analysis, and performs STL decomposition using those periods. Fit a SARIMA model to the deseasonalized component to generate 30-step forecasts with 95% intervals, saving detected periods, decomposition components, and forecasts to disk.', NULL, NULL),
('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Build a CLI tool that performs Bayesian inference for a stochastic SIR model using ABC-SMC to estimate transmission and recovery rates from observed daily case counts with an adaptive tolerance schedule. The program outputs weighted posterior samples and posterior predictive simulations for a fixed forecast horizon as standardized CSV files.', NULL, NULL),
('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Build a CLI tool that performs hierarchical Bayesian calibration of a Michaelis–Menten kinetics model across multiple temperatures, linking Vmax(T) via an Arrhenius law to jointly infer activation energy, pre-exponential factor, Km, and per-experiment noise with MCMC. Write posterior parameter summaries and posterior predictive trajectories with 95% credible intervals for each experiment to designated output files.', NULL, NULL),
('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Calibrate an SIR epidemic ODE model to noisy incidence data using Bayesian inference (e.g., PyMC/NumPyro with NUTS), estimating transmission and recovery rates and R0. Run multi-chain MCMC to produce posterior credible intervals and posterior predictive trajectories and save a concise summary artifact.', NULL, NULL),
('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Create a Python tool that fits a stochastic SIR model to a provided daily incidence CSV using Particle Marginal Metropolis–Hastings with a bootstrap particle filter, jointly inferring β, γ, initial I0, and a reporting rate under Negative Binomial observation noise. Output posterior samples and 95% credible intervals for parameters plus posterior predictive incidence trajectories to standardized JSON/CSV files.', NULL, ARRAY['python']),
('Scientific Computing & Analysis', 'Uncertainty Quantification & Sensitivity Analysis', 'Bayesian Parameter Estimation', 'Implement a CLI tool that calibrates an SIR ODE model to noisy daily incidence via Bayesian inference (PyMC NUTS), estimating beta, gamma, initial infections, and a reporting rate under a Negative Binomial likelihood. The program must run MCMC, compute R0 and posterior predictive trajectories with coverage metrics, and write diagnostics and posterior summaries to standardized output files.', NULL, NULL);
