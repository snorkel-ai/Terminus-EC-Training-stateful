id,category,subcategory,subsubcategory,description,difficulty,tags
547d91d9-4d9a-4c06-8f52-a589bfd66fae,Build & Dependency Management,Build Optimization & Performance,Build Profiling & Benchmarking,"Benchmark a CMake/Ninja C++ project across linkers (ld.bfd vs lld) and with/without LTO, capturing compile vs link phase durations and Clang -ftime-trace to identify the five slowest translation units. Produce a JSON report comparing full and incremental rebuild times (after touching a common header) and recommend the fastest configuration.",,
1a51ef9e-c5ff-4404-8d22-acb9a6e93767,Build & Dependency Management,Build Optimization & Performance,Build Profiling & Benchmarking,"Instrument a provided CMake/Ninja C++ project with clang’s -ftime-trace and Ninja -d stats to profile cold and incremental builds, reporting the slowest translation units and link steps. Enable ccache and a precompiled header via CMake, then re-benchmark and output a before/after summary of total build time, parallelism, and cache hit rates.",,
52884334-2cb5-43cc-9f71-1ef5a3d68107,Build & Dependency Management,Build Optimization & Performance,Incremental Builds & Caching,"Configure a Bazel workspace to use a local HTTP remote cache (bazel-remote) persisted under /cache, build a mixed C++/Java project to prime the cache, then simulate a fresh checkout and rebuild. Verify the second build achieves >95% remote cache hits with no compile actions executed, based on Bazel’s build event summary.",,
0cb8dbf4-cb11-4ed6-a212-325fd5d97ba5,Build & Dependency Management,Build Optimization & Performance,Incremental Builds & Caching,"Configure sccache for a Rust workspace and wire cargo to use it with rustc, enabling incremental compilation with a shared on-disk cache. Build twice across two clean worktrees, then modify a single crate to demonstrate minimal rebuilds and record timings plus sccache hit/miss stats to /app/metrics.json.",,
d24c17f0-b523-4201-9aa8-6607e663f198,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,Repair a CMake-based C shared library that leaks internal symbols and lacks proper SONAME/versioning by enforcing hidden visibility and a GNU ld version script. Validate that the built lib has SONAME libfoo.so.1 and exports only the intended API symbols under version FOO_1.0 (checked via nm/readelf) and that a minimal client links and runs successfully.,,
302565c6-1518-4598-8b25-959449e038a6,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,"Repair a CMake-based build so the produced shared library is libvector.so.3 with an exact exported symbol set matching /app/exports.txt, no undefined symbols, no RUNPATH/RPATH, and the correct SONAME. Validate by diffing nm -D --defined-only against the reference, checking readelf -d for SONAME/RPATH, and building a tiny client that links dynamically and prints a known checksum to confirm ABI correctness.",,
6ab71fa9-3c39-4264-b360-1ea25465615a,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,"Repair a failing CMake build of a versioned shared library (libimagelib) by fixing PIC/visibility flags and defining a proper SONAME and symlink chain. Validate by ensuring libimagelib.so.2 resolves via ldd, nm -D exposes only intended symbols, a tiny consumer links and runs, and a sample transform output matches an expected SHA256.",,
c740044a-9fea-437c-a79b-4cba343a4e0c,Build & Dependency Management,Build Troubleshooting & Repair,Compiler & Linker Errors,"Repair a CMake-based C++17 project that fails to link a shared library due to non-PIC static dependencies and missing OpenMP/filesystem linkage. Rebuild static libs with -fPIC (or use shared), enable OpenMP via CMake and conditionally link stdc++fs for older GCC, set $ORIGIN rpath, and validate by running a threaded test that dlopens the library.",,
55eb2da0-d05c-47e8-afe7-a3999b231e8e,Build & Dependency Management,Build Troubleshooting & Repair,Compiler & Linker Errors,"Repair a failing JNI native library build by fixing missing jni.h includes, enabling position-independent code, and linking against the correct libjvm with proper RPATH in the build configuration. Verify by producing a loadable libnative.so that the provided Java class can load and call to print an expected message.",,
3ca94130-8b92-4f25-8017-eb0015e29ce6,Build & Dependency Management,Build Troubleshooting & Repair,Configuration & Environment Issues,"Diagnose and fix a Meson-based C project that fails to detect SDL2 because it is installed under a non-standard prefix (/opt/sdl2). Configure environment variables (e.g., PKG_CONFIG_PATH and LD_LIBRARY_PATH) and, if needed, a Meson cross file so the project configures, builds, and the resulting binary links against /opt/sdl2 as verified by ldd.",,
ac20dff2-1cd9-458a-903c-7706dd3a20b7,Build & Dependency Management,Build Troubleshooting & Repair,Configuration & Environment Issues,Diagnose and repair a Rust crate build that fails to compile openssl-sys and bindgen by installing the proper system tools and correctly setting PKG_CONFIG_PATH/OPENSSL_DIR and LIBCLANG_PATH/LD_LIBRARY_PATH so Cargo can find OpenSSL and libclang. Verify by building in release mode and running a provided HTTPS client example to confirm TLS works end-to-end.,,
58b4b54c-32e1-49f0-925a-93fd3a1d008a,Build & Dependency Management,Build Troubleshooting & Repair,Dependency & Compatibility Issues,"Diagnose a CMake C++ project that fails to build and link because the protoc used for code generation does not match the installed libprotobuf runtime version. Install or build a matching protobuf toolchain, update PATH and CMAKE_PREFIX_PATH so generation and linking use the same version, then rebuild to produce a binary that runs and prints a provided test message.",,
6c516e46-8264-4ce9-b469-3b90d890e67e,Build & Dependency Management,Build Troubleshooting & Repair,Dependency & Compatibility Issues,"Diagnose a Rust Cargo build failing on Linux due to an OpenSSL headers/library version mismatch (openssl-sys expecting OpenSSL 3 while the OS provides 1.1). Resolve by only modifying Cargo.toml (pin compatible crate versions or enable the vendored OpenSSL feature) and installing minimal build tools so cargo build --release succeeds and the produced binary runs and prints ""TLS: OK"".",,
91bab3c5-b257-41cf-82d2-16024239856e,Build & Dependency Management,Build Troubleshooting & Repair,Dependency & Compatibility Issues,Diagnose and repair a Node.js project failing to build because the sharp native addon is incompatible with the installed Node.js version and the required libvips system libraries are missing. Align the Node/ABI and dependency versions (or rebuild sharp from source) and install the OS-level libraries so npm install completes and the test suite passes.,,
ef97f6d0-15e0-48df-9ea3-af07d2d0c965,Build & Dependency Management,Continuous Integration & Automation,Artifact Publishing & Deployment,"Create a CI-style release pipeline that cross-compiles a Go CLI for linux/amd64 and linux/arm64, packages deterministic tarballs with embedded build metadata, generates SBOM and checksums, signs the artifacts, and publishes them to a local “release” store; verify by installing from that store and validating the signature.",,
d004bf1a-696f-4bb1-a2d9-f894daf0d652,Build & Dependency Management,Continuous Integration & Automation,Artifact Publishing & Deployment,"Package a small CLI tool as a Debian .deb and publish it to a locally hosted APT repository served over HTTP. Generate and sign repository metadata, add the repo to sources.list, install the package via apt by name, and verify the installed binary runs.",,
d01a7519-dcc0-43bb-a65e-4074b940ba11,Build & Dependency Management,Continuous Integration & Automation,Build Verification & Reproducibility,"Create a hermetic CI-style script that builds a provided Go CLI twice in separate directories with different GOPATHs, using -trimpath, -buildvcs=false, and SOURCE_DATE_EPOCH to eliminate path and timestamp leakage, then asserts identical SHA-256 hashes of the binaries. On success, emit a brief reproducibility report and a minimal provenance JSON; on failure, output a targeted diff (e.g., cmp/strings) to highlight remaining non-determinism.",,
89a3682b-5a04-4ffb-985b-3f58e545e0c7,Build & Dependency Management,Continuous Integration & Automation,CI Configuration & Maintenance,"Configure a GitHub Actions workflow that builds and tests a Rust project in a matrix (Linux and macOS) with sccache and dependency caching, then on tags performs two clean release builds and asserts the binaries are bit-for-bit identical before uploading them as artifacts. The pipeline must also generate and upload an SBOM for each artifact and fail if reproducibility or SBOM generation checks fail.",,
acbbbb45-f549-44d6-9a72-46f4e39283d2,Build & Dependency Management,Continuous Integration & Automation,CI Configuration & Maintenance,"Fix and harden a GitHub Actions workflow for a CMake-based C project by pinning actions to SHAs, enabling ccache with cache restore/save across a gcc/clang matrix, and splitting build/test/release with minimal permissions and concurrency cancellation. Validate locally with act that pushes run build+test across the matrix and that tagging v* produces an uploaded release artifact.",,
b200346c-e6fc-4d49-9949-7ab77fac3f00,Build & Dependency Management,Dependency Management,Dependency Installation & Version Control,"Resolve peerDependency conflicts in a Yarn v3 Plug'n'Play monorepo by using resolutions and packageExtensions to align versions of React, Webpack loaders, and ESLint plugins. Produce a reproducible install (yarn.lock) and verify the workspace builds and lints successfully under Node 20.",,
6a07d759-30bc-4395-b9a2-7de5f67f9049,Build & Dependency Management,Dependency Management,Dependency Resolution & Conflict Fixing,"Diagnose and fix a Rust project’s build failure caused by a dependency tree pulling in both native-tls (openssl-sys) and rustls while the host OpenSSL version is incompatible. Align Cargo features and versions (e.g., select rustls-tls, enable vendored OpenSSL, or install the correct libssl-dev) so cargo build and the test suite complete successfully.",,
415de7ad-9949-4882-a4b6-b21b0197f6ac,Build & Dependency Management,Dependency Management,Dependency Resolution & Conflict Fixing,"In a Rust Cargo workspace, diagnose and resolve a build failure caused by conflicting serde/serde_json versions and incompatible feature requirements across multiple member crates and a pinned transitive dependency. Modify only Cargo.toml constraints (workspace dependency versions, [patch.crates-io], and feature flags) so that cargo build completes without changing source code or removing dependencies.",,
c24cdce5-7f82-4449-8918-53a0a402ddd7,Build & Dependency Management,Dependency Management,Dependency Resolution & Conflict Fixing,"Resolve a Rust Cargo workspace that fails to compile due to transitive version/feature conflicts between reqwest, openssl-sys, and tokio plus a system OpenSSL 1.1 vs 3.0 mismatch. Pin compatible crate versions, adjust features and Cargo patches, configure pkg-config to link the intended OpenSSL, vendor dependencies for offline build, and validate by building and running a CLI that performs an HTTPS request.",,
2db2d3ba-ed01-45d4-9a16-d0d4170b247d,Build & Dependency Management,Dependency Management,Lockfile & Manifest Maintenance,"In a Rust workspace with crates using branch-based git and wildcard semver dependencies, pin each to exact versions and commit SHAs in Cargo.toml and regenerate a deterministic Cargo.lock. Verify reproducibility by building with cargo build --frozen in a clean state, ensuring no yanked or platform-specific mismatches remain in the lockfile.",,
b2086247-1990-4dbe-baff-69682324c773,Build & Dependency Management,Dependency Management,Lockfile & Manifest Maintenance,Resolve peerDependency conflicts in a Yarn v3 workspaces monorepo by aligning manifest ranges and regenerating a deterministic yarn.lock with Corepack enabled so yarn install --immutable succeeds on Linux. Prove reproducibility by performing two clean installs that yield identical resolved versions and an unchanged install-state file.,,
a71eb1f6-ef8a-4aed-a908-73c7e9743ce0,Build & Dependency Management,Language & Ecosystem-Specific Build Management,C/C++ & Systems Builds,"Configure a CMake-based C project to produce bit-for-bit reproducible builds by enabling deterministic archives and stripping build paths (e.g., SOURCE_DATE_EPOCH, ar D, -ffile-prefix-map/-fdebug-prefix-map) with split DWARF. Build twice in different directories and verify identical SHA-256 digests while ensuring no absolute build paths remain in the binary.",,
c75d663b-a8a7-45cb-abeb-61b44a63c008,Build & Dependency Management,Language & Ecosystem-Specific Build Management,C/C++ & Systems Builds,Create a CMake superbuild that compiles vendored zlib and libpng via ExternalProject_Add and then builds a C++ CLI (pngdim) that links them. Ensure correct SONAME and RUNPATH so the produced binary runs in the sandbox and transforms a provided PNG to /app/out.png with an expected SHA256.,,
39716413-7d88-4e24-b6d5-6b5e72ea2bba,Build & Dependency Management,Language & Ecosystem-Specific Build Management,C/C++ & Systems Builds,"Refactor a small C library to use modern CMake, installing both shared and static variants along with a FooConfig.cmake export and a pkg-config foo.pc that correctly express include and link interfaces. Build a separate consumer in a clean environment using find_package(Foo CONFIG) and pkg-config, run it to generate /app/out.txt, and verify correct SONAME and RPATH on the linked binary.",,
4f8bba66-220c-409c-bc32-faacbc258a09,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Configure a multi-module Gradle (Kotlin DSL) Java/Kotlin project to build offline against a pre-seeded local Maven repository, enable dependency locking and verification, and produce a deterministic shaded fat JAR targeting JDK 17. Verify by building twice with the same SOURCE_DATE_EPOCH to obtain identical SHA256 sums and by running the JAR to print its git-derived version.",,
7be18455-a5ce-4020-aa35-3f6359ca35cb,Build & Dependency Management,Build Troubleshooting & Repair,Dependency & Compatibility Issues,"Diagnose and repair a multi-module Maven project failing with conflicting Guava and Jackson versions: introduce a dependencyManagement section to unify versions, exclude outdated transitive dependencies, regenerate the effective POM, and verify a clean mvn compile in both online and offline modes.",,
8f891fee-624c-4427-abcd-3d369379dbb9,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Configure and build a mixed-language (Java + Kotlin) multi-module Maven project using toolchains to compile one legacy module with JDK 8 and the rest with JDK 17, wiring Lombok and MapStruct as annotation processors on the correct processor path. Produce a deterministic, shaded CLI artifact with relocated dependencies and attached sources/javadoc, publish to the local Maven repository, and verify by building and running a tiny consumer project that imports the library and executes the CLI.",,
5c787f25-48b7-4c85-8bef-ef7732e9c381,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Python Builds & Packaging,"Refactor a Cython-based Python project to a PEP 517 build with setuptools, ensuring generated C sources are included in the sdist so pip install from the sdist works without Cython present. Build reproducible sdist and wheel (respecting SOURCE_DATE_EPOCH), then verify in a clean virtualenv by installing only from the sdist and running the provided import/CLI smoke tests.",,
f2cf83db-0b98-4fda-9e4f-459895dc0631,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Rust/Go/Other Modern Toolchains,"Refactor a provided multi-crate Rust project into a Cargo workspace, vendor all dependencies with cargo vendor, and configure .cargo/config.toml so the project builds fully offline. Cross-compile a static x86_64-unknown-linux-musl release binary with feature ""cli"" (default-features=false) and verify by running cargo test --workspace and executing the binary to emit a deterministic SHA256.",,
c4519d89-2811-4dd8-b0e2-a19bff8b9bd1,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Rust/Go/Other Modern Toolchains,"Vendor all Cargo dependencies for the provided Rust CLI, switch TLS features from OpenSSL to rustls, and cross-compile a fully static x86_64-unknown-linux-musl binary in strict offline mode. Validate by proving no network access during build, ldd reports it is not a dynamic executable, and repeated builds with the same SOURCE_DATE_EPOCH produce identical SHA256 sums.",,
06beb7e4-7592-4fcf-a472-f7ccf68bd752,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Implement a Git-aware Makefile for a Rust CLI that enforces branch-specific builds: main produces a stripped LTO release with version from the latest tag and a sha256 checksums.txt; staging enables a telemetry-staging feature and adds an -rc suffix; feature/* appends +branch.sha and writes to /app/dist/feature, while release/* fails if Cargo.toml version doesn’t match the tag. The harness will check out different branches and verify artifact names, --version output, and the presence of checksums only on main.",,
7790614a-4402-41e5-b055-16d5bb7ae920,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Implement a Git-aware build script that enforces branch-specific rules: feature/* runs tests only and emits a -SNAPSHOT artifact, staging builds produce debug binaries with embedded staging config, and main requires an annotated tag to create a stripped release tarball with semver from the tag and a SHA256 checksum in /app/dist. Validate by creating branches and tags and showing the correct artifacts and version strings are generated for each branch.",,
c1acc84f-be6b-42eb-b51a-fbfd7aa811c4,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Create an offline release pipeline that signs a Git tag for a provided source tree, builds a normalized tar.gz and binary, and generates SHA256SUMS along with both GPG (.asc) and minisign signatures for the artifacts. Provide a verify.sh that validates the tag signature against a supplied public key, checks checksums and signatures, and confirms the binary’s embedded commit hash matches the signed tag.",,
3ce981d3-aea0-466b-80ea-6f8a31a743a2,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Implement a release pipeline that signs the vX.Y.Z Git tag and a SHA256SUMS file with GPG, builds a binary embedding git describe/commit hash, and provides verify.sh to validate the tag signature, the embedded version against the tag, the checksum signature, and the artifact hashes. The task must detect and fail on any tampering with either artifacts or checksums.",,
cae93ac6-6b5c-4b85-91a4-fe0164a4b5cf,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"Create a POSIX shell release script that parses Conventional Commits since the last tag to compute the next semantic version, updates a version file, generates/updates CHANGELOG.md, creates an annotated git tag, and pushes tags to a provided local bare remote. Validate by running the script twice on a seeded repo to produce v1.1.0 then v1.1.1 and confirm the tags, changelog sections, and versioned build artifact output match the computed versions.",,
29e0a374-7d5c-4c49-9b27-5e5781d97bfd,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"Create a portable release script that parses Conventional Commits since the last git tag to compute the next semver (major/minor/patch), updates a VERSION file and CHANGELOG.md, then creates an annotated tag (vX.Y.Z). On success, build the project to dist/, archive it as project-vX.Y.Z.tar.gz with SHA256SUMS, and refuse to run on a dirty tree while verifying the changelog covers exactly the tagged commit range.",,
1b32b22b-b7eb-41e3-93c0-513eeebcd636,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"In a Git monorepo with a Rust workspace of multiple crates, implement a release script that parses Conventional Commits since the last per‑crate tag, bumps versions in Cargo.toml/Cargo.lock with dependency propagation, writes per‑crate and aggregate changelogs, and creates annotated tags (v{crate}-{version}) plus a workspace tag. The run must support dry‑run vs apply, handle prerelease channels (e.g., -beta) and BREAKING CHANGE semantics, be idempotent on a second run, and leave the workspace building successfully at the new versions.",,
64f49b40-d8fb-4f91-b650-b482cfb1918c,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Build the provided C++ library into both a versioned shared object (with correct SONAME symlinks) and a static archive, and generate pkg-config and CMake package config files while staging headers and licenses under a prefix. Package the staged tree into a relocatable tar.gz release and verify by compiling a tiny consumer that locates the library via pkg-config and find_package.",,
1628ebe2-8742-4b51-b41b-256e4cf27820,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Configure a CMake project and use CPack to produce both .deb and .rpm packages for a small C/C++ CLI, including /usr/bin binary, a man(1) page, bash completion, and a separate -dbg package with split debug symbols. Validate package metadata (version from git tag), ownership/permissions, dependencies, and contents via dpkg-deb and rpm queries, and by extracting to a temporary root to confirm correct install paths.",,
69cda8ed-8a02-4079-88ee-026a170db619,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Package a small C library built with CMake into two Debian packages: a versioned runtime shared library with correct SONAME (e.g., libfoo2) and a -dev package containing headers and a pkg-config file, using debhelper and dpkg-buildpackage. Install the .debs and verify by compiling and running a tiny consumer that links via pkg-config against the installed library.",,
b5b0bbc5-49ee-4af2-a915-d0dc08b877cc,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Configure a CMake superbuild that fetches and builds pinned zlib and libpng from source via FetchContent/ExternalProject, then builds a small C/C++ image utility that links to them. Install targets with an exported CMake package (MyImgToolConfig.cmake), verify find_package works from a separate minimal project, and run the utility on a provided PNG sample.",,
d816e628-6aac-4e20-b42a-1d63b3462f37,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Configure a CMake-based build for /app/engine using Ninja, CMakePresets.json, and a cross-compiling toolchain file to produce both native (x86_64) and ARMv7 binaries with an ENABLE_SIMD option that toggles sources and compile definitions. The workflow must emit compile_commands.json, run ctest, and generate relocatable cpack TGZ packages for each configuration, verifying the ARM artifact is an ARM ELF and the native build links against system zlib via find_package(ZLIB).",,
7f7c24fe-aa2e-4234-bf95-75f048e564a5,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Configure a CMake/Ninja project to run a two-stage Profile-Guided Optimization workflow: first build instrumented binaries and execute a provided training script to generate profiles, then rebuild using those profiles to emit an optimized executable at a fixed path. Verify that the profile was consumed (via build logs/artifacts) and that the optimized binary demonstrates a measurable runtime improvement over a baseline build.",,
2ef44fb4-f868-4a50-9e93-7db8113234f2,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Create a CMake superbuild using ExternalProject_Add to compile vendored zlib and libpng from local tarballs with Ninja, then build a top-level C++ library and CLI that link them and install to /opt/app with correct RPATH. Emit pkg-config and CMake export targets, and verify by running the CLI to convert a provided PNG into a raw byte dump without network access.",,
6287b90a-760f-4c75-bb7d-0f4dd44589cd,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Replace the project's Autotools build with Meson + Ninja, adding a subproject wrap for a missing dependency, installing headers, and generating a pkg-config file, and then add a Meson cross file to support armv7hf cross-compilation with hard-float. Verify by building native and cross variants, running the native tests, and using qemu-arm to execute a sample program linked against the cross-built shared library while pkg-config resolves the correct paths.",,
32fb441f-e951-448e-a5be-58eaf2faf2b0,Build & Dependency Management,Source Compilation & Build Systems,Cross-Compilation & Multi-Platform Builds,"Cross-compile a CGO-based Go CLI that embeds SQLite into static binaries for linux/amd64, linux/arm64, linux/riscv64, and windows/amd64 using zig as the cross C compiler/linker. Verify by running the riscv64 binary under qemu-user to execute a SQL query and confirming the Windows PE binary via wine or PE header inspection outputs the exact expected result.",,
5c4cb634-2981-46ca-a1cd-26e5da312f71,Build & Dependency Management,Source Compilation & Build Systems,Cross-Compilation & Multi-Platform Builds,"Cross-compile a provided C/C++ utility into static aarch64 and riscv64 Linux binaries using a musl-based toolchain (e.g., Zig as cc). Validate by running both under qemu-user to process the same input and write matching SHA256 output hashes to a verification file.",,
728df3b9-1b6a-4b2e-8713-10b48acca390,Build & Dependency Management,Source Compilation & Build Systems,Cross-Compilation & Multi-Platform Builds,"Cross-compile the provided CMake-based CLI to produce three artifacts: x86_64-linux-musl (fully static), aarch64-linux-gnu, and x86_64-w64-mingw32. Verify correctness by inspecting ELF/PE headers and running the ARM64 build under qemu-aarch64 and the Windows build under wine, ensuring the musl binary has no glibc dependency and all builds honor a fixed SOURCE_DATE_EPOCH.",,
fb8a76dc-4c84-4d19-9518-226d376800aa,Build & Dependency Management,Source Compilation & Build Systems,Cross-Compilation & Multi-Platform Builds,"Cross-compile the ripgrep Rust project into statically-linked binaries for x86_64-unknown-linux-musl and aarch64-unknown-linux-musl from an x86_64 host, packaging each artifact with a LICENSE file and SHA256 checksum. Validate the ARM64 build by executing it under qemu-aarch64 on a provided test corpus and verifying the expected grep results.",,
0835c043-a6fb-42f5-b51d-4fbc43c9b88e,Build & Dependency Management,Source Compilation & Build Systems,Manual Compilation,"Perform a two-phase profile-guided optimization build of the C program in /app/pgotask: first compile with -fprofile-generate and run it over the input corpus in /app/corpus to emit profiles, then recompile with -fprofile-use to produce /app/bin/app_pgo. Verify by timing both pre- and post-PGO binaries on the same workload and writing the speedup and file sizes to /app/pgo_report.txt.",,
c4cbe0e7-8be2-4fe9-b6d7-84f978991543,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Cross-compile the Go project in /src for linux/amd64, linux/arm64, and windows/amd64 targets with CGO disabled into versioned binaries, package each artifact into tar.gz or zip (including README and LICENSE), then generate SHA256SUMS.txt and a GPG-signed SHA256SUMS.txt.asc signature file.",,
a0f631b2-7d99-4006-9206-397fa8ef8d8c,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Write debian/control, rules, changelog, and a postinst script to register a systemd timer, then cross-build a C++ CLI tool into amd64 and arm64 .deb artifacts inside Docker. Verify that each .deb installs cleanly and activates the timer service in a fresh container.",,
acb8f5bf-1ceb-42d8-8f49-28f48fbbf7b4,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Develop a shell script that cross-compiles a Go project for Linux/amd64, Linux/arm64, Darwin/amd64, and Windows/amd64 targets embedding semantic version and Git commit into each binary, then packages them into versioned tar.gz or zip archives alongside a SHA256SUMS manifest. Finally, verify artifact integrity by extracting each archive and running a built-in --version flag check.",,
0f663307-ca46-47ac-ab84-21210074bca6,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Compile a Zig-based HTTP file server into a standalone binary and package it as both a .deb and .rpm including proper control metadata and a systemd unit file. Automate installation and removal in Debian and RPM containers, validate with lintian and rpmlint, enable and start the service, and confirm clean install/uninstall without residual files.",,
d2098433-4d6e-4c6f-9a5c-1deef77fff3a,Build & Dependency Management,Continuous Integration & Automation,Artifact Publishing & Deployment,"Implement a CI pipeline using Docker Buildx in GitHub Actions to build and push multi-architecture images (amd64, arm64, armv7) from a single Dockerfile, tag them based on semver and git commit, and publish a manifest list to both Docker Hub and GitHub Container Registry. Verify pulls on each platform succeed and embed an SBOM label in the image metadata during the build.",,
2a98e3ad-2899-4cfa-8398-3137ba5bfd4a,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Develop a POSIX-compliant build wrapper that detects the current Git branch and invokes CMake with branch-specific build types (Debug for feature/*, RelWithDebInfo for staging, Release+strip for main), automatically appending branch suffixes to the project version. After compilation, verify the binary’s symbol table, size reduction, and embedded version metadata to ensure the correct flags and suffix were applied per branch rule.",,
ce71531e-d0b1-48af-8e57-24a49fbcb95d,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Implement a shell-based build orchestrator that reads branch-specific policies from a JSON file to automatically apply different compiler flags, dependency injections, and artifact naming based on the current Git branch. The tool must reject and cleanly report any builds that don’t conform to the defined staging, release, and production rules across three sample branches.",,
24b1b3e5-5b55-46a0-a95d-df0dac681af3,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Implement a CI script that, based on the git branch, applies different build configurations: on 'dev' branches builds include debug symbols and are tagged '-dev' in the version header, while on 'main' builds enable optimizations, strip symbols, update semantic version from the latest tag, and produce packaged release artifacts under /dist. Validate by running builds on both branch contexts in Docker, verifying version strings and artifact contents accordingly.",,
9a541ce3-593a-446f-bf69-a5cb44682a6d,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,"Fix cross-compilation configuration to build a static ARMv7 ELF binary from provided C source. Then validate with readelf and qemu-arm that the binary’s ELF header reflects ARMv7, has no dynamic dependencies, and outputs the expected text when run.",,
ef108b77-7d14-40e2-b5ee-33f35a447cf4,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,"Set up a CMake-based C project that can be built reproducibly by normalizing timestamps, file ordering, and compiler flags. Build the project twice in separate Docker runs with different build dates via SOURCE_DATE_EPOCH and compare SHA256 sums of the generated tar.gz artifacts to ensure bitwise identical outputs.",,
2edd5fd5-5801-4927-801e-da0613703c36,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,Create two independent Dockerized builds of a small C++ static library with timestamp normalization and sorted archive members to ensure reproducible outputs. Verify that the generated .a files are byte-identical and that their symbol tables match the expected list in /app/expected_symbols.txt.,,
41683247-978e-4192-9e89-266c65b01401,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,"Implement a CLI tool that performs two consecutive builds in a reproducible, timestamp-sanitized environment, normalizes ELF binaries by stripping debug info and build-ID notes, then verifies the outputs are bit-for-bit identical. Additionally, extract and compare DT_NEEDED entries against a provided expected dependencies list to ensure the binary links only the approved shared libraries.",,
02eaed24-fc17-4297-9bdf-4ef9ced8c87f,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,"Validate reproducible builds for a C/C++ project by building twice under different environments (e.g., varied timestamps or locales), comparing sha256 checksums of the resulting binaries, and then eliminate sources of non-determinism by applying flags like SOURCE_DATE_EPOCH, -fdebug-prefix-map, and -frandom-seed to achieve identical outputs.",,
41213872-428c-4e5e-a65c-34cce80fec25,Build & Dependency Management,Build Optimization & Performance,Build Profiling & Benchmarking,"Implement a CLI tool that wraps a Make or Ninja build to record start and end timestamps of each build command, then aggregates durations by target, source file, and file extension. Output both a JSON report of per-step statistics and an interactive HTML flame graph to visualize build-time hotspots.",,
bb0b53c3-0ee9-46d4-aa24-8bca1cd7a6cc,Build & Dependency Management,Build Optimization & Performance,Build Profiling & Benchmarking,Instrument a CMake+Ninja build of a mixed C/C++/CUDA project using Ninja’s --profile option and GNU time to capture per-target durations and peak memory. Parse the Ninja profile database and time logs to generate a JSON report listing the top 5 slowest and most memory‐consuming build steps with suggestions for caching or parallelization.,,
e0f3b9ab-726e-4481-84d3-fca3fa8a11a8,Build & Dependency Management,Build Optimization & Performance,Build Profiling & Benchmarking,"Implement a Python wrapper that profiles a CMake/Ninja build by instrumenting each compile and link invocation with GNU time (capturing duration, CPU and memory usage), then aggregates results into a JSON report with per-target timings and resource metrics, and generates an SVG flame graph of the critical build path. Verify the tool highlights the top five longest-running compilation units on a provided sample project and output optimization suggestions based on the data.",,
f05df7ce-c5d8-48b4-aa8f-6907a2c98bab,Build & Dependency Management,Continuous Integration & Automation,Build Script Development,"Implement a Python CLI that reads a Jinja2 template and a project manifest defining microservices and target architectures to generate a GitLab CI YAML configuration with dynamic matrix jobs for building, testing, and publishing multi-arch Docker images with shared cache pools. The tool must also validate the generated pipeline config using gitlab-ci-lint before writing to .gitlab-ci.yml.",,
bfba37dd-55d1-4f82-b855-f541f928b493,Build & Dependency Management,Continuous Integration & Automation,Build Script Development,"Write a .github/workflows/ci.yml GitHub Actions workflow to run a matrix build on Ubuntu and Windows for Python 3.8–3.10 and Node.js 14/16, caching pip and npm dependencies, linting, testing, and uploading coverage. On semver git tags it should automatically publish artifacts to PyPI and npm using encrypted secrets.",,
e139df25-f52e-4ba9-b5fe-91cd1e6d9f55,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Configure a Bazel workspace for a polyglot (Java, Go, Python) project with custom toolchains and remote caching, and define Bazelrc profiles for development and release builds. Provide a script that builds all //... targets using a specified profile and captures the Build Event Protocol output in JSON.",,
1db603b5-ad30-465c-b3d1-875447743c58,Build & Dependency Management,Dependency Management,Dependency Installation & Version Control,"Develop a Python CLI at /app/dep_bumper.py that reads both package.json and requirements.txt to detect outdated npm and PyPI packages, allows interactive selection of updates, applies version bumps, regenerates lockfiles (npm ci and pip-compile), and outputs a conventional-commit-ready summary.",,
4895e261-6837-4ff1-9794-ef82d90a9e4a,Build & Dependency Management,Continuous Integration & Automation,Build Verification & Reproducibility,"Create a CI workflow that builds a Go CLI project for linux/amd64 and windows/amd64 in two container environments (Alpine vs Debian) using -trimpath and disabling build IDs, then verify that resulting binaries are byte-for-byte identical by comparing SHA256 checksums. The pipeline must automatically fail on any checksum mismatch to enforce reproducible cross-platform artifacts.",,
e16e1f1a-8b2a-472d-8910-5341df2b0816,Build & Dependency Management,Language & Ecosystem-Specific Build Management,C/C++ & Systems Builds,"Cross-compile a C++ project using CMake and Conan: configure a custom toolchain file and Conan profile for ARMv7 Linux, statically link Boost and OpenSSL, enable -O2 stripping, and produce a sub-1MB executable. Validate the binary under QEMU-arm with provided test scripts to ensure successful execution.",,
585f16e9-ef35-4e4d-9cd7-13769db30599,Build & Dependency Management,Language & Ecosystem-Specific Build Management,C/C++ & Systems Builds,Write a POSIX shell script that cross-compiles a CMake-based C project into static and shared libraries for both x86_64-linux-gnu and armv7-linux-gnueabihf using provided toolchain files and installs each build into separate staging directories. Then generate a combined pkg-config index merging metadata for both architectures and verify correct linkage by building and running sample executables against each library variant.,,
626458c4-0384-42f1-8771-de8e3d116758,Build & Dependency Management,Build Troubleshooting & Repair,Compiler & Linker Errors,"A CMake-based C++ project using Boost.Asio and OpenSSL fails at link time due to missing SSL and crypto libraries. Update CMakeLists.txt (or build invocation) to correctly find and link OpenSSL and required Boost components, then verify the resulting HTTPS client connects to example.com and prints the HTTP status code.",,
f4b932c1-d9f3-4410-a525-6e9b1ea85365,Build & Dependency Management,Build Troubleshooting & Repair,Compiler & Linker Errors,"Diagnose and fix undefined reference linker errors in a C++ project caused by missing explicit template instantiations and mismatched symbol visibility. Update source and CMake build files to add required 'extern template' declarations, apply proper -fvisibility flags, and correct link order to achieve a successful build.",,
9cff9d5e-6c07-4b65-a428-99c15efa2222,Build & Dependency Management,Build Troubleshooting & Repair,Compiler & Linker Errors,"Diagnose and fix linking errors in a Bazel build for a mixed Java/C++ JNI project, where native libraries report 'undefined symbol Java_com_example_MyClass_nativeMethod'. Update BUILD.bazel rules to include correct cc_library dependencies, apply -shared linkopts, and configure include and runtime paths so the binaries load without LD_LIBRARY_PATH.",,
83bb7efd-1efc-4bb8-bcc2-3ef57737dcda,Build & Dependency Management,Build Troubleshooting & Repair,Compiler & Linker Errors,"Diagnose and resolve runtime linking errors in a C++ plugin framework where dynamically loaded modules fail to find required symbols due to incorrect visibility attributes and missing version scripts. Modify source annotations and CMakeLists to export versioned symbols, apply a custom linker version script, and confirm that all plugins load and execute their registration routines.",,
3fadab1a-6581-441d-ac88-f11c6921e6eb,Build & Dependency Management,Build Troubleshooting & Repair,Configuration & Environment Issues,"Diagnose and fix a Rust project’s cross-compilation setup for ARMv7 Linux by installing and configuring the appropriate GCC cross-toolchain, setting environment variables (CC_armv7_unknown_linux_gnueabihf, CARGO_TARGET_ARMV7_UNKNOWN_LINUX_GNUEABIHF_LINKER), and updating .cargo/config.toml. Verify that cargo build --target armv7-unknown-linux-gnueabihf succeeds and that the produced ARM binary executes correctly under QEMU with the sample CLI.",,
51c7c08a-145f-4160-ba2b-ecb0773239e3,Build & Dependency Management,Build Troubleshooting & Repair,Configuration & Environment Issues,"In a Debian-based Docker sandbox, install and configure an aarch64-linux-gnu cross-compiler toolchain, set CMAKE_TOOLCHAIN_FILE, CC, CXX, SYSROOT, and PKG_CONFIG_PATH to resolve missing include and library paths, and build the CMake-based project for ARM64. Verify the resulting binary runs under QEMU-aarch64 and prints the expected token.",,
ef842a7d-813c-4517-8a36-18b715855451,Build & Dependency Management,Build Troubleshooting & Repair,Configuration & Environment Issues,"Set up and configure a cross-compiling environment in a Docker sandbox to build a CMake-based C project for the ARMv7 target, diagnosing and fixing toolchain file misconfigurations, incorrect CC/CXX/SYSROOT environment variables, and missing cross-compiler packages. Then rebuild the project, run the resulting ARM binary under QEMU, and verify it prints the expected output.",,
6917c9bd-2d2f-47b9-95f6-dba908f827d1,Build & Dependency Management,Source Compilation & Build Systems,Cross-Compilation & Multi-Platform Builds,"Cross-compile a Python C extension module on a Linux host to produce wheels for Linux x86_64 (glibc), Linux aarch64 (musl), Windows x86_64 (mingw-w64), and macOS universal (x86_64 & arm64) using Docker-based cross-toolchain images with automated packaging in setup.py. Verify each wheel by installing it in appropriate emulated or container environments and running module-specific tests to confirm correct behavior.",,
95345a41-bb46-4607-814e-b5196b2203c3,Build & Dependency Management,Source Compilation & Build Systems,Cross-Compilation & Multi-Platform Builds,"Create a multi-stage Dockerfile using Docker Buildx and QEMU to cross-compile a Go HTTP server into static binaries for linux/amd64, linux/arm64, and linux/arm/v7, then assemble them into a single multi-arch image manifest. Verify correctness by running each platform variant under emulation to serve a health endpoint and report its architecture.",,
7e2de5a7-0cfa-4200-9ddd-d82b0d64d5a0,Build & Dependency Management,Build Troubleshooting & Repair,Dependency & Compatibility Issues,"Investigate and fix a Node.js monorepo build failure caused by conflicting React versions and unmet peer dependency requirements across multiple packages. Update workspace configuration, apply package resolutions or overrides, and verify clean install and successful webpack builds for each subproject without warnings.",,
4e7e3aa1-3a0c-4fe7-9483-a2f5dcd76a74,Build & Dependency Management,Build Troubleshooting & Repair,Dependency & Compatibility Issues,"Fix a Node.js native addon build that fails under Node.js 12–18 due to mismatched N-API versions, incorrect include paths, and deprecated V8 APIs: update binding.gyp and source code, rebuild with node-gyp per target, and verify the addon loads and passes its tests.",,
d3756dc8-6eeb-4b0c-bade-fcb3d4fb6242,Build & Dependency Management,Build Troubleshooting & Repair,Dependency & Compatibility Issues,Diagnose and fix a .NET solution build failure caused by conflicting Newtonsoft.Json and System.Text.Json versions across multiple projects by updating csproj PackageReference entries and adding appropriate assembly binding redirects. Verify that dotnet build completes without errors and that all serialization unit tests pass successfully.,,
ada49b3b-3f1f-4d11-811c-f9cde414aeff,Build & Dependency Management,Build Troubleshooting & Repair,Dependency & Compatibility Issues,"Debug a Node.js project with native C++ addons that fail to build due to Node/Electron ABI mismatches: configure and run node-gyp to rebuild against the correct N-API version, update package.json build scripts and version constraints, and verify successful installation and tests in both Node and Electron environments.",,
069e3982-9322-496e-8bfb-c4229c82f76b,Build & Dependency Management,Dependency Management,Dependency Resolution & Conflict Fixing,"Implement a CLI tool that scans a mixed Gradle/Maven Java project for conflicting transitive JAR versions causing duplicate classes, then automatically generates and injects a dependencyManagement or resolutionStrategy snippet to enforce consistent versions and update the build files accordingly.",,
eeeea1c9-8a05-48d8-ad9c-2120a84506bd,Build & Dependency Management,Dependency Management,Dependency Resolution & Conflict Fixing,"Diagnose and resolve peer dependency conflicts in a Node.js Yarn workspaces monorepo where multiple packages require incompatible React and TypeScript versions by applying selective ""resolutions"" and workspace overrides. After remediation, perform an offline install and run each package’s test suite to confirm that all dependencies are unified and builds succeed.",,
e4955eb6-984d-48f9-9d53-02e757a43823,Build & Dependency Management,Build Optimization & Performance,Incremental Builds & Caching,"Set up sccache in a Rust multi-crate workspace to use a local S3-compatible cache (via a MinIO container), configure Cargo to route compilation artifacts through sccache, then run a cold build followed by a warm build to demonstrate cache hits and measure time savings. Clean the target directories and rebuild to confirm that all artifacts are fetched from cache without recompiling sources and report hit/miss statistics.",,
263d28d3-3e91-494b-8939-bc0855118895,Build & Dependency Management,Build Optimization & Performance,Incremental Builds & Caching,"Set up a Meson-based C project with Ninja and ccache in a Docker sandbox, then write a script that applies controlled header and source edits to measure clean vs. incremental rebuilds. The script must emit a JSON report detailing cache hit rates, list of rebuilt targets, and total build time improvements.",,
a2c07b67-0133-4662-9bb5-edc6b63b8163,Build & Dependency Management,Build Optimization & Performance,Incremental Builds & Caching,"Set up sccache inside a Dockerized mixed Rust and C++ project to push and pull build artifacts to an S3-compatible object store with local-disk fallback and custom key prefixes, then run two clean builds to verify cache hits and output sccache metrics in JSON format.",,
6396072e-626b-4db9-94d4-45f0aba3b87a,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Create a Maven multi-module project combining Java and Kotlin submodules, configure the kotlin-maven-plugin, and produce a multi-release JAR that contains legacy implementation for Java 8 and modern code under META-INF/versions/11. Validate by building under JDK 8 and JDK 11 and running the appropriate module-specific features via the Surefire plugin.",,
acf91b3b-c6dd-46b7-9e3d-f00652e1fc83,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Configure and build a Java 11 multi-module Maven project using the Java Platform Module System with `core` and `cli` modules, set up the Maven Shade plugin to produce a relocated uber-jar for the CLI, then generate a minimized custom runtime image via the Maven JLink plugin and verify the bundled runtime executes the CLI correctly.",,
dd6be65a-73b8-4197-93fa-bdde30633481,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Configure a multi-module Maven project to produce reproducible, deterministic JARs by normalizing timestamps, sorting entries, and stripping non-essential metadata using the Maven Reproducible Builds Plugin. After two clean builds in separate directories, verify the byte-for-byte equality of all generated artifacts.",,
682f9326-6867-446e-bfee-a60ce8d2c4c8,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Implement a Maven multi-module build that compiles Java and Kotlin modules, generates Protobuf sources, executes SpotBugs and JUnit5 tests with a minimum 85% coverage threshold, assembles a shaded uber-jar, and deploys snapshots and releases to a Nexus repository using custom staging profiles. Ensure build reproducibility by locking plugin and dependency versions via the Maven Enforcer plugin and verify offline builds with a mirrored local repository.",,
fdcfb252-49b5-4f4c-8970-d58c2581227d,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Configure a Dockerized multi-module Maven project using the Maven Toolchains plugin to compile and test the same codebase against both Java 8 and Java 17, emitting artifacts into separate target subdirectories. Validate each build by inspecting class file major versions and ensuring all tests pass under both JDKs.",,
e768ab48-c8e2-47bf-a72d-ead15e42fab4,Build & Dependency Management,Language & Ecosystem-Specific Build Management,JavaScript & Frontend Builds,"Set up a Node.js monorepo with Yarn workspaces containing two reusable TypeScript React component libraries and a Next.js app, configuring Rollup to produce ESM/CJS bundles and declaration files for the libraries and Webpack with CSS modules and code splitting for the app. Verify hoisting, correct peerDependencies, local linking, and that a production build of the app dynamically imports both libraries successfully.",,
2800d9b1-47b2-4650-b49a-1414af354989,Build & Dependency Management,Language & Ecosystem-Specific Build Management,JavaScript & Frontend Builds,"Create a pnpm monorepo with two TypeScript packages (‘lib’ and ‘app’), configure esbuild to emit both CJS and ESM outputs with declaration files for ‘lib’, and bundle ‘app’ into /dist with hashed filenames. Verify that workspace protocol aliases resolve correctly in the app and generate a manifest.json mapping entrypoints to the output files.",,
f4b86f44-9a00-4d08-93e2-4af61a975cad,Build & Dependency Management,Language & Ecosystem-Specific Build Management,JavaScript & Frontend Builds,"Set up a TypeScript-based library that uses Rollup to output CJS, ESM, and UMD bundles with corresponding sourcemaps, integrates PostCSS with CSS Modules and autoprefixer targeting the last two browser versions, and minifies code according to a Browserslist. Write an automated script to build all formats, run Node tests importing both CJS and ESM modules, and launch a headless browser to verify the UMD bundle loads and applies scoped CSS correctly.",,
4e7f6069-5b03-4482-bf67-f5a796f7b569,Build & Dependency Management,Language & Ecosystem-Specific Build Management,JavaScript & Frontend Builds,"Initialize a Yarn v3 zero-install workspace with three packages (ui, utils, app) sharing TypeScript and ESLint configs. Use Rollup to produce code-split bundles, output a JSON report of entrypoint sizes and deduplicated dependencies, and verify that unused utils code is tree-shaken from the app bundle.",,
8e4d5979-142f-43ff-8339-a342b3ceffe4,Build & Dependency Management,Dependency Management,Lockfile & Manifest Maintenance,"Implement a Python CLI that reads both package-lock.json and yarn.lock, detects version discrepancies across direct and transitive dependencies, and computes a unified dependency tree by choosing the latest semver-compatible versions. The tool must update both lockfiles to reflect the reconciled tree with deterministic integrity hashes, and validate that npm ci and yarn install yield identical node_modules structures by comparing directory digests.",,
6f455a65-be37-42e5-a917-fc07a36f7166,Build & Dependency Management,Dependency Management,Lockfile & Manifest Maintenance,"Synchronize and update lockfiles across a Node.js/Python monorepo by bumping specified dependencies to target major versions, applying npm overrides and pip-compile to flatten transitive mismatches, regenerating yarn.lock and Pipfile.lock, and verifying deterministic installs via npm ci and pip-sync. Handle conflicting version constraints, honor ecosystem-specific resolution strategies, and ensure builds in each ecosystem pass their respective test suites.",,
a657066f-1f6d-4ff4-aad8-6cc5ec5b7971,Build & Dependency Management,Source Compilation & Build Systems,Manual Compilation,"Compile all C sources under /src into position-independent object files using gcc with -O2, -fPIC, -Wall, and -Werror; then archive them into libfoo.a and link them into a SONAME-versioned shared library libfoo.so.1.0.0 (with SONAME libfoo.so.1). Next, compile a test program that links against this shared library using an rpath to its directory and verify it runs and outputs the expected result.",,
9826377d-b79b-4d4e-954f-971bae5b72dd,Build & Dependency Management,Source Compilation & Build Systems,Manual Compilation,"Manually compile a C++20 module interface and implementation (.cppm) using clang++ with -std=c++20 -fmodules-ts, producing BMI files in /build/modules, then compile and link main.cpp that imports the module into an executable. Verify the binary prints correct mathematical results.",,
98c0259a-ec94-4f1f-94ab-d80a6a8b419a,Build & Dependency Management,Source Compilation & Build Systems,Manual Compilation,"Compile a C program in /src manually using gcc for two targets: x86_64-linux-gnu and armv7-linux-gnueabihf, applying -static, -O2, and target-specific sysroots. Then verify each statically linked binary under QEMU in Docker to confirm correct execution and identical outputs.",,
d421b447-a44a-4614-90ae-752ab45463ca,Build & Dependency Management,Continuous Integration & Automation,Multi-Arch Container Publishing,"Implement a CI pipeline script that uses Docker Buildx to build and push a multi-architecture (amd64, arm64) image to Docker Hub and GitHub Container Registry, including manifest list creation, Cosign signing, and secure credential handling. Validate by pulling each platform-specific image under QEMU and running a test command to ensure correctness.",,
75570d17-768f-4fe0-ad7b-263d427820d8,Build & Dependency Management,Build Optimization & Performance,Parallelization & Resource Utilization,"Deploy a local Bazel remote execution and caching server in Docker, then configure a mixed C++ and Java Bazel workspace to leverage remote cache and distributed execution across multiple cores. Validate by running cold and warm builds and generate a JSON report detailing cache hit rates and build time improvements.",,
217e1f59-6efe-40a4-b31d-88826e5cd71f,Build & Dependency Management,Build Optimization & Performance,Parallelization & Resource Utilization,"Configure a distributed CMake build to leverage distcc and ccache across three Docker nodes by automatically setting up remote hosts, wrapper scripts, and environment variables, then execute make -j to verify tasks are offloaded. Provide a Python utility that parses distcc logs to output a JSON report of host utilization, per-file compile times, and cache hit rates.",,
9df569d4-bb88-450d-ab57-74bc7518ee52,Build & Dependency Management,Build Optimization & Performance,Parallelization & Resource Utilization,"Create a Dockerized CMake-based C/C++ project that integrates ccache and distcc to distribute compilation across a user-specified number of simulated remote build agent containers, automatically generating the distcc hosts configuration. Execute a parallel Ninja build using this setup and output /app/metrics.json summarizing per-file compile times, per-host utilization, cache hit rates, and overall build speedup compared to a local single-core baseline.",,
60b6b512-56a5-4d1c-af97-02af706f2097,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Python Builds & Packaging,"Implement a Python CLI that migrates a legacy setup.py project into a PEP 517 pyproject.toml preserving all metadata, dependencies, entry points, and package data, then builds both sdist and wheel via the build module. The tool must normalize timestamps, sort file listings, and verify SHA256 checksums of artifacts across two runs to guarantee reproducible, deterministic builds.",,
29857d5c-a68a-423e-b794-debdf284f2ca,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Python Builds & Packaging,"Develop a release automation script that parses Conventional Commits since the last git tag to determine the next semantic version, updates pyproject.toml and the package __init__.py, then builds sdist and wheel via PEP 517 build, runs twine check, and publishes to Test PyPI. Finally, the script must create a fresh virtualenv, install the package from Test PyPI, and verify the import and version output.",,
ea9d38ea-8ce2-4d23-9ebb-f37d02ee4bfc,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Python Builds & Packaging,"Use Docker’s manylinux2014 image to build Python wheels for a project with Cython extensions, configuring build options solely via pyproject.toml and running auditwheel repair to ensure compliance. Then automate testing by installing each wheel in isolated venvs for Python 3.7–3.10 and executing a sample import and function call.",,
3d22c1c0-8e7f-41dd-b6f9-8b62051f565b,Build & Dependency Management,Release Engineering & Version Control Integration,Reproducible Release Provenance,"Compile and package release binaries for Linux x86_64, ARM64, and Windows in separate Docker sandboxes, generate SHA256 checksums, GPG detach signatures, and SPDX SBOMs for each. Then perform a second independent build to verify bit-for-bit reproducibility and bundle all artifacts, signatures, and SBOMs into an in-toto provenance statement, confirming integrity and authenticity.",,
dea5d588-a9e9-43ec-bea7-dc1e43af8fdc,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Rust/Go/Other Modern Toolchains,"Set up a Rust project with feature flags, embed Git tag–based semantic version and commit hash into the build, and cross-compile release binaries for x86_64-unknown-linux-musl, aarch64-apple-darwin, and wasm32-unknown-unknown. Produce a JSON manifest in /app/releases.json listing each artifact’s target triple, file size, and SHA256 checksum.",,
34e3080d-b757-4e52-8f3e-6781afffb69b,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Rust/Go/Other Modern Toolchains,"Set up a local Go module proxy server that mirrors all dependencies for a sample project, configure GOPROXY to point to it (disabling GOSUMDB), and vendor the modules to enable fully offline operation. Perform cross-compilation builds for linux/amd64 and windows/386 with embedded version metadata via ldflags, package each binary into a versioned tarball, and verify reproducible offline builds by checking SHA256 sums.",,
e48f72b4-210d-45bc-98b8-566f5cd43f98,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Create a release automation script that cross-compiles a Go project for Linux amd64 and arm64, packages the binaries into tar.gz archives, generates SHA256SUMS, and digitally signs the checksum manifest and Git tag with a specified GPG key. Provide a verify.sh script that validates the GPG signatures, confirms the integrity of the checksums against the archives, and verifies the authenticity of the signed Git tag.",,
788102de-4552-4f51-ac90-24e81d5b15fc,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Implement a POSIX-compliant release automation script that checks out a provided git tag, builds artifacts for multiple platforms, generates SHA256 and SHA512 checksum files, and signs both artifacts and checksums with a GPG key from /env/keys. The script must then verify all signatures against a public keyring, produce a manifest.json with artifact metadata and signature statuses, and prepare a versioned release directory for distribution.",,
de8e270e-8d29-47f8-9cfc-1f710348b821,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Configure a Dockerized signing environment that uses a hardware-backed GPG key (e.g., YubiKey) with gpg-agent to detach-sign multiple built artifacts (.tar.gz, .zip, .deb), generate SHA256 checksums, and publish them to /dist as .asc and .sha256 files. Also implement a verify.sh script that fetches the public key via WKD, validates both signatures and checksums, and fails cleanly on any mismatch or missing artifact.",,
7638d832-1d0a-467a-b43e-9ae6a660234d,Build & Dependency Management,Dependency Management,System vs. Project Dependency Isolation,"Configure a Docker image with rbenv to install Ruby 2.7.3 and 3.0.1, automatically select the Ruby version via .ruby-version, vendor gems to a per-project path, and generate an offline mirror of all dependencies. Then verify that bundle install --deployment --local succeeds for both Ruby versions without any network access.",,
983fc111-f70f-4ded-b61e-2ccc62445ab4,Build & Dependency Management,Dependency Management,System vs. Project Dependency Isolation,"Develop a bash orchestration script that bootstraps isolated environments for a polyglot monorepo: it creates a Python virtualenv, runs npm ci inside a Node.js Docker container, and configures a Go modules cache in a local directory, then executes each language’s build and test suites within its sandbox. Finally, verify reproducible, offline builds by replaying the orchestrator with network disabled and checking for failures or unexpected host dependency access.",,
817a5e75-9065-472d-9eb0-9a6924d7468e,Build & Dependency Management,Dependency Management,System vs. Project Dependency Isolation,"Implement a Bash script '/app/venvctl.sh' that detects a Python project root by locating pyproject.toml or requirements.txt, creates or reuses a virtualenv in .venv using the specified Python interpreter version, and provides subcommands to activate, deactivate, list, and remove the environment. Verify by installing a sample dependency and ensuring 'python -c' imports succeed inside the venv and fail outside.",,
322a3d26-1836-4292-b59e-9d75f2b9075f,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"Develop a POSIX-compliant release automation script that determines major, minor, patch, or prerelease versions (alpha/beta) from Conventional Commits plus a --pre flag, updates both package.json and setup.py with the computed version and prerelease identifier, generates a unified changelog, creates annotated git tags, and builds npm packages and Python wheels. The script must place versioned artifacts and tags in /releases, robustly handle missing or malformed tag histories, and validate consistency of versions across both language ecosystems.",,
2130a558-cbe7-4510-a02c-95b5e92cb652,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"Develop a shell-based release manager that scans a monorepo for crates and package.json files, bumps each module’s semantic version based on Conventional Commits and commits the version updates. Then it creates annotated git tags per module and generates a consolidated CHANGELOG.md with links to the merged PRs.",,
2466540a-4876-45e0-8448-dd6ebd3e5891,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"Create a cross-platform release script that reads a YAML manifest of target platforms, runs builds inside per-platform Docker containers, computes SHA256 checksums and GPG-signs each artifact, then tags the commit with a semantic version, creates or updates a GitHub release via the API, and attaches the signed artifacts. The script must be idempotent—skipping existing tags or uploads—handle API rate limits with exponential backoff, and validate all manifest entries with clear error reporting before starting.",,
0662a9e4-afeb-4437-b66e-c926870f430b,Data Processing & Scripting,File System Operations,Archival & Backup Scripting,"Create a POSIX shell backup tool that performs rsync-based hard-link snapshots of /data into /repo/YYYY-MM-DD using --link-dest for incrementals, generates a JSON manifest with per-file SHA256 and total logical size, then zstd-compresses and age-encrypts the manifest with a provided public key. Implement verify and restore modes that reconstruct the latest snapshot into /restore (preserving sparse files, symlinks, permissions, and mtimes) and enforce GFS retention (7 daily, 4 weekly, 6 monthly) while producing a human-readable report.txt.",,
95b7040f-a6da-461f-9068-cf9027f423a3,Data Processing & Scripting,Data Cleaning & Transformation,Aggregation & Reduction,"Create a Python CLI tool that reads a directory of JSONLines sensor event logs with ISO8601 timestamps and sensor IDs, normalizes timestamps to UTC, and groups readings by sensor and hourly buckets to compute count, sum, average, min, and max. The tool should write /app/output/hourly_summary.csv and an anomaly_report.json listing sensors whose hourly variance exceeds a specified threshold.",,
0e9742c8-32b3-483a-a94c-0d3f14ab14aa,Data Processing & Scripting,Data Cleaning & Transformation,Aggregation & Reduction,"Write a Python 3 script that reads newline-delimited JSON clickstream events from /app/input/events.ndjson, normalizes timestamps to ISO8601 UTC, segments events into user sessions using a 30-minute inactivity threshold, and computes per-session metrics (duration, event_count, avg_inter_event_ms). The tool must flag the top 5% longest sessions and write /app/output/session_metrics.csv with per-session stats plus /app/output/summary.json containing global aggregates (total_sessions, avg_duration_ms, 95th_percentile_ms) and details of flagged sessions.",,
8292b8cb-370a-40ad-9d89-14612811927a,Data Processing & Scripting,Data Cleaning & Transformation,Aggregation & Reduction,"Create an executable Python script that ingests timestamped JSON sensor files from /data/sensors, discards records with missing or out-of-range values, and computes per-device hourly averages, daily maxima, and uptime percentage. Output a YAML summary at /output/summary.yaml and a CSV at /output/metrics.csv with time-series entries, filling any missing hourly slots via linear interpolation.",,
38950ca2-07f6-4271-aa4f-456c2e4e3a4e,Data Processing & Scripting,Integration with External Systems,API Data Fetching & Posting,"Create a Python CLI tool that reads a list of cities from a CSV, uses the OpenWeatherMap API to fetch current weather metrics, normalizes units, and computes average temperature and humidity. The tool must POST the resulting summary JSON to a provided REST endpoint with retries and error logging.",,
24335e7e-cafe-4d87-9e39-1fd1539bd375,Data Processing & Scripting,Text & Document Processing,Report & Document Generation,"Develop a Python CLI that ingests JSON-exported GitHub issues and pull requests, groups them by milestone and label-based priority (via a configurable mapping), and emits a Markdown backlog report with per-milestone tables and aggregate stats plus a JSON dashboard summarizing counts and label distributions.",,
529da52b-0a12-4b71-9eef-011ff77ba0ec,Data Processing & Scripting,File System Operations,Archival & Backup Scripting,"Create a Python CLI that performs incremental, chunk-level deduplicated backups of user-specified directories by archiving with zstd, splitting into fixed-size segments, encrypting each chunk with GPG, computing SHA-256 checksums for integrity, and supporting uploads to local storage or AWS S3 with configurable retention pruning and a dry-run summary mode.",,
7f2ff386-0f24-4a05-af99-7d9e39d32b37,Data Processing & Scripting,File System Operations,Batch File Operations,"Create a Python CLI tool that recursively scans a source directory for JPEG and PNG images, extracts capture dates via exiftool (falling back to file mod times), and renames/moves each file into an /output/YYYY/MM/ folder with filenames formatted as YYYYMMDD_HHMMSS_originalname.ext. Normalize names (replace spaces, strip special characters), append counters on duplicates, generate a manifest.json mapping original to new paths, and exit non-zero on any validation or I/O error.",,
2220a80b-5037-45a0-a8c9-7721727f7aa2,Data Processing & Scripting,File System Operations,Batch File Operations,"Create a Python CLI script that scans a directory of image and video files, extracts EXIF metadata or falls back to filesystem timestamps, and renames and moves each file into a YEAR/MM/DD folder hierarchy with filenames based on ISO8601 timestamps plus unique counters. The tool must generate a catalog.json mapping original paths to new locations, handle missing metadata, avoid name collisions, and support dry-run and apply modes.",,
4929242f-998e-4275-ba05-bfb07d59398b,Data Processing & Scripting,File System Operations,Batch File Operations,"Create a script that recursively scans a target directory for files with specified extensions, computes SHA256 hashes to identify duplicates, moves all but the first occurrence of each hash into a “duplicates” subfolder (renaming them with a sequential suffix), and preserves one original. It must also generate a report.json mapping each unique file path to its list of moved duplicates.",,
f3980dcd-38d6-4c51-b4ba-1993de9b9095,Data Processing & Scripting,File System Operations,Batch File Operations,"Implement a CLI tool that scans a directory for image files, extracts EXIF creation timestamps to rename each into a standardized ""YYYY-MM-DD_HHMMSS_<n>.<ext>"" format and organizes them into a year/month/day folder structure, detecting duplicates via SHA-256 to skip or report. Produce a JSON summary of all renamed, moved, and duplicate-handled files.",,
ebf05f9b-2cb7-4c1e-b1c6-fbc09b5b4b23,Data Processing & Scripting,Integration with External Systems,Cloud Storage Interaction,"Develop a Python CLI tool that mirrors /data/backup to a specified S3 bucket as timestamped snapshot prefixes, uses multipart uploads for files larger than 100 MB, and enforces daily, weekly, and monthly retention by purging old snapshots. The tool must record each action in structured JSON at /app/logs/sync_log.json and emit a restore shell script at /app/restore.sh that retrieves the latest snapshot files.",,
f4725201-09e9-400c-b3e8-08c0bf5c9b96,Data Processing & Scripting,Integration with External Systems,Cloud Storage Interaction,"Implement a CLI that mirrors an AWS S3 bucket to a Google Cloud Storage bucket with authenticated multi-threaded, resumable transfers, metadata and ACL preservation, conflict detection, and an optional dry-run mode. Produce a JSON summary report listing synced, skipped, and failed objects.",,
0bf4af96-0ddb-40d6-a937-e1e178e507b8,Data Processing & Scripting,Integration with External Systems,Cloud Storage Interaction,"Implement a Python CLI tool at /app/s3_sync.py that synchronizes a local /data directory to a specified AWS S3 bucket prefix by comparing file MD5 checksums against S3 ETags, uploading only new or modified files and supporting a --dry-run mode. The tool must handle concurrent uploads with configurable threads, retry failed operations with exponential backoff, and write a timestamped JSON log manifest at /output/sync_manifest.json, exiting non-zero on any unrecoverable error.",,
048b06d3-976b-4bd9-97de-0fdf06889593,Data Processing & Scripting,Integration with External Systems,Cloud Storage Interaction,"Develop a Python CLI that lists all gzipped JSONL blobs under a given Azure Blob Storage prefix, downloads and decompresses them in parallel, merges into one NDJSON file, compresses and uploads the result to a target container, and outputs a JSON manifest with checksums, sizes, and operation statuses. The tool must support credential overrides, idempotent runs, failure retries, and a summary report of skipped, failed, and successful blobs.",,
4e5299cb-8cf0-494b-a96b-b22fca1b5df4,Data Processing & Scripting,Data Validation & Quality Assurance,CSV Schema Enforcement,"Create a Python CLI tool that reads a directory of CSV files plus a YAML schema defining expected columns, data types (integer, float, date with format, enum), and value constraints, then validates and coerces each row, normalizes date formats, and writes cleaned CSVs to /app/output with invalid rows written to per-file .reject logs. It must also produce report.json summarizing per-file and per-column counts of errors and coercions.",,
657bea07-78c6-4cec-b16c-f01e83814295,Data Processing & Scripting,Data Cleaning & Transformation,Data Merging & Joins,"Create a script that ingests multiple CSV files of IoT sensor readings along with a JSON device registry, normalizes timestamps to UTC ISO8601, left-joins readings on device_id while flagging unmatched entries, and outputs a consolidated CSV plus a summary JSON detailing join statistics.",,
3055c56e-1912-411c-b0a9-83f8e4be1200,Data Processing & Scripting,Data Cleaning & Transformation,Data Merging & Joins,"Implement a Python CLI tool at /app/merge_tool.py that scans /data/inputs for multiple CSV files, performs a full outer join across user-specified key columns (via CLI args), automatically detects and reconciles mismatched headers by normalizing case and inserting nulls for missing fields, and writes a deterministic /output/merged.csv with lexicographically sorted columns and rows. Ensure strict input validation, no stdout on success, and exit non-zero on any parsing or validation error.",,
24b8847b-8c89-4ca3-826b-28653764b067,Data Processing & Scripting,Integration with External Systems,Database Query & Export,"Build a Python CLI tool that reads a YAML configuration of named SQL SELECT queries against a PostgreSQL database, executes each query, exports results to newline-delimited JSON files with sorted keys, and generates an index.json summarizing each export’s filename, row count, and SHA256 checksum.",,
385c35cc-3d80-4774-a664-6f8232ffa436,Data Processing & Scripting,Integration with External Systems,Database Query & Export,"Create an executable Python script at /app/join_export.py that reads two MySQL DSNs from /conf/mysql.toml, connects to both databases, joins customers and orders tables for the past 30 days, sorts by total_amount descending, and writes a Gzip-compressed CSV to /app/output/recent_orders.csv.gz with a UTF-8 BOM. The script should retry transient connection errors up to three times and report metrics (rows exported, duration) in /app/output/export_report.json.",,
ce7bc0e7-ef10-45a4-a4ec-886d6fb318b6,Data Processing & Scripting,Integration with External Systems,Database Query & Export,"Develop a Python CLI that connects to a PostgreSQL database, introspects schemas and lets users run SQL queries, then partitions query results by a detected date/time column into monthly Parquet files compressed with Snappy and writes a JSON manifest with each file’s schema, row count, and partition ranges.",,
19f028ec-e284-4df1-99c8-d3a932fe38ab,Data Processing & Scripting,Integration with External Systems,Database Query & Export,"Build a script that connects to a PostgreSQL database using environment-supplied credentials, tracks the highest processed timestamp in a local state file, queries new rows in batches from a specified table, writes each batch as newline-delimited JSON files to /app/output/, and updates the state file with the latest timestamp. The script must implement retry logic for transient DB errors and produce a summary.csv with total exported rows, duration, and last export timestamp.",,
5998a098-793c-4bd5-9e48-ffb70896a2ad,Data Processing & Scripting,Data Sampling & Exploration,Descriptive Statistics & Summaries,"Develop a Python script that reads a CSV of geolocated measurements (latitude, longitude, value), partitions data into hexagonal bins at a user-specified resolution using the h3 library, and for each bin computes count, mean, median, and standard deviation of values. The script should output a GeoJSON FeatureCollection with each hexagon’s geometry and aggregated statistics in its properties and generate a summary JSON with global extremums and bin counts.",,
f6f08ffe-15a7-4d1e-8bc0-ce720fa1f30f,Data Processing & Scripting,Data Sampling & Exploration,Descriptive Statistics & Summaries,"Implement an executable CLI tool at /app/summary_stats.py that reads a CSV file, validates headers and data types, and computes for each numeric column the count of non-null entries, mean, median, and standard deviation. For each non-numeric column compute distinct value counts and the top-5 most frequent categories, then write a deterministic JSON summary with sorted keys, indent=2, and a trailing newline, exiting non-zero on any validation error.",,
69e9469a-e843-4d7c-82b7-0b637aa65476,Data Processing & Scripting,Data Sampling & Exploration,Descriptive Statistics & Summaries,"Develop a Python CLI that streams delimited (CSV/TSV/GZ) datasets with auto-detected delimiter, uses reservoir sampling to bound memory and employs online algorithms (e.g., P²) to compute approximate mean, variance, min, max, and key percentiles per numeric column. Output results as structured JSON and human-readable ASCII histogram tables.",,
3bfae430-c97f-4c1a-91b5-27fcab36fd94,Data Processing & Scripting,File Parsing & Format Conversion,Encoding & Compression,"Create a command-line tool that recursively auto-detects and extracts mixed-format archives (.zip, .tar.gz, .7z, .bz2), verifies extracted files against an optional SHA256SUMS manifest while preserving metadata and symlinks, and then repackages the flattened output into a single tar.xz archive. Generate a JSON summary report listing original archive paths, total file counts, per-archive compression ratios, and any checksum mismatches.",,
0256e000-9067-401c-b30e-fef7b6372ac7,Data Processing & Scripting,File Parsing & Format Conversion,Encoding & Compression,"Develop a CLI tool that recursively unpacks mixed-format archives (zip, tar.gz, gzip), detects and repairs corrupted members, re-encodes all text files to UTF-8 without BOM, then repackages them into size-limited tar.xz chunks. Finally, emit a manifest.json listing original paths, new archive names, file sizes, and SHA256 checksums.",,
f887b76c-dbd7-4437-bfb6-dae37a4c086c,Data Processing & Scripting,File Parsing & Format Conversion,Encoding & Compression,"Implement a Python CLI tool at /app/normalize_compress.py that recursively scans /app/input for gzip, bzip2, xz, or zip archives, decompresses each entry, converts text files to UTF-8 with Unix line endings (skipping binaries), and packs them into a single deterministic tar.zst archive /app/output/archive.tar.zst sorted by path with no timestamps. It must detect and log corrupted archives without stopping, exit non-zero only on critical failures, and emit /app/output/report.json with per-file original format, size, and compression ratio.",,
4df129b2-6cf9-4e5f-a253-8f31e14b8b0b,Data Processing & Scripting,Automation & Workflow Scripting,ETL (Extract-Transform-Load) Workflows,"Write an executable Python ETL script at /app/etl_inventory.py that loads inventory data from /data/excel/inventory.xlsx, price lists from /data/csv/prices.csv, and discount rules from /data/json/discounts.json, merges on SKU, applies discount computations and rounding policies, filters out-of-stock items, and loads the cleaned dataset into a SQLite database at /app/output/inventory.db. Then generate /app/output/inventory_report.csv summarizing total items, estimated revenue, out-of-stock counts, and discount application statistics.",,
9739787d-13c0-4f42-b2d2-f3121d16bbbf,Data Processing & Scripting,Automation & Workflow Scripting,ETL (Extract-Transform-Load) Workflows,"Create a Python CLI tool that reads /app/urls.csv of webpage URLs, fetches and parses the first HTML table from each page into structured rows, logging any fetch or parse errors. Then normalize numeric and ISO8601 date fields, merge all results into an SQLite table at /app/data.db and output a summary JSON with total records, per-source counts, and average values.",,
eba2cbe0-35d9-4c7d-84e0-ec7c610b1a94,Data Processing & Scripting,Automation & Workflow Scripting,ETL Workflows,"Design a Python CLI that extracts paginated JSON data from two mock REST APIs (users and orders), joins them on user_id, normalizes timestamps to UTC ISO-8601, enriches orders with user metadata from a configurable JSON, and computes per-user daily order totals. Load the processed dataset into a local SQLite table with idempotent upsert logic, and output a JSON manifest summarizing record counts, transformation errors, and load statistics.",,
55bfe902-a627-4414-a0f4-f66610e25947,Data Processing & Scripting,File System Operations,File Discovery & Search,"Create a script that recursively scans a given directory, groups regular files by size and SHA-1 hash to identify duplicates, and writes a deterministic JSON array of duplicate groups using relative POSIX paths sorted lexicographically. The tool must ignore non-files, resolve symlinks, normalize paths, and output sorted keys and arrays for reproducibility.",,
7ecf1533-4048-4f06-9a33-1aea6ab4bd0b,Data Processing & Scripting,File System Operations,File Discovery & Search,"Create a shell or Python CLI that scans a directory tree for files exceeding a configurable size threshold, identifies duplicate content groups via partial and full hashing, and outputs a sorted report plus an idempotent cleanup script to replace duplicates with hardlinks; support dry-run, exclude patterns, and size overrides.",,
5f77a8d3-02ba-407d-a9c8-e874119f47be,Data Processing & Scripting,File System Operations,File Discovery & Search,"Write a script that recursively scans a directory (excluding hidden directories), computes SHA256 hashes for each regular file, groups files sharing identical hashes into duplicate sets and selects the earliest-modified file as the canonical copy. The tool must output duplicates.json listing each set with file paths, sizes, and canonical paths, and generate summary.txt with total files scanned, duplicate groups found, and total reclaimable space.",,
3e819e90-178f-41b8-9d02-c9bc21c4eba7,Data Processing & Scripting,File Parsing & Format Conversion,File Format Conversion,"Create a Python script that reads an Excel workbook (/app/input/workbook.xlsx), extracts each sheet to a properly quoted CSV with date, number, and string type coercion while filling merged cells, writing one CSV per sheet in /app/output/. Also emit a metadata JSON summarizing each sheet’s column names, inferred types, row counts, and missing-value statistics.",,
99f07b9e-5f0c-462e-9b35-65b3c2784fab,Data Processing & Scripting,File Parsing & Format Conversion,File Format Conversion,"Develop a Python CLI tool that reads all .xlsx workbooks in an input directory, flattens each sheet into CSV tables with type inference, and writes them as Parquet files partitioned by a user-specified column. The tool must also generate a JSON schema file per sheet containing column statistics (min, max, null count, unique values).",,
4603d9d5-3c61-42ff-97ae-9fefba37fa20,Data Processing & Scripting,Data Cleaning & Transformation,Filtering & Selection,"Implement a Python script that reads newline-delimited JSON IoT sensor readings, normalizes timestamps to UTC, and filters out records outside a configured time window, missing humidity, or whose temperature deviates more than three standard deviations per sensor. Write the cleaned records to /app/output/filtered_readings.json and a summary_report.json detailing removal counts per reason and per-sensor statistics.",,
3d1c3f1a-6163-4c7c-9a40-558c98529b01,Data Processing & Scripting,Data Cleaning & Transformation,Filtering & Selection,"Create an executable Python script at /app/filter_tool.py that reads newline-delimited JSON from stdin or /app/input.ndjson, loads /app/filters.yaml defining inclusion and exclusion rules via JSONPath selectors, regex patterns, numeric thresholds, and date ranges, and writes matching records to /app/output/matched.ndjson and rejected ones to /app/output/rejected.ndjson. Generate a JSON summary at /app/output/summary.json with per-rule match counts and exit non-zero if no records satisfy any inclusion rule.",,
43c550d2-e52a-4a19-80fa-8673240f58ae,Data Processing & Scripting,Data Cleaning & Transformation,Filtering & Selection,"Implement an executable Python CLI at /workspace/filter_logs.py that reads newline-delimited JSON from stdin, filters records where metadata.status equals 'active' and metrics.value falls within user-specified bounds, removes duplicates based on id, sorts by timestamp ascending, and writes a valid YAML array to /output/filtered.yaml. Invalid JSON lines should be appended to /output/errors.log with line numbers and parse errors, and the script must exit non-zero if any errors are encountered.",,
032aa2a6-9384-4aa6-890b-1b47cdf4f4d0,Data Processing & Scripting,Data Cleaning & Transformation,Filtering & Selection,"Develop a CLI that filters CSV input using a JSON/YAML spec defining regex, numeric, and date-range rules combined with AND/OR/NOT operators across columns. The tool outputs matching rows as CSV and a JSON summary with per-rule drop counts and overall acceptance rate.",,
64b7e06e-edb9-47f7-8324-f3ced17926a7,Data Processing & Scripting,Data Validation & Quality Assurance,Integrity Checks & Diffs,"Create an executable Python script at /app/csvdiff.py that takes --old.csv, --new.csv, and a list of primary key columns, reads both files with robust CSV parsing, and matches rows on the composite key to detect added, removed, and updated records. Write a JSON report to /app/output/changes.json containing arrays for 'added', 'removed', and 'updated' entries (each update including old and new values), and exit non-zero if any differences are found.",,
5d97bf00-9a66-4087-b694-bf47af785103,Data Processing & Scripting,Data Validation & Quality Assurance,Integrity Checks & Diffs,"Develop a Python CLI that takes two directory snapshots and builds Merkle trees using BLAKE3 checksums for every file and directory, then identifies added, removed, moved, and modified items while ignoring metadata-only changes. The tool should output both a human-readable diff and a machine-readable JSON report with checksums and change types.",,
02e55115-a3fa-4ef6-9a37-9d36caaa157c,Data Processing & Scripting,Text & Document Processing,Markdown/HTML/Text Conversion,"Build a CLI tool that ingests a directory of Markdown files with YAML front-matter, concatenates them in specified order, and generates a single standalone HTML book with an autogenerated table of contents, inlined CSS, and images embedded as Base64. The tool must validate all internal links, emit index.html, and produce a JSON manifest describing chapter order and heading hierarchy.",,
657fb85a-f4df-47a4-ad3b-42ae5f1be0a3,Data Processing & Scripting,Text & Document Processing,Markdown/HTML/Text Conversion,"Implement a CLI tool that merges all Markdown files in a given /docs directory into a single HTML document: generate a nested table of contents, normalize internal links to HTML anchors, embed referenced images as base64, apply syntax highlighting with Pygments, and honor YAML frontmatter metadata for title and author. The script must strictly validate input files and resources, write the final output to /output/book.html, and exit with a non-zero code on any missing or malformed input.",,
1218c715-8db5-45be-b7ae-835a8db376e3,Data Processing & Scripting,File System Operations,Metadata Extraction & Logging,"Create a Python script that recursively scans a specified directory to extract file metadata (size, owner, group, permissions, and access/modification timestamps) and writes entries sorted by path as newline-delimited JSON in a dated gzip file at /var/logs/file_audit_{YYYYMM}.json.gz. Rotate logs monthly and automatically delete archives older than 90 days, exiting non-zero if inputs are invalid or any error occurs.",,
ec498504-2063-4160-9a4c-a3bb93e3ea13,Data Processing & Scripting,File System Operations,Metadata Extraction & Logging,"Implement an executable Bash script that recursively scans /data and extracts for each file its path, size, timestamps, permissions, owner, group, symlink target, POSIX ACLs and SELinux context, emitting deterministic JSON Lines at /output/metadata.jl. When run with --diff and --base=/output/metadata.jl it must compute added, removed, and changed metadata entries and write a CSV change log to /output/changes.csv.",,
9aeff1b1-c00a-4185-a5c0-6304c4cce037,Data Processing & Scripting,File System Operations,Metadata Extraction & Logging,"Create a CLI tool that recursively scans a specified directory to capture file metadata snapshots (size, permissions, timestamps, owner) and saves them as timestamped JSON files. On subsequent runs, the tool should compare the latest snapshot with the previous one to detect additions, deletions, and metadata changes, outputting a diff report in JSON and a human-readable log summary.",,
02b20d6f-6fc8-4437-aa82-daaa4f901c62,Data Processing & Scripting,Data Validation & Quality Assurance,Missing & Duplicate Detection,"Develop a Python script that reads newline-delimited JSON order logs from /data/input/, detects missing mandatory fields (order_id, customer_id, timestamp, items) and removes or flags invalid records. It must also identify duplicate orders by matching order_id or identical customer+timestamp+item hash within a 5-second window, then write cleaned JSONL to /data/output/clean_orders.jsonl and produce a /data/output/report.json summarizing counts and excluded IDs.",,
d13993a6-7d8a-4b69-ba0f-34dc910a20a7,Data Processing & Scripting,Data Cleaning & Transformation,Normalization & Standardization,"Create a script that processes a directory of mixed-format spreadsheet files (.csv, .tsv, .xls, .xlsx) containing inventory logs with inconsistent date columns, currency symbols, number formats and encodings. The tool must detect file encoding, normalize column headers to snake_case, convert all dates to ISO 8601 UTC, strip currency symbols and convert numeric fields to floats, unify missing values as null, and output a single newline-delimited JSON file plus a schema report summarizing original schemas and record counts.",,
e0650f37-e473-471d-a3c6-c3529e037766,Data Processing & Scripting,Data Cleaning & Transformation,Normalization & Standardization,"Create an executable Python script that reads /data/contacts.csv, parses and normalizes free-form phone numbers into E.164 format using a default country code, filters out invalid numbers, and writes /output/standardized_contacts.csv with the original data plus a phone_e164 column. Log each invalid or unparseable phone entry with row index and error reason to /output/invalid_phones.log.",,
0428d403-0576-4fcb-a557-803970047491,Data Processing & Scripting,Data Cleaning & Transformation,Outlier & Error Detection,"Create a CLI tool that analyzes multivariate time-series CSV sensor logs to detect anomalies using configurable methods (z-score, IQR, rolling MAD), generates a JSON anomaly report with details (sensor name, timestamp, value, method) sorted by severity, and optionally outputs a cleaned CSV with anomalies replaced via interpolation or forward-fill. The tool must handle timezone conversions, missing timestamps, support custom window sizes and thresholds, and emit summary statistics validating input integrity.",,
ee5c42be-0b16-4de0-b093-38e84917130b,Data Processing & Scripting,Data Cleaning & Transformation,Outlier & Error Detection,"Implement a Python CLI tool that ingests newline-delimited JSON log files, validates each record against a provided JSON schema, applies interquartile range (IQR) outlier detection on numeric fields, and flags timestamp gaps exceeding a configurable threshold. The tool should output cleaned records sorted by timestamp to cleaned.jsonl, anomalous or schema-invalid entries to anomalies.jsonl, and generate an anomalies_summary.json with counts and field-level breakdowns.",,
3e31a6d5-731e-4e39-9b51-d88954247446,Data Processing & Scripting,Text & Document Processing,Pattern Extraction & Regex Matching,"Create a Python CLI that reads a directory of text files and a patterns file with named regex (including multi-line rules), extracts each match along with file path, line numbers, and context into a JSONL stream, and produces a Markdown summary grouping hits by pattern name with counts and sample excerpts.",,
1049fdae-2aab-485e-b7bb-db0b6e95faff,Data Processing & Scripting,Text & Document Processing,Pattern Extraction & Regex Matching,"Implement a CLI tool that recursively scans a code tree for TODO and FIXME markers using regex, extracts file path, line number, tag type, and comment text, then outputs a deterministically sorted JSON report alongside a summary count per tag.",,
a8118477-ea53-4d4c-ba32-3e63fb06991c,Data Processing & Scripting,Text & Document Processing,Pattern Extraction & Regex Matching,"Develop a script that processes SubRip (.srt) subtitle files, using regex to extract and normalize timecodes (to milliseconds) and text cues, then merges any overlapping cues. It must output a cleaned .srt file preserving original sequence and produce a summary JSON detailing per-cue durations, overlap counts, average words per cue, and total unique word count.",,
fdba6dd9-417f-44b4-bdd2-9b5a5a082388,Data Processing & Scripting,Automation & Workflow Scripting,Pipeline Orchestration,"Develop a Makefile-driven pipeline that downloads historical weather CSVs from an FTP server for a list of configured stations, normalizes units and UTC timestamps, and merges them into a single Parquet dataset. Then run DuckDB CLI to compute daily temperature and precipitation aggregates, output JSON summary files and PNG charts, support idempotent execution with failure resume, config overrides, and emit a DOT-format DAG visualization.",,
8db9bc4e-cb68-40fa-8e5a-e2963ffeec4d,Data Processing & Scripting,Automation & Workflow Scripting,Pipeline Orchestration,"Create a Makefile-driven ETL pipeline that downloads remote weather station CSVs, invokes a Python script to normalize timestamps and convert all units to a common system, then runs gnuplot to generate hourly‐average charts and finally packages the normalized CSVs and charts into a versioned tar.gz archive. The pipeline must correctly manage file dependencies so that only changed inputs trigger the necessary rebuild steps.",,
c8aaf135-7a5d-4d00-9d56-a1d99ee4a962,Data Processing & Scripting,Automation & Workflow Scripting,Pipeline Orchestration,"Create a Makefile-driven pipeline with targets: 'fetch' to download CSV datasets into data/raw; 'validate' to run a Python CLI script that schema-checks the raw files; 'transform' to merge and clean them into data/processed; 'load' to import the processed CSV into a local SQLite database; and 'report' to generate Markdown and HTML summaries. Implement proper dependencies, phony targets, parallel execution support, and a 'clean' target to reset all generated artifacts.",,
42504526-304d-4e11-ab55-77b8d75d4f98,Data Processing & Scripting,Automation & Workflow Scripting,Pipeline Orchestration,"Create a Makefile that orchestrates a five-step data pipeline: download remote JSON files, run a Python script to clean and merge them, execute an aggregation module to compute summary metrics, generate a report with embedded charts, and package the outputs into a timestamped archive. Ensure correct dependency tracking, parallelizable downloads, a ‘make clean’ target to remove intermediates, and that ‘make all’ runs the full pipeline.",,
19317dc3-8ca9-4bc6-8ad4-d12e9512cc3f,Data Processing & Scripting,Automation & Workflow Scripting,Python/Perl/Ruby Scripting,"Create a Python CLI tool at /app/pipeline.py that monitors /app/incoming for new CSV and JSON files, validates and normalizes records against a provided JSON schema, ingests them into a SQLite database with on-the-fly schema migrations, and archives each file with a timestamped rename. It must generate a daily summary report CSV and an error log for all schema violations.",,
8d6f34c1-c974-40b7-96d2-4c98fc863b93,Data Processing & Scripting,Data Validation & Quality Assurance,Regression Testing for Data Outputs,"Develop a CLI tool that runs two versions of a time-series aggregation pipeline over log data to produce daily metrics, then automatically diff the JSON outputs with configurable numeric tolerances. The tool must detect schema changes, unexpected field additions/removals, metric drifts beyond thresholds, and emit a JUnit-style XML report summarizing pass/fail for each comparison.",,
82011837-29c5-4518-b6a6-9380ed1cade6,Data Processing & Scripting,Integration with External Systems,Remote Pipeline Execution,"Implement a Bash script that reads a JSON config of remote hosts, provisions a Python virtualenv on each via SSH, pulls the latest ETL repository, runs a daily export to produce CSVs, retrieves and merges them locally, and triggers a local database import with retry logic and error logging.",,
7b22e704-6c59-4454-8ed2-84768d02f39d,Data Processing & Scripting,Integration with External Systems,Remote Pipeline Execution,"Build a Bash CLI tool that reads a JSON inventory of remote hosts and a Docker image spec, SSHs into each host to pull and run the container with specified mounts and env vars, streams logs back in real-time, and aggregates exit codes, runtimes, and log checksums into a consolidated JSON report under /app/results.",,
cb375e65-03a3-4275-9931-3abddadd63df,Data Processing & Scripting,Integration with External Systems,Remote Pipeline Execution,"Develop a CLI tool that connects via SSH to multiple remote servers, deploys the latest ETL script, triggers its execution, streams and parses logs for predefined success/failure patterns, and upon completion retrieves the generated output files into /app/results. Generate a summary JSON with execution times, success statuses per host, and aggregated error counts.",,
072d1674-7ab2-4fac-a5f9-615ddf71461f,Data Processing & Scripting,Text & Document Processing,Report & Document Generation,"Create a command-line tool that scans a directory of Markdown notes with YAML front-matter (date, tags, authors), extracts metadata and titles, and generates a consolidated meeting_archive.md grouped chronologically by month. Also output a JSON index mapping each tag to its associated note file paths.",,
b6e7b812-cc95-4a97-855e-d5a4bb3ac697,Data Processing & Scripting,Data Sampling & Exploration,Sampling & Subsetting,"Create a script that reads a CSV of geotagged records, partitions the geographic bounding box into an N×N grid, and selects one sample per cell (random or nearest to center). Output the sampled CSV and a JSON summary of cell counts and assignments.",,
32476fd6-13dc-4c64-9f62-84bfdc0f384e,Data Processing & Scripting,Data Sampling & Exploration,Sampling & Subsetting,"Create an executable Python script that performs reservoir sampling on streaming CSV or JSON Lines data to produce a fixed-size random subset, with optional stratification by a user-specified column. The tool must support sampling with or without replacement, seed-controlled randomness, and emit a summary comparing sample vs population distributions for each strata.",,
cfd5d7a4-ba90-496b-bb1a-2664398c2a85,Data Processing & Scripting,Data Validation & Quality Assurance,Schema & Type Validation,"Implement a Python CLI at /app/validate_references.py that reads a YAML schema defining multiple CSV file structures (field types, regex or numeric constraints) and cross-file foreign-key relationships, recursively validates every row in /data against these rules, and writes a deterministic minified /output/errors.json summarizing field and referential-integrity violations, exiting non-zero if any errors occur.",,
8dfdb00e-3cc2-4c5d-8458-74b5e22df28e,Data Processing & Scripting,Data Validation & Quality Assurance,Schema & Type Validation,"Create a Python 3 script that reads a JSON schema defining CSV column names, data types (integer, float, ISO8601 date, regex patterns), optionality, and coercion rules, then processes /app/input/data.csv to auto-coerce safe conversions, flags uncoercible entries, and writes a cleaned CSV to /app/output/cleaned.csv plus an error_report.json with per-line validation issues.",,
dbd3a71e-d3ac-43b1-8df5-d22fec5fb013,Data Processing & Scripting,Data Validation & Quality Assurance,Schema & Type Validation,"Create a CLI tool that ingests a YAML-defined schema and a directory of mixed CSV/JSONL files, then validates each record against field types, enumerations, regex patterns, numeric ranges, and required/missingness rules. Produce per-file and global error reports, a TSV summary of violation counts, and optionally emit a corrected output stream for coercible type mismatches.",,
67c82738-1059-450c-b919-5f30469c9884,Data Processing & Scripting,Data Validation & Quality Assurance,Schema & Type Validation,"Implement an executable Python script validate_csv_schema.py that loads a YAML schema at /conf/schema.yaml defining expected CSV column names, data types (integer, float, string, date), optional regex patterns, and min/max constraints, then recursively scans /data for .csv files and validates each cell. The script must log detailed errors (file, row, column, issue) to /reports/errors.json and write a summary report /reports/summary.txt with totals for files scanned, rows processed, valid/invalid rows, and error counts per column.",,
bb682ee0-42c0-47cb-97d6-593c47d55587,Data Processing & Scripting,File Parsing & Format Conversion,Schema Inference & Validation,"Create an executable Python script infer_schema.py that reads all CSV files in /app/data, samples rows to detect column types (integer, number, boolean, date-time, string), requiredness, value ranges, patterns, and low‐cardinality enums, then writes a JSON Schema draft-07 to /app/inferred_schema.json. The script must then validate every row of each CSV against this schema, log violations with row/column details to /app/validation_errors.log, and exit non-zero on any errors.",,
8df47b9e-640a-40dc-b42b-ea6a96e619b1,Data Processing & Scripting,File Parsing & Format Conversion,Schema Inference & Validation,"Implement a Python CLI that scans a directory of mixed JSON, CSV, and YAML data samples to infer a consolidated JSON Schema capturing types, required fields, string patterns, numeric ranges, and enums, then writes it to schema.json. Next, validate all samples against this schema, emitting a report of violations with frequency counts per error type and an overall exit code indicating success or failure.",,
771d6a74-c5b7-4804-84d5-371434cd1705,Data Processing & Scripting,File Parsing & Format Conversion,Schema Inference & Validation,"Implement a Python CLI that scans a directory of mixed JSON and YAML documents, infers a unified JSON Schema capturing required vs optional fields, union types, enums, and nested structures, then validates every document against it. The tool must output the inferred schema as a draft-07 JSON Schema file and a detailed JSON report listing all schema violations with file paths and error details.",,
766c9805-0c3e-4417-b358-6812765f91f9,Data Processing & Scripting,Automation & Workflow Scripting,Shell Scripting & CLI Automation,"Create a portable Bash script that scans /app/logs for files older than 24 hours, archives them into date-based tar.gz bundles, uploads each bundle to an S3 bucket with aws-cli (including retry and backoff), and purges local logs and archives older than 30 days. The script must record its operations in a rotating log file and exit with non-zero on any transfer failures.",,
38a786e5-c932-412d-92c4-e1fd7aac8317,Data Processing & Scripting,Automation & Workflow Scripting,Shell Scripting & CLI Automation,"Create an executable Bash script /app/collect_and_archive_logs.sh that reads /conf/hosts.txt for remote hosts, SSHs them in parallel to compress and fetch Apache logs, then merges and sorts all logs by timestamp into /app/merged_logs/access.log. The script must rotate the merged log by date-stamped filenames and prune archive files older than 30 days.",,
a6012ffb-da21-46dc-968e-a07a3a27e11c,Data Processing & Scripting,Automation & Workflow Scripting,Task Scheduling & Cron Jobs,"Develop a Python CLI and cron setup: a job running every minute that reads a JSON list of URLs, measures HTTP response times, logs timestamped results, and sends email alerts on consecutive failures. Additionally, schedule a monthly log-rotation task that archives and compresses logs older than 30 days, purges archives beyond six months, and generates a rotation_summary.json.",,
a2b6368e-deda-45ad-a9ef-9820794e7b2f,Data Processing & Scripting,Automation & Workflow Scripting,Task Scheduling & Cron Jobs,"Design a cron-scheduled script that monitors a specified directory for new CSV files, validates and transforms incoming data (schema checks via csvkit, field normalization with awk, summary stats via jq), archives processed files into daily timestamped folders, and sends email alerts on failures. Ensure idempotent runs through lockfile or pidfile management, retry logic for transient errors, and generate a daily digest report at midnight.",,
f3d8c4cc-6f48-4cb7-a23a-8190dd926dd9,Data Processing & Scripting,Automation & Workflow Scripting,Task Scheduling & Cron Jobs,"Create a bash script scheduled via cron that compresses and rotates log files older than a retention period, uploads each archive to an AWS S3 bucket, verifies integrity by generating and comparing SHA-256 checksums recorded in a manifest, and prunes local archives past the configured retention window. The cron schedule, S3 credentials, bucket name, and retention settings must be configurable via an INI file, with any failures triggering an email alert.",,
5968d1d4-0e79-45a2-a9af-b34107ccfa12,Data Processing & Scripting,Text & Document Processing,Template Rendering & Macro Expansion,"Implement a Python CLI at /app/template_expander.py that scans a specified --templates-dir for Jinja2 templates, loads variables from a YAML config, renders each file using custom date and uppercase filters, and writes outputs to /app/output preserving relative paths. The tool must exit non-zero on undefined variables or syntax errors and emit warnings for any unused config keys.",,
95f149a6-fb56-45f2-84a6-10db8fc8b11f,Data Processing & Scripting,Text & Document Processing,Template Rendering & Macro Expansion,"Implement a Python CLI that recursively renders Markdown files using Liquid-style macros defined in a YAML context (including includes, loops, and conditionals), supports cached code-snippet injection, and outputs fully expanded Markdown preserving structure. Also generate a JSON dependency graph mapping templates, snippets, and variable usage, along with a report of undefined or unused variables.",,
280e5b60-b378-4b85-adc3-7e70f2a065e5,Data Processing & Scripting,Text & Document Processing,Template Rendering & Macro Expansion,"Implement a Rust CLI tool that processes a directory of text templates containing custom macros (@include, @define, @if, @each), supports nested includes and default values, and renders output files mirroring the input structure. It must also emit a JSON report of macro usage and undefined references and support a --check-only flag to detect missing definitions without writing files.",,
71659a9b-5540-4071-9629-57042ecb13ff,Data Processing & Scripting,Text & Document Processing,Template Rendering & Macro Expansion,"Create a Python CLI tool at /app/render.py that reads a context YAML or JSON file at /app/context.yml and processes every .j2 template in /app/templates using Jinja2 with two custom filters (slugify and tojson). The tool must preserve directory structure under /app/output, resolve nested includes, report any undefined variables as warnings, and emit a JSON manifest mapping each input template path to its output path and SHA256 checksum.",,
2ca0c211-e0e0-4f6b-9db0-998965fdcbb9,Data Processing & Scripting,File Parsing & Format Conversion,Text & Log Parsing,"Create a CLI tool that ingests gzipped Postfix maillog files, normalizes timestamps to UTC ISO8601, and extracts delivery failure events with recipient address, error code, and queue ID. It should aggregate hourly failure counts per recipient domain and top error codes, then output a summary JSON and a CSV report.",,
4399f143-11d9-4bd4-8ef0-02cc31d77cea,Data Processing & Scripting,File Parsing & Format Conversion,Text & Log Parsing,"Implement a Python CLI tool at /workspace/project/session_reporter.py that recursively reads all app.log and app.log.*.gz files in /workspace/logs, decompressing gzipped logs on the fly, extracts ISO8601 session start/end events to compute per-user session durations, and aggregates total, average, and maximum session times. The tool must output a sorted, deterministic JSON at /workspace/output/session_summary.json with no stdout on success and exit non-zero on any parsing error.",,
380357b3-5b32-47c7-8d0d-eb9e64e7e5c6,Data Processing & Scripting,File Parsing & Format Conversion,Text & Log Parsing,"Create a Python CLI that reads rotated and compressed web access logs in mixed formats (Common, Combined, JSONL), normalizes fields, groups entries into user sessions using HTTP cookies or IP+User-Agent with a 30-minute inactivity cutoff, and emits JSONL session objects alongside a summary CSV of session counts, durations, and request distributions.",,
604c36b0-5b97-4389-acfe-04f7f98c9a65,Data Processing & Scripting,File Parsing & Format Conversion,Text & Log Parsing,"Create a Python script that ingests BIND DNS query logs, normalizes timestamps to UTC ISO8601, extracts queried domain names and response codes, aggregates per-minute counts, identifies anomalous NXDOMAIN spikes via a configurable z-score threshold, and writes both a JSON time-series file and a CSV alert report.",,
a53b5348-671f-4f5e-9afb-d5000e7d1062,Data Processing & Scripting,Data Sampling & Exploration,Visualization & Reporting (CLI-based),"Implement a CLI tool that reads a CSV of timestamped events with numeric values, bins them into hourly or daily intervals per user flag, computes counts and aggregates, and renders an ASCII heatmap using intensity‐scaled block characters in the terminal. Also emit a Markdown summary table of overall statistics (total bins, peak interval, average per bin) and a mini textual histogram of value distribution.",,
205fd5c8-f8d9-482e-a7a7-16752f8ed368,Data Processing & Scripting,Data Sampling & Exploration,Visualization & Reporting (CLI-based),"Implement a CLI tool that reads a delimited dataset, computes box-plot statistics (min, Q1, median, Q3, max, outliers) for each numeric column, and renders side-by-side ASCII box plots with a summary table of counts, means, and outlier counts. Support optional ANSI color highlighting and a Markdown-formatted report with embedded visuals.",,
5b0a9d07-4585-44f7-8012-c8b6ea8e2623,Debugging & Troubleshooting,Code Debugging & Error Resolution,Interactive Debugger Usage,"Diagnose and fix a sporadic SIGSEGV in a multithreaded C ring-buffer logger by reproducing under load, attaching with gdb, and using thread-aware stepping and watchpoints on head/tail indices to find the out-of-bounds write. Patch the bug using proper atomics/locking and verify stability with a stress test.",,
1fc5a443-3d07-46d8-bab3-1ab080fd296e,Debugging & Troubleshooting,Code Debugging & Error Resolution,Interactive Debugger Usage,"Reproduce and debug an intermittent segmentation fault in a minimal C HTTP chunked-encoding parser by running it under gdb with a crafted malformed request, stepping through the state machine and inspecting buffer pointers to locate an out-of-bounds write. Implement the fix with proper bounds checks/index corrections, recompile, and verify the parser handles the input without crashing and produces correct output.",,
dbee79db-de69-489a-b369-1082438bcc36,Debugging & Troubleshooting,Code Debugging & Error Resolution,Interactive Debugger Usage,"Track down an intermittent segmentation fault in a multi-threaded C log processor by using gdb to reproduce, inspect per-thread backtraces, and set watchpoints on a shared ring buffer to catch the corrupting write. Fix the use-after-free in the consumer, rebuild, and verify stability under a provided parallel stress test.",,
dfff138f-928f-4707-b0c5-baba6cb4944b,Debugging & Troubleshooting,Code Debugging & Error Resolution,Interactive Debugger Usage,Use gdb to diagnose and fix a sporadic crash in a multithreaded C ring buffer that only fails under -O2 by setting thread-aware breakpoints and watchpoints to catch an out-of-bounds write caused by missing synchronization. Implement correct memory ordering or locking and verify stability by running the provided stress harness until it completes without errors.,,
8279b181-d525-440e-8b7b-6a93db868e59,Debugging & Troubleshooting,Code Debugging & Error Resolution,Logic & Algorithmic Bugs,"Fix a Rust CLI’s Dijkstra implementation that returns incorrect shortest-path distances on graphs with zero-weight and parallel edges due to premature visited-marking and missing decrease-key handling. Correct the relaxation and priority-queue logic, add regression tests, and verify outputs on provided fixtures.",,
6144e8da-1051-4a51-813e-4574fb5b8198,Debugging & Troubleshooting,Data & Pipeline Debugging,Automation & Cron Job Failures,"Investigate why a nightly cron job that runs /app/etl/run_pipeline.sh succeeds interactively but fails under cron due to missing virtualenv activation, PATH differences, non-UTF-8 locale, and a stale lock blocking retries. Make the job cron-safe by using absolute paths and a venv-aware shebang, exporting LANG/LC_ALL, adding flock-based locking, correcting permissions, and verifying execution/logging when triggered by cron.",,
92535062-5c95-45be-9a7c-a9cb23550926,Debugging & Troubleshooting,Data & Pipeline Debugging,I/O & File Handling Errors,"A log aggregation ETL that tails /var/log/app.log misses data after rotation and crashes on reading gzipped archives due to stale file handles and incorrect decompression. Diagnose and fix the pipeline to detect log rotation (reopen on inode change), read both .log and .log.*.gz with correct permissions, and emit a complete deduplicated JSONL to /app/out.jsonl for a target date.",,
a1c9e54d-879d-4bf6-b3e8-44d35260ebc4,Debugging & Troubleshooting,Data & Pipeline Debugging,I/O & File Handling Errors,"Debug a Python ETL that merges CSVs from input/ into a single Parquet but crashes with UnicodeDecodeError and FileNotFoundError because it assumes UTF-8 and only matches *.csv while some inputs are .csv.gz and Windows-1252 or UTF-8-BOM encoded. Implement robust file discovery and decoding (support .csv/.csv.gz, handle BOM and cp1252 fallback) and ensure the output writes to out/ with proper permissions, then rerun to pass row-count and schema checks.",,
5dd131f3-72b4-440c-ac59-2215fc087e64,Debugging & Troubleshooting,Data & Pipeline Debugging,Pipeline Stage Failures,"Diagnose and fix a Snakemake data pipeline where a mid-stage rule fails because its declared outputs don’t match the files written by the upstream step (gzip enabled, wrong suffix and temp directory), causing MissingOutputException. Align input/output patterns and compression flags, add any missing dependencies, and run the workflow end-to-end to produce /app/out/summary.csv.",,
e79205fc-86d4-428c-9d7c-39f5548199f9,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Build Configuration & Toolchain Issues,"Diagnose a CMake project whose shared plugin fails to link and cannot be loaded at runtime due to missing -fPIC objects and incorrect RPATH/SONAME. Update CMakeLists.txt to enable POSITION_INDEPENDENT_CODE, correct link order, and set a proper INSTALL_RPATH so the host executable can dlopen the plugin and pass the provided test.",,
75199510-2eca-43db-bbd6-ef6df695929c,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Build Configuration & Toolchain Issues,"Diagnose a CMake-based C++ project that fails to link on a clean environment due to missing transitive dependencies and non-PIC objects in a shared library. Fix CMakeLists.txt to use imported targets with correct PUBLIC/INTERFACE scopes and enable POSITION_INDEPENDENT_CODE, then rebuild and verify by running the provided demo binary.",,
10ad4763-204b-4555-a103-b2153aa5b68f,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Build Configuration & Toolchain Issues,"Diagnose and fix a CMake project that fails to build a shared plugin because a bundled static library is compiled without position-independent code, causing relocation errors at link time. Update the build to ensure all static libraries linked into shared targets are built with -fPIC (e.g., setting POSITION_INDEPENDENT_CODE and propagating flags) and verify the plugin builds and loads with a small test program.",,
32b8fda4-0489-4e27-a99d-8473e8cdf862,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Build Configuration & Toolchain Issues,Diagnose and repair a CMake-based C++ project that fails to link a shared library due to non-PIC static dependencies and whose test binary cannot locate the built .so at runtime. Modify CMake to build static libs with POSITION_INDEPENDENT_CODE and set correct RPATH/INSTALL_RPATH so the library links and the tests execute successfully.,,
7cc112ec-88b8-4558-bfd5-19eb3b4a14a8,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Build Configuration & Toolchain Issues,Fix a CMake-based C++ project that fails to build shared libraries due to missing -fPIC and unresolved OpenMP symbols when using Clang. Diagnose the errors and update the CMake configuration to enable position independent code and link the correct OpenMP runtime so the project compiles and tests run successfully.,,
f28007da-02aa-483f-8ef4-c6d8aadb5390,Debugging & Troubleshooting,Dependency & Build Troubleshooting,System Library & Path Errors,Diagnose a Python + GDAL/PROJ setup where importing osgeo.gdal fails with a libgdal.so load error or missing grid files because the shared libraries and data directories aren’t on the search path. Fix by correctly wiring PATH/LD_LIBRARY_PATH/PKG_CONFIG_PATH and GDAL_DATA/PROJ_LIB (or adding an rpath) and verify by importing GDAL and performing a coordinate transform.,,
d89fd597-6943-456b-a4c1-e34f7663f788,Debugging & Troubleshooting,Dependency & Build Troubleshooting,System Library & Path Errors,"Diagnose and repair a Pillow import failure caused by a missing or mislinked system libjpeg (e.g., 'libjpeg.so.X: cannot open shared object file'). Install or relink the correct library and rebuild or reinstall Pillow, then verify JPEG load/save works in a short script.",,
ebfed21f-c7ae-4475-a4d6-fc9b51af653d,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Version Incompatibility,"Diagnose a Node.js project that fails with a 'module was compiled against a different Node-API/ABI' error due to a mismatch between the installed Node version and native addon binaries (e.g., sharp/sqlite3). Align versions by switching Node via nvm/asdf or rebuilding addons, then verify the app runs a provided command successfully.",,
b8730aa5-c47e-49e9-86e7-f3dfd237606c,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Version Incompatibility,"Diagnose a Rust workspace that fails to build because the pinned dependencies require a newer Rust toolchain/edition than the installed rustc and cargo. Resolve by activating a compatible toolchain (e.g., via rustup or a directory override) or re-resolving to compatible crate versions, then build and run the tests successfully.",,
f5039b2a-a5d6-4f01-ac17-49f328843add,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Version Incompatibility,"Diagnose and fix a Node.js project that fails to start due to a native addon compiled for an incompatible Node-API/ABI (e.g., “Module version mismatch” or “Module did not self-register”). Align the Node.js/runtime version and rebuild the addons (or select a compatible prebuilt) so the program runs and the addon loads successfully.",,
e9c68fcd-8b20-435a-a16f-3f45bcfac29a,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Version Incompatibility,"Diagnose and fix a Rust project’s build failure where the openssl-sys crate is incompatible with the system OpenSSL version (e.g., libssl3 vs libssl1.1). Apply a minimal remedy (pin a compatible crate version, install matching OpenSSL dev headers, or enable the vendored feature), then rebuild and verify the binary performs a successful HTTPS request.",,
9272b4b1-9072-4f13-b2e6-483e64a339f2,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose and optimize poor TCP throughput between two local endpoints under simulated WAN latency by measuring with iperf3, inspecting kernel TCP settings, and identifying buffer/congestion-control bottlenecks. Apply sysctl/qdisc tuning (e.g., enable BBR, adjust rmem/wmem and net.core.{r,w}mem_max, set fq qdisc) and verify at least a 2× throughput improvement.",,
1d1219ba-bcd9-46e8-aa42-8f9338066ef6,Debugging & Troubleshooting,Environment & Configuration Debugging,Configuration File Parsing & Validation,"Diagnose and fix a CI pipeline failure caused by a YAML config that mixes tabs, YAML 1.1 booleans (on/off), merge keys/anchors, and unexpanded ${VAR} placeholders that the runner’s parser rejects. Normalize indentation, quote literals per YAML 1.2, inline merged sections, supply safe defaults for env placeholders, and verify with yamllint and a successful dry-run of the pipeline.",,
e3bb2cb7-bab2-4666-9447-65457a8f92ce,Debugging & Troubleshooting,Environment & Configuration Debugging,Cross-Platform Environment Differences,"Diagnose a Python CLI project that runs on macOS/Windows but fails on Linux due to case-mismatched imports and CRLF-terminated helper scripts causing /bin/sh^M errors. Make it Linux-portable by correcting import/module casing and normalizing line endings and path handling, then verify the CLI executes successfully end-to-end.",,
c0b5e3a4-f4c6-4498-baec-eb30e3e4c935,Debugging & Troubleshooting,Environment & Configuration Debugging,Cross-Platform Environment Differences,"Diagnose a Python CLI that crashes with UnicodeEncodeError on Linux but works on macOS due to running under the C/POSIX locale. Generate and set a UTF-8 locale in the container (e.g., en_US.UTF-8), update startup config to export LANG/LC_ALL, and verify it correctly processes non-ASCII filenames.",,
92885c23-fc50-41e2-9110-a9004eb38e0e,Debugging & Troubleshooting,Environment & Configuration Debugging,Cross-Platform Environment Differences,"Diagnose why project entrypoint scripts run on Windows/macOS but fail in Linux containers with errors like '/usr/bin/env: python\r: No such file or directory' or 'Permission denied'. Normalize line endings to LF, fix shebangs, set executable bits, and add .gitattributes rules to enforce cross-platform-safe endings, then verify the scripts execute successfully.",,
a810f634-cff5-4115-913b-6838096aafa9,Debugging & Troubleshooting,Environment & Configuration Debugging,Cross-Platform Environment Differences,"Investigate a Python CLI project that works on Windows but fails on Linux with a python^M shebang error and a ModuleNotFoundError from a case-mismatched import. Fix by converting CRLF to LF, correcting import/file casing, and adding .gitattributes rules to enforce LF line endings and case-consistent paths.",,
df505d7f-a198-4a02-91a5-f1a207a3e530,Debugging & Troubleshooting,Environment & Configuration Debugging,Environment Variable Misconfiguration,A local API test suite times out because HTTP_PROXY/HTTPS_PROXY force localhost traffic through an external proxy and NO_PROXY is misconfigured. Diagnose and fix the proxy-related environment variables (including IPv4/IPv6 loopbacks and custom ports) so requests reach the local service and the test script completes successfully.,,
9a4a1ae7-2b78-45a6-80b7-e0556695cc57,Debugging & Troubleshooting,Environment & Configuration Debugging,Environment Variable Misconfiguration,Diagnose and fix a CLI application’s UnicodeDecodeError caused by running under the POSIX C locale with LANG/LC_* unset or misconfigured. Configure and activate a UTF-8 locale and appropriate environment variables so the program can read and print UTF-8 (including emojis) without errors.,,
89a4dc01-5bd4-40ae-900f-c8acdee350a7,Debugging & Troubleshooting,Environment & Configuration Debugging,Environment Variable Misconfiguration,"Diagnose and fix a CLI tool that crashes on Unicode filenames due to a non-UTF-8 locale by correctly configuring LANG/LC_ALL and generating the required UTF-8 locale in the container. Persist the fix for both interactive and non-interactive shells, then verify the tool processes files with accented characters without errors.",,
8e2daee5-6622-45b0-b6c7-7b8da8af504c,Debugging & Troubleshooting,Environment & Configuration Debugging,Environment Variable Misconfiguration,"Diagnose why both curl and a Python requests client fail HTTPS verification against a provided local TLS service, tracing it to a missing CA trust path. Configure SSL_CERT_FILE or SSL_CERT_DIR to point at the bundled CA bundle so both tools succeed, and verify by performing a successful GET request.",,
0f51d8ba-8394-4306-a849-f556639e1cc2,Debugging & Troubleshooting,Environment & Configuration Debugging,Virtual Environment & Container Issues,"Diagnose and fix a relocated Python virtual environment whose scripts and sys.path still reference an old absolute interpreter path, causing entry points and imports to fail. Recreate or patch the venv so it binds to the container’s Python and current path, then verify by activating it and successfully running the project’s console script and an import/version check.",,
89d944d6-f7e1-496e-a6cb-f194102eb08c,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Diagnose why a Python CLI using requests gets 401 and 415 from a local OAuth2-protected REST API: the token exchange is incorrectly sent as JSON instead of application/x-www-form-urlencoded and subsequent requests pass the token as a query param instead of Authorization: Bearer. Fix the payload encoding and header usage, then verify by successfully calling a paginated endpoint while honoring Retry-After to avoid 429s.",,
e92097fc-225d-45d8-b080-9d22fd45c678,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Diagnose why a provided CLI client receives 401 'signature mismatch' from a mock HMAC-signed REST API by auditing canonicalization (query param order, header inclusion, body hashing) and timestamp/nonce handling. Correct the signing logic and required headers so POST /v1/payments returns 201, then verify by GETting the created resource and writing its id to /app/payment_id.txt.",,
43914bc3-52d4-4152-a7c2-9e87c25a7bcc,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Diagnose and fix slow HTTP requests caused by the system preferring IPv6 (AAAA) addresses that are unroutable, leading to connection timeouts before IPv4 fallback. Reconfigure address selection, routing, or resolver settings so connections to a dual-stack host complete quickly without timeouts.",,
d02fda27-8f45-4e99-b67a-7ad4181f80a4,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Diagnose why outgoing HTTP requests from a CLI client to a local/internal API consistently time out due to misconfigured proxy environment variables (HTTP_PROXY/HTTPS_PROXY/NO_PROXY) that route localhost/intranet traffic through a dead proxy. Correct the environment and client/server settings so direct connections to 127.0.0.1 and internal hostnames bypass the proxy and succeed, verifying with curl and a simple script.",,
937af724-367b-47e9-a504-532fefa26f4a,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Investigate persistent timeouts when a local microservice calls an internal API and discover they are caused by inherited HTTP(S)_PROXY environment variables pointing to a dead proxy. Reconfigure NO_PROXY or unset the proxy so direct connections succeed, and verify with curl and a test run.",,
610418d5-8908-4e84-b717-02030e0b6cd7,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Investigate why a client app’s HTTP requests to an internal service stall before timing out: the hostname resolves to IPv6 while the server only binds on IPv4. Fix the mismatch (e.g., enable dual-stack binding or force IPv4 resolution) and verify low-latency success with the provided test script.",,
2bc44715-4107-4e3b-b98e-5af3df0f1807,Debugging & Troubleshooting,Network & Service Debugging,"Proxy, SSL & Certificate Errors","Fix a broken mutual TLS setup on an Nginx reverse proxy fronting a local API: clients see handshake failures and 'unknown ca' errors due to an incomplete server certificate chain and verification against the wrong client CA. Rebuild and reference the correct fullchain, configure nginx to trust the proper client CA, issue a client certificate/key, reload, and verify curl with the client cert succeeds while requests without it are rejected.",,
d17e09b3-cb78-4370-95b2-fa028e0e4408,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,"Diagnose a Nginx→Gunicorn→Flask stack that never passes its health check because Nginx proxies to a nonexistent unix socket, Gunicorn is listening on TCP port 8001, and the /health endpoint hard-depends on a missing database. Reconfigure the upstream to the correct port and make the health route shallow so the service reports healthy and curl to /health returns 200.",,
3069f428-49d1-43f1-b475-88a798f49ce7,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,Diagnose an Nginx-proxied FastAPI service whose /health endpoint returns intermittent 502s due to IPv6/IPv4 mismatch (upstream resolving to ::1 while the app binds only to 127.0.0.1). Adjust the app bind address or Nginx upstream to ensure consistent HTTP 200 health checks across restarts.,,
09560491-b8d1-4d16-8008-e5d4c88f66f0,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,"Diagnose and fix a misconfigured reverse proxy that causes a healthy backend service to fail its /healthz check (e.g., wrong upstream port, missing Host/X-Forwarded headers, or TLS-to-HTTP mismatch). Correct the proxy and service configs and reload them so curl http://localhost/healthz returns 200 with the expected body.",,
c0c13fda-fd2f-4c16-8b5a-dfd10f274e0f,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a C log-parsing utility that becomes slow and runs out of memory on a large dataset due to quadratic string concatenation and leaked allocations. Use Valgrind (memcheck/massif) or perf/callgrind to pinpoint hotspots, refactor to buffered/streamed processing and proper frees, and verify identical output with markedly lower peak RSS and faster runtime.",,
ec4fd0c2-c956-4e65-8813-43d6b8cbd2ee,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a Go HTTP log aggregator that shows steadily rising memory usage and high CPU under sustained load using pprof (heap and CPU profiles) to uncover a goroutine leak and an O(n^2) JSON concatenation hotspot. Implement fixes (proper context cancellation, bounded channels, and bytes.Buffer-based assembly) and verify with the provided load test that throughput improves and peak RSS remains bounded.",,
10d169bd-c0bd-475b-8541-027a954e43dc,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a Python CSV-to-JSON pipeline that pegs a CPU core and steadily increases RSS on large inputs. Use cProfile and tracemalloc to locate an O(n^2) dedup step and an unbounded cache, refactor to a streaming/chunked approach with bounded caching, and verify at least 2× speedup and <200 MB peak memory on a 1M-row dataset.",,
dcaa6c21-9f0f-445e-a338-defbe106a3a7,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a mixed Python+C log-processing tool to locate CPU hotspots and memory bloat using cProfile, perf, and Valgrind (memcheck/massif). Eliminate an O(n^2) Python loop and fix a C-side leak so the job completes ≥2x faster with ≥50% lower peak RSS while preserving identical output.",,
5a95189c-f5e7-4de6-bfe1-a370d9da209e,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose a C-based log aggregator that is extremely slow due to 1-byte read() calls and an fsync/flush on every line. Refactor it to use buffered streaming and batched writes (e.g., setvbuf/FILE* or coalesced writev) and verify /app/bench.sh runs at least 5x faster without changing output.",,
2a3ae5e0-48c7-4ded-a4da-24f8f26025e0,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose a Python SQLite ingestion script that is painfully slow due to per-row transactions causing fsync storms and page cache thrashing. Use strace/iostat to confirm the I/O bottleneck, then optimize by batching transactions and enabling WAL with appropriate PRAGMAs to achieve >5× speedup while preserving identical database contents.",,
5965df14-24fe-4901-a1c7-f1fda9612fe6,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose a Python log-processing CLI that is extremely slow because it writes output one line at a time with fsync after each write and a tiny buffer. Rework it to batch and buffer writes and use atomic rename on completion, remove unnecessary fsyncs, and verify at least a 5x speedup on the provided dataset with byte-for-byte identical output.",,
7e3ecd21-2e81-4a59-884f-856e05fbcd8e,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose and fix a severe disk I/O bottleneck in a Python-based SQLite bulk loader that inserts rows individually (autocommit on), triggering per-row fsyncs and tiny writes. Optimize by batching transactions and enabling WAL with appropriate PRAGMAs (e.g., synchronous=NORMAL, page/cache tuning) to achieve a measurable speedup while preserving identical dataset contents.",,
7a70dec1-597a-4059-b7d0-d7f367d836d2,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose why a Python log-processor that splits records per user is extremely slow due to per-line open/flush/close and tiny writes causing fsync storms. Use strace/iostat to pinpoint the issue, then refactor to maintain buffered file handles and batch writes, verifying identical output and improved runtime.",,
a9221318-48d3-484d-ad08-1bc430c35b4e,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose a severe throughput collapse and sporadic stalls across a VXLAN tunnel caused by an MTU black hole (broken PMTUD), using ping with DF and tcpdump to determine the effective path MTU. Apply a fix by setting appropriate interface MTUs and TCP MSS clamping so iperf3 throughput improves at least 3x without packet loss, and write the discovered MTU/MSS to /app/mtu_report.txt.",,
11c20a91-4167-4cf8-8e03-228dc784976b,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose and fix severely limited throughput between two containers on a high-RTT simulated link by identifying TCP window/buffer and congestion-control misconfiguration. Measure with iperf3 and ss/tcpdump, then tune sysctl (enable window scaling, raise rmem/wmem and tcp_rmem/tcp_wmem, switch to BBR with fq, adjust MTU/MSS if needed) and verify higher goodput with fewer retransmits.",,
0552b1b6-e643-4fa2-a674-feb1a34f080b,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose and optimize a gRPC microservice’s network stack under a simulated 80 ms RTT and 1% packet loss to cut p99 latency by at least 50% without reducing throughput. Apply and verify kernel- and app-level tuning (e.g., congestion control/qdisc, HTTP/2 flow-control windows, TCP keepalive/Nagle, MTU/MSS) using the provided load generator and report.",,
feaad0c2-33fc-4a13-ae26-357bf213a8e9,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose why a Python asyncio TCP client/server for log shipping achieves poor throughput and high p99 latency due to tiny writes triggering Nagle/delayed-ACK interactions and lack of connection reuse. Tune by enabling TCP_NODELAY, batching into 64KB frames, increasing socket buffers and enabling keep-alive/pooling, then verify a 5–10× throughput gain and sub-20ms p99 with the provided load generator.",,
ef3a32bc-f6d6-450c-a6dc-e665d6ec55cf,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose a deadlock and throughput collapse in a Rust Tokio-based pipeline where a Mutex is held across await points and a bounded mpsc channel backpressures a blocking file writer. Refactor to avoid cross-await locks and move blocking I/O to spawn_blocking or a dedicated thread pool, then verify no hangs under a provided stress script and achieve at least 3× higher throughput.",,
ac0d3063-c9d0-431f-b508-63cb4ca3ceab,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose and fix a deadlock and goroutine leak in a Go fan-out/fan-in worker pool where misordered channel closes and blocking sends during cancellation stall the pipeline under load. Correct the synchronization (context propagation, channel buffering, and close/drain order) so the provided stress test finishes under the time limit and go test -race shows no leaks or races.",,
7ba28845-6bdc-475f-923c-2de6a8617864,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose and fix a deadlock in a Go-based concurrent log processor where workers hold a mutex while sending to a results channel, creating a circular wait with the aggregator that acquires the same lock. Refactor to avoid holding locks across channel operations (e.g., copy before send or introduce a dispatcher) and verify under a stress harness that prior hangs disappear and throughput improves.",,
a98b0755-c848-4504-9e5b-11874ad053f6,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose and fix an intermittent deadlock in a Rust Tokio service caused by holding a std::sync::Mutex across await points and doing blocking file I/O inside async tasks, leading to hangs under load. Refactor to use tokio::sync::Mutex/RwLock and spawn_blocking for I/O, add cancellation timeouts, and verify via a stress script, cargo test, and tokio-console traces.",,
7f67ecba-ac23-4415-b4f2-ab07d0300adc,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Diagnose why a Node.js project’s native addon (e.g., sharp or grpc) fails to load with errors like GLIBC_x.y not found or wrong ELF class inside the container. Audit Node ABI vs compiled binaries and system libc/libstdc++ versions, rebuild or pin a compatible binary with node-gyp and verify the addon loads in a minimal script.",,
03ddad07-9c29-4945-9c02-1209f9711978,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Diagnose why the prebuilt /app/server web binary exits on launch with “No such file or directory” and fix it by auditing dynamic library dependencies and environment drift (e.g., missing libsqlite3 due to CGO). Install or rebuild with the correct dependencies (or static linking), verify the /health endpoint responds, and write a brief postmortem to /app/POSTMORTEM.md.",,
cfa13688-5d5b-4feb-9dab-bbf7eb89ccb6,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Investigate a prebuilt C++ CLI tool that fails at startup with a “GLIBCXX_x.y not found” error inside the container. Identify the ABI mismatch between the binary and the system libstdc++/glibc, remediate by aligning runtime libraries or rebuilding, and verify the tool runs successfully end-to-end.",,
3a93c960-ec0b-45ae-8c66-b6bce2e25d34,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Investigate why importing a pip-installed C++ extension (e.g., scikit-learn) now fails with GLIBCXX/CXXABI symbol errors after a base image or compiler runtime change by auditing the system’s libstdc++/libgcc versus the wheel’s required ABI. Resolve by aligning the C++ runtime or installing compatible wheels/pins, then verify with a minimal script that imports and exercises the package.",,
7be70182-c38c-48a3-96f1-4e1067274b79,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"Diagnose an intermittent segfault in a C utility that only occurs when compiled with -O2. Reproduce by varying compiler flags and inputs, then reduce the program to a minimal C file that crashes reliably and reveals the underlying undefined behavior.",,
eeca33de-dffe-4e25-8319-9c89e7e42de9,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"Reproduce a flaky 'Address already in use' failure by isolating the smallest script that deterministically triggers a TCP port reuse race (TIME_WAIT) during rapid server restarts. Build a tiny server/client and use only standard OS tools to narrow the failure to missing socket cleanup/options, yielding a minimal reproducible case.",,
6257cbed-5d4c-42ba-81cf-5f90372554c6,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"Reproduce an intermittent deadlock in a Go HTTP server that occurs only under specific GOMAXPROCS values and concurrent request patterns, then isolate a minimal single-file program and deterministic request sequence that triggers it. Capture the exact environment and commands used (race detector, pprof blocking profile, goroutine dumps) to demonstrate the deadlock reliably.",,
4b9fc436-581f-48b2-a630-944410a1c053,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,Reproduce an intermittent timestamp parsing failure that occurs only during daylight-saving transitions by controlling TZ and the system clock inside the sandbox. Isolate the minimal failing input and code path by iterating across DST boundary timestamps and documenting the exact timezone/offset combination that triggers the error.,,
d766a87a-85eb-4397-a212-3185aaf6fa8c,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"Reproduce and isolate a CLI tool crash that emits 'Broken pipe' or exits non-zero when its stdout is piped to head/grep -m1, identifying the minimal code path that triggers SIGPIPE/EPIPE under controlled conditions. Implement graceful handling so the pipeline exits cleanly without stack traces or spurious errors.",,
73368045-611d-48c8-a63c-9e36b360bb4d,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Investigate a production failure where package installs and writes error with 'No space left on device' despite ample free disk space, trace the root cause to inode exhaustion from a runaway temp/log file generator, and validate via df -i and remediation. Produce a concise postmortem detailing impact, timeline, contributing factors, and preventive measures such as file-count monitoring, log rotation policies, tmp cleanup jobs, and quotas.",,
5765ffec-9b64-4ecf-8bc8-2da658548495,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Investigate an incident where API requests intermittently returned 401 due to container clock drift causing JWT nbf/exp validation failures around a DST transition. Reconstruct the timeline from logs and metrics, identify the root cause, and produce a postmortem summarizing impact, detection, and preventive measures (time synchronization, validation leeway, targeted monitoring/alerts).",,
237d4275-fc9c-48da-9af8-0c1782267e94,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Investigate intermittent authentication failures (401/403) traced to JWT validation errors caused by container clock drift and misconfigured timezone/time sync. Write a postmortem detailing timeline, root cause, impact, detection gaps, and concrete preventive measures (time synchronization policy, startup time sanity checks, monitoring/alerts, and validation tolerances).",,
68893eaf-4de5-4cfb-998e-1f0544eef49b,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Investigate why a nightly data export executed twice and produced corrupted partial uploads by reconstructing the timeline from cron logs, application logs, and a stale PID lock during a DST transition. Write a postmortem detailing root cause, impact scope, contributing factors, and preventive measures (timezone policy, idempotent runs, and robust lock hygiene).",,
595e978f-b1e3-4d3b-8adc-6a4865b1d5d9,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,"Diagnose a Java service hang by capturing and analyzing multiple jstack thread dumps to trace a lock-order inversion deadlock (each thread waiting on the other’s monitor) and identify the exact code paths involved. Implement a fix by enforcing a consistent lock acquisition order or using tryLock with timeouts, rebuild, and verify the service remains responsive under concurrent load.",,
c87ad7c9-2d5a-45c4-bd5e-99d3d9d5498c,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,"Investigate a Python ProcessPool-based task that fails with BrokenProcessPool by reading the exception chain and worker stack traces to find the underlying pickling error caused by a nested/local function. Refactor the callable to be picklable (e.g., move to module scope) and verify the parallel job completes successfully.",,
c0eb882b-94ba-410a-8052-937bf756c5dd,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,Investigate an intermittently crashing Go HTTP service by analyzing its panic log and full goroutine dump to trace the execution path to a 'concurrent map writes' failure and pinpoint the offending map and call sites. Implement a minimal synchronization fix and a stress test that runs with -race to verify the panic no longer occurs.,,
e1ec2f70-7562-452b-8c6e-086af7187282,Debugging & Troubleshooting,Security & Access Debugging,Access Policy & Role Misconfiguration,Diagnose and correct a MinIO S3 setup where a data-ingest user cannot list or upload objects due to conflicting bucket and user policies. Apply the least-privilege fix by adjusting the bucket and user policies so that aws s3 ls and multipart uploads succeed only within the intended bucket/prefix.,,
87e31f70-0cfb-4d78-9ff2-1bbe6d9c8498,Debugging & Troubleshooting,Security & Access Debugging,Access Policy & Role Misconfiguration,"Diagnose and fix a Redis ACL misconfiguration that blocks a non-default user from executing required commands (e.g., SET/GET) on a specific key prefix used by a sample app. Update the ACLs to grant least-privilege access for that user and verify the app completes successfully end-to-end.",,
a6fb3357-f867-46b0-a331-2ec5e02eb79a,Debugging & Troubleshooting,Security & Access Debugging,Access Policy & Role Misconfiguration,"Diagnose why a data-ingestion script receives 403 AccessDenied when uploading to an S3-compatible MinIO bucket due to a mismatched bucket policy and user credentials. Correct the bucket and user policies to grant least-privilege PutObject/ListBucket on the intended prefix, update the client configuration, and verify the script completes successfully with upload and listing.",,
867223f1-dafd-4286-8033-36eab5a1bd03,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,"Debug an AWS CLI profile that intermittently fails to access an S3 bucket via SSO + AssumeRole (AccessDenied and ExpiredToken errors). Refresh the SSO cache, correct the profile’s role_arn/region, and ensure the role has s3:ListBucket/s3:GetObject/s3:PutObject permissions; verify by listing the bucket and uploading a test object.",,
24d44981-13e8-4969-b7e5-e812153b1e96,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,"Diagnose and fix a local PostgreSQL login failure for user 'app' where URI-based connections are rejected due to pg_hba.conf rule order, SCRAM-vs-MD5 password mismatch, and missing LOGIN/CONNECT privileges. Correct the configuration and role settings, reload PostgreSQL, and verify with psql postgresql://app:app@localhost:5432/appdb -c SELECT 1.",,
646ab4bf-63df-40e8-a278-01982c4dd463,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,"Diagnose and repair a local PostgreSQL connection that fails with pg_hba.conf rejection and mismatched password method (SCRAM vs md5), preventing a bundled Python app from logging in. Update pg_hba.conf, recreate the user with the correct authentication scheme and role grants, reload Postgres, and verify a psycopg2 script can perform read/write queries.",,
ce16cf7e-8f6a-403c-948c-0dd4a68e35dd,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,Diagnose and resolve npm 401 Unauthorized errors when installing from a local Verdaccio registry by pinpointing bad/expired credentials or scope misconfiguration in ~/.npmrc and registry ACLs. Reauthenticate or correct token scopes/registry settings so installing a private package succeeds from the terminal.,,
1beb0ff4-5739-4ed0-81bb-f94786734a5c,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"Diagnose a bootstrap script that fails to fetch secrets from a local HashiCorp Vault due to a stale VAULT_TOKEN, missing VAULT_NAMESPACE, and incorrect CA settings. Implement AppRole login using role_id/secret_id files, set VAULT_ADDR/VAULT_CACERT/VAULT_NAMESPACE correctly, and update the script so non-interactive secret retrieval and app startup succeed.",,
c8dbf6ca-00b2-4769-92b2-e4ba0d94ab09,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"Diagnose and fix a CI/container build that fails to fetch private npm packages and Git submodules due to mismanaged tokens (missing/misnamed env vars, malformed .npmrc, and SSH key permission issues). Repair the credential chain and config so npm install and git submodule update complete non-interactively.",,
4ed834c9-9cf8-42e4-a8ea-90751111bed8,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"Diagnose and repair a failing S3 backup in a local MinIO sandbox caused by mismanaged AWS credentials and environment (incorrect AWS_ACCESS_KEY_ID/SECRET, missing region, wrong endpoint URL, and a conflicting default profile). Reconfigure environment variables and ~/.aws files so both aws CLI and a boto3 script can authenticate and list the target bucket without hardcoding secrets.",,
d741b44e-0beb-490c-af33-5291056f25a3,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"Diagnose why sops cannot decrypt secrets.enc.yaml in the container because the AGE private key is provided as a base64, single-line environment variable that is never materialized as a key file. Reconstruct the PEM from the env var, set SOPS_AGE_KEY_FILE with correct permissions, and verify decryption by producing /app/secrets.yaml.",,
272f50a7-ddea-4c75-aa20-494817c60257,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"A reverse proxy cannot connect to its backend via a Unix domain socket at /run/app.sock due to permission denied on the socket path. Diagnose and correct directory/socket ownership, mode bits, and group/ACL settings so the proxy user can connect, then verify a 200 OK from curl localhost.",,
e00a901d-2733-46cc-a84a-13fcf0e80382,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose and fix a Unix domain socket connection failing with 'Permission denied' by auditing the socket file and its parent directory ownership/modes and the creator’s umask. Implement a least-privilege solution (e.g., dedicated group, setgid directory, corrected socket permissions), then verify the client can connect and exchange data successfully.",,
d3fd7160-608b-4486-a7d4-f9c8499ae4b9,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose and fix a reverse proxy failing with 502 because nginx cannot access a backend UNIX domain socket (EACCES) due to incorrect ownership/permissions on the socket and its parent directories. Adjust ownership, mode, and directory execute bits or set ACLs, then make the fix persistent by updating the systemd .socket/.service or tmpfiles.d configuration, and verify that curl via nginx returns 200.",,
48151bba-a57f-4381-a82b-18e12a9fd1a5,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,Diagnose why a client fails to connect to a local service over a Unix domain socket (/run/app/app.sock) with EACCES and fix the underlying directory and socket ownership/permission and group-membership issues. Verify the repair by enabling the non-root client to connect end-to-end using the provided health-check script.,,
a3292310-b1a9-4dd6-923f-cafe4b2acf44,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose why a client receives 'Permission denied' when connecting to a Unix domain socket at /app/run/metrics.sock: the socket’s parent directory lacks execute permission for the client’s group and the daemon’s umask creates overly restrictive socket permissions. Implement a least-privilege fix by adjusting directory ownership/modes and the daemon’s umask or group, then verify bidirectional communication over the socket.",,
b5ce9afb-2425-4316-8588-b45a6970a803,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose a systemd socket-activated service that never starts on client connect due to mismatched unit names, incorrect ListenStream/ListenUnix path, and restrictive socket directory permissions. Correct the .socket/.service units (naming, ExecStart, WorkingDirectory, User), reload and enable socket activation, and verify the daemon spawns on demand and successfully serves a test request.",,
cb5e00ce-f061-472d-b7b5-1e540c6f5c5f,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Investigate a failing systemd timer + service that should create periodic backups but exits immediately under systemd while the same script runs fine interactively. Diagnose and fix unit misconfigurations (absolute ExecStart, WorkingDirectory, EnvironmentFile, and executable permissions), reload the daemon, and verify the timer produces a backup in /app/backups.",,
8a5d9d20-4d99-4af1-ab68-83aa9ef95085,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Investigate a systemd-managed Celery worker that immediately enters a restart loop because it launches before its Redis backend and points to a non-existent virtualenv, producing empty or truncated logs. Repair the unit by correcting ExecStart/WorkingDirectory/Environment, adding Requires= and After= redis-server.service, and verifying the service stays active and processes a sample task.",,
44f6f3f4-98ca-4100-ad4a-c65fd7d28465,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Investigate a systemd-managed daemon that immediately enters a restart loop because unit hardening (DynamicUser with ProtectSystem=full) prevents creation of its PID/log/state files. Use journalctl and unit inspection to diagnose and then update the unit to provision writable runtime/state paths (e.g., RuntimeDirectory/StateDirectory or ReadWritePaths) so the service starts and stays active, verified by a heartbeat file appearing.",,
055b25b7-9b24-4b05-8344-e9f859a14a1d,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Investigate why a systemd timer’s backup.service succeeds when started manually but fails when triggered by the timer due to environment/working-directory differences and reliance on relative paths. Update the unit(s) to use absolute ExecStart, set WorkingDirectory and Environment (PATH/HOME), add logging, then verify the timer fires and completes successfully.",,
9a5986c7-0631-41f8-b9f9-932e5685344a,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Correlate a recurring 2–3 minute outage by analyzing nginx access/error logs, systemd-journal logs, and cron logs while compensating for a deliberate 5‑minute clock skew between components. Identify that a misconfigured logrotate postrotate script intermittently sends SIGSTOP to the web app and apply a minimal fix so the outage ceases.",,
2ee3d744-e373-437a-bdaf-382455c3b965,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Diagnose intermittent restarts of a systemd-managed service by analyzing journalctl and kernel logs to detect OOM-killer and memory pressure events time-correlated with the service’s crashes. Implement a mitigation (e.g., adjust MemoryMax or service configuration) and verify stable operation with no recurring log anomalies.",,
fef1f0e3-ace8-4f90-b117-b5dc35325496,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Investigate intermittent TLS handshake failures by scanning journalctl/syslog and application logs for anomalies like “certificate not yet valid” alongside abrupt timestamp jumps, correlating them with NTP desynchronization events. Restore correct time sync (e.g., via systemd-timesyncd or chrony) and verify by re-running a TLS client to confirm error-free handshakes and aligned log timestamps.",,
4cb4368f-febd-4b0a-8edd-3283dd8db8b5,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Scan syslog, auth.log, and NTP logs (including rotated .gz) to detect a surge in authentication errors and correlate it with a significant NTP time step, pinpointing the drift magnitude and window. Output a concise timeline report naming the triggering event and the impacted services (e.g., sshd, sudo) where errors align with the clock change.",,
f9699ffe-3309-4f74-b2af-98bee57407e4,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"A Node.js script using the sharp image library crashes with SIGSEGV; enable core dumps and use coredumpctl + gdb (with addr2line) to analyze the core and trace the fault into libvips due to an ABI/version mismatch. Repair by installing compatible libvips/sharp binaries or rebuilding the module, then verify an image resize completes without crashing.",,
5a61e76e-ffef-4de4-9c18-74f959da53a3,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Analyze a core dump from a Rust CLI that intermittently SIGSEGVs during FFI calls into a C library. Use gdb and addr2line to pinpoint a dangling pointer/use-after-free across the FFI boundary, patch the Rust/C bindings to fix ownership and lifetimes, rebuild, and verify the crash no longer occurs under the stress script.",,
d4ed029c-1962-401a-a7a4-8e50767ccaf3,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Diagnose why /app/bin/ingest crashes with SIGSEGV and leaves /app/core by using gdb to obtain a fully symbolicated backtrace (installing debug symbols if needed) and tracing the fault to a NULL function pointer returned by dlsym due to a missing plugin symbol. Repair the runtime environment (e.g., install the correct .so or adjust LD_LIBRARY_PATH) or patch the loader to handle NULL safely, and verify the program runs to completion without crashing.",,
0f1f8d48-3f4e-4462-b792-7aa1f573f67c,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Investigate a Node.js service that segfaults when requiring a native addon, analyzing the generated core dump with gdb to pinpoint an ABI/version mismatch between Node and the .node binary. Rebuild the addon for the correct Node-API/ABI (e.g., via node-gyp or prebuilds), replace the artifact, and verify the service runs and responds to a simple request without crashing.",,
2cbc448e-d36f-4232-bc28-2026808e3dbb,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Reproduce and analyze a core dump from a multithreaded C service that intermittently segfaults on SIGTERM due to a reentrant, non-async-signal-safe signal handler freeing shared memory twice. Enable core dumps, use gdb to pinpoint the crashing thread and double-free path, refactor the handler to defer work via a self-pipe and enforce single-ownership, rebuild, and verify stability under a stress harness.",,
c152c71e-49b6-42c3-886a-d0982177d5d0,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose a backup job that aborts with ""No space left on device"" even though df shows ample free space, uncovering inode exhaustion from millions of stale temp/log files. Mitigate by reclaiming inodes and preventing recurrence (e.g., targeted cleanup, log rotation, and moving TMPDIR to a larger filesystem), then rerun the backup to complete successfully.",,
6df1af8a-ec99-43aa-b0c4-af8806293361,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose intermittent 'EADDRNOTAVAIL' and 'cannot assign requested address' errors in a service that spawns many short-lived outbound TCP connections, tracing the issue to ephemeral port exhaustion and sockets stuck in TIME_WAIT. Implement mitigations (e.g., enable connection pooling, tune the ephemeral port range and TIME_WAIT reuse via sysctl in the container), then rerun load to verify stable connectivity.",,
b3a9f03f-1cb0-47cd-97e0-255e98b088ab,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose intermittent cargo build/test failures in a Rust workspace that end with 'Killed' or LLVM crashes, caused by OOM from parallel compilation and a nearly full disk from stale build artifacts. Mitigate by freeing disk space, adding a swapfile, and limiting build parallelism, then rebuild and run the tests to confirm stability.",,
ab5fd16a-85f7-453b-93eb-811f08bffe4d,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose sporadic 'No space left on device' errors despite ample free disk by identifying inode exhaustion caused by millions of small files in /var/tmp/app-cache. Implement cleanup and a prevention policy (e.g., tmpfiles.d or a cleanup cron) and verify new files can be created successfully.",,
458d7bf7-553e-4215-a7db-dd1ee868471c,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose why package installs and temporary builds fail with 'No space left on device' by pinpointing which filesystem is full (/var or /tmp) and identifying the largest consumers (journald logs, apt/pip caches, orphaned artifacts). Reclaim space and implement mitigations (logrotate/journald limits, apt clean, TMPDIR relocation) so subsequent installs and builds succeed reliably.",,
ac6936c6-d785-4b30-8319-975489f51b28,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Local vs Remote Environment Divergence,"Diagnose why a Python test suite passes locally but fails in the provided CI container due to differing locale and timezone settings (e.g., C vs en_US.UTF-8, UTC vs local), leading to UnicodeDecodeError and timestamp assertion mismatches. Standardize encoding and timezone across environments via environment variables and test/config changes so pytest passes identically in both contexts.",,
accbd531-5ac2-4b85-9361-7ef6cd54c38e,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Local vs Remote Environment Divergence,"Investigate Python tests that pass locally but fail in the provided CI-like container due to differences in locale and timezone affecting sorting, casing, and datetime parsing. Identify the mismatch (e.g., POSIX/C vs UTF-8 locale and non-UTC TZ) and reconcile it by standardizing environment settings and hardening code/tests to be locale- and TZ-independent.",,
b0e9eac7-8002-417f-9782-9152d36195b5,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Local vs Remote Environment Divergence,"Investigate a Python project whose tests pass locally but fail in the provided CI container due to differing default locale (C/POSIX vs en_US.UTF-8) and timezone (UTC vs local), affecting collation and datetime formatting. Make the test run deterministic by enforcing explicit locale/TZ and locale-independent sorting/parsing so the suite passes in both environments.",,
aeed9900-cadf-4f8b-be7f-83bd2cfb05b4,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Diagnose a Jest/TypeScript test suite that passes locally but fails in CI due to case-sensitive path resolution on Linux (imports reference files with incorrect casing). Correct the import paths and adjust TypeScript/Jest module resolution to enforce strict casing, add a CI check to catch casing mismatches, and verify the pipeline passes.",,
2c02e64c-dba4-4be2-abd5-98a014853daf,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Diagnose why a pytest suite passes locally but fails in CI where LANG=C and TZ=UTC cause Unicode encoding and time-format assertions to break. Make the pipeline and/or code locale- and timezone-stable (install a UTF-8 locale, set LANG/LC_ALL/TZ, and remove locale-dependent assumptions) and demonstrate a consistent green run.",,
b994aa41-8175-4fd7-b6a9-e17ba446151c,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose why a systemd socket-activated Python HTTP service intermittently fails with 'Cannot assign requested address' by correcting network-online.target ordering, socket file cleanup, and ExecStart bindings. Deliver fixed .socket and .service units, a cleanup helper script, and proof of consistent HTTP responses after restarts.",,
a14a5612-d734-43ea-93ee-1b9eb87665eb,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Investigate a Python pytest suite that passes locally but fails in CI due to hidden timezone/locale assumptions (naive datetime comparisons and locale-dependent formatting). Make tests deterministic by enforcing UTC and a fixed locale in both code and pipeline (e.g., TZ=UTC, LC_ALL=C) and refactoring tests to use timezone-aware datetimes or freezegun, then verify consistent green runs.",,
c91311b0-abd4-46a3-9466-53a8f7fe5722,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Investigate why tests that rely on large sample assets fail in CI but pass locally, discovering that Git LFS-tracked files are checked out as pointer stubs in the CI environment. Initialize and configure Git LFS in the pipeline, fetch actual binaries, and rerun the suite until all tests pass.",,
a960b220-897e-4949-9d90-c4ab858560af,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Reproduce and fix a CI-only failure in a React/Jest snapshot test that passes locally but fails in a headless CI container due to missing system fonts and locale/timezone differences. Identify the mismatches, install/configure the necessary fonts, set deterministic TZ/LC_* and rendering flags, and make the pipeline pass with consistent snapshots.",,
6636f4c3-61f8-46a0-93d2-7c811cf06e2d,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose a Node.js monorepo where CI fails because the pipeline runs npm ci against a pnpm-managed workspace using pnpm-lock.yaml, breaking workspace links and dependency resolution. Reconfigure the workflow to use a pinned pnpm via corepack, install with pnpm in all jobs, regenerate the lockfile if needed, and verify that build and tests complete successfully.",,
50fece10-7cb0-4217-afee-c4a2071aaf78,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose a Rust workspace that fails in a simulated CI script due to dependency drift and toolchain mismatch (yanked versions in Cargo.lock, incompatible feature flags, and an unsupported rustc). Repair by pinning a compatible toolchain, updating/patching dependencies and regenerating the lockfile so cargo build and cargo test complete successfully.",,
48f9471c-dc0f-40ea-81c5-58a45d7152dd,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose and repair a broken Git pre-commit setup where hooks (e.g., black/isort/flake8/mypy) fail due to Python interpreter mismatches and outdated hook revisions. Update .pre-commit-config.yaml and environment so pre-commit install and pre-commit run -a complete successfully and reproducibly from the terminal.",,
c9f29cd3-b51f-4d92-bb74-36b46cfadebb,Debugging & Troubleshooting,Security & Access Debugging,Access Policy & Role Misconfiguration,Diagnose and fix an Azure Key Vault access issue where a service principal’s Conditional Access policy blocks secret retrieval. Provide the corrected JSON policy and a CLI-based verification script demonstrating least-privilege secret get/set operations.,,
df7fcbbc-1517-4880-be4e-d82b7b45b1e2,Debugging & Troubleshooting,Security & Access Debugging,Access Policy & Role Misconfiguration,"Diagnose and fix an AWS IAM role and trust policy bound to an EKS service account that prevents pods from accessing a KMS-encrypted secret in SSM Parameter Store. Update policies to include the correct kms:Decrypt and ssm:GetParameter statements, then validate by retrieving the parameter via aws-cli inside the pod.",,
25f2b4a7-8b3c-4af4-8318-72845c280340,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Debug and fix a Go CLI tool in /app/client.go that interacts with a protected REST API but fails with 401 Unauthorized and 422 Unprocessable Entity errors due to missing Bearer token header and incorrect JSON struct tags. Use httputil to inspect raw requests, correct the Authorization header formatting, align JSON tags with the API schema, implement exponential backoff retries on 429 Too Many Requests by parsing the Retry-After header, and output the aggregated items array to /output/result.json.",,
069e6f4d-dd20-458a-8957-f585f4f7c98f,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Diagnose and fix a Node.js HTTP client’s mismanagement of chunked Transfer-Encoding causing truncated JSON responses and silent failures during paginated API calls. Implement proper chunk aggregation, error handling for malformed chunks, and ensure retry logic respects the Retry-After header, then validate with the provided integration tests.",,
9c086cc7-cb15-462c-8b7a-62607d5948da,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Diagnose and fix a Python client that intermittently receives 401 Unauthorized errors from a mock OAuth2-protected API by correcting its token acquisition, caching, and refresh logic. Ensure proper retry with exponential backoff and validate successful authenticated requests after token expiry simulation.",,
f2270d72-20cd-4860-83e0-3b92e1f80820,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,Diagnose and repair a Node.js Express service’s JWT authentication misconfiguration caused by an algorithm mismatch and missing environment secrets. Update the app’s config and .env keys so that POST /login issues a verifiable JWT (RS256) and GET /protected succeeds with a valid Authorization header.,,
ac7133d1-5525-4e0a-a118-97f17398dcdc,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,"Diagnose and fix a broken HashiCorp Vault integration in a CI/CD pipeline where tokens are not renewing, policies are misapplied, and secrets cannot be fetched. Ensure the pipeline can authenticate, auto-renew tokens, and retrieve required secrets with correct Vault policies in place.",,
b197aee4-df8d-420e-a034-953a3bede830,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,"Diagnose an AWS Lambda function failing with AccessDenied errors when fetching S3 objects by analyzing CloudTrail logs, IAM role policy, and bucket policy. Fix incorrect resource ARNs and condition keys in the policies, then verify successful GetObject calls via AWS CLI.",,
ea983489-c595-48b8-9bd0-ba3d73e6badc,Debugging & Troubleshooting,Data & Pipeline Debugging,Automation & Cron Job Failures,"Diagnose and repair a Cron-scheduled ETL pipeline that uses a Python script to fetch daily CSVs from S3, convert them to Parquet, and load them into Postgres—address issues with missing environment variables, inconsistent dependency versions, file locking and idempotency, and ensure robust logging and exit codes for reruns.",,
3eae9629-e441-44eb-8ef7-24837e1cfd7a,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose why a systemd-timer–driven daily log-rotation service skips or duplicates runs around daylight saving transitions; inspect journal logs and unit files, correct OnCalendar settings or add Persistent flag, reload systemd, and verify the next scheduled runs occur exactly once.",,
05725bba-518d-428c-a385-1cb945124a14,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Analyze /var/log/auth.log and journalctl for unauthorized SSH access attempts by detecting bursts of failed logins, correlate with any subsequent successes within a sliding 10-minute window, and generate a JSON security report summarizing IP addresses, usernames, attempt counts, and timestamps.",,
6734c6bf-6507-455a-ba0f-0e88ea6dec8d,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose a systemd-managed Celery worker service that silently stops processing tasks by inspecting journal logs to uncover misconfigured broker URLs, missing virtualenv activation, and low file descriptor limits. Provide a corrected .service unit with proper ExecStart, EnvironmentFile, LimitNOFILE settings, and a health-check script to verify continuous task processing.",,
62075f38-8c64-4d40-858f-136849efb268,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose a systemd timer-backed backup service that intermittently fails with SELinux permission denials by analyzing journalctl and audit logs. Restore correct file contexts, write a custom SELinux policy module, and update the unit file to ensure reliable, policy-compliant backups.",,
cd5b94bb-1d23-40c0-9f41-22e3cb9ba79f,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Build Configuration & Toolchain Issues,"Debug and repair the provided Makefile for a C project where missing dependency tracking and incorrect phony targets cause stale builds, header-change rebuild failures, and -j job races preventing successful builds. Revise the Makefile to implement automatic header dependency generation, proper phony declarations, and respect CC/CFLAGS/LDFLAGS environment overrides so that both clean and parallel builds succeed without errors.",,
b74650df-4ec4-4c70-ac99-6f1f5dc18296,Debugging & Troubleshooting,Environment & Configuration Debugging,Configuration File Parsing & Validation,"Diagnose and correct a broken docker-compose.yml with misplaced YAML anchors, wrong indentation, and unresolved environment variable references so that all services start with proper networks, volumes, and linked dependencies. Validate the repaired file using ""docker-compose config"" and ensure each container launches without errors.",,
081bdf25-1b7d-449e-ad3b-51656956983b,Debugging & Troubleshooting,Environment & Configuration Debugging,Configuration File Parsing & Validation,"Diagnose and fix a Helm chart values.yaml containing misplaced YAML anchors, duplicate keys, and deprecated API fields to restore proper rendering of a multi-service deployment; validate with helm lint and helm template to ensure output manifests match the provided schema.",,
7ff993fe-02f0-4bb9-978b-ff62815f8094,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Diagnose intermittent outbound HTTP request timeouts in a Node.js microservice under high concurrency by analyzing socket metrics, identifying OS ephemeral port exhaustion and absent keep-alive connections. Implement sysctl tuning and HTTP agent pooling, and supply a Bash load-test script that verifies zero timeouts and outputs connection stats in JSON.",,
2bb29e8b-56e0-46e6-9887-da30870dae51,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Diagnose and repair intermittent HTTP request timeouts between two Docker containers caused by an MTU mismatch on the bridge network. Reconfigure Docker network MTU or enable path MTU discovery, adjusting system settings so that large HTTP payload transfers reliably succeed under test scenarios.",,
be17d313-6d86-41f2-8ba2-33936b8281d5,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a Go HTTP microservice using pprof to identify memory leaks and surviving goroutines caused by unclosed response bodies and never-closed channels. Fix the code to properly close resources, eliminate goroutine leaks, and verify reduced memory footprint and improved request throughput.",,
1fc78324-dc48-4450-9867-b05ab1c70371,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a Python ETL script that loads multi-gigabyte CSVs using cProfile and memory_profiler to pinpoint I/O and transformation hotspots. Refactor it to use generator-based streaming, chunked processing, and optimized libraries so peak memory stays below 500 MB and total runtime is under 60 seconds.",,
78f797ac-01f2-42cb-b7f6-a6327b4a7705,Debugging & Troubleshooting,Environment & Configuration Debugging,Cross-Platform Environment Differences,"Debug a Node.js CLI tool that installs and runs correctly on Unix but fails on Windows due to shebang, path separator, and CRLF issues. Update package scripts, shebang lines, and path handling to ensure seamless operation and consistent behavior on both platforms.",,
558916ac-8dc0-4c81-8372-0ebc09d6b3e1,Debugging & Troubleshooting,Environment & Configuration Debugging,Cross-Platform Environment Differences,"Diagnose and fix a cross-platform Node.js CLI tool’s install scripts so that installation and execution succeed on Linux, macOS, and Windows by correcting shebangs, line endings, path separators, and environment variable syntax. Verify in each platform container by running the CLI’s help command and ensuring consistent output.",,
a0b2375c-0067-4729-a97b-777a7e4c04e8,Debugging & Troubleshooting,Environment & Configuration Debugging,Cross-Platform Environment Differences,"Diagnose and fix a Node.js file-sync CLI whose scripts break on Windows due to hard-coded POSIX path separators, case-insensitive file systems, and LF-only line endings. Update the scripts, configuration, and tests to normalize paths and line endings so the utility installs and runs seamlessly on both Linux and Windows.",,
cbf5f9a5-2df2-4d94-97bd-75476b8ba094,Debugging & Troubleshooting,Environment & Configuration Debugging,Cross-Platform Environment Differences,"Diagnose and fix a Node.js CLI project whose shell scripts and npm tasks fail on Windows due to CRLF line endings, hard-coded POSIX commands, and improper path separations. Update scripts and configurations so the tool builds and runs seamlessly on both Linux and Windows environments.",,
30d3e236-af8f-4336-b7a5-6fd4f9e78119,Debugging & Troubleshooting,Data & Pipeline Debugging,Data Format & Schema Mismatches,"Inspect the Spark job code at /app/etl.py to resolve schema mismatch errors caused by inconsistent CSV inputs: varied date formats, thousands separators in numeric fields, and missing columns. Implement a unified schema with casting, sanitization, and default values so that the job successfully writes a Parquet dataset to /app/output with the expected schema.",,
47972e09-4802-4773-bc76-6e4ae80d0c28,Debugging & Troubleshooting,Data & Pipeline Debugging,Data Format & Schema Mismatches,"Debug and fix a Kafka Streams application consuming Avro-encoded 'orders' events that fails due to schema evolution issues—renamed fields, type mismatches, and missing optional attributes. Update schema registry compatibility, enhance serializers/deserializers with fallback for deprecated fields and type coercion, and validate successful end-to-end message processing.",,
e6658173-12e2-4de0-9ca6-0c43bcc20c52,Debugging & Troubleshooting,Data & Pipeline Debugging,Data Format & Schema Mismatches,"Debug a Python ETL script that reads multiple CSV files with inconsistent headers (column order changes, missing optional fields, and extra columns), normalize the data into a consistent schema by adding default values and dropping unknown columns, and output a unified Parquet file. Verify that the output matches the provided schema (/app/schema.json) and contains all rows from the input files.",,
898e0af3-d343-4166-96c6-da625a8479a0,Debugging & Troubleshooting,Data & Pipeline Debugging,Data Format & Schema Mismatches,"Diagnose and fix a PySpark ETL job in /app that crashes on nested JSON input with inconsistent field types and missing optional attributes by defining explicit schemas, implementing robust type coercion, and handling absent fields. Ensure the pipeline produces a unified Parquet dataset in /output that passes the provided schema‐validation tests.",,
3f633404-3d3e-4dcd-bf96-8a5bc8dfcd75,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Audit a Dockerized Node.js microservice to detect silent dependency drift between declared semver ranges in package.json and actual versions in yarn.lock, identify which transitive updates introduced a runtime error in health-check endpoints, and implement resolution overrides or version pins to restore consistent behavior. Verify reproducibility by rebuilding the Docker image and running the provided end-to-end tests successfully.",,
3882ef92-ee8c-4fc4-9855-c90b929aee86,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Audit a Python Flask app’s Docker-based environment by comparing pip freeze outputs in development and production containers to identify silent version mismatches causing intermittent 500 errors. Update the Dockerfile and requirements.txt to pin the correct dependency versions, rebuild images, and verify consistent behavior by running a predefined load-testing script.",,
c81c6732-8cba-4b2c-941e-b9d8580f146f,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Audit two provided Docker images by enumerating installed apt, pip, and npm packages, identify version mismatches and missing dependencies, and output a structured env_drift.json. Then generate a remediation_plan.sh script to synchronize the development environment with production based on the drift analysis.",,
8b27cfcc-3eca-465b-a49e-519528fa77c7,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"Diagnose and fix a Python Flask application in /app that fails AWS S3 uploads due to misconfigured or missing AWS credentials: ensure the .env loader runs before boto3 initialization, enforce presence and correct naming of AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_REGION, and fix file permissions on ~/.aws/credentials. Update the CI pipeline to securely inject these variables without exposing secrets and verify uploads via provided integration tests.",,
7b1bbefa-7666-40d0-97b8-48d814ef37c2,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"Debug and repair a Node.js microservice that fails to authenticate to an external REST API due to missing or malformed credentials in its .env file and misconfigured AWS Secrets Manager integration. Implement an entrypoint script that retrieves Base64-encoded JSON secrets via aws-cli, validates and decodes them, exports the required environment variables with correct permissions, and proves authentication by calling the service’s /health endpoint with a valid Authorization header.",,
047e6885-1b25-4b53-bac9-9d94d9982d9b,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"A Node.js API service running in Docker Compose fails with missing API key and secret errors because its .env file is excluded by .dockerignore and not mounted via env_file. Fix the Dockerfile, docker-compose.yml, and application startup to include environment variables securely, enforce file permissions, and add graceful logging when credentials are absent.",,
4b9fea24-2ce5-4f5a-b9c1-0fffe48e2659,Debugging & Troubleshooting,Environment & Configuration Debugging,Environment Variable Misconfiguration,"Diagnose and repair a Node.js Express application containerized with Docker Compose that fails to start due to missing or misnamed environment variables (e.g., PORT, DB_URI, JWT_SECRET). Update the .env file, Dockerfile, and entrypoint script to load, validate, and apply defaults for required variables, then confirm the app responds with 200 OK on /health and passes the integration tests.",,
f39279e1-afb2-494d-8185-53349a363659,Debugging & Troubleshooting,Environment & Configuration Debugging,Environment Variable Misconfiguration,"Diagnose and fix misnamed and incorrectly formatted environment variables in a Docker Compose setup for a Node.js application (e.g., MYSQL_USER, DB_HOST, JWT_SECRET) so that the service can connect to its MySQL database and authenticate requests. Verify success by restarting the containers and issuing an HTTP GET /users that returns a valid JSON array.",,
cd7a2802-97ff-4ff3-9b87-1fa6145aa67e,Debugging & Troubleshooting,Environment & Configuration Debugging,Environment Variable Misconfiguration,"Diagnose and fix missing and incorrect environment variable definitions in a Docker Compose-based microservices stack (Node.js API, Postgres, and Redis), ensuring proper .env file loading, variable expansion, and inter-service connectivity. Use shell tools and logs to detect mismatched env keys, apply fallback defaults, and validate fixes through successful container health checks.",,
3d69a0af-81b2-4f74-a7f1-e02ac87aca15,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,Design a load-testing harness in Docker to systematically reproduce an intermittent race condition in a Go HTTP server under concurrency. Then isolate and extract a minimal standalone Go program and test script that reliably triggers the data race without external dependencies.,,
bf899048-58a1-4871-8d87-bdb8b24bb4ab,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"Systematically reproduce an intermittent deadlock in a multithreaded Java application by crafting and running a minimal test harness that triggers the issue under deterministic scheduling, then isolate and document the smallest code fragment and thread interleaving responsible for the deadlock.",,
fa636fbd-101a-408c-9c77-d5c39bfe1d66,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"A Docker sandbox includes a multi-threaded C++ program that sporadically segfaults under concurrent std::map insert/erase operations. The task is to write a stress-test harness to reproduce the failure, iteratively reduce the code to isolate a minimal standalone example that reliably triggers the segfault, and document the narrowing process.",,
a0b9e680-46d1-4574-96a0-015bf63a7924,Debugging & Troubleshooting,Code Debugging & Error Resolution,Exception Handling & Recovery,"Enhance the Python HTTP downloader at /app/downloader.py to handle network errors, timeouts, and partial downloads by implementing retries with exponential backoff, resuming interrupted transfers based on Content-Range, and cleaning up temporary files so that the provided tests pass without unhandled exceptions.",,
c936f828-7732-4b92-81df-6940c702925c,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose and fix file and directory permission issues preventing the Redis service from creating and binding its Unix socket at /var/run/redis/redis.sock by correcting ownership set by a faulty install script, adjusting the systemd unit’s RuntimeDirectory settings, and verifying that redis-cli can connect without sudo.",,
956ec99a-2e92-4414-853e-9fca243ca8f6,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose permission denied errors preventing a systemd-managed Go web service from creating its runtime directory (/var/run/goapp) and log file (/var/log/goapp/app.log). Update the unit file to use RuntimeDirectory, UMask, and correct ownership so the service and a non-root user can access its socket and logs properly.",,
4822773f-c827-4363-a5d3-2123b813bf89,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Git & Version Control Issues,"Diagnose and repair a misconfigured Git submodule setup where .gitmodules contains wrong URLs and submodules are stuck on detached HEADs, causing CI checkout failures. Update .gitmodules, fix each submodule’s branch tracking, remove stale submodule folders, and implement a reproducible script to clone and sync all submodules correctly so all tests in /ci pass.",,
91ed2df6-45b2-47dc-902c-1c74d8d32dc8,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Git & Version Control Issues,"Diagnose and repair a repository with nested Git submodules that fail to initialize due to incorrect URLs and detached HEADs; update .gitmodules, fix references, perform recursive initialization, and validate that the superproject and all submodules can be cloned and updated correctly.",,
32ab428c-2fe3-48f3-b98c-469d05dbd987,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Git & Version Control Issues,"Recover from an erroneous force-push that wiped out recent commits and caused local-remote divergence. Use reflogs and remote refs to restore lost commits, reconcile branches and tags, and update the remote to a correct fast-forward state while preserving collaborator workflows.",,
d79af8c3-f05e-4af4-a3a6-be9c3f5d9502,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose a Python ETL utility that writes hundreds of thousands of rows and is slowed by per-record os.fsync() calls; use strace or iostat to pinpoint excessive sync syscalls. Refactor the script to use buffered writes and batch fsyncs, then benchmark to confirm at least 5× throughput improvement.",,
eddac8bb-720f-42a0-8441-b3481a73aee5,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose and optimize a Python ETL pipeline that repeatedly reloads large CSV files causing severe disk thrashing under high-volume workloads. Implement file streaming, SQLite-based caching, and chunked processing to reduce disk I/O by at least 70%, achieve sustained throughput of 200k rows/sec, and output a reproducible perf_report.json summarizing I/O stats before and after optimization.",,
edf7f1df-0014-4e49-917c-9f493cbc110c,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose a Python script performing bulk inserts into a SQLite database where unbatched transactions and default journaling cause excessive fsync calls, then optimize by batching inserts, tuning PRAGMA journal_mode and synchronous settings, and rewriting to use executemany to achieve at least a 3× throughput improvement on the provided benchmark harness.",,
ad69ff0f-6868-419e-b753-14b7e405654a,Debugging & Troubleshooting,Data & Pipeline Debugging,I/O & File Handling Errors,"Diagnose and repair a Java-based log merger utility under /app/src that intermittently fails with ""Too many open files"", mishandles CRLF line endings, and outputs unsorted logs. Ensure proper file stream closure, correct alphabetical ordering of merged entries, and atomic writing of /app/output/merged.log with POSIX-compliant permissions.",,
e1b75df3-0295-43d0-a617-9488caefbe0f,Debugging & Troubleshooting,Data & Pipeline Debugging,I/O & File Handling Errors,"Fix the Python ETL script at /app/process.py that currently crashes with UnicodeDecodeError or ValueError on CSVs using different encodings (UTF-8, UTF-16LE/BE with BOM), delimiters (comma, semicolon, tab), and missing EOF newlines. Implement dynamic encoding detection, BOM stripping, delimiter sniffing, newline normalization, and robust file-permission handling so all /app/data/*.csv transform into a consolidated JSON array at /app/output/data.json without errors.",,
f66e35a2-d04b-413c-a875-34fb1a578074,Debugging & Troubleshooting,Code Debugging & Error Resolution,Interactive Debugger Usage,"Use gdb to identify and fix a race condition in a C++11 thread pool implementation that intermittently crashes under load. Reproduce the crash in a stress test, set breakpoints and watchpoints to inspect the task queue and mutex usage, correct missing locks to ensure thread-safe task dequeuing, and pass all provided concurrency tests.",,
68d164f2-6576-45ee-a12a-c6873eef6be0,Debugging & Troubleshooting,Code Debugging & Error Resolution,Interactive Debugger Usage,"Debug a Go HTTP server in /app/server.go using the Delve debugger to step through goroutines and inspect variable states, identifying and resolving a race condition that causes sporadic panics under concurrent load. After patching, rerun the provided load tests to confirm zero panics and correct HTTP responses.",,
6172f44c-9395-4715-a442-7fb29104752d,Debugging & Troubleshooting,Code Debugging & Error Resolution,Interactive Debugger Usage,"Use ipdb to step through an aiohttp-based asynchronous Python microservice that is returning coroutine objects instead of HTTP responses due to a missing await. Identify and correct the misplaced await, then run the provided tests to verify valid JSON responses.",,
b8038cb7-6bcf-4013-90ca-d6afca6979e1,Debugging & Troubleshooting,Code Debugging & Error Resolution,Interactive Debugger Usage,"Use pdb to step through an asyncio-based Python TCP server in /app/server.py that intermittently deadlocks under high load; set breakpoints to inspect coroutine states, identify the missing await causing starvation, add proper awaits, and verify no deadlocks with a concurrent test harness.",,
fc07e789-b20c-4511-b093-ca5dbe739b88,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Local vs Remote Environment Divergence,"Detect and reconcile discrepancies (Node.js versions, environment variables, dependency lockfiles, and file permissions) between local development and CI Docker environments for a Node.js microservice. Update the Dockerfile, .env configuration, and npm scripts so builds and tests pass identically in both contexts.",,
6bf5dcda-8a53-4a12-920b-6a14b10fbec8,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Local vs Remote Environment Divergence,"Identify and reconcile differences between local and CI environments of a Node.js TypeScript monorepo causing build and test failures, including Node/NPM version mismatches, missing environment variables, and case-sensitive imports. Update project and CI configs (.nvmrc, GitHub Actions workflow, .env.example), add environment validation scripts, and ensure `npm ci && npm test` succeeds identically in both environments.",,
6a7b037a-920d-4690-8bbb-757c4ab1677d,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Local vs Remote Environment Divergence,"Detect and reconcile mismatched Node.js and npm versions between the developer’s local environment (using .nvmrc and package-lock.json) and the CI pipeline (configured in GitHub Actions), regenerate lockfiles, update CI and Docker configs, and validate that both local and remote builds/tests succeed identically.",,
d2601164-c47a-49e6-94ae-783aab34fd57,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Analyze system journal, NTP, and application logs to detect time synchronization drifts causing request sequencing errors. Correlate timestamps across /var/log/journal, /var/log/ntp.log, and /app/service.log to identify drift windows and output a JSON report of each anomaly with evidence and affected services.",,
6a26affa-f5a6-4785-9593-a142fdab17aa,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Analyze syslog and kernel logs to detect recurring disk I/O errors, SMART failures, and ECC correction events. Correlate timestamps to identify the failing device, count error occurrences, determine the failure window, and generate /app/disk_error_report.json with device details, error metrics, time window, and remediation suggestions.",,
d2c8a870-fb56-4b75-a680-0bdaccd9e349,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Develop a CLI tool that scans /var/log/syslog, /var/log/kern.log and journalctl outputs to detect and correlate OOM-killer invocations with preceding high-memory usage processes. The tool must produce a chronological report (CSV or JSON) of timestamps, PIDs, memory footprints, and killed processes while gracefully handling rotated/compressed logs, timezone differences, and malformed entries.",,
61d39ab6-fceb-4377-a287-34a563755de2,Debugging & Troubleshooting,Code Debugging & Error Resolution,Logic & Algorithmic Bugs,"Debug and correct a C++ Disjoint Set Union implementation in /app/dsu.cpp where flawed path compression and union-by-rank logic yield incorrect connectivity results and degrade performance. Ensure that find() and unite() return proper representatives, compress paths correctly, and pass provided deep-tree and redundant-union test scenarios.",,
e9add470-b0e1-4e86-810b-b6d382c57efb,Debugging & Troubleshooting,Code Debugging & Error Resolution,Logic & Algorithmic Bugs,Debug and fix the in-place Quicksort implementation in /app/sort.c so it correctly handles arrays with many duplicate elements without infinite recursion and maintains average-case O(n log n) performance. Preserve the existing public function signature and ensure all tests in /tests/test_sort.c pass unchanged.,,
710b0e33-ebae-46f2-b4b6-94edc109b9f4,Debugging & Troubleshooting,Code Debugging & Error Resolution,Logic & Algorithmic Bugs,"Identify and correct logical flaws in the Python Dijkstra implementation at /app/dijkstra.py so it reliably computes shortest‐path distances and predecessors for weighted graphs. Ensure proper heap-based relaxation, handle disconnected nodes, and validate outputs against known test graphs with expected optimal paths.",,
169c6aa5-7e34-4b96-b6b9-e491cf516d7f,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose and resolve throughput issues in a Docker overlay network by identifying MTU mismatches and suboptimal socket parameters; tune sysctl TCP window sizes, container network MTU, and gRPC socket options to achieve a specified high-bandwidth target and validate with iperf3 tests.",,
024944e3-cc32-4470-a555-fda9d61a7725,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose and reduce tail latency in a Dockerized Go gRPC service under heavy concurrent load by analyzing tcpdump and pprof outputs, then optimize Linux TCP settings (socket buffers, congestion control, Nagle’s algorithm) and tune gRPC keepalive parameters. Validate sub-50 ms 99th-percentile latency using the provided load-test script and submit the adjusted sysctl configuration alongside benchmark results.",,
e96dafaf-4755-49d8-9f5b-c3e6a77df0d9,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Package Installation Failures,"Diagnose and fix a Node.js project failing npm install due to node-gyp misconfiguration, missing C++ build tools, and conflicting dependency versions; ensure npm ci completes successfully and native modules compile and pass their test suite.",,
ff3d1224-4d59-4038-89a5-4eff4f48db5b,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Package Installation Failures,"Diagnose and fix failing npm install errors in a Node.js project caused by conflicting React versions and unmet peer dependencies in custom Webpack plugins. Update package.json, apply dependency overrides, regenerate the lockfile, and ensure a clean install without vulnerabilities or warnings.",,
f8601c8c-cc1a-443c-a620-9da1cb9668da,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Package Installation Failures,"Diagnose and fix failing Poetry dependency installation in a Dockerized Python project where conflicting version constraints and missing system headers cause `poetry install` errors. Update pyproject.toml constraints, install required OS packages, regenerate the lock file, and verify a clean `poetry install --no-dev` build.",,
a4bec849-7734-4196-a96a-8c4efbbaee7e,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Package Installation Failures,"Fix npm install failures in /app by installing missing build dependencies (make, gcc, python3) and configuring node-gyp to use Python3; update the Dockerfile to include these prerequisites and set npm config variables. After changes, verify that npm ci completes successfully offline and all tests in /app/test.sh pass.",,
12628b09-93b7-45ef-85ec-d187a3be813b,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose and fix a race condition in a Go microservice that uses a shared in-memory cache across goroutines, replacing unsafe map access with proper synchronization (e.g., sync.Map or mutex sharding) to eliminate data corruption while preserving throughput. Provide a benchmark harness and verify 99th percentile request latency remains below 50 ms under simulated concurrent load.",,
91460ea0-fc8b-40b4-84a4-98722e3e229f,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,Diagnose and fix a non-deterministic race condition in a C++11 multi-threaded file transformation service that intermittently corrupts output under high load. Introduce proper synchronization (mutexes or atomics) and ensure all provided concurrency stress tests pass without impacting single-threaded performance.,,
f2ad4d83-7a09-4408-9774-c36fe736e823,Debugging & Troubleshooting,Data & Pipeline Debugging,Pipeline Stage Failures,"Diagnose and repair a five-task Apache Airflow DAG that executes extract, validate, transform, summarize, and load tasks where the validate step fails due to a deprecated Pandas API call, causing all downstream tasks to be skipped. Update the validation task code to use the correct DataFrame methods, adjust XCom handling, and ensure the full DAG run produces the final consolidated report.csv passing schema checks.",,
dd360841-73b5-492a-aa4f-c26e92dd8ac3,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Diagnose why a Java Spring Boot microservice running under realistic load intermittently hangs and drops requests due to thread-pool exhaustion and deadlocks. Produce /app/incident_postmortem.md summarizing root cause analysis, impact metrics, and preventive measures such as pool tuning, circuit breaker patterns, and enhanced monitoring alerts.",,
3dc694f4-2cf1-4113-b25f-e5166e963a45,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Analyze a simulated e-commerce checkout service outage by examining container logs, health check configurations, and deployment scripts to identify the root cause of continuous restarts and transaction failures. Compile a postmortem report at /app/postmortem.md detailing the incident timeline, impact, root cause, resolution steps, and recommended preventive measures such as improved monitoring and configuration validation.",,
6c518aa3-7d78-47b1-9f2e-d3775608e3f2,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Investigate a core dump from a Node.js service that crashed with SIGSEGV in a custom native addon; use gdb or lldb to pinpoint the null pointer dereference in the C++ code. Patch the addon to add proper null checks, rebuild it, and verify the Node.js application no longer crashes under the same workload.",,
5ec4b776-7294-4a95-83d5-dcf5a5d22b90,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,Analyze a core dump from a Node.js application crashing with SIGSEGV inside a custom C++ native addon by using llnode and gdb to reconstruct a JS backtrace and pinpoint misuse of v8::Persistent handles. Then update the addon source to correctly manage handle lifetimes and verify the fix under GC stress without further crashes.,,
29971e5d-eadb-4255-9cac-ab5d27ce9e70,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Analyze a core dump from a multithreaded C++ data aggregator that intermittently segfaults in worker threads; use gdb to trace the crash to a race condition and off-by-one buffer overflow in its circular queue, then implement thread-safe boundary checks and verify stability under stress tests.",,
1a2ed9e1-daa2-4151-8a68-70e940844e54,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,Analyze a core dump from a C-based JSON validator that crashes with a segmentation fault on long keys. Use gdb to pinpoint the buffer overflow in the key-handling function and patch the code to allocate buffers dynamically and safely copy strings.,,
b7b4667f-6e4c-4728-a5a5-b3293ea17168,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Analyze the core dump of a multithreaded C++ HTTP server that intermittently segfaults under load. Use gdb backtraces to pinpoint a use-after-free in the request parser, then implement proper ownership and synchronization to eliminate crashes under stress tests.",,
b04f7e4b-c4ac-494d-8bb5-1a4be48929f2,Debugging & Troubleshooting,Network & Service Debugging,"Proxy, SSL & Certificate Errors","Diagnose and repair an HAProxy reverse proxy that is dropping HTTPS connections for multiple domains due to an expired wildcard certificate, missing SNI configuration, and incompatible cipher suites. Update haproxy.cfg with the renewed certificate, enable SNI host-based backend selection, adjust TLS cipher settings, reload the service, and validate end-to-end secure connections.",,
c3261a5c-7f2e-432c-a0fa-648a99770549,Debugging & Troubleshooting,Network & Service Debugging,"Proxy, SSL & Certificate Errors","Diagnose and repair a misconfigured Nginx reverse proxy that is blocking mutual TLS authentication with a backend gRPC service by correcting the certificate chain, enabling ssl_trusted_certificate and proxy_ssl_server_name, and updating client_certificate settings. Verify successful mutual TLS calls using grpcurl and curl and document the validation steps.",,
5f1f2b3e-c90c-4e8b-bab5-30017590e147,Debugging & Troubleshooting,Code Debugging & Error Resolution,Runtime & Compilation Errors,"Diagnose and repair the Cython extension at /app/fastmath.pyx that currently fails to compile due to undefined references and crashes at runtime with segmentation faults by correcting cdef declarations, fixing function signatures, and ensuring proper reference count handling.  Ensure the build succeeds via setup.py and that all provided tests in /app/tests/test_fastmath.py pass without errors.",,
d1c544da-3e36-47d5-9a62-53f25c0cf1cf,Debugging & Troubleshooting,Code Debugging & Error Resolution,Runtime & Compilation Errors,"Diagnose and fix compilation failures in a Rust CLI application caused by incorrect lifetime annotations, missing trait implementations, and outdated feature flags in Cargo.toml. After repair, ensure cargo build --release succeeds and the tool processes /app/config/input.json without errors, printing the expected output.",,
bdd503a0-1660-44f4-8ef6-df42b44bed4e,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,"Diagnose and fix misconfigured Docker Compose healthcheck definitions and startup dependencies in a multi‐service application by correcting healthcheck syntax, adding wait-for logic, and ensuring proper startup order. Verify that all containers report a healthy status via docker-compose ps and by querying each service’s /health endpoint successfully.",,
ab30f2e5-f0bb-4675-9929-f38d07fc6178,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,"Diagnose and correct liveness and readiness probe failures in a Kubernetes-deployed Spring Boot microservice by fixing health endpoint implementations, adjusting probe timeouts and initial delays, and tuning resource requests so that rolling updates complete without downtime.",,
3fc257e0-1572-42b6-9e94-fc628aebfec1,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,"Diagnose a Docker Compose stack where a Node.js API behind an Nginx proxy fails its health checks due to misconfigured probe endpoints and improper startup dependencies. Fix the Docker healthcheck definitions, Nginx config, and service ordering so that all containers report healthy and the /healthz endpoint returns HTTP 200 within 15 seconds.",,
2279b8cc-9f7f-428e-8afb-ef12518214be,Debugging & Troubleshooting,Dependency & Build Troubleshooting,System Library & Path Errors,"Diagnose and repair a C++ CMake build that fails to locate Boost and OpenSSL libraries due to missing CMAKE_PREFIX_PATH and misconfigured RPATH settings, then update the CMakeLists.txt and environment variables so that cmake, make, and make test complete successfully inside the Docker sandbox.",,
c44daf03-3c32-4b51-b1ab-eac762180392,Debugging & Troubleshooting,Dependency & Build Troubleshooting,System Library & Path Errors,"Diagnose and fix a Go CLI that uses cgo for image processing (libjpeg and libpng) but fails to build and run due to missing pkg-config files and incorrect CGO_CFLAGS/LDFLAGS. Install and link the proper dev packages in the Docker sandbox, adjust environment variables, and verify the binary correctly processes sample images in /data.",,
75539f6d-6f0c-44d2-96ff-1a2f554e2bfd,Debugging & Troubleshooting,Dependency & Build Troubleshooting,System Library & Path Errors,"Diagnose a C++ application failing at runtime due to a missing custom shared library and incorrect RPATH settings, then update the Dockerfile to install the library under /usr/local/lib, configure ldconfig, and embed the correct RPATH so ldd reports no missing dependencies. Validate the fix within the Docker sandbox without modifying files outside /app.",,
ef65f07d-d37a-4c1d-a810-3c5eed2358ef,Software Engineering & Development,Software Architecture & Design Patterns,Design Pattern Implementation,"Implement a Python CLI menu system using the Composite pattern to represent nested submenus and commands. The program reads a JSON config to build the menu tree, allows interactive navigation, and executes associated shell actions.",,
b6ad0055-d1cf-4fc0-a8d5-03592c59380b,Debugging & Troubleshooting,Dependency & Build Troubleshooting,System Library & Path Errors,"Diagnose and fix build errors in a CMake-based C++ project where OpenSSL and zlib are installed in non-standard prefixes under /opt/extra by correctly configuring environment variables and CMakeLists to locate headers and libraries, ensuring both Debug and Release builds complete and all ctest cases pass.",,
398deb1e-1415-40c6-a7c3-2521cef65a26,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose periodic failures of a long‐running Python logging service caused by disk exhaustion from unrotated log files. Implement log rotation with proper retention and compression, then verify stability by simulating high log throughput and confirming disk usage remains under a safe threshold.",,
cf08737d-ea98-4c02-80a0-2f89c1bb1976,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose and mitigate disk space exhaustion in a Dockerized logging service by identifying unbounded log growth under load, implementing log rotation with compression and retention policies, and freeing existing logs. Verify that no container runs out of space during a simulated high-traffic test and produce a cleanup_report.txt summarizing before/after disk usage statistics.",,
d34c31d6-109f-47ac-b812-d37bb8213a50,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose a Node.js HTTP server leaking file descriptors under high load by analysing lsof outputs and system logs, then patch the code to close sockets properly and adjust systemd LimitsNOFILE. Validate stable FD usage below 1k under simulated 10k concurrent connections and provide patched server.js, updated unit file, and fd_report.json.",,
cec5d234-62f9-4448-9234-2e4162c496e9,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Diagnose a flaky GitHub Actions CI workflow for a Python project where parallel pytest jobs against a shared PostgreSQL service intermittently fail due to database lock contention and misconfigured environment variables. Update the workflow to ensure isolated test databases, proper service health checks, and effective caching, then verify five consecutive successful runs and document findings in /app/ci_diagnosis.md.",,
fb94fa1a-5157-45d4-8686-2e54bba02e82,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Diagnose and repair a GitHub Actions workflow for a Node.js monorepo that intermittently fails due to caching issues and outdated lockfile conflicts. Implement automated steps to validate YAML, refresh dependency caches, lock Node versions, and ensure deterministic installation so all CI runs succeed reliably.",,
338c51f4-79be-4de5-b5bb-d4058b17840e,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Diagnose and remediate intermittent test failures in a Node.js monorepo CI pipeline by pinpointing misconfigured Jest caches, inconsistent workspace dependency resolutions, and phantom registry URLs. Update workspace and CI configurations, regenerate the lockfile, tweak caching directives, and provide a reproducible validation script to ensure deterministic, flaky-free test runs.",,
451d3cbb-40b0-4944-98ae-3f4904e56de8,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose and fix a broken GitHub Actions CI pipeline for a Yarn v2 monorepo where dependency drift across workspaces leads to mismatched lockfile states and test failures. Synchronize package.json versions, regenerate the PnP lockfile, configure proper caching steps, and verify that all /packages/* modules build and pass tests under the updated workflow.",,
ccd11bd1-5cff-4c20-8491-05f3d7ac838c,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose and repair a failing GitHub Actions CI workflow in .github/workflows/ci.yml caused by deprecated actions, misconfigured cache keys, and YAML syntax errors. Update action versions, correct cache configurations, adjust matrix definitions for Node.js (14/16) and Python (3.8/3.9), and validate the workflow completes successfully without cache misses.",,
5c014df5-0376-4ebf-8020-1e7fd55ebf5b,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,"Analyze a Rust Tokio-based service that panics with a long backtrace due to an unwrapped Option in nested async calls; trace through the stack frames to identify the faulty unwrap, then implement proper error handling to prevent the panic. Ensure the service starts and handles missing values gracefully under asynchronous workloads.",,
ba1cffa3-ffb2-4dae-9e1b-c30c01fd14ef,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,"Diagnose a Node.js microservice crash by analyzing its V8 heap snapshot and long-stack-trace to reconstruct the async call chain leading to an UnhandledPromiseRejectionError, locate the missing await causing context loss, and propose a minimal patch restoring correct error propagation.",,
5fef8bb7-5895-47cb-9016-7997f7e1a03f,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,"Analyze a Go HTTP server panic of 'invalid memory address or nil pointer dereference' by inspecting the panic stack trace to pinpoint an uninitialized map used in request handling. Fix the code by initializing the map and verify that no panics occur under load, documenting the root cause and resolution.",,
3178267a-f258-478c-96fa-a136cc3688d1,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Version Incompatibility,"Diagnose and resolve conflicting lodash versions across multiple packages in a Yarn workspace monorepo by aligning dependency declarations and regenerating the lockfile so that yarn install, yarn build, and all package tests succeed without touching application code.",,
51996ac3-7415-4a76-bc23-c593e1cadcab,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Version Incompatibility,"Diagnose and resolve conflicting SLF4J/Logback versions in a Maven-based Java service that compiles successfully but throws NoSuchMethodError at runtime due to transitive dependency mismatches. Update the POM to apply correct exclusions, align versions via dependencyManagement, and verify the fix using mvn dependency:tree and replayed integration tests.",,
f4e03c5a-4923-4523-bb6a-d2f1720775c2,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Version Incompatibility,"Diagnose and fix version mismatches in a Rust project where two crates depend on conflicting OpenSSL versions causing cargo build failures. Adjust Cargo.toml with appropriate version overrides and features to unify the OpenSSL dependency, then rebuild and verify all tests pass.",,
9507ce46-3098-40eb-a664-3426374b6a4a,Debugging & Troubleshooting,Environment & Configuration Debugging,Virtual Environment & Container Issues,"Analyze and correct a Python Conda environment bundled in a Dockerfile that fails to import C-extensions due to ABI mismatches and conflicting package versions. Update environment.yml, channels, and multi-stage build steps to produce a minimal image under 500 MB where all pytest tests pass.",,
5977f040-05e8-424a-b6ae-23adb5ec95f3,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Exploit & Reverse Engineering Games,"Interact with a CLI vault that issues sequence-based one-time passcodes derived from a predictable PRNG. Infer or reverse engineer the PRNG from observed outputs and generate the correct admin code to unlock the root vault, then write the revealed secret to /app/flag.txt.",,
5029d177-1471-49b4-897d-ad1028dbf534,Debugging & Troubleshooting,Environment & Configuration Debugging,Virtual Environment & Container Issues,"Debug and repair a multi-stage Docker build for a Python microservice where dependencies installed in the builder stage are missing in the final image, causing ModuleNotFoundError. Optimize layer caching, ensure correct working directories and environment variables, and validate the service responds on /health with HTTP 200.",,
14c29726-a237-4bb3-90d6-8e541f5495a5,Interactive Challenges & Games,Interactive Education & Learning Tasks,Command Discovery Quests,"Explore a custom git-style CLI called cmdschool whose subcommands are intentionally undocumented except via --help, man pages, apropos, and an interactive cmdschool tutor, and learn to combine preinstalled tools (jq, ripgrep, curl, gpg, imagemagick) to pass five stages. Finish when cmdschool status reports 'graduated' and write the issued certificate token to /app/results.txt.",,
14be6e0d-cf4b-427e-bb7a-a2ef2e466be8,Interactive Challenges & Games,Interactive Education & Learning Tasks,Command Discovery Quests,"Explore a custom lab CLI that discovers subcommands from executables named 'lab-*' on the PATH; by chaining 'lab help' and each subcommand's --help/man pages, deduce the correct workflow to authenticate and extract a hidden secret. Write the recovered secret to /app/flag.txt.",,
ed9babc0-59b5-4ba0-947f-492a261eb8d0,Interactive Challenges & Games,Interactive Education & Learning Tasks,Error Interpretation & Correction Games,"Broken Build Bootcamp: a staged C project with intentional faults (misconfigured Makefile flags, segfaults, and undefined behavior) driven by a tutor CLI that provides compiler/linker logs, sanitizer traces, and unit-test feedback. Progress by interpreting each failure and patching the Makefile and C sources until every stage reports PASS.",,
cba808c8-eb2c-4b5b-98f2-24bda8461aa9,Interactive Challenges & Games,Interactive Education & Learning Tasks,Error Interpretation & Correction Games,"Interact with a simulated init system where a multi-service stack fails to start due to curated faults (dependency order, bad permissions, missing env vars, and port conflicts). Use logs and status tools to identify and fix each issue until all services are active, then write the final status summary to /app/answer.txt.",,
9f1d0fd4-e299-4c37-b54d-869e420b1991,Interactive Challenges & Games,Interactive Education & Learning Tasks,Error Interpretation & Correction Games,"Repair a staged break-and-teach microservice where each run of ./grade.sh reveals the next failure (dependency conflict in requirements, timezone-induced flaky test, and a CLI parsing error masking a logic bug). Interpret logs and stack traces to apply minimal targeted fixes in code or config until all stages pass and the script writes PASS to /app/result.txt.",,
96ca5917-25f4-4eb6-bc3f-2e2cab894159,Interactive Challenges & Games,Interactive Education & Learning Tasks,Progressive Learning Environments,"A progressive Git kata inside a pre-seeded repository where a mentor CLI unlocks each level after verifying the repository state. The agent advances by performing real git operations—branching/merging, resolving conflicts, bisecting a failing test, interactive rebasing to rewrite history, and final tag signing—then outputs the mentor’s token to /app/result.txt.",,
67e4f07b-41d9-4a54-a320-8f0c1aae189e,Interactive Challenges & Games,Interactive Education & Learning Tasks,Progressive Learning Environments,"Create a terminal-based Bandit Lab where each level runs a simulated multi-armed bandit and the agent must implement a policy that beats a regret threshold to unlock the next level. Later stages introduce non-stationary payouts, delayed feedback, contextual features, and pull-budget constraints with automated evaluation after each run.",,
6c3cca77-4ef7-4350-b136-2e6dd0ad56b4,Interactive Challenges & Games,Interactive Education & Learning Tasks,Progressive Learning Environments,"Progress through a 'Git Time-Travel Academy': a series of levels that each present a corrupted or tangled repository requiring specific git operations (recovering lost commits, conflict resolution, bisecting a regression, history rewrite to purge secrets, submodules/sparse-checkout) to meet exact verifiable end-states. A terminal proctor script validates artifacts (commit DAG shape, tags, signed commits, message formats) and unlocks the next level upon success.",,
fb795164-d47a-4f9f-bab2-b8cd31d7559b,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Debugging Under Constraints,"Debug a terminal-based roguelike in C that intermittently crashes after a few moves due to a use-after-free in its pathfinding queue; locate the bug using only gdb with at most three breakpoints and fix it by changing no more than five lines in src/queue.c, then survive 300 turns without a crash. The harness limits you to five launches and validates the fix by running under AddressSanitizer and a randomized input script.",,
0663113c-d580-4b79-a617-1b4dbe595ee4,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Debugging Under Constraints,"Diagnose and fix a deadlock in a multithreaded C echo server that intermittently hangs under load, using only strace and gdb with a maximum of 12 commands total and editing at most two source lines. Verify the fix by running the concurrent client harness to completion and writing OK to /app/result.txt.",,
c8d57c8b-262b-42c3-9e85-6329ca211fdd,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Debugging Under Constraints,"Given a buggy terminal-based Snake game (C/ncurses) that intermittently segfaults when the snake grows near the top-left wrap, locate and patch the defect using only grep, sed, make, and gdb with at most 10 debugger commands and 3 rebuilds. The fix must allow a provided deterministic input script to reach length 25 without crashing and the program should write the final score to /app/score.txt.",,
bdccbcd2-58e8-4fbe-8deb-91cf4f908406,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Debugging Under Constraints,"Perform a constrained git-bisect on a pre-seeded repository: using at most a small fixed number of shell commands and only batch-mode tools (git, make, ./test.sh), identify the first commit that breaks an integration test. Apply a one-line patch to fix the bug so all tests pass, then write the bad commit SHA and the fixed binary’s checksum to /app/answer.txt.",,
bd105a6f-4263-48fb-92e7-fb8a8362cb3a,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Debugging Under Constraints,"Repair a minimal in-terminal SQL REPL that returns incorrect results for nested WHERE conditions due to a faulty lexer and precedence handling. Debug using only the built-in 'explain' and 'trace' commands with at most five REPL sessions, and fix it by editing only tokenizer.py and eval.py until all transcript tests pass.",,
899a0ef9-eeca-43c3-be72-f322900ebfcf,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Exploit & Reverse Engineering Games,"Analyze a provided crackme.wasm that validates a passphrase; reverse or patch it using wasm2wat/wasm-objdump and run it (e.g., via wasmtime/node) to trigger the success path and print the hidden flag. Write the exact flag to /app/flag.txt.",,
1baa4f7d-60b3-4ab0-b18c-6debd3a4dc61,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Exploit & Reverse Engineering Games,Bypass a dynamic license check in a stripped ELF by either reversing libcheck.so to derive a valid key or injecting an LD_PRELOAD shim that overrides the verifier; then run the program to unlock and print the secret. Save the exact secret to /app/flag.txt.,,
fa4d86bb-3130-4995-82c9-10661d2bd462,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Exploit & Reverse Engineering Games,"Reverse a stripped 64-bit ELF that embeds a tiny stack-based VM and a hidden print_flag() routine; using gdb or radare2, recover the VM instruction set and craft an input/bytecode that pivots execution to the win path despite ASLR and NX. Execute the payload against the service to reveal the flag and write it to /app/flag.txt.",,
3b27ad89-0623-4bdc-b38d-f6bbc1e5425a,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Exploit & Reverse Engineering Games,Reverse a stripped ELF implementing a custom WASM-like bytecode VM that loads program.bin and rejects unknown opcodes; interactively recover the instruction set via objdump/gdb and black-box probing. Assemble a crafted bytecode payload that calls the hidden reveal routine to print the secret and write it to /app/results.txt.,,
c56000f5-0840-4cbf-8a0b-dd3e4ec2db3d,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Live Coding Challenges,Solve an interactive regex-golf ladder where a CLI judge streams sets of positive and negative examples and you submit a single POSIX ERE pattern under a byte-length budget that must match all positives and none of the negatives to advance. Clear 20 levels with cumulative pattern length capped and immediate pass/fail feedback after each submission.,,
0dfa7f50-d9f8-4424-bc3a-8c5bcbc54a81,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Dynamic Difficulty Adjustment,"Build a terminal-driven stealth microgame where the agent exchanges JSON messages with a referee, issuing one legal move per turn to reach an exit while avoiding dynamic guard line-of-sight. After each success the referee expands the grid, upgrades guard AI, injects decoys/noise, and the agent must clear three escalating tiers and write the final run transcript to /app/replay.json.",,
327f83e2-60c1-4703-8fd9-15a0a4a89ddb,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Dynamic Difficulty Adjustment,"Build an agent that plays an adaptive Unix Pipe Gauntlet: a judge program presents level-by-level data-processing goals and allowed/forbidden tools; each success raises difficulty by tightening constraints (e.g., streaming-only, no temp files, limited forks) and larger inputs. The agent must clear at least 6 consecutive levels without invalid commands and then write the exact pipeline used for each level, in order, to /app/pipelines.txt.",,
934039e9-6a59-406b-8e98-b5e633452348,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Dynamic Difficulty Adjustment,"Build an agent to play a terminal-based adaptive Mastermind/Wordle hybrid where, after each successful round, the secret’s length, symbol set, and feedback strictness increase; the agent must reach and solve Tier-5 difficulty and export every round’s secret and full guess history to /app/solutions.json.",,
c38c09e8-674c-4ed2-a141-988dfdf96eb0,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Dynamic Difficulty Adjustment,"Create an agent that plays an adaptive 'Protocol Negotiation' game where a local server alters its text-based handshake, auth, and payload schema each round based on prior success. The agent must probe, infer, and complete three escalating exchanges to obtain and write the final session token to /app/result.txt.",,
e050d0fd-680c-4e2c-a81b-74ecc42abd6e,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Goal Discovery & Hidden Objective Games,"Interact with a shape-shifting oracle CLI whose feedback adapts to your recent commands, signaling only via exit codes, response latency, and log entropy whether you’re getting closer or farther. Deduce that the hidden objective is to achieve a ‘Harmony’ state by simultaneously satisfying three latent conditions (a process with specific args, a file with exact permissions/content, and an open port), then coax the oracle to reveal a token to write to /app/answer.txt.",,
beceee21-838f-4a7e-b909-4d501196cb50,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Goal Discovery & Hidden Objective Games,"Interact with a terminal mood-daemon that returns only a scalar score in response to your filesystem and process actions, while adaptively changing its hidden preferences if you repeat patterns. Infer the evolving rule set (names, layout, permissions, and timing) to push the score past a threshold that emits a secret phrase, then write the phrase to /app/answer.txt.",,
e7eecf0b-a292-4a1c-90a2-e3dfa778f780,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Design a terminal-driven heist simulation where the agent first conducts reconnaissance to map a procedurally generated facility and infer rotating passcodes from noisy logs, then executes a timed infiltration. The environment adapts to missteps by reshuffling room topology and passcode rules; the agent must extract two target artifacts and POST them to an exfiltration endpoint while saving a full action transcript to /app/heist.log.",,
89685975-e62f-435a-808f-73f1776fd7b2,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Interact with a terminal-based adaptive market simulator that changes regimes (fees, tick-size, order throttles, volatility) in response to your PnL and risk. In phases, first probe and infer the current rules, then place exactly one legal order per tick to survive all rounds and finish above a target net worth, finally writing your ending equity and inferred parameters to /app/answer.txt.",,
2390a635-e82a-446a-a59a-98092abb254f,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Launch an adaptive Forensics Gauntlet CLI that presents a three-stage sequence of artifacts (e.g., pcap, stego-image, packed binary) whose exact types and hints change based on the agent’s prior actions and errors. Extract a token from each stage with appropriate terminal tooling, concatenate them into the final passphrase, and write it to /app/flag.txt.",,
b46685c4-94c5-4040-9be5-783ec0642c63,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Play a terminal-based adaptive heist simulator in three phases: gather recon from noisy CLI sensors and dynamic map feeds, infer guard patterns and rotating lock ciphers, then edit system/cron/firewall configs to schedule a breach and exfil path. The environment reacts to missteps by mutating routes and codes, so the agent must replan and ultimately write the retrieved vault_token to /app/results.txt.",,
49aaf64e-8d1f-4b27-ab5c-e6ffba5568bb,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Adversarial Game Environments,"Build a terminal client for a Tron-style light-cycle duel on a toroidal grid that receives per-tick state over a socket and must emit exactly one legal move under a strict per-turn deadline. To pass, the agent must outlast or trap the AI opponent across a best-of-N series while maintaining a target non-loss rate and zero invalid moves.",,
0f1c38c9-72d2-4e41-9089-49eee085a5da,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Adversarial Game Environments,"Create a terminal agent that plays an adversarial Battleship variant against a hidden AI where ships can legally drift one cell per turn after each round. With a limited number of probes and optional sonar sweeps, the agent must track probabilistic ship positions, anticipate evasive maneuvers, and achieve a target win rate over a best-of series.",,
1cb5eba8-e3cb-4ec6-af68-5442a4d4953a,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Adversarial Game Environments,"Create a terminal bot that plays Notakto (misère tic-tac-toe) on three simultaneous 3×3 boards against a provided adversarial engine via a simple text protocol. The bot must issue legal moves under a per-turn time limit, strategically closing boards to force a win across a best-of-five match and log the full transcript.",,
67faa4dd-4d87-4406-a9c6-fff1e01b039e,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Adversarial Game Environments,Create an agent that plays a fog-of-war Battleship variant against a deceptive AI via a line-based terminal protocol. The AI may relocate damaged ships and emit noisy decoy feedback; the agent must track uncertainty and sink all ships within a fixed shot budget without illegal moves.,,
33e94781-5b93-493c-b633-80ff8f309c0e,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Collaborative Simulations,"Coordinate three autonomous spelunking drones in a fog-of-war cavern using the provided TCP JSON protocol: each drone has limited sensors, battery, and comm range, and some passages require synchronized two-drone actions to unlock. Implement a controller that schedules moves, plans rendezvous to sync maps, avoids collisions, and writes a globally merged ASCII map to /app/cavern_map.txt.",,
03b7e6d0-33a3-41ca-9752-41d02406b52b,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Collaborative Simulations,"Coordinate three simulated warehouse robots via provided CLI tools and TCP sockets to pick, carry, and deliver items on a 2D grid while avoiding collisions and respecting capacity and battery limits. Plan a joint schedule including charging stops, issue synchronized move/pick/drop commands, and write the final delivery ledger to /app/fulfillment.txt.",,
412a9133-415b-45c4-860f-1e1291062629,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Collaborative Simulations,"Implement a terminal controller that coordinates two cooperative agents—Scout and Carrier—over JSON via UNIX pipes in a partially observable 2D mine. Map hazards, schedule pickups, and deliver a target ore quota to base within a strict tick limit without collisions or invalid commands, then write the mission summary to /app/results.txt.",,
e75aa374-67b9-48ba-858b-8f2e80672ab4,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Collaborative Simulations,"Implement an agent that joins a turn-based, socket-driven cooperative pipe network repair simulation alongside a simulated teammate controlling a disjoint set of tiles. Using a 16-byte-per-turn radio channel, coordinate synchronized rotations and valve toggles to connect all sources to sinks without leaks within 250 turns, then output the final ASCII grid to /app/network.txt.",,
ad926719-62f7-46ab-b113-e3555db095af,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Implement an agent that conducts multi-attribute contract negotiations (price, delivery window, warranty) via a terminal CLI with three simulated vendors using an alternating-offers protocol, inferring each vendor’s hidden preferences from their counteroffers. The agent must secure at least two agreements under a global budget and write the finalized deals as JSON to /app/deals.json.",,
8eb2b7ab-9a0e-4fcb-a6b1-7ab51dd50749,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Implement an autonomous negotiator that interacts via a stdin/stdout JSON protocol with two simulated counterparts to settle a multi-issue contract (price, delivery, warranty) under a strict 10-round deadline. The agent must adapt to counteroffers, maintain feasibility and constraints, achieve a target utility score, and persist the agreed terms and full transcript to /app/contract.json.",,
87620ef7-43d6-40e7-ae51-a3a1e1ac64c5,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Negotiate a cloud service contract with two simulated vendors over a JSON-lines CLI broker, adapting to counter-offers and surprise constraint changes (budget, latency SLO, and data residency) to reach a Pareto-feasible deal in ≤20 rounds. On success, write the agreed terms as valid JSON to /app/contract.json and the complete dialogue transcript to /app/transcript.log.",,
26964ebc-83b1-4621-8f36-81bf12537c07,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Negotiate a multi-item procurement contract with three simulated vendors over a CLI dialogue protocol, exchanging offers that vary unit price, lead time, and minimum-order constraints. Produce a single purchase order that fulfills the given BOM within budget and deadline while minimizing total cost.",,
e877425c-af70-43a0-8bc0-8e3c35d6586a,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Use the provided market_sim CLI to negotiate concurrently with two competing suppliers that bluff, issue time-limited counteroffers, and adapt pricing to your messages. Secure a single bundled contract meeting target quantity, budget, and delivery constraints, then write the agreed terms to /app/contract.json in the required schema.",,
36e285d9-1040-40b7-a0a4-5009d78f8fa3,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Build an agent that explores a fog-of-war hex-grid rover simulation via CLI, where each move reveals neighbors, drains battery, and encounters dynamic hazards (e.g., shifting dunes or rockfalls). The agent must locate and collect two beacons, then reach the uplink before power depletion, outputting the discovered map and exact move sequence to /app/route.txt.",,
dc1560d7-231d-4c1a-b67c-7b8110e3c1d2,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Create an agent that interacts with a terminal simulator to explore a partially observed 2D grid featuring toroidal wrap-around, paired teleporters, and one-way wind tiles that push the agent upon entry. The agent must output an exact ASCII map labeling S, E, walls, portal IDs, and wind directions, and a minimal-length path from S to E that respects these mechanics to /app/solution.txt.",,
88e7a3cf-dd88-4725-b66d-0d4b8463d784,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Explore a terminal-based grid with hidden paired portals and one-way conveyor tiles under partial observability, inferring teleport linkages and movement dynamics as you go. Reconstruct the exact ASCII map, list portal pairings, and compute the shortest S→E route that respects conveyors and teleports.",,
1cba6ca4-a978-4998-bb4d-035399cf9fe9,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Interact with a time-evolving grid simulator where hazards drift each turn; using only local scans and actions (up/down/left/right/wait/ping), explore to map the environment, collect two artifacts, and return to S. Write the final ASCII map and the time-indexed action sequence to /app/solution.txt.",,
5663ed95-c50e-4223-829f-d654451d06d1,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Navigate a CLI-driven toroidal ocean grid where each move (N/S/E/W/WAIT) is followed by a hidden current vector that displaces the agent, with limited sonar pings revealing local distances to walls and the exit. Infer and map the per-cell current field and chart a route that reliably reaches the extraction gate within a turn limit, then output the final ASCII map and move sequence.",,
3b5f6c3f-5a55-4ddc-9a42-16063886a1c1,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Interact with a terminal-based 2D n-body gravity sandbox where a probe starts on an escape trajectory; issue one thrust command per tick under a fixed fuel budget to capture into and maintain a near-circular orbit around a specified body for 600 steps. On completion, write the measured semi-major axis, eccentricity, and mean motion to /app/orbit.txt.",,
7a103628-4adb-4e84-b364-6ecef4c0c772,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Interact with a terminal-driven Conway’s Game of Life sandbox to synthesize a seed that evolves into a provided 40x40 target bitmap at generation 20. Using only add/remove and step/reset commands, find a seed with ≤200 live cells that yields the exact target and write the seed coordinates to /app/seed.txt.",,
3a1c4571-3aba-4da2-8721-1be5f8deeafa,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Pilot a capsule in a simplified 2D orbital dynamics simulator by issuing discrete thruster burns via a CLI to match position and velocity with a target module before fuel runs out. On successful dock, write the timestamp of docking and remaining fuel to /app/docking_report.txt.",,
14274b8e-39fd-46e6-ab74-dd4be289eb8f,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Pilot a spacecraft in a terminal-based 2D orbital simulator by issuing discrete thrust commands each tick to rendezvous and soft-dock with a moving satellite while conserving fuel. Parse telemetry, predict trajectories under gravity, avoid collision zones, and complete docking within time and distance/velocity tolerances.",,
8a3e5b65-56e4-46b1-a6eb-04cbb4caa5b0,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Probe an unknown 2D cellular automaton via a terminal interface that lets you seed patterns, step the simulation, and snapshot states under a fixed global step budget. From these experiments, infer the local update rule and implement a predictor that, given a fresh initial grid and K, writes the K-step future state to /app/answer.txt.",,
b9c2fd74-1dc4-4289-9121-71483ed4a540,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Operate a simulated island microgrid via a terminal CLI—dispatch diesel gensets, curtail wind/solar, and charge/discharge a battery each tick—to meet demand and maintain a spinning-reserve margin without blackouts over a 24h scenario. Minimize total operating cost and emissions while surviving randomized weather dips and a forced-outage event, then write the final KPIs to /app/report.json.",,
81a60d51-f295-4aec-9713-4b69bf997404,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Operate a terminal-based microgrid simulator by dispatching generators and scheduling battery charge/discharge each tick to meet demand under transmission constraints and variable renewable output. Survive 96 ticks without load shedding while minimizing fuel and carbon cost, then write final KPIs (cost, unserved energy, CO2) to /app/results.txt.",,
4088a2b5-ac52-47de-9504-98f4696ed1eb,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Operate a terminal-based power grid where you must schedule generators with ramp/warm-up constraints, shift energy via batteries, and buy/sell on a volatile spot market as demand and weather vary each tick. Survive a multi-day horizon with zero blackouts while minimizing total operating cost under emissions and maintenance limits.",,
e3edeaf2-4590-4b95-a597-8eaab5c4655c,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Operate a terminal-driven microgrid where each tick you dispatch generators, charge/discharge batteries, and optionally shed load amid stochastic demand and weather. Keep blackout events below a threshold and total operating cost under a budget for 500 ticks, then write the final cumulative cost and unmet-load percentage to /app/answer.txt.",,
373ee238-ca44-41d0-bb31-efa123e7ec31,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Use a terminal microgrid-sim to manage solar, wind, battery, and diesel assets over 48 simulated hours, issuing per-tick dispatch commands to meet demand without blackouts. Minimize fuel use and battery wear amid stochastic weather and output a final KPI summary to /app/report.json.",,
399b2def-5601-4895-b69b-c65d8299d2ca,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Operate a simulated three-tank industrial control system via a terminal CLI, reading sensor states and issuing bounded pump/valve commands under latency and sensor noise. Keep all tank levels within target bands for 500 ticks despite disturbances, then write the stability checksum to /app/answer.txt.",,
4cb79ca2-0bef-4a15-9e39-c3fcea16641c,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,Operate a terminal-driven Raft cluster simulator where nodes suffer leader flapping from mis-tuned timeouts and intermittent network partitions. Diagnose logs and adjust per-node settings and links to maintain quorum and consistency across hundreds of simulated ticks.,,
8fc5d3ea-a935-4121-86c4-f14720bfd6f3,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Pilot a simulated Software-Defined Network: use the provided controller CLI to install and update OpenFlow rules across six virtual switches so tenant networks stay isolated, service A is load-balanced, and failover occurs within 2s during injected link failures. Keep dropped-allowed-traffic under 1% as reported by the monitor and write the final rule set and metrics to /app/results.txt.",,
73a39e67-e20a-483e-bd4e-bcee9484faa1,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Using a provided Raft cluster simulator, bootstrap a 5‑node key-value store, write a test key, then induce controlled failures by stopping/restarting nodes to trigger leader elections while preserving linearizable reads. Verify consistency by reading the key from all nodes after recovery and write the observed leader IDs over time to /app/leader_log.txt.",,
38ed211b-176d-4929-877c-d34bb902ef57,Interactive Challenges & Games,Strategy & Reasoning Games,Board & Turn-Based Games,"Build an agent that plays terminal Battleship against a provided opponent, using probabilistic heatmaps and constraint reasoning to select shots and update an internal belief grid. Run multiple seeded matches, sink all ships, and write the shot sequences and outcomes to /app/shots.json while meeting a shots-per-game efficiency target.",,
417fe0a6-eecb-44d2-bde7-9930c606945c,Interactive Challenges & Games,Strategy & Reasoning Games,Board & Turn-Based Games,"Build an autonomous Battleship solver that connects to the provided TCP referee, maintains a 10x10 belief grid, and fires one coordinate per turn using a probability-density hunt/target strategy. Sink all ships within the shot limit without repeating guesses, then output the final reconstructed board to /app/fleet.txt.",,
d75ad266-96a9-492d-9296-16d94162e123,Interactive Challenges & Games,Strategy & Reasoning Games,Interactive Optimization Problems,"Build an interactive traveling-salesman optimizer that queries a provided HTTP API to reveal individual edge distances at a cost and iteratively proposes route improvements. Under a strict query budget and time limit, the agent must produce a tour beating a baseline length and write the final city order to /app/route.txt.",,
c6ecf7e7-8028-41c2-8eac-a4ede986d0e7,Interactive Challenges & Games,Strategy & Reasoning Games,Interactive Optimization Problems,"Design an agent for a query-limited Traveling Salesman problem: interact with a terminal oracle that reveals pairwise city distances on demand (each query consumes budget), then decide when to stop and output a complete tour. The agent must balance which distances to learn versus constructing a near-optimal route under strict query and time constraints.",,
a1d624cf-cdd1-43ce-8e04-53ecb92db920,Interactive Challenges & Games,Strategy & Reasoning Games,Interactive Optimization Problems,"Interact with a CLI contextual multi-armed bandit simulator: each round you read feature vectors, choose one of K actions, and observe a noisy reward with occasional non-stationary drift. Implement an online policy that maximizes cumulative reward over N rounds and writes the final score and learned parameters to /app/results.txt.",,
dc3bc568-f0ad-48f0-b261-5268fa64e1e9,Interactive Challenges & Games,Strategy & Reasoning Games,Interactive Optimization Problems,"Interact with a terminal-based noisy-knapsack simulator: over multiple rounds, optionally probe items (incurring small costs) to reveal noisy weight/value estimates, then choose a subset to pack under a fixed capacity. Design an agent that balances exploration and exploitation to maximize cumulative packed value and write the per-round selections and final total to /app/results.txt.",,
e83b13b6-4a0e-4323-a14b-ae5d0ef0a8a1,Interactive Challenges & Games,Strategy & Reasoning Games,Interactive Optimization Problems,"Play a terminal-based nonstationary multi-armed bandit: each turn, choose one of N arms via stdin and receive a noisy reward, with reward distributions drifting over time. Over a fixed horizon, adaptively balance exploration and exploitation to minimize regret, then output total reward and estimated regret to /app/answer.txt.",,
d150d9fc-e51d-48c5-8f06-f25c393f8e36,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,"Build a terminal agent to play a non-stationary multi-armed bandit exposed via CLI/HTTP, choosing among 10 arms with stochastic rewards and occasional distribution shifts. Across 5,000 rounds, the agent must adapt online and complete with sublinear regret while writing final metrics to /app/results.json.",,
df57b3f1-0f01-4963-ac96-06edc451adf1,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,"Implement an agent that plays a terminal-based K-armed Bernoulli bandit by reading JSON feedback each round and emitting exactly one arm index to pull, using a probabilistic policy (e.g., Thompson sampling) to balance exploration and exploitation. After a fixed number of pulls, the agent must achieve cumulative regret below a given threshold and write posterior mean estimates for each arm to /app/posteriors.json.",,
f9a478fe-eae1-4f73-9743-75e3478be577,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,"Implement an agent that plays a terminal-hosted multi-armed bandit with unknown, stochastic rewards; within a fixed number of pulls, it must adaptively explore and exploit (e.g., via Thompson Sampling or UCB) to maximize total reward and then report the inferred best arm and its estimated success rate. The agent must handle randomized seeds, noisy observations, and persist state to resume if interrupted.",,
7908fc3e-bb97-44ce-864e-65143469ef6e,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,"Play repeated rounds of a generalized Monty Hall game via a CLI where the host’s door-opening policy is unknown and possibly biased; after each reveal, decide whether to stay or switch to maximize win rate. Learn and update a probabilistic model of the host to adapt strategy, then write the estimated host parameters and final win rate to /app/results.txt.",,
aeed6c52-03bf-4918-8b99-235e91ee279a,Interactive Challenges & Games,Text-Based Games & Puzzles,Adventure & Exploration Games,"Launch a terminal adventure, The Teleporting Labyrinth, where rooms connect via rune-marked pads with non-obvious transitions; explore to learn glyph rules, collect three keystones in the correct order, and unlock the Central Gate. Upon success, capture the exact final inscription shown and write it to /app/answer.txt.",,
1f080de7-29a1-45d8-a061-0cf4f7f16658,Interactive Challenges & Games,Text-Based Games & Puzzles,Adventure & Exploration Games,"Launch the provided Wumpus-style cave adventure and interact via text commands to explore rooms, infer hazards from sensory cues (e.g., breeze/stench), and locate the Wumpus. Kill the Wumpus with limited arrows and escape alive, then write the inferred cave graph and your exact action transcript to the specified output files.",,
0fef431c-1356-469b-bf4a-ed4db70b94f5,Interactive Challenges & Games,Text-Based Games & Puzzles,Adventure & Exploration Games,"Play a terminal-based time-loop mystery where the facility resets every 10 in-game minutes, altering NPC schedules and door states. Across multiple loops, navigate rooms, cache items in persistent lockers, infer patterns from logs, and assemble a 6-symbol code to trigger the final shutdown and escape.",,
4fe897df-62f8-482d-a7aa-9eb5b7bcc4ec,Interactive Challenges & Games,Text-Based Games & Puzzles,Escape Room & Challenge Scenarios,"Escape a locked research facility via a simulated command console: probe subsystems, parse scattered logs, and solve layered ciphers (base64, Vigenère, and a custom keypad code) to restore power, calibrate sensors, and enter the final passphrase. The agent must deduce the correct action order and submit the passphrase to unlock the exit and write the confirmation token to /app/escape.txt.",,
67b8d7b1-5cdd-4314-9aec-d4b006d63ebc,Interactive Challenges & Games,Text-Based Games & Puzzles,Escape Room & Challenge Scenarios,"Explore a haunted Git repository where branches, tags, and orphaned objects act as rooms, with clues hidden in commit messages, notes, reflogs, and blob deltas. Reconstruct a three-part key using low-level git plumbing and feed it to a provided door CLI to unlock and write the final exit token to /app/exit.txt.",,
7b726ce4-932e-417e-aaec-2373128bad49,Interactive Challenges & Games,Text-Based Games & Puzzles,Escape Room & Challenge Scenarios,"Navigate a git-based escape room where each room is a branch and doors open by resolving crafted merge conflicts that conceal ciphered codes, with clues hidden in commit messages, tags, notes, and diffs. Progress through the repository to reach the final release tag, decode the ultimate passphrase, and write it to /app/answer.txt.",,
8bbfceb5-7ac4-40b1-b235-ae97c4e28c84,Interactive Challenges & Games,Text-Based Games & Puzzles,Escape Room & Challenge Scenarios,"Navigate a terminal-driven escape room with a mock OS and devices (keypad, radio, safe) where clues are hidden across system logs, in-game tools, and a live numbers-station stream. Use shell pipelines to decode layered ciphers (hex -> XOR with a key inferred from artifacts -> base32) and assemble the final passphrase to unlock the exit.",,
13e8ca5d-0be6-43be-b38e-1ecd2e21014a,Interactive Challenges & Games,Text-Based Games & Puzzles,Word & Pattern Games,"Create an agent to play a multi-round Regex Golf terminal game: for each round, synthesize a single POSIX ERE that matches all ‘in’ words and none of the ‘out’ words within a length budget by iteratively querying a validator binary. Output the final winning patterns for all rounds to /app/answers.txt.",,
d1dd455d-7e9c-4dc3-8ea4-be8485476152,Interactive Challenges & Games,Text-Based Games & Puzzles,Word & Pattern Games,"Interact with a terminal-based Regex Golf engine that provides positive and negative word lists per level; craft a single PCRE regex per level that matches all positives and none of the negatives within a character budget, iterating based on feedback until the level passes. Output the final regex for each level, one per line with its level number, to /app/solutions.txt.",,
83f2aa0c-ab74-42bd-9e69-af94cbc9774d,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Launch gdb on the provided 'vault' ELF, interactively identify the password check routine, patch the branch condition in-memory to bypass it, run the program to reveal the secret, and write the token to /app/flag.txt. Do not modify the binary on disk; all changes must occur live in the debugger.",,
e20cb93e-75c0-4990-a0d1-738abdca9278,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Load the provided stripped ELF into gdb, set breakpoints to inspect the password-check routine (disassemble/step/examine memory) and recover the required passphrase or live-patch the check to reveal the computed token. Execute the program to its success state and write the exact success banner to /app/answer.txt.",,
2482f393-cd7b-49b6-9f35-b7456cfb3757,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Use the Python debugger (pdb) to load a protected script, set breakpoints to inspect the call stack and variables, and live-patch values/functions to bypass randomized checks. Continue execution to reveal the secret token and write it to /app/answer.txt.",,
96f41e47-b750-4ff0-b213-1b155aa12819,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Using the GNU Debugger (gdb) REPL, attach to and analyze the provided /app/lockbox binary, intercept its credential check (e.g., via breakpoints on strcmp) to recover the correct unlock token, then rerun the program to reveal the secret and write it to /app/flag.txt.",,
d4923f5d-c4dc-4d7a-8c71-d2dc06f2a54a,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive Tool Learning,"Analyze an unknown ELF binary using radare2’s CLI (r2, pdf, afl, aec, izz, etc.) to locate the input check routine and recover the exact passphrase that reveals a secret when the program is run. Run the binary with the recovered input and write the secret output verbatim to /app/answer.txt.",,
851ac4a3-226a-4bde-9849-d782a1a0d381,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive Tool Learning,"Use radare2 to recover a hidden passphrase from a deliberately obfuscated, stripped ELF in /app/bin using only r2’s analysis and debugging features. Consult r2’s help/man to identify the validation routine, step/trace to derive the correct input, then run the binary with that input and write the exact success banner to /app/flag.txt.",,
50f760a1-ab18-4bc6-b9b4-c1485abc05c4,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"Aggregate mixed-format logs (CSV, JSON, Apache) scattered in nested compressed archives and directories, then correlate timestamps and locations using only shell pipelines (find/grep/awk/jq/sort) to invalidate alibis. Identify the single culprit and write their username to /app/answer.txt.",,
e1a3a086-08f6-4a19-93ad-920bed84cb53,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"Recover a hidden release key by streaming through a labyrinth of nested archives and mixed-format shards, normalizing CSV/TSV/JSONL on-the-fly, key-joining records, and verifying order with checksums using a single shell pipeline. No intermediate files are allowed; write the final key to /app/results.txt.",,
c15ebdd3-59d8-4013-84c3-80811771c0ed,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"Starting at /app/maze/start, traverse a symlink-based filesystem maze where each encountered file contains JSON giving a regex for the next filename plus a token fragment and sequence number. Using only shell tools (find, sed/awk, jq, sort), detect and avoid cycles, collect and order fragments, then base64-decode and gunzip the concatenated string to plaintext and write it to /app/answer.txt.",,
f7d04b05-7d5a-4fb8-acab-ea8fc0ea58b5,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"Traverse a directory tree containing mixed-format event fragments (logs, JSON, CSV, and filename-encoded timestamps), some nested in unlabeled archives, and normalize their heterogeneous timestamps (RFC3339, epoch ms/nanos, DOY, base36) using shell tools. After deduping by event id and globally sorting, extract one character per event to reconstruct the hidden message and write it to /app/message.txt.",,
ad738dde-56c7-4279-a00d-9147dd6d6f34,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Open lazygit in the provided Git repo and resolve a pending merge by choosing “theirs” for config/app.yml and accepting only the first two conflicting hunks from “ours” in src/core.py, then finalize the merge with the supplied message and exit. After leaving the TUI, write the resulting HEAD commit SHA and the total count of remaining conflict markers (<<< or >>>) in the repo to /app/answer.txt.",,
0173c5be-d3b2-425d-bcef-168649ab9184,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Open the provided mixed CSV/JSONL dataset in the VisiData TUI, interactively filter to completed EMEA orders in Q3 2024, join users to orders, group by user, compute total spend, sort descending, and export a 2‑column TSV to /app/report.tsv. All data manipulation must be performed inside VisiData via keyboard-driven operations, then exit cleanly.",,
7b7bde3a-310a-4184-bb32-bf320ea05a7d,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Use the tig ncurses Git interface to locate the first commit that introduced a target function signature and determine the first tag that contains it by navigating log, search, and blame views. Record the exact commit SHA and tag name to /app/results.txt as 'SHA TAG' after exiting the TUI.",,
04f6f0f4-9f1e-4a1f-a001-6be5713a256c,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Using the lazygit TUI, resolve a prepared merge conflict by selectively staging hunks to restore a passing implementation, commit with the exact message 'merge-fix: OK', and push to the provided local bare remote. After the test suite passes, write the resulting commit SHA to /app/result.txt.",,
d2a9fdde-9c92-4984-aa1b-d508269855f2,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Using the visidata TUI, open /app/orders.csv and interactively create a pivot grouped by region and product_category for orders in 2023-Q4, calculating total_revenue and order_count, then sort by total_revenue descending and export the result to /app/summary.tsv. Also write the single top row of that pivot (tab-separated) to /app/top.txt.",,
edd6489e-82f8-402e-81d1-2b583f8b839a,Interactive Challenges & Games,Text-Based Games & Puzzles,Adventure & Exploration Games,"Build a Python interactive escape-room simulator at /app/escape_mansion.py where an agent issues stdin commands to navigate a procedurally generated mansion, collect items, decode riddles, unlock sealed doors, and find the hidden exit within 100 moves. The harness verifies correct room transitions, inventory actions, puzzle solutions, and final escape sequence.",,
88e0d678-4fc1-4003-a49d-feaf6c0da3a5,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Adversarial Game Environments,"Implement a Python ColonelBlottoAgent in /app/output/blotto_agent.py that defines class ColonelBlottoAgent with allocate_troops(total, battlefields, history) returning a legal distribution vector over battlefields. The agent must run under 1 ms per move, stay under 10 KB of code, and win at least 80% of matchups against random and heuristic opponents across varied troop and battlefield counts.",,
78e1873c-f5c4-47c7-821c-5e9096a91111,Interactive Challenges & Games,Strategy & Reasoning Games,Board & Turn-Based Games,"Implement a high-performance Python Ultimate Tic-Tac-Toe agent exposing class UltimateTTTAgent.next_move(global_board, active_board) that, using only numpy/numba and no I/O, selects moves to achieve ≥90% win rate against random and depth-1 minimax opponents across varied board configurations. The solution must average under 10ms per move and be written to /app/output/ultimate_ttt_agent.py.",,
aa5aaaac-d5a8-40b9-a61e-65422e358793,Interactive Challenges & Games,Strategy & Reasoning Games,Board & Turn-Based Games,"Implement a Python Mancala agent saved to /app/output/mancala_agent.py that defines class MancalaAgent with select_pit(board) returning a legal pit index, handling extra turns and captures with an alpha-beta search and heuristic evaluation; the agent must use only numpy, avoid file I/O, average under 10 ms per move, and win ≥90% against a basic minimax opponent.",,
956d8a64-259b-4b32-8cf7-abf14e693b5d,Interactive Challenges & Games,Strategy & Reasoning Games,Board & Turn-Based Games,"Implement a fast Gomoku (five-in-a-row) agent module at /app/output/gomoku_agent.py that defines a GomokuAgent.select_move(board) method returning a valid (row,col) move using pattern-based heuristics or search. The agent must win at least 90% of games as first player and 80% as second against a provided basic opponent on a 15×15 board, averaging under 20 ms per move and fitting within 50 KB of code.",,
8b35f089-3155-4719-b367-41d3a6a79a8b,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Collaborative Simulations,"Implement a cooperative terminal-based kitchen simulation agent that works alongside a scripted sous-chef to fulfill incoming meal orders under strict time limits by issuing move, chop, cook, and assemble commands. The AI must maximize orders completed across varied recipes by optimally assigning tasks, timing actions, and coordinating with its partner.",,
73f94be5-154c-4e69-897c-57cbad9a2f89,Interactive Challenges & Games,Interactive Education & Learning Tasks,Command Discovery Quests,"Navigate a sandboxed labyrinth of directories where each folder contains cryptic hints pointing to Unix commands or flags; use man pages, --help, and grep to discover and execute the correct commands to unlock the next directory and ultimately reveal the hidden passphrase.",,
344e0d07-4d49-462a-9a50-69dccbcba4a6,Interactive Challenges & Games,Interactive Education & Learning Tasks,Command Discovery Quests,"Agent explores $PATH to discover custom text-transform utilities, inspects their --help output to infer usage, and assembles a pipeline that compresses, encrypts, and Base64‐encodes a given file, writing the final result to output.txt.",,
b787757b-29c5-4149-aba2-d107a706f05d,Interactive Challenges & Games,Interactive Education & Learning Tasks,Command Discovery Quests,"Build a Python harness at /app/quest.py that sequentially prompts for shell commands to list block devices, check disk usage, display open/listening ports, show the routing table, list logged-in users, and report system uptime. The agent must discover and submit the correct commands (using man, apropos, help, etc.); the harness executes each, compares its output to expected results with unified diffs on mismatch, allows retries, and writes the final correct commands to /app/solutions.json.",,
3929e872-b25f-4061-ab2e-991b8296f932,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Debugging Under Constraints,"A buggy Python CLI Minesweeper script miscalculates neighbor mine counts and crashes on edge cells; the agent must debug using only diff, patch, and at most five hunk-based modifications to make all provided tests pass.",,
712d8ddf-7072-40c4-8a6e-af5f92a36a57,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Debugging Under Constraints,"Debug a prepackaged Python log parser that misparses timestamps, user IDs, and error codes, using only grep, sed -i, and pytest within five CLI iterations to ensure all provided unit tests pass.",,
caf3c13e-b28b-44ff-9bef-8a74683ace37,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Dynamic Difficulty Adjustment,"Create a Python CLI maze solver that navigates a sequence of procedurally generated ASCII mazes via N/S/E/W commands. After each success the harness increases maze dimensions and adds obstacles or timed traps, while failures decrease complexity; the agent must adaptively solve ten mazes in succession.",,
db25a979-fbe9-4e99-a68a-afbf2efc59ba,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Dynamic Difficulty Adjustment,"Interact with the adaptive text-based Dungeon Master via /app/dungeon_master, where room layouts, puzzles, and monster behaviors dynamically scale in complexity based on your success rate. Navigate to retrieve the Forge Key, Crystal Skull, and Phoenix Feather, then escape and write their ordered names to /app/escape_note.txt.",,
90bac5a7-c590-4401-9670-c0d5e8cccacb,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Dynamic Difficulty Adjustment,"Implement a Python CLI maze-solving agent at /app/output/maze_agent.py that reads ASCII mazes from stdin and outputs move sequences to solve within 1.5× the optimal path length. The test harness dynamically increases maze size, obstacle density, and novel trap mechanics after each success—and reduces complexity on failure—to evaluate the agent’s adaptability across ten escalating difficulty tiers.",,
32fcfbca-777c-41f3-a319-5929b24219bc,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Control a simulated Mars rover in a text-based 20×20 grid with varying terrain costs and randomly placed science targets; the agent must issue movement, scanning, and sample-collection commands to gather all samples and return to base before battery depletion.",,
27b4e612-c833-4581-b020-a5b1c81e5134,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Implement a Python vacuum agent at /app/robot.py that uses /app/harness.py to explore an unknown 2D grid with obstacles and limited sensor range, clean all marked dirt cells, build an internal map, and avoid traps. The agent must output both the discovered map and its cleaning route to /app/solution.json while keeping its total moves within 150% of the optimal path length.",,
1c471491-9a75-4b03-a1f8-6108d801c8a6,Interactive Challenges & Games,Interactive Education & Learning Tasks,Error Interpretation & Correction Games,"Build a Python harness at /app/harness.py that iteratively presents five C source files under /app/roundN.c, each containing a specific compile-time or runtime bug. The agent must submit corrected code that compiles under -Wall -Werror and produces expected outputs, with the harness showing compiler errors or output diffs on failure and saving all patches to /app/fixes.zip upon success.",,
aa88da86-5031-4d4e-b699-90faad301729,Interactive Challenges & Games,Interactive Education & Learning Tasks,Error Interpretation & Correction Games,"In a Docker sandbox, a multi-module Python project with pytest tests fails due to a sequence of syntax, import, and logic errors. The agent must iteratively analyze failure outputs, correct each bug in the source, and achieve a fully passing test suite.",,
fef46ec1-85b6-493c-8c19-2b14c5f265a1,Interactive Challenges & Games,Interactive Education & Learning Tasks,Error Interpretation & Correction Games,"Provide a Docker Compose project with several services intentionally misconfigured (e.g. broken environment vars, port conflicts, volume permission errors and missing dependencies). The agent must inspect container logs and iteratively correct compose files, Dockerfiles and service configurations until docker-compose up runs without errors and all integrated health checks pass.",,
9c979b02-01d0-4c6e-b3dd-3d9e59bbe439,Interactive Challenges & Games,Interactive Education & Learning Tasks,Error Interpretation & Correction Games,"Sandbox contains a Node.js web app and an intentionally broken Dockerfile that fails to build or run due to dependency and configuration errors. Agent must interpret build and runtime error logs, iteratively correct the Dockerfile and application code, then rebuild until the container launches and passes HTTP endpoint tests.",,
839e4594-73b4-4495-b54e-431571c3ffb0,Interactive Challenges & Games,Text-Based Games & Puzzles,Escape Room & Challenge Scenarios,"Interact with /app/museum_heist to explore four themed galleries, decode a hex-dumped inscription, reverse a Caesar-shifted security log, and apply bitwise transformations to hacker terminals to assemble four colored keycards. Use netcat to connect to a hidden service and retrieve the final vault code, writing it to /app/answer.txt.",,
64727b45-8789-4a73-8888-c6bc4c88e0f0,Interactive Challenges & Games,Text-Based Games & Puzzles,Escape Room & Challenge Scenarios,"Navigate the Arcane Library simulation at /app/arcane_library.py by issuing directional and interaction commands to uncover hidden tomes, solve page-based ciphers, and operate a magical printing press. Produce /app/route.txt with one command per line (≤75 turns) to retrieve the final incantation and write it in uppercase to /app/manuscript.txt.",,
9da7acc9-cd9c-4781-bb18-138d7fad0de6,Interactive Challenges & Games,Text-Based Games & Puzzles,Escape Room & Challenge Scenarios,"Navigate a simulated file-system maze where each directory represents a room with puzzle files; use command-line tools (grep, sed, awk, gpg, etc.) to extract codes, decrypt clues, and unlock the next room. Complete all stages by chaining shell commands and scripts to ultimately retrieve and display the final escape key.",,
5a24c8c2-9aac-454f-8bb8-9f016399427d,Interactive Challenges & Games,Text-Based Games & Puzzles,Escape Room & Challenge Scenarios,"Interact with a provided ‘Mystic Library’ text adventure, using terminal tools like hexdump, strings, and openssl to decode hidden cipher scrolls scattered across rooms, solve four sequential puzzles, and write the final vault passphrase to /app/passphrase.txt.",,
9bbb2315-513e-4ace-9c63-bf701dc8a966,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Exploit & Reverse Engineering Games,"Reverse-engineer the /app/vuln_vm binary that implements a custom stack-based bytecode VM, then craft a malicious bytecode payload to hijack control flow, bypass its authentication check, and print the hidden FLAG. Use the provided interactive harness at /app/harness.py to iteratively test and submit your payload as /app/exploit.bin.",,
1a7d0ded-8693-493f-99bd-9cc7beb8d89f,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Exploit & Reverse Engineering Games,"Bundle a stripped 64-bit binary in /app/vuln that interactively prompts for a username and token and then leaks its stack canary; the agent must reverse engineer the binary via standard terminal tools to discover ROP gadgets and craft a base64-encoded payload that invokes system(""cat /flag""). Upon success the agent writes the exploit to /app/exploit.b64.",,
783c51c2-b5b3-4119-b497-217fa7a92832,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Exploit & Reverse Engineering Games,"Analyze the /app/bf_sandbox Brainfuck interpreter to reverse-engineer its hidden buffer underflow vulnerability, then craft a Brainfuck program that escapes the sandbox and prints the secret flag. Write the exact flag string to /app/flag.txt.",,
84230560-65ec-4f50-b329-a49a33f92dd2,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Exploit & Reverse Engineering Games,"Interactively analyze a provided ELF ‘vault’ binary to discover and exploit a buffer overflow and format-string vulnerability, leaking the secret passphrase using gdb or strace. After successfully unlocking the vault, write the extracted passphrase to /app/flag.txt.",,
54857356-a38a-4763-b575-fa98fffd3d3b,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Goal Discovery & Hidden Objective Games,"Implement a Python solver at /app/agent.py that interacts over STDIN/STDOUT with the provided Mastermind harness (/app/harness.py), inferring a hidden 4-color code via black/white peg feedback within six guesses and writing the guess sequence to /app/solution.json for validation.",,
6c3ab004-4cf8-4232-8083-4dd45ff6abf7,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Goal Discovery & Hidden Objective Games,"Use the interactive text-adventure harness at /app/harness.py to explore an enchanted ruin, inspect artifacts, and converse with spirits that drop cryptic hints. Infer and enact the unstated objective of reassembling the Celestial Orb by collecting and placing elemental shards in the correct order and write the action sequence to /app/solution.json.",,
023dc62e-5bcd-435f-ab32-b1c7112c05be,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Goal Discovery & Hidden Objective Games,"Run /app/rune_maze and explore a grid of cryptic rooms emitting puzzle hints with no stated goal; infer from changing inscriptions that you must activate three elemental pillars in ascending power sequence, then write the final portal code to /app/answer.txt.",,
1b10bfda-d0cd-43a0-b92e-ebb5f9feba20,Interactive Challenges & Games,Strategy & Reasoning Games,Interactive Optimization Problems,"Develop a Python TSPAgent that, given the current tour and distance matrix via an interactive harness, proposes city‐swap moves to iteratively minimize total length. Within 2000 swaps it must reach ≤1.5% above the known optimum on a 100-city instance, using only numpy/numba, no external I/O, and staying under 25 KB.",,
eb323c8a-6ddd-4950-b036-ef7854f696dd,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,Implement a randomized smoothing defense wrapping a pretrained CIFAR-10 ResNet18 with configurable Gaussian noise to certify predictions under L2 adversarial budgets. The CLI must also generate PGD adversarial examples to measure empirical robustness and write certified and empirical accuracy metrics to results.json.,,
21b7b726-fd28-4955-aa6d-ee1d89c2e9b8,Interactive Challenges & Games,Strategy & Reasoning Games,Interactive Optimization Problems,"Implement a Python class OnlineBinPackingAgent with an assign(item_size) method that interactively reads item sizes from stdin and outputs a bin index or new bin decision to minimize total bins used. The test harness will feed multiple randomized item streams, enforce tight per-decision latency, and score the agent on average bin utilization under varying distributions.",,
856f9719-5342-479a-9d7b-2a149aff3ac3,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,Create a Python agent at /app/predator_prey_agent.py that interacts with a provided harness to control a predator–prey cellular automaton by issuing add/remove commands for wolves and sheep each generation and reading the updated grid. The agent must keep the predator-to-prey ratio within a target range for 100 consecutive turns using only the harness API and no external I/O.,,
73ac681e-95a0-4f86-a549-4ff989bb1c39,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"In a 2D heat‐diffusion sandbox with random initial temperatures, the agent selects one grid cell per timestep to activate a heater under a global energy budget and must drive the entire grid to a uniform target temperature within a fixed number of steps. The solution must interact via the CLI, reading the grid state each turn and outputting heater coordinates while respecting performance and budget constraints.",,
1b52da74-b648-4c39-8049-c9646796f2fd,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Create a Python CLI agent that, given an N×N Conway’s Game of Life grid and a target pattern, interactively places up to K live cells each generation (or passes) to evolve the automaton into the goal shape within M steps, then outputs success or failure.",,
a0d5e6c4-6399-46e7-a8a4-782a567d2234,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Interactively use the Python REPL on /app/crypto_challenge.py to inspect its RSA parameters, factor the provided modulus using only standard libraries or sympy, compute the private exponent, decrypt the ciphertext, and write the recovered ASCII message to /app/flag.txt. No file writes other than the flag are permitted and all work must occur within the REPL session.",,
fc84c8db-0247-4f2b-8527-b7fb9f8d4cc2,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Launch the provided sieve.py under Python’s pdb, step through and identify the off-by-one error in the sieve_of_eratosthenes implementation, interactively patch the function in the REPL, verify it outputs all primes up to 100, and save the corrected script to /app/sieve_fixed.py.",,
b0e4600c-5084-4880-9a5d-2262e8debfb8,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Launch the Python debugger (pdb) on the provided /app/cipher_app.py and set breakpoints at the encrypt/decrypt functions to inspect and modify the in-memory key variable. After decrypting the hidden message, write the plaintext to /app/output/secret.txt and save the pdb command sequence in /app/output/session.log.",,
69502798-bb80-4eda-8e33-291dc5d9daf9,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Launch the sqlite3 interactive shell on /app/words.db, write and run SQL (plus .mode and .output meta-commands) to select the 10 longest palindromic entries from the words table, ordered by length descending, and export them with headers to /app/palindromes.csv, then quit the REPL.",,
9a743a14-e12f-4fe4-a8bf-d98fbc38c5ac,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive Tool Learning,"Given a CSV file of global sales data at /app/data.csv, use the xsv command-line toolkit (consulting its help/man pages) to filter rows with sales > 1000, sort by region descending, select only the ‘region’ and ‘sales’ columns, and write the output to /app/results.csv using exclusively xsv subcommands.",,
985572c3-24c6-451a-a954-a6733c0e0dea,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive Tool Learning,"Using pandoc’s CLI (consulting --help or man), convert the supplied Markdown file with YAML metadata into a PDF with a title page, depth-2 table of contents, custom LaTeX template, and embedded fonts, saving to /app/output/report.pdf.",,
b3036238-e066-4883-a1ad-3c0bf22ac599,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive Tool Learning,"Use the dasel CLI to load /app/config/settings.toml, mutate nested values (double limits.timeout, append ""feature_x"" to features.enabled, set database.port to 5432), then export the resulting configuration as JSON to /app/output/config.json.",,
f2cfc88e-a7a0-4319-8a3e-b1fefc4fec4c,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive Tool Learning,"Given a nested transactions.json file, use the jq CLI tool (consulting its manual) to filter all 2023 records, group by user_id to sum transaction amounts, sort the sums in descending order, and save the top 10 users to /app/output/top_spenders.csv in CSV format.",,
0c5ea816-e8ba-4768-bc7c-16f897ace907,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Live Coding Challenges,"Implement a Python function 'topo_sort(graph)' that returns a valid topological ordering for a given directed acyclic graph represented as an adjacency list, with O(V+E) time complexity. The interactive harness will test your code on random DAGs and expect a ValueError for cyclic inputs.",,
7caa0acd-18e2-4552-bb66-50c32eae7a29,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Live Coding Challenges,"Write a mini regular-expression engine in Python (/app/regex_engine.py) that supports literal concatenation, alternation '|' and Kleene star '*', exposing a match(pattern, string) function. The provided CLI harness will run randomized pattern/string tests with instant pass/fail feedback until your implementation passes a full suite of unit tests covering nesting, precedence, and edge cases.",,
c09f1bc8-4cf7-4dcd-a774-78f227ba3ed4,Interactive Challenges & Games,Interactive Programming & Debugging Challenges,Live Coding Challenges,"Use the interactive harness at /app/harness.py to iteratively craft concise Python implementations of edit_distance(s, t) under a strict character limit, passing multiple automated rounds of Levenshtein testcases and writing the validated solutions to /app/answers.txt.",,
8e047e3d-6efd-4d42-bd05-ed0577acec34,Interactive Challenges & Games,Text-Based Games & Puzzles,Logic & Math Puzzles,"Implement a Python CLI Mastermind solver agent saved to /app/output/mastermind_agent.py exposing class MastermindAgent.next_guess(history) that, given a list of prior 4-peg guesses and their (black, white) feedback, returns the next guess. The agent must crack random codes in an average of ≤5 guesses across 1000 trials, averaging under 1 ms per move and using only numpy for computation.",,
d530fd45-cbcd-44d0-92ee-8402df9e0b8b,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Interact with a multi-stage network pentesting simulator—discover open services, craft and deploy exploits, escalate privileges, retrieve encrypted secrets, and purge audit logs under a strict command budget, with the environment adapting dynamically to your tactics. Produce /app/loot.txt containing recovered secrets and /app/timeline.txt logging each command executed.",,
55dc23c6-d537-43f9-ac4c-823b9fd2ccb2,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Implement a multi-phase terminal treasure hunt game where the agent first navigates a hidden directory maze with shell commands to locate clue files, then deciphers those clues using UNIX text utilities and simple cryptography, and finally completes a simulated network handshake challenge by crafting and sending packets with netcat. The harness dynamically adjusts puzzle complexity based on the agent’s performance, enforces timeouts for each phase, and records all successful commands and answers to /app/results.json.",,
c91b2d29-aa73-4c81-80b1-2e2c41cbc2d2,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"In a dockerized three-host network, enumerate services, brute SSH using a rotating wordlist to compromise a print server, pivot to a database host to retrieve a secret flag, and exfiltrate it via an HTTP POST to a simulated C2 endpoint. Host configurations, open ports, and credentials change on each run, requiring adaptive tool use and multi-step planning.",,
852470db-20bd-47f2-9929-128a5b4cb2c8,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Simulate a corporate network intrusion where the agent must sequentially perform reconnaissance, analyze compromised services, isolate infected hosts, and deploy patches via a CLI interface. The sandbox dynamically escalates threat complexity based on the agent’s successes or mistakes, demanding long-horizon planning and adaptive reasoning.",,
2c2ffab9-ecc7-408b-aff1-ba6c00af4b1a,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Implement a Python CLI negotiation agent that interacts with /app/car_dealer_sim to buy a car within a fixed budget. The agent must adapt its offers over at most 8 turns to various dealer concession strategies, achieving an average discount of at least 15% off list price across 20 runs, and write the final agreed price and dialogue transcript to /app/negotiation.txt.",,
f85c695f-abd8-45c3-8924-8535d16ab5b8,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Build a Python negotiation agent at /app/deal_agent.py that interactively negotiates a multi-issue contract (price, warranty, delivery) with a simulated vendor via STDIN/STDOUT over a fixed number of rounds, adapting to opponent concessions to maximize joint utility. The test harness randomizes the vendor’s hidden utility weights and requires the agent to reach a normalized joint score ≥0.8 within 10 exchanges.",,
95efe220-bce3-4989-9ac1-a90cb6f30c24,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,"Implement a Python BattleshipAgent at /app/output/agent.py that defines shoot(history) to choose grid coordinates (row,col) for the next shot. The agent must use Monte Carlo sampling over all valid ship placements consistent with past hits and misses to estimate hit probabilities and average under 60 moves to sink a standard 10×10 fleet over 100 random boards.",,
3f19cc0f-3e28-4027-a306-d0100021ed1d,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,Implement a Python agent that plays standard Battleship against hidden random ship layouts by maintaining and updating a probability heatmap to choose each guess. The agent must sink all ships within an average of 60 moves over 1000 random placements and complete a full game in under 2 seconds.,,
75a4e653-9eb6-4f54-9db6-9426090934ff,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,"Build a Python solver that interacts with /app/harness.py to play standard 4-peg 6-color Mastermind by submitting guesses and processing (black, white) feedback, employing an optimal minimax strategy to solve each secret code within five guesses; after running through a randomized set of codes, record the average number of guesses and each code’s guess sequence to /app/solutions.json.",,
3c4008be-1602-4e41-a48c-a75e5fd3bdd1,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,"Implement a Python agent at /app/output/minesweeper_agent.py defining class MinesweeperAgent with next_move(board) returning (action,row,col) where action is 'reveal' or 'flag'; the agent must use deterministic inference and probabilistic reasoning to clear random 16×16 boards with 40 mines, achieving ≥90% success over 500 games while averaging under 5 ms per move without any I/O.",,
daa39340-1f07-479e-aafe-a8aa98d413b4,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,"Create a Python script that non‐interactively plays the provided terminal‐based Minesweeper CLI on a 16×16 grid with 40 mines by issuing open/flag commands via stdin; use constraint propagation and probabilistic inference to guide moves and achieve at least a 90% win rate over 100 fixed‐seed boards, writing the final revealed board state to /app/solution.txt.",,
c713c508-69b2-4562-8ac7-2f34b942909a,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,Exploit a misconfigured JWT verification flow vulnerable to HS/RS algorithm confusion by crafting a forged admin token to access a protected API and read /app/flag.txt. The task validates payload delivery by confirming elevated access and can be extended with a code/config hardening fix.,,
376fea5f-efb0-4884-8b4a-9a0a442ae325,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Exploit an unsafe YAML deserialization endpoint in a Python microservice that uses yaml.load on user input to achieve remote command execution. Craft and deliver a payload from the terminal that writes /tmp/pwn1, /tmp/pwn2, and /tmp/pwn3 and verifies their creation.",,
9bf447aa-010e-4323-92d9-f2983b1fa715,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,Design a command-line workflow that uses masscan for fast discovery and nmap (with select NSE scripts) for deep enumeration to build a complete inventory of open TCP/UDP ports and service metadata across a provided 172.20.0.0/24 sandbox network. The tool should fall back to netcat banner grabs when NSE is inconclusive and write a normalized JSON report to /app/scan.json plus a brief human summary to /app/REPORT.md.,,
f9adbd14-6587-400a-9039-19bf9f3b9bbf,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,"In a dual-stack (IPv4/IPv6) sandbox with multiple interfaces, perform comprehensive TCP/UDP scanning to enumerate open ports, service versions, and TLS SNI/ALPN-based virtual hosts using nmap, masscan, and netcat. Extract a port-knocking sequence from a discovered banner to temporarily expose a hidden management port and produce a structured report of all findings.",,
ef864d29-2387-47cd-a582-fea3aafd5cf3,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,"Scan node1 and node2 for open TCP and UDP ports using masscan or nmap, then perform service enumeration (nmap -sV/-sC plus banner grabs with netcat/curl) to capture service names, versions, HTTP titles, TLS certificate CNs, and SSH key fingerprints. Produce a deduplicated, host-and-port-sorted JSON report at /app/scan_results.json summarizing all discovered endpoints and metadata.",,
2a5817f7-ad3b-4a66-80e0-afebbcd030c3,Interactive Challenges & Games,Interactive Education & Learning Tasks,Progressive Learning Environments,"A ten-stage shell data-wrangling tutorial where each level presents a dataset in a different format (plain text, CSV, JSON, XML, etc.) and requires you to submit a single-line pipeline (using grep, sed, awk, jq or xmlstarlet) under a strict character budget; on success the harness logs your command and unlocks the next exercise.",,
dc075298-4057-4eed-a543-c04f16c97e04,Interactive Challenges & Games,Interactive Education & Learning Tasks,Progressive Learning Environments,"Implement a multi-stage CLI-based Git learning game where each level tasks the agent with accomplishing specific Git operations (e.g., init, branching, merging, conflict resolution). Automated tests verify the repository state before unlocking increasingly advanced levels like rebasing, bisect debugging, hooks, and submodule management.",,
34597cb7-3e47-4d94-a986-791d743cc066,Interactive Challenges & Games,Interactive Education & Learning Tasks,Progressive Learning Environments,"Implement an interactive multi-level Git workshop CLI where each level presents a hidden repository state and a target state; the agent must issue correct git commands to transform the repo and, upon matching the target state, unlocks the next level.",,
5c0fe062-41c9-4ac4-9947-caeeb66715db,Interactive Challenges & Games,Interactive Education & Learning Tasks,Progressive Learning Environments,"Create a Python 3 interactive shell-pipeline dojo at /app/pipeline_dojo.py that guides the user through eight sequential levels, each presenting sample input and an expected output. For each level the agent must submit a one-line shell pipeline using standard Unix tools, see diffs on mismatch, retry until correct, and record all successful pipelines in /app/solutions.json.",,
74dbbe43-f190-4352-9783-8ee88ae20be0,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Use the /app/grid_sim.py CLI tool to deploy and configure generators, storage units, and transmission lines to meet dynamic 24-hour power demand across three zones under budget and emission limits. Aim to minimize total cost without causing any outages, then save the final configuration and metrics in /app/solution.json.",,
b120c147-aac0-42de-803c-b5726f552adf,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"Chain-decode a series of BASE64-encoded, gzip-compressed files (e.g., level1.b64 → levelN.b64) using only bash builtins, base64, gzip, and coreutils to extract the final plaintext flag into /app/flag.txt.",,
c3faadcc-2f6f-4ec9-bfda-111dd2c2cbb3,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"Reassemble scattered base64-encoded, gzipped JSON fragments from numbered part files in nested hex-named directories, then decode and extract the JSON objects; filter those with prime 'id's below 1000, sum their 'value' fields, and write the total to /app/output/result.txt using only shell tools.",,
4481c04b-ca3e-4b03-b260-655e779e8eec,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"The /app/puzzle/input.txt file holds a secret message that’s been transformed through layered hex encoding, gzip compression, ROT13, and base64 in an unknown order. Use shell utilities (xxd, gunzip, tr, base64, etc.) to infer and apply the correct reverse-decoding pipeline and output the original text to /app/output/secret.txt.",,
016eba79-1b40-444d-b799-2280f138fb69,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Build a Python controller script at /app/agent.py that uses the provided /app/harness.py to interact with a simulated microservice cluster where nodes randomly crash or partition. The agent must issue start, stop, and migrate commands to maintain at least three healthy replicas of each service and write a JSON recovery report to /app/deployment_report.json.",,
c77ab31e-66d1-40dd-ae33-09b1ae3e1ce7,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Provision a three-node Docker network comprising a router, web server, and client; configure IP routing and iptables on the router to permit only HTTP traffic from client→web and MySQL traffic from web→db while blocking all other flows. Verify services with curl and mysql-client from the client node, and write a summary of passed connectivity tests to /app/answer.txt.",,
c13b387e-f1e4-4ac5-a262-9259085b24ad,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"The agent must launch htop non-interactively, apply a filter for a provided process name, and sort by memory usage. It must then programmatically extract the top three PIDs and write them to /app/top_pids.txt.",,
d7722ad3-9ade-421f-8fdc-946982241984,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Use the ncurses-based websrv-config tool to configure a web server on port 8080 with SSL enabled and document root /srv/www via menu navigation and save the settings. Finally, verify the server returns a valid 200 OK response serving the expected test page.",,
4aceae92-80ed-4ad2-99fc-5e93877c8bc9,Interactive Challenges & Games,Text-Based Games & Puzzles,Word & Pattern Games,"Implement a Bash or Python solver script that interfaces with the provided Wordle CLI (/app/wordle.sh), issues guesses, parses colored letter-status feedback, and deduces each secret five-letter word within six attempts. Run the solver over 1000 fixed random seeds, record seed, target word, and attempts used for each game in /app/results.csv, and achieve an average of ≤4.5 guesses per word.",,
98b40764-004a-4c7c-9d37-a4efd3740fef,Interactive Challenges & Games,Text-Based Games & Puzzles,Word & Pattern Games,"Implement a Python agent that uses the provided dictionary to play a Word Ladder challenge via /app/harness.py, reading start and end words and outputting each intermediate valid word in sequence. The solver must find shortest ladders for 100 random 4–6-letter puzzles within 5 seconds total, then write all sequences to /app/solutions.json.",,
2c0d4b8a-2285-4939-9e92-80194e703474,Interactive Challenges & Games,Text-Based Games & Puzzles,Word & Pattern Games,"Create a Python Wordle solver that interacts with /app/harness.py to play multiple rounds of a five-letter guessing game, submitting each guess and parsing color-coded feedback to deduce the secret word within six tries per round. After solving all puzzles, write the guess sequences for each round to /app/solutions.json.",,
45d54a79-bd19-4b9c-ae4c-a832a52571c7,Interactive Challenges & Games,Text-Based Games & Puzzles,Word & Pattern Games,"Implement a self-contained Python GhostAgent saved to /app/output/ghost_agent.py exposing class GhostAgent with select_letter(prefix) that, given a fixed English word list, plays the word game Ghost (avoiding completing valid words ≥4 letters), achieves ≥90% wins against random or heuristic opponents, and averages under 5 ms per move using only numpy/numba.",,
7e616e02-80a3-403e-9b31-c310a2f337cb,Machine Learning & AI,Deep Learning & Neural Network Engineering,Training Stabilization Techniques,"Retrofit an unstable DCGAN training script to add spectral normalization to the discriminator, an R1 gradient penalty, adaptive global-norm gradient clipping, EMA of generator weights, and a cosine learning-rate schedule with warmup; train on a provided CIFAR-10 subset and write FID and Inception Score to /app/metrics.json, ensuring no NaNs and FID below a set threshold.",,
3c68563e-e1c5-44a2-9ddf-4dfc5c54095e,Machine Learning & AI,Foundation Models & Large-Scale Systems,Data & Model Sharding,"Implement a minimal ZeRO Stage-2 optimizer in PyTorch that shards Adam states and gradients across ranks, using reduce-scatter for gradient partitioning and on-demand all-gather of parameters for forward passes. Train a small model on synthetic data and verify numerical parity with an unsharded baseline, correct save/load of sharded checkpoints, and peak memory reduction for world_size 1, 2, and 4.",,
2a5a07d8-41e9-4810-b56b-47862ee64ec3,Machine Learning & AI,Foundation Models & Large-Scale Systems,Inference Optimization at Scale,"Export a BERT-base QA model to ONNX, build both FP16 and INT8 TensorRT engines (with calibration), and deploy them in NVIDIA Triton with dynamic batching and two concurrent instances. Benchmark with perf_analyzer over batch sizes {1, 8, 32} and write a JSON summary of latency/throughput and INT8 vs FP16 speedups to /app/perf_report.json.",,
9a4f3362-ce04-4654-b837-e3d64f65c578,Machine Learning & AI,Foundation Models & Large-Scale Systems,Inference Optimization at Scale,"Export a HuggingFace BERT-base encoder to ONNX, build FP16 and INT8 TensorRT engines with entropy calibration, and deploy both behind NVIDIA Triton Inference Server with a model repository configured for dynamic batching and multiple concurrent instances. Provide a CLI load generator to send large-batch requests, verify output parity vs. PyTorch within tolerance, and report throughput to demonstrate INT8 speedup over FP16.",,
c7b4fbb7-cb3d-4d57-a34f-b7095b48088a,Machine Learning & AI,Foundation Models & Large-Scale Systems,Large Model Fine-Tuning & Adaptation,"Build a CPU-only QLoRA fine-tuning pipeline for a small Hugging Face causal LM that can switch between LoRA and prompt-tuning via a CLI flag, training on /app/data/train.jsonl with sequence packing and evaluating perplexity on /app/data/valid.jsonl. Save adapter weights to /app/adapter and a merged full model to /app/merged, and write the final validation perplexity to /app/perplexity.txt.",,
90fe463e-a963-40f7-80d9-25fb7b2c3764,Machine Learning & AI,Machine Learning Pipelines & Automation,Experiment Tracking & Logging,"Create a Python CLI that runs 5-fold cross-validation with hyperparameter search, using MLflow to record a parent run and nested child runs per trial and fold with parameters, metrics, and artifacts (ROC/PR plots, confusion matrices, and serialized models). The CLI must support resuming by skipping completed child runs, produce an aggregated leaderboard.csv, and register the best model with signature and input example in the Model Registry.",,
1c06b42f-d94d-42b0-aaff-6bbf39928c04,Machine Learning & AI,Machine Learning Pipelines & Automation,Experiment Tracking & Logging,"Deploy an MLflow tracking server with a SQLite backend and a MinIO S3 artifact store behind an Nginx reverse proxy on localhost, then build a training pipeline that uses nested runs and autologging for both scikit-learn and PyTorch, logs SHAP artifacts, a model signature, and an input example, and registers two models with stage transitions. Add a script that queries MLflow for the best run by a validation metric, downloads its artifacts to run batch inference, logs predictions as a new artifact, and prints the chosen run_id.",,
e23f964c-12b1-410d-b716-90297594b95d,Machine Learning & AI,Machine Learning Pipelines & Automation,Model Registry & Versioning,"Build a local, file-backed model registry with a SQLite metadata store and content-addressable artifact storage, including a CLI to register versions, assign stage aliases (staging/production), and promote or rollback based on evaluation metrics. Provide an inference loader that consumes a lockfile to fetch a pinned version and verifies immutability and lineage.",,
0cdd2e52-7b6b-4fec-82f3-9698717e4dfe,Machine Learning & AI,Machine Learning Pipelines & Automation,Model Registry & Versioning,"Create a Python CLI that publishes trained models as OCI artifacts to a local Docker registry (registry:5000), storing model weights and a metadata.json layer with code/data hashes, metrics, and dependency manifest. Support semver tags and aliases (staging/production), integrity verification by content digest, version comparison by a chosen metric, and atomic promote/rollback of the production alias.",,
7e97a35d-5b4b-48d0-837a-08059fee7962,Machine Learning & AI,Machine Learning Pipelines & Automation,Model Registry & Versioning,"Create a schema-aware local model registry that assigns semantic versions (MAJOR/MINOR/PATCH) when registering scikit-learn models by diffing input schema, hyperparameters, and data hashes. Provide a CLI to register, list, and promote versions with stage transitions and a 'champion' alias, then verify by loading the Production model to score a held-out set.",,
8682d333-252a-435a-8009-94cfec88e0af,Machine Learning & AI,Machine Learning Pipelines & Automation,Model Registry & Versioning,"Start a local MinIO S3 server on localhost:9000 and configure a DVC remote (s3://model-registry) to serve as a centralized model registry for versioned model artifacts and metrics. Train two scikit-learn models, push both versions with semantic tags (e.g., v0.1.0, v0.2.0), implement a promote.py CLI to label Staging/Production in a bucket-hosted registry.json, and demonstrate a rollback to the prior Production version.",,
ba14482f-1094-4350-a6fa-1f5ae7ccb93f,Machine Learning & AI,Machine Learning Pipelines & Automation,Pipeline Construction & Scheduling,"Build a Prefect 2.x flow and deployment that orchestrates an end-to-end ML pipeline with ETag-aware data ingestion, feature engineering, model training/evaluation, and conditional promotion; configure retries, result persistence/caching, and a cron schedule, ensuring re-runs skip unchanged tasks. Provide a CLI to register the deployment, start a worker, trigger a run, and emit versioned artifacts plus a run_report.json summarizing cache hits, timings, and the promotion decision.",,
3e965fed-0eda-449f-808f-a9f3e497c6d0,Machine Learning & AI,Machine Learning Pipelines & Automation,Pipeline Construction & Scheduling,"Build an Apache Airflow DAG that watches /app/data/incoming with a FileSensor, validates new CSVs using Great Expectations, then transforms, trains, and evaluates a scikit-learn model on accepted data, writing artifacts and metrics under /app/outputs/{{ ds }}. The DAG must use the TaskFlow API with XCom to pass artifact paths, support backfilling for the past 7 days, and run on a daily 02:00 schedule.",,
44b1cc9d-dec7-48ba-8990-8ef84d432941,Machine Learning & AI,Machine Learning Pipelines & Automation,Pipeline Construction & Scheduling,"Create a Prefect 2 flow and deployment that ingests new CSVs, computes feature drift against a stored baseline, and conditionally runs preprocessing, training, evaluation, and model registration only when drift exceeds a threshold. Enable local caching and retries, add a cron schedule, and persist run artifacts and the chosen model under /app.",,
5d9c7fea-014b-4380-b646-54f4d3257717,Machine Learning & AI,Machine Learning Pipelines & Automation,Reproducibility & Environment Setup,"Build a Dockerized ML pipeline that achieves bit-for-bit reproducibility by using a conda-lock lockfile, fixing locale/timezone, seeding all RNGs, and pinning BLAS thread counts, while prefetching wheels and dataset artifacts for fully offline execution. Train a scikit-learn model and write both metrics and a SHA256 of the serialized model; rerunning the container (including offline) must produce identical outputs.",,
87e04c7d-ab41-4ae5-84e2-2e527c3c8cf8,Machine Learning & AI,Machine Learning Pipelines & Automation,Reproducibility & Environment Setup,"Build a Dockerized, conda-lock–pinned environment that runs a fully deterministic scikit-learn training pipeline on /app/data.csv, fixing seeds and BLAS threads to yield identical artifacts across runs. The CLI must produce model.pkl, metrics.json, and a reproducibility_report.json capturing package versions, BLAS backend, thread config, and SHA256 checksums of code/lockfile/data, with a make target that verifies bit-for-bit reproducibility.",,
bb5c3ff5-93b7-445e-ae55-25e95508ff8e,Machine Learning & AI,Machine Learning Pipelines & Automation,Reproducibility & Environment Setup,"Build a Dockerized, fully reproducible ML pipeline using DVC stages (data prep → feature extraction → training) with a conda-lock generated environment and pinned pip extras. Verify that running dvc repro in two clean clones yields bit-for-bit identical model and metrics artifacts and emit a manifest with exact package versions and data checksums.",,
44025c5e-e4a9-4ede-bf48-7f9c0eceaadc,Machine Learning & AI,Machine Learning Pipelines & Automation,Reproducibility & Environment Setup,"Create a Nix flake that defines a hermetic Python 3.11 environment with pinned NumPy, pandas, and scikit-learn, plus a CLI that trains a logistic regression on /app/data.csv with fixed seeds. Add a Makefile target that builds the flake and runs the training twice in fresh pure shells, asserting identical SHA256 hashes for model.pkl and metrics.json to confirm bit-for-bit reproducibility.",,
e7edd89f-ed66-4f38-801a-e83b1890d9cd,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"Build a CPU-only benchmarking CLI that compares FP32, FP16, and INT8 (quantized) variants of a given image classifier on a provided dataset, reporting accuracy, Brier score, and p50/p95 per-sample latency. Output a leaderboard CSV and select the best configuration by maximizing accuracy under a 95th-percentile latency budget, saving the chosen tag to /app/selection.txt.",,
a1eb54d6-a5bb-42f3-9ed6-087ad52d0a2e,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"Create a reproducible CLI benchmarking harness that trains and evaluates at least three scikit-learn classifiers on every CSV dataset in /app/data using nested stratified k-fold CV, computing accuracy, ROC-AUC, F1, log-loss, Brier score, and calibration error with 95% bootstrap confidence intervals. Aggregate results across datasets with paired Wilcoxon tests and effect sizes to rank models, also measuring CPU inference latency on fixed batch sizes and exporting a single results.json with per-dataset metrics, CIs, significance, and an accuracy–latency Pareto summary.",,
dd4a6ebd-c1a5-409e-a78b-8944e814287c,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"Create a reproducible benchmarking harness that trains five scikit-learn classifiers across four built-in datasets with repeated stratified k-fold, logging ROC-AUC, log loss, Brier score, per-sample latency, and model size to a results file. Run a Friedman test with Nemenyi post-hoc to rank methods, emit a critical-difference diagram, and pick a champion model that satisfies latency and size thresholds.",,
b1d298e3-6b22-4ba5-811c-8bd289344cd3,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"On an imbalanced binary dataset in /app/data.csv, train two baselines (Logistic Regression and Gradient Boosting) and calibrate each with temperature scaling and isotonic regression using a validation split. Benchmark pre/post-calibration AUROC, AUPRC, accuracy, Brier score, NLL, and ECE with bootstrap 95% CIs, then output a metrics CSV and a JSON naming the best-calibrated variant that keeps accuracy within 1% of the uncalibrated best.",,
520925cf-6497-4fde-bc11-0c027dd89f59,Machine Learning & AI,Model Evaluation & Validation,Error Analysis & Visualization,"Create a Python CLI that evaluates multivariate time-series forecasts against ground truth, computing per-horizon sMAPE, MASE, and prediction-interval coverage, and generates horizon-wise error heatmaps plus overlay plots of predictions vs. actuals for the worst 10 series by MASE. Write a metrics.json and PNG plots to /app/output while streaming to handle >1e6 points with numerically stable aggregations.",,
c8676e05-1f7f-4bc2-8dad-c6b470f9a31a,Machine Learning & AI,Model Evaluation & Validation,Error Analysis & Visualization,"Implement a CLI tool that ingests a CSV of predictions (y_true, y_pred, per-class probabilities) plus optional metadata columns and performs comprehensive error analysis: confusion matrix, per-class PR curves, reliability diagram/ECE, and per-slice metrics for each metadata field. Identify the top-3 statistically significant failure slices via bootstrap, then export PNG plots and a JSON report listing highest-confidence false positives/negatives and an optimal threshold per class.",,
60543e90-2b42-4f5e-8aab-a5a36fca811b,Machine Learning & AI,Model Evaluation & Validation,Metric Computation & Reporting,"Build a CLI that ingests CSVs of true labels and model logits/probabilities for in-distribution and OOD samples, fits a single temperature on a validation split, and computes accuracy, macro-F1, ROC-AUC, PR-AUC, NLL, Brier score, ECE/MCE (fixed and adaptive bins), and OOD AUROC/AUPR/FPR@95 using MSP and energy scores. Output a metrics.json and per-class.csv plus reliability diagrams and score histograms with strict input validation and numerically stable computations.",,
b1a69c2c-bd16-4a81-bac0-6ea31595ccf6,Machine Learning & AI,Model Evaluation & Validation,Metric Computation & Reporting,"Create a CLI that ingests a CSV of multiclass prediction probabilities and ground-truth labels, computes macro/micro F1, top-1/top-5 accuracy, per-class precision/recall, confusion matrix, and calibration metrics (ECE with adaptive binning, MCE, Brier), and writes a JSON summary plus per-class CSV. Include 1,000-sample bootstrap confidence intervals for scalar metrics and save a reliability diagram and normalized confusion matrix as PNGs.",,
50f20ca8-b5cc-4b94-ab80-f9ce76710bfd,Machine Learning & AI,Model Evaluation & Validation,Metric Computation & Reporting,"Create a CLI that ingests a Parquet file containing multilabel ground-truth indicators and model score columns, learns per-label thresholds on a validation split to maximize macro-F1, then evaluates the test split with those thresholds. Output a JSON report with per-label precision/recall/F1, micro/macro averages, LRAP, coverage error, Jaccard index, and the chosen thresholds, and write per-label 2x2 confusion matrices to CSV.",,
8ce34bcc-c9c8-406d-85f3-9839d0499e4e,Machine Learning & AI,Model Evaluation & Validation,Metric Computation & Reporting,"Ingest /app/logits.csv (Nx5 logits) and /app/labels.csv (N class ids), fit temperature scaling to calibrate probabilities, and compute top-1/top-5 accuracy, NLL, ECE (15 bins), Brier score, and macro-F1 before and after calibration with 95% bootstrap confidence intervals. Write a JSON summary to /app/report.json and save a before/after reliability diagram to /app/reliability.png.",,
c28e5380-fb60-47c1-b860-5f6a794946b1,Machine Learning & AI,Model Inference & Serving,Batch & Online Inference,"Build a CPU-only FastAPI inference service that loads a scikit-learn model from /app/model.pkl, performs dynamic batching by aggregating requests for up to 50 ms before a single model call, and hot-reloads the model when the file changes without dropping in-flight requests. Provide a batch_infer.py CLI that reads /app/input.csv, runs identical pre/post-processing for batched predictions, and writes results to /app/preds.csv including a model_version column.",,
d350e2dc-3f14-415f-9d10-53e9cd88a180,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,Build a CPU-only FastAPI inference server for a torchvision ResNet-18 and implement a background queue that performs dynamic micro-batching (coalesce requests for up to 16 images or 10 ms) with a single forward pass using a TorchScript-compiled model and tuned num_threads. Provide a CLI load generator to compare baseline (no batching) versus micro-batched serving and write p50/p95 latency and requests/sec to /app/results.json.,,
339dc3f9-b73a-440f-9bfe-36d009221b8c,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Build a CPU-only FastAPI service that serves a DistilBERT sentiment classifier via ONNX Runtime, then add three optimizations: static INT8 quantization with calibration, adaptive micro-batching (max batch 16, 10ms timeout), and an LRU cache of tokenized inputs keyed by content hash. Provide a benchmark script that drives concurrent requests and outputs a JSON report comparing p50/p95 latency and throughput before vs after, with a required ≥1.5× throughput and ≥25% p95 latency improvement to pass.",,
d9c06643-8ff6-4bf2-826c-c973377a5646,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Build an async Python inference server for a small Hugging Face Transformer that adds micro-batching (time-windowed), dynamic int8 quantization, and a tokenizer cache. Provide a replay benchmark that outputs baseline vs optimized p50/p95 latency and throughput to a JSON report.",,
4d0e0cae-0f5f-466b-8c7f-555fb77528af,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Containerize a FastAPI inference service for a small Transformer text classifier that implements a background request queue with dynamic micro-batching and an LRU tokenizer cache, and provide an ONNX Runtime int8-quantized variant. Use a load generator to measure QPS and p50/p95 latencies for fp32, int8, and 'int8+batching+cache' modes, writing a comparison summary to /app/bench.json.",,
4f24d349-65e9-4cb9-a521-5c5ad09508cf,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Create a CPU-only FastAPI inference server for a pretrained DistilBERT classifier that implements time-windowed dynamic batching, int8 dynamic quantization of Linear layers, and a content-hash response cache; include a short warm-up and pad inputs to multiples of 8 tokens. Supply a load generator that compares baseline vs optimized builds and outputs p50/p95 latency and throughput, with tests requiring at least 1.5x throughput improvement without violating a p95 latency SLA.",,
a794bc5c-52f7-4c41-bff6-fb522c9ac6cc,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Export a PyTorch sequence model to both TorchScript (scripted) and ONNX with dynamic axes and opset 17, saving weights in safetensors with strictly pickle-free serialization. Provide a CLI that loads the exported artifacts on CPU, runs onnxruntime and TorchScript inference on the same inputs, and asserts numerical parity within a tight tolerance.",,
cd5f1ac0-fb2e-4fcb-9f66-412c6f71c86a,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Export a scikit-learn Pipeline that includes a custom categorical encoder and a RandomForest model to ONNX by implementing a custom converter and shape calculator, then verify output parity against the original pipeline with onnxruntime on a mixed-type dataset. Save the portable ONNX and a small parity report summarizing numerical differences and opset/ir metadata.",,
c8ea136f-159f-4d16-a2ab-3105eda0f02c,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Export the 'sentence-transformers/all-MiniLM-L6-v2' PyTorch encoder to ONNX with dynamic batch and sequence axes and also produce an int8-quantized ONNX using onnxruntime. Provide a CLI that tokenizes sentences from /app/input.txt, runs PyTorch vs ONNX (fp32 and int8), checks cosine-similarity parity (1e-3/1e-2), and writes a JSON report with model sizes and average latency.",,
b864608e-13d2-4708-b59d-43f6a6405630,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Implement a CLI that builds a variable-length batched BiLSTM tagger in PyTorch using PackedSequence, exports it to TorchScript and ONNX (opset 17) with dynamic batch and sequence length, and provides an ONNX-compatible unpacking path. Validate numerical parity across eager PyTorch, TorchScript, and ONNX Runtime on randomized inputs, saving all artifacts and a sample input under /app/export.",,
8180271e-c677-4105-9640-132420a97a92,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Train a scikit-learn mixed-type Pipeline (ColumnTransformer with numeric StandardScaler and categorical OneHotEncoder feeding LogisticRegression), then export it to ONNX (opset ≥17) with a dynamic batch axis, explicit input dtypes, and embedded class-label metadata. Validate with onnxruntime that class probabilities and predictions match scikit-learn within a tight tolerance across a holdout CSV, and save both the ONNX artifact and a JSON parity/latency report.",,
2d05c44c-06bc-44af-a5a3-ed77727174d3,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Deploy a FastAPI microservice that serves a small ONNX sentiment classifier via ONNX Runtime with async micro-batching (max batch size and wait time), concurrency-safe tokenization, and pydantic request validation. Provide Dockerfile and startup scripts, expose /predict, /healthz, and /metrics (Prometheus) endpoints, and implement a zero-downtime hot-swap endpoint that atomically loads and switches to a new model file.",,
246a9b2e-757b-4b05-8425-3fbd010e8d7d,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Implement a Python gRPC inference server that loads a CPU-only ONNX Runtime model and performs dynamic micro-batching (bounded by batch size and a 50 ms queue window), exposing the gRPC health checking service and a Prometheus /metrics endpoint. Provide a CLI load generator to issue concurrent requests and write a JSON report comparing latency/QPS in batched vs unbatched modes to /app/bench.json.",,
b177f1f7-5293-49fa-8a4a-ac9d694b6fb1,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Package a CPU-only ResNet18 into a TorchServe .mar with a custom handler that performs torchvision preprocessing and returns top-5 class probabilities as JSON. Launch TorchServe on 0.0.0.0:8080, register the model, support both single and batched image requests at /predictions/resnet18 with proper 400 errors for invalid inputs, and expose /ping and Prometheus /metrics for health and monitoring.",,
955019b3-f7cd-4c80-84dd-ed39cae77562,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Package a pre-trained PyTorch ResNet18 into a TorchServe .mar with a custom handler that accepts base64-encoded images, applies preprocessing, and returns top-3 labels with probabilities. Launch TorchServe with dynamic batching (e.g., max_batch_size=8), register the model via the management API, issue batched requests, and write a latency/throughput summary to /app/serve_metrics.json.",,
defb78db-061d-467c-9685-1fa72d8f649d,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Fine-tune T5-small with parameter-efficient prefix tuning to translate English task descriptions into Bash one-liners on a provided dataset; evaluate exact match and BLEU on a held-out split, and save both the prefix adapter and a merged model plus predictions.json to /app.",,
bfce7f82-557a-40b0-a69b-98d3f57a4a43,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Fine-tune a pretrained sentence-transformer (e.g., sentence-transformers/all-MiniLM-L6-v2) on provided positive/negative sentence pairs with a contrastive cosine-similarity loss to adapt it for semantic search. Provide a CPU-only CLI that trains, saves the fine-tuned encoder, and reports MRR@10 and Recall@10 on a held-out query set using exact cosine similarity over corpus embeddings.",,
8d4f7a93-4604-40f5-aef6-04d92d051a9e,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Implement parameter-efficient fine-tuning by inserting lightweight adapter modules into a pretrained DistilBERT for domain text classification, training only adapters with discriminative layer-wise learning rates and a slanted triangular schedule. Provide a CLI to train/evaluate, export adapter-only weights, verify the frozen base model hash is unchanged, and support hot-swapping different adapter checkpoints at inference.",,
38f9769c-54a5-4abd-9cd6-084ce00cfc51,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Build a CLI that performs multi-objective hyperparameter optimization with Optuna for a PyTorch CNN on Fashion-MNIST, maximizing validation accuracy while minimizing wall-clock time via ASHA pruning and a SQLite-backed study that can be resumed. After the search, pick the Pareto-optimal trial under a 30s time budget, deterministically retrain on the full training set, and export best_config.json, study.db, metrics.json, and best_model.pt.",,
c52f37f6-f681-455d-8904-8cd2f8ef403d,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Build a reproducible Optuna-powered multi-fidelity search (ASHA pruner) that tunes learning rate, weight decay, batch size, and transformer depth for a small text classifier on a provided CSV, persisting the study to SQLite. After the search, retrain the best trial and export the final model along with a Pareto front that balances validation accuracy against measured inference latency.",,
039571e4-dfab-4ccd-b130-f526007c0c9c,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Create a reproducible, multi-objective Optuna study that tunes a CPU-only PyTorch tabular classifier (layers, width, dropout, learning rate, weight decay, batch size) to simultaneously maximize ROC-AUC and minimize measured inference latency using ASHA pruning within a fixed time budget. Persist the study to a local SQLite DB, export the Pareto-optimal trials to /app/pareto.json, and save the fastest model meeting a target AUC threshold to /app/best_model.",,
10429246-4af7-4e89-99b6-409a54705264,Machine Learning & AI,Model Training & Optimization,Supervised & Unsupervised Learning,"Learn a supervised metric using scikit-learn’s Neighborhood Components Analysis on labeled data, then perform k-means clustering in the learned embedding on the full dataset. Save cluster assignments and evaluate clustering quality with adjusted mutual information and silhouette scores to a metrics file.",,
dcff2fc0-b4ae-4b12-9bba-bea765ff73d6,Machine Learning & AI,Model Training & Optimization,Supervised & Unsupervised Learning,"Train a sparse autoencoder in PyTorch on a numeric tabular dataset with early stopping and L1 activation regularization, saving the encoder to /app/encoder.pt. Freeze the encoder to generate embeddings and train a scikit-learn logistic regression on labels, reporting stratified 5-fold ROC-AUC and writing metrics and artifact paths to /app/results.json.",,
03f02971-558b-42ff-8db5-fa4961114657,Machine Learning & AI,Model Training & Optimization,Training Loop Implementation,"Implement a PyTorch training loop for a tiny character-level language model on a given corpus with truncated BPTT, gradient accumulation, global-norm gradient clipping, and early stopping on validation loss. Support rotating checkpoints (keep N), exact resume of optimizer/scheduler and RNG state after interruption, and deterministic results when a seed is provided.",,
68f9e62d-1d50-4979-9221-4d0ceb7a209f,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Create and register a custom Gymnasium environment 'ThermalControl-v0' whose dynamics (heat capacity, loss rate, actuator limits, and disturbance sequence) are loaded from /app/dynamics.yaml, and train a Soft Actor-Critic agent with stable-baselines3 (automatic entropy tuning) to keep temperature within a target band via domain-randomized episodes. Save the trained policy to /app/checkpoints and a 100-episode seeded evaluation log (time, state, action, reward) to /app/eval.csv for automated verification.",,
6062f9bc-1a32-4539-ab64-bb6ab2b97285,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Install Ray RLlib with PettingZoo and SuperSuit, configure the MPE simple_spread_v3 multi-agent environment, and train a shared-parameter PPO policy using vectorized parallel environments. Export the trained policy to TorchScript and run a seeded evaluation that writes per-agent rewards and coverage metrics to /app/mpe_eval.json.",,
f66a96fd-e9c5-420f-8920-27f75eca211e,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a PSRO self-play pipeline for the Rock-Paper-Scissors-Lizard-Spock normal-form game, iteratively training best-response policies via no-regret updates against the evolving meta-strategy. After convergence, compute the mixed Nash distribution and exploitability, and write them to /app/solution.json, passing tests by staying below a specified exploitability threshold.",,
e4de7787-4b00-4ab3-a58e-2e3f9ed14bcb,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a self-play Counterfactual Regret Minimization trainer for Kuhn Poker with a minimal game engine including chance nodes, information-set caching, and average-strategy export. The script should train to a low-exploitability policy verified by a best-response evaluator, be reproducible via seeding, and finish on CPU within tight time limits.",,
ada92c7c-5d37-4f64-8724-ec6138a568d1,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,Implement from-scratch CFR+ self-play for Kuhn Poker with a CLI to train for N iterations and compute exploitability via an exact best response. Save the average strategy to /app/kuhn_policy.json and ensure the final policy’s exploitability is ≤0.05 chips.,,
908ba69b-2e25-46e5-81f4-a1cad26cdbad,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Train a near-Nash strategy for Kuhn Poker via self-play Counterfactual Regret Minimization (CFR/CFR+) using OpenSpiel (pyspiel), then serialize the average policy and compute exploitability. Produce a policy artifact and a metrics report demonstrating exploitability below a specified threshold.",,
42542e5b-3910-49d1-8d17-6b843192891f,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Augment Gymnasium’s LunarLander-v2 with a configurable multi-objective reward balancing landing accuracy, fuel efficiency, and leg-contact stability, then sweep at least 32 coefficient sets where each trains a lightweight PPO agent for a fixed budget. Compute and save the Pareto frontier and knee-point selection with CSV/plots of episodic return, crash rate, and fuel use to verify the chosen reward balances competing objectives.",,
fddab346-f2c4-49e6-9ac6-1e22bfc87919,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Design and evaluate multi-objective rewards for Gymnasium’s Taxi-v3 by augmenting the sparse reward with penalties for illegal pickup/dropoff and a discomfort cost proportional to action changes, implementing both scalarized (lambda-weighted) and Lagrangian-constrained formulations. Train a tabular Q-learning agent across a sweep of coefficients and report the Pareto frontier between episode length and discomfort with a baseline comparison to the original sparse reward.",,
a763d4b1-82c3-4b62-9b06-b3a2bbaae338,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Implement a Gymnasium-compatible 'Windy Keys-and-Doors' gridworld and design a potential-based reward shaping function that balances goal completion, energy use, and safety while preserving the optimal policy. Provide a training/evaluation script that compares shaped vs. sparse rewards (e.g., with tabular Q-learning), demonstrating faster learning and fewer collisions, verifying equal optimal returns, and flagging reward-hacking behaviors.",,
4fc46959-8f65-49e1-a8fa-271dec78720d,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Implement a custom Gymnasium GridWorld with a sparse goal reward, time penalty, and stochastic hazard tiles, then compare two rewards: potential-based shaping via Manhattan-distance potential and a naive per-step progress bonus. Train PPO under both and report success rate, hazard contacts, and path optimality gap to highlight shaping invariance vs reward hacking.",,
bc7ef49f-3e4e-4df4-a9ce-5f765d77d9b6,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"In a 2D gridworld with a key, a locked door, and a fragile vase, implement and compare three rewards: sparse goal-only, potential-based shaping with step penalty, and a side-effect avoidance term that penalizes action impact relative to an inaction baseline using object-position L1 distance. Train a fixed PPO agent under each reward, detect reward hacking like key pick/drop loops, and produce a summary of goal success, vase collisions, loop frequency, and sample efficiency.",,
aba66aee-ba00-4791-9b3f-42c88721be78,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a disk-backed prioritized replay buffer daemon that ingests CartPole-v1 transitions from multiple local producer scripts over TCP, computes n-step returns across episode boundaries, and persists state for crash-safe restart. Provide a client to sample mini-batches with PER (alpha/beta) and importance weights, with a test harness that verifies sampling distribution, deterministic checksums for sampled batches, and replay continuity after restart.",,
abd711d4-0eb1-4e41-897f-8ebcc789b12d,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a goal-conditioned 2D grid environment and generate large-scale rollouts to an on-disk replay buffer supporting Hindsight Experience Replay, n-step returns, and prioritized sampling with importance weights. Train a lightweight DQN for several thousand updates from this buffer and output success-rate curves and sampling diagnostics derived from the stored trajectories.",,
10862da4-27c2-4b86-9fd5-8dd2a1478b3d,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a memory-mapped, Zarr-backed replay buffer for Gymnasium Dict/Box spaces with prioritized experience replay, n-step returns, and sequence sampling for RNN policies (burn-in, overlap, zero-padding). Provide a CLI to run vectorized rollouts to populate the store, then deterministically sample batches under a fixed seed and output a JSON report verifying priority distributions, importance-sampling weights, and crash-safe resume behavior.",,
47ac2a0d-24bd-45ed-95e6-6f6a198df1f3,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a multiprocessing rollout + learner system that generates goal-conditioned episodes and stores them in a segment-tree prioritized replay buffer with n-step returns and on-the-fly Hindsight Experience Replay relabeling. The buffer must support batched append/sample/update with importance-sampling weights, be mmap-backed to handle 10M+ transitions, and a training script should reach a target success rate while validating sampling distribution and bias correction.",,
c65e85c9-bb0c-4372-a7c0-e62ca71f36bf,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a prioritized experience replay buffer using a segment tree that supports n-step returns, sequence sampling for recurrent policies, and per-sample importance weights. Provide a CLI to collect rollouts from parallel Gymnasium environments, persist the buffer to disk in chunked files, then reload to verify sampling probabilities, TD-error updates, and n-step target consistency.",,
943ac041-04a1-4110-a8aa-ed1db97bf7c3,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Create a CLI pipeline that attacks a pretrained image classifier with EOT-PGD over random crops, rotations, and Gaussian noise, then reports robust accuracy and worst-case loss. Implement a defense via randomized smoothing with calibrated sigma to compute per-sample certified radii and write a CSV summarizing clean/robust accuracy and certificates for a test subset.",,
cde85dee-1de4-49ad-8a26-7cc359dc2db0,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Implement a CPU-only Python CLI that loads a provided CIFAR-10 model, wraps it with a non-differentiable defense (bit-depth reduction plus randomized resizing), and evaluates robust accuracy under FGSM, PGD, and BPDA+EOT-PGD. Save per-attack metrics to /app/robust_metrics.json and 32 adversarial samples per attack to /app/adv/{attack}/, demonstrating that BPDA+EOT meaningfully reduces reported robustness compared to naive PGD.",,
61bc22bb-461b-46db-88ca-602960cc80d4,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Train a small CNN on MNIST (CPU) and implement FGSM and PGD-Linf attacks. Add a feature-squeezing detector (bit-depth reduction + median smoothing) and an adversarially trained variant, then report clean/robust accuracy at eps=0.3 and ROC-AUC for detection, saving metrics and checkpoints.",,
67100375-6784-4304-add2-1bda8f310b88,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Train a small CNN on MNIST, implement FGSM and multi-step PGD (with Expectation-over-Transformation for stochastic defenses) to craft adversarial examples at multiple L∞ epsilons, and report clean/robust accuracies with saved adversarial image grids. Add PGD adversarial training and a randomized smoothing inference defense, then re-evaluate and output a JSON metrics report plus a file of estimated certified radii for 100 test samples.",,
29648b82-9dde-4906-8c3d-6913bff7e075,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Build a CLI pipeline that scans a raw text corpus, detects PII (emails, phones, names, addresses) via regex+NER, applies consistent pseudonymization, and produces both a redacted dataset and a provenance ledger with SHA-256 hashes, source URLs, and SPDX license IDs. Then evaluate a fine-tuned text generation model for privacy compliance by running canary extraction and membership inference tests, emitting a JSON report of leakage metrics and pass/fail flags against given thresholds.",,
b157750b-e7d5-47ff-a4f9-09a87f0f54e6,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Build a CLI that audits a JSONL training dataset and a local text-generation model for policy compliance by verifying data provenance (required source_url and license in an allowed whitelist) and detecting/redacting PII (emails, phones, addresses, SSNs) with deterministic hashing. Run a fixed red-teaming prompt suite against the model to flag PII leakage and disallowed content, then emit a compliance_report.json with per-rule counts, sample snippets, thresholds, overall pass/fail, and a sanitized_data.jsonl output.",,
234421b3-850f-460f-8191-44cf96c3bdf7,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Build a Python CLI that scans /app/data/{train,test} and /app/logs/inference.log for PII (names via a bundled dictionary, emails, phones, IPs, street addresses, government IDs) and validates that each record has provenance in /app/metadata.jsonl with a source, timestamp, and SPDX license from an allowed list. Automatically redact violations, emit a tamper-evident audit to /app/compliance_report.json with SHA-256 hashes and a redaction map, and exit non-zero if any unredacted PII or disallowed licenses remain.",,
df43241a-62ee-44fa-9a9c-356ca44134a3,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Build a streaming Python CLI that ingests a large CSV of free-text training data plus a whitelist of permitted licenses, detects and redacts PII (names, emails, phone numbers, addresses, SSNs) via regex and spaCy NER, and validates each row’s provenance against a provided source-to-license map. Output a JSONL compliance report with SHA-256 hashes of raw and redacted text, per-row PII categories found/redacted, license verdicts, and exit non-zero if any violation exceeds configured thresholds.",,
8e5b43e6-42ad-48fe-814e-12358747ee12,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Create a terminal CLI that validates a dataset’s licensing and provenance for model training by parsing per-file metadata and SPDX identifiers, verifying cryptographic hashes against a manifest, and checking compatibility with a specified usage policy (e.g., commercial use). The tool should emit a machine-readable compliance report and a symlinked approved/ subset, failing with clear diagnostics for missing, incompatible, or conflicting licenses.",,
40aeee02-2b06-490e-9ee7-e999fa8da260,Machine Learning & AI,Responsible AI & Model Robustness,Explainability & Interpretability,"Build a CPU-only CLI that trains a simple MLP on a tabular dataset and computes per-sample feature attributions using LIME, KernelSHAP, and Integrated Gradients, normalizing outputs into a common schema. Export JSONL attributions, a global feature ranking, and quantitative consistency metrics (additivity/completeness checks, Kendall tau agreement, and deletion/insertion AUCs) to predefined paths.",,
41bea51e-f8d6-4967-8200-f5e1bd452e75,Machine Learning & AI,Responsible AI & Model Robustness,Explainability & Interpretability,"Implement a CLI that explains predictions of a pretrained HuggingFace sentiment model on a text file using both SHAP and LIME, repeating each method over multiple random seeds to quantify stability (Kendall tau of token-importance ranks and top-k Jaccard overlap). Write a JSON summary of stability metrics, a CSV of per-example attributions, and HTML token heatmaps for the most unstable cases.",,
44020cfc-9591-44e9-8604-fa4e2a02ee06,Machine Learning & AI,Responsible AI & Model Robustness,Explainability & Interpretability,"Train a gradient boosting classifier on the UCI Adult dataset and generate local explanations for 20 test instances using both SHAP and LIME. Implement a faithfulness evaluation via deletion/insertion curves over ranked features, report AUC metrics for each method, and save per-instance attributions (JSON) and summary plots to /app/.",,
503551a7-7be4-4144-8a11-abea2c2a904e,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Implement a CLI to load a pretrained CIFAR-10 classifier and generate FGSM, PGD, and CW adversarial examples at user-specified perturbation levels. Then apply adversarial training and randomized smoothing defenses to compute robust accuracy curves, per-sample certified radii, and save artifacts and plots in a reproducible format.",,
fec512ab-5691-404c-a919-0c4c5244f990,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Implement a randomized smoothing defense by wrapping a pretrained PyTorch CIFAR-10 classifier to produce certifiably robust predictions under Gaussian noise, computing per-sample certified radii and robust accuracy at multiple thresholds, and saving both detailed certificates and an aggregate JSON report.",,
9e2fb891-354d-420b-a689-cc40b0097aea,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Create a Python pipeline that uses TextAttack to craft adversarial text examples against a BERT sentiment classifier under semantic and grammatical constraints, logs attack success rates and similarity metrics, then fine-tunes the model on the adversarial examples and outputs pre- and post-defense robustness reports in JSON.",,
fa54768d-53c4-4b06-8861-0c7fc96cf184,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Implement a randomized smoothing certification pipeline that wraps a pretrained CIFAR-10 PyTorch classifier to compute and report per-sample L2 robustness radii and average certified accuracy, saving results to cert_results.json and radii.csv with specified schema.",,
161df2d8-205e-434d-b348-c55dd774ac8c,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Provide a vulnerable C server binary exhibiting a format-string bug and stack canary; write a Python pwntools exploit to first leak the canary and libc base, then build a ROP chain calling system(""/bin/sh"") over the network. Include an automated test harness that verifies a remote shell is obtained and the flag.txt is read successfully.",,
210a6c73-4894-4b9b-9f1f-bdd526e07645,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Compile the provided vulnerable network service and write a Python pwntools-based exploit to perform a buffer overflow with a ROP chain that spawns a shell, then connect to the service, deliver the payload, and retrieve the flag from /app/flag.txt.",,
4a181056-ac64-47fe-a5c9-c5a3db8303c7,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Write a non-interactive script to analyze the provided Windows memory dump, locate the in-memory OLE stream of a malicious Word process, extract its embedded VBA macro to /app/macro.vba and any decoded shellcode to /app/payload.bin. Produce /app/report.txt summarizing extraction offsets, payload sizes, and the method used for discovery.",,
f562069e-cde0-48ff-b23d-775f7cac256d,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Develop a Python tool to parse a raw memory dump at /app/memdump.raw, carve out embedded PNG files by locating their magic headers/footers, and extract hidden ASCII flags encoded via LSB steganography in pixel data. Save each carved image under /app/images/ and write all recovered flags with their offsets into /app/flags.txt.",,
f3eadb0d-87f0-4e45-8e70-614e49678f7f,Machine Learning & AI,Deep Learning & Neural Network Engineering,Architecture Design & Implementation,Design and implement a PyTorch module for a Time-Series Transformer that integrates learnable time embeddings and irregular sampling interpolation blocks to handle variable-length multivariate inputs. Include multi-head self-attention layers with real-valued positional encodings and a forecasting head for next-step prediction.,,
83115328-355c-4d2f-87af-5ab6ec56bc6a,Machine Learning & AI,Deep Learning & Neural Network Engineering,Architecture Design & Implementation,"Implement a PyTorch GATv2Conv module that supports multi-head edge-feature-aware attention, residual connections, dynamic graph batch processing, and optional layer normalization. Provide a deterministic CLI that seeds synthetic graphs, runs forward/backward passes, and reports attention weights, gradient norms, and per-head utilization.",,
cf234f07-8a9b-45b1-a6e2-bf0280d8561e,Machine Learning & AI,Deep Learning & Neural Network Engineering,Architecture Design & Implementation,"Create a PyTorch module implementing a CapsuleNetwork block with primary and digit capsules, EM dynamic routing, margin and reconstruction losses, and train end-to-end on a synthetic 28×28 shape classification dataset. Compare to a standard CNN baseline and output a results.json containing classification accuracies, average routing entropy, and reconstruction errors.",,
27e91a30-7e87-455e-8e6e-8286c39aaefa,Machine Learning & AI,Model Inference & Serving,Batch & Online Inference,"Create a Python CLI that loads a HuggingFace text-classification pipeline for sentiment analysis, supports both batch mode (reading input JSONL files and writing JSONL outputs with scores) and interactive streaming mode (reading from STDIN), handles input validation and logs per-request latencies to a CSV for performance monitoring.",,
175e453b-4953-42a1-b619-828ee02fe9f5,Machine Learning & AI,Model Inference & Serving,Batch & Online Inference,Implement a Python CLI that loads a pre-exported BERT sentiment-analysis ONNX model and runs batch inference over a directory of text files to emit JSON predictions with confidence scores and per-file latency logs. Add an interactive REPL mode for single-sentence inference with live latency reporting and adjustable confidence thresholds.,,
a078a83f-7de0-485e-bb2c-6d00d4e1978f,Machine Learning & AI,Model Inference & Serving,Batch & Online Inference,"Implement a Python CLI tool that loads a TorchScript-exported object detection model and processes images in adjustable batches from a given directory, applying non-max suppression to produce bounding box predictions. Generate a COCO-formatted predictions JSON and a metrics.json detailing average per-image latency and peak GPU memory utilization.",,
1e745a23-7f68-4658-b006-f18b28d2d1d8,Machine Learning & AI,Model Inference & Serving,Batch & Online Inference,"Create a Python CLI that loads a quantized ONNX transformer for sentiment analysis, processes text files in batch from /app/data/texts/ to emit a CSV of id, score, and label with GPU/CPU timing and memory logs, and supports an interactive REPL mode for single-sentence inference mixing CPU fallback.",,
8b41ef0d-2b1e-4313-9675-e31048e1b66c,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"Implement a CLI tool that benchmarks varying pruning and quantization configurations on a pre-trained PyTorch image classification model by measuring top-1 accuracy, model size, and inference latency for each setup. The tool should output a JSON report ranking configurations across these trade-off metrics.",,
5a4596f0-5004-42ff-bf48-2c6b73788f48,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"Implement a CLI that applies three model compression techniques (structured pruning, post-training quantization, and knowledge distillation) to a pre-trained ResNet-18 on CIFAR-10, benchmarks accuracy, inference latency (CPU/GPU), and memory footprint, and outputs a comparison.json and an HTML report summarizing the trade-offs.",,
c68bd706-7925-4128-b595-c08285175ee4,Machine Learning & AI,Responsible AI & Model Robustness,Bias Detection & Mitigation,"Implement a Dockerized Python CLI that audits classification bias on a dataset with protected attributes by computing demographic parity, equalized odds, and disparate impact metrics, outputs JSON reports and plots, then applies a reweighing-based preprocessing to retrain a fair logistic regression and produces updated metrics and model artifacts.",,
f4200f4a-2697-49f7-924c-2481958d8981,Machine Learning & AI,Responsible AI & Model Robustness,Bias Detection & Mitigation,"Implement in PyTorch an adversarial debiasing pipeline using a gradient reversal layer to train a neural classifier that removes sensitive attribute information from learned representations on a tabular dataset. Compute and save pre- and post-debiasing fairness metrics (such as demographic parity, equal opportunity difference, and disparate impact) along with classification performance to /app/metrics.json.",,
bc24bcf9-f69f-4012-af7d-4da2b4a5928e,Machine Learning & AI,Responsible AI & Model Robustness,Bias Detection & Mitigation,"Implement a Python CLI that loads the /app/data/credit.csv dataset, computes group fairness metrics (demographic parity difference, equal opportunity difference, and disparate impact) for a baseline logistic regression classifier, then applies a reweighing pre-processing algorithm to mitigate bias. Retrain the classifier on the reweighted data, evaluate the same metrics post-mitigation, and write before/after metrics to /app/output/fairness_metrics.csv, ROC curves to /app/output/roc_plots.png, and a summary report in /app/output/fairness_report.txt.",,
8c1a19eb-ffa7-4cda-9de5-c0d7937dea70,Machine Learning & AI,Model Evaluation & Validation,Cross-Validation & Statistical Testing,"Implement nested 5-fold cross-validation to tune logistic regression hyperparameters via grid search alongside a baseline random forest, record per-fold accuracies, and perform paired Wilcoxon signed-rank and McNemar’s tests to compare model performance. Generate fold_scores.csv, p_values.json, and confidence_intervals.txt with the exact schemas and formatting constraints.",,
f87e299c-26dc-4a06-8006-42481d2d51de,Machine Learning & AI,Model Evaluation & Validation,Cross-Validation & Statistical Testing,"Create a Python CLI that implements nested stratified k-fold cross-validation to tune hyperparameters for two classifiers, records their test accuracies across outer folds, and performs a paired Wilcoxon signed-rank test at α=0.05 to evaluate performance differences. The tool should output a JSON report containing fold-level scores, p-value, and a significance decision.",,
082e1cd5-2f54-430a-a05c-5b0c18c8e7f1,Machine Learning & AI,Model Evaluation & Validation,Cross-Validation & Statistical Testing,"Design a Python CLI that implements nested cross-validation with configurable inner hyperparameter search (grid or random) and outer k-fold evaluation, aggregating per-fold performance metrics for multiple models. After training, conduct paired Wilcoxon signed-rank and paired t-tests with multiple testing corrections to assess statistical significance, and emit comprehensive JSON and human-readable summary reports containing metric distributions, p-values, corrected alpha levels, and confidence intervals.",,
8c1dddab-7f75-4dc9-a24a-51059d2ed48f,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Custom Environment Setup & Curriculum Policy Training,"Implement and register a custom OpenAI Gym environment simulating a 2D robotic pick-and-place task with randomized object positions, sparse success rewards, and failure conditions. Then train a PPO agent via stable-baselines3 through a three-phase curriculum, logging per-episode returns, success rates, and training checkpoints to metrics.json.",,
91ee1809-6693-4a02-a14f-73d9837f7365,Machine Learning & AI,Foundation Models & Large-Scale Systems,Data & Model Sharding,"Develop a CLI tool in the Docker sandbox that launches a 2-node, 4-GPU distributed training job on a small Transformer using DeepSpeed’s ZeRO-3 with custom tensor partitioning, automatically tuning partition sizes to fit under 14 GB per GPU. The tool must log per-GPU memory usage and training throughput, and output a final sharding plan JSON.",,
b9bea2fe-26c8-4ab9-8835-8da9081af742,Machine Learning & AI,Foundation Models & Large-Scale Systems,Data & Model Sharding,Implement a PyTorch two-way tensor parallelism wrapper that shards embedding and linear submodules across two GPUs and runs forward/backward passes on synthetic data. Validate that outputs and gradients match a monolithic baseline within a given numerical tolerance and report peak memory savings.,,
fd469ff2-817c-4cda-a1e5-0042869c3c4e,Machine Learning & AI,Foundation Models & Large-Scale Systems,Data & Model Sharding,"Develop a Python CLI that shards a pretrained Transformer model across multiple GPUs using hybrid tensor and pipeline parallelism, including dynamic load balancing based on real-time memory utilization. The tool should execute synthetic inference and training batches, collect per-shard timing and memory metrics, and validate output consistency against a baseline single-GPU run.",,
1c910fba-ba10-4cc5-9e9b-a0a75e47a328,Machine Learning & AI,Data Preparation & Feature Engineering,Data Augmentation & Synthesis,Create a CLI tool to augment a CoNLL-formatted NER dataset by performing consistent entity swapping using an ontology and contextual masking to maintain grammatical correctness. The tool should output augmented sentences with updated labels and produce a manifest.json capturing augmentation provenance and entity mappings.,,
283a1e43-e75d-46cf-93f3-49daaaf2ad6a,Machine Learning & AI,Data Preparation & Feature Engineering,Data Augmentation & Synthesis,"Create a CLI tool that uses a CTGAN to generate synthetic tabular data from an input CSV, preserving both numerical correlations and categorical distributions; it should compute privacy metrics (e.g., membership inference risk) and output augmented datasets at a user-defined ratio.",,
eda4f108-5ea3-4243-bcf4-dcda7fd0032f,Machine Learning & AI,Data Preparation & Feature Engineering,Data Augmentation & Synthesis,Implement a Python CLI that fine-tunes a pre-trained T5-small model on a provided text classification dataset to generate diverse paraphrases for each labeled example. Filter augmented samples using embedding-based semantic similarity thresholds to maintain label consistency and output the expanded dataset along with a JSON report of paraphrase diversity and semantic drift metrics.,,
b0b62705-c7be-49d8-a931-b30876c9b381,Machine Learning & AI,Data Preparation & Feature Engineering,Data Cleaning & Preprocessing,"Implement a Python CLI that reads multiple nested JSON log files with inconsistent timestamp formats and flattens them into tabular records while normalizing all timestamps to UTC ISO 8601. It should impute missing numeric values using group-based rolling-window medians, flag outliers beyond three standard deviations, and output a cleaned CSV and a JSON report with imputation counts and anomaly statistics.",,
768b7f5c-4b03-4abb-9d85-149daebde055,Machine Learning & AI,Data Preparation & Feature Engineering,Data Cleaning & Preprocessing,"Create a Python CLI utility that reads multivariate sensor CSV files with irregular timestamps, resamples them to a user-specified uniform frequency, performs linear interpolation for missing data, and clips values beyond configurable statistical outlier thresholds. The tool should apply channel-wise normalization, handle timezone-aware timestamps, and output processed time series as NumPy .npz files along with a JSON log detailing all imputations and outlier corrections.",,
3e85fa08-28dc-4479-8791-e1e5a8553d01,Machine Learning & AI,Data Preparation & Feature Engineering,Data Cleaning & Preprocessing,"Create a CLI tool that ingests a directory of mixed‐format data files (CSV, JSON, XML), automatically standardizes field names, normalizes datatypes and inconsistent date/time formats to ISO8601, imputes or flags missing values via user‐specified strategies, and deduplicates records. Output a single clean CSV and a JSON data quality report summarizing null counts, imputation actions, and any schema transformations.",,
aa485370-2284-49de-a88e-e79ec24633c3,Machine Learning & AI,Data Preparation & Feature Engineering,Dataset Splitting & Sampling,"Create a Python CLI that partitions a timestamped, multi-entity dataset into training, validation, and test splits using stratified group time-series windows to ensure no entity appears across sets and class distributions remain balanced. The tool should accept parameters for window size, number of folds, and imbalance tolerance, then output CSVs for each split along with a JSON summary of group and class distributions.",,
c3cf16bb-da35-4021-ac25-5cf5397321b6,Machine Learning & AI,Foundation Models & Large-Scale Systems,Distributed & Parallel Training Infrastructure,"Implement a Slurm-based orchestration script that deploys PyTorch DDP training of a BERT model across 8 GPU nodes with NCCL backend, supports dynamic batch-size scaling and automatic requeue on preemption. The script must collect per-step latency, allreduce synchronization time, and per-node GPU/memory usage, then output a consolidated performance_report.json and TensorBoard logs for analysis.",,
df9cbf82-62b2-413d-9ded-1711d0411690,Machine Learning & AI,Foundation Models & Large-Scale Systems,Distributed & Parallel Training Infrastructure,"Implement a multi-node distributed training pipeline for a Transformer-based language model using DeepSpeed stage-3 ZeRO and pipeline parallelism with automatic data sharding, mixed precision, and dynamic micro-batch sizing. Integrate fault-tolerant checkpointing and provide a CLI to launch the job across at least four GPUs on two separate nodes.",,
482ec49a-8032-4f97-a0ea-d06c224a1cf4,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Create a Dockerized custom OpenAI Gym environment simulating a 2D gridworld with dynamic obstacles and moving goals, register it via gym.make(), and automate training a PPO agent with curriculum learning and reward shaping. Provide a deterministic CLI that seeds all randomness, launches training, logs TensorBoard metrics, saves the final policy, and runs evaluation episodes with aggregated performance output.",,
80cf23a6-1605-48be-b953-a85477726665,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Implement a custom OpenAI Gym environment simulating a grid-based delivery robot with stochastic obstacles and define its reset, step, and reward logic. Train both a DQN and a PPO agent to maximize successful deliveries within a fixed timestep budget, saving the trained models and comparative performance metrics.",,
2826f686-e7d8-45be-860f-3ffc81252e18,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Create a Dockerized Gym environment wrapper that applies domain randomization to CartPole’s physics parameters (mass, length, gravity), configure and train a Soft Actor-Critic agent using stable-baselines3 with a linear learning-rate schedule and TensorBoard logging, then export the saved policy. Validate the policy over 10 unseen physics seeds to achieve an average return ≥195.",,
e82e442a-f53d-453b-b1ab-86068e4e6732,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Implement a custom OpenAI Gym multi-asset trading environment using /app/data/price_history.csv, with portfolio and risk-adjusted reward shaping. Configure RLlib to train a PPO agent for 200k timesteps, output training logs, Sharpe ratio and cumulative returns in metrics.json, and save the final policy checkpoint.",,
a76e4ea3-5b27-4987-8e1b-4cc66e74bc56,Machine Learning & AI,Model Evaluation & Validation,Error Analysis & Visualization,"Implement a reproducible Python CLI that ingests true labels, predicted probabilities, and corresponding image file paths for a multiclass image classifier, computes per-class calibration errors, and generates reliability diagrams, confusion matrix heatmaps, and per-class residual error plots. The tool should also automatically collate and display top-5 misclassified image thumbnails per confusing pair in a consolidated HTML report with embedded plots and summary statistics.",,
eae5b996-46ac-4d1a-bfe1-8d1f2764d2a4,Machine Learning & AI,Model Evaluation & Validation,Error Analysis & Visualization,"Implement a CLI tool that reads prediction and label CSVs, computes per-class confusion matrix, calculates expected and maximum calibration errors, and identifies the top-3 most confused label pairs. The tool must generate a normalized confusion heatmap PNG, a reliability diagram PDF, and write metrics.json, confusion_matrix.csv, and top_confusions.csv with the exact schemas and filenames.",,
f2a5ba62-8332-45c1-8bd3-814b9b14b56b,Machine Learning & AI,Model Evaluation & Validation,Error Analysis & Visualization,"Implement a Python CLI that loads a trained multi-class classifier and its test dataset, computes the confusion matrix to identify the top K most confused class pairs, and plots a heatmap along with per-class precision-recall curves and a reliability diagram. Then extract penultimate-layer embeddings for misclassified samples, apply UMAP to cluster failure modes, and save all visualizations as PNG files.",,
d825ac2d-0f53-40b0-8426-84ece5e78816,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Implement a Python CLI that scans /app/data/text_corpus.jsonl to detect and redact PII (emails, SSNs, phone numbers) using a combination of regex and named‐entity recognition. The tool must output a sanitized.jsonl and a compliance_report.json summarizing PII counts by type, redaction recall/precision, and ensure ≥99% recall on a held‐out validation sample.",,
97dc219e-c094-4084-a095-7258006b7c57,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Create a Python CLI tool that scans a JSONL dataset of customer interactions, automatically detects and redacts PII (names, locations, phone numbers, and email addresses) using regex patterns and a spaCy NER model, and outputs a sanitized dataset plus a compliance report summarizing redaction counts by type. Ensure the tool logs any records with missed or ambiguous redactions, maintains an audit trail, and exits with a non-zero code if validation checks fail.",,
4057a216-3879-4431-89e8-2809d458b1f3,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Implement a Python CLI that scans an input CSV with free-text fields, detects PII using regex patterns and spaCy NER, redacts each entity with a type-specific placeholder, and writes the sanitized CSV. Generate a JSON compliance report detailing counts per PII category and exemplar redacted snippets for audit.",,
f39260af-e708-4460-aee8-c34398ef25a7,Machine Learning & AI,Responsible AI & Model Robustness,Explainability & Interpretability,Implement a CLI tool using LIME to generate per-instance local explanations and aggregate global feature importances for a provided scikit-learn text-classification pipeline and input CSV. The tool should output HTML highlight files for each text showing influential tokens and a summary JSON listing top features with their weights.,,
39f7764e-c629-4289-a67a-7133d8419f41,Machine Learning & AI,Data Preparation & Feature Engineering,Feature Extraction & Transformation,"Implement a Python CLI that reads a CSV of raw text documents, uses Hugging Face transformers to tokenize and compute mean-pooled sentence embeddings (handling long texts with a sliding window), and writes a Parquet file of document IDs and embedding arrays. Ensure deterministic batching for GPU/CPU inference, log token counts and processing time, and validate output schema against the expected metadata.",,
dcd03eb6-12b2-44c9-b4d2-84b20d34d18d,Machine Learning & AI,Data Preparation & Feature Engineering,Feature Extraction & Transformation,"Implement a command‐line tool that ingests /app/data/events.csv (with user_id, event_type, timestamp), then computes per-user features over sliding windows (1h, 24h, 7d) including event counts, distinct event_type counts, and average inter-event times, with event_type one-hot encoding in aggregates. The tool must process data in chunks for large files and output a Parquet file of feature vectors plus a JSON schema file.",,
c0cd07b6-c699-4f4c-b067-6c8a7fbbeaa6,Machine Learning & AI,Data Preparation & Feature Engineering,Feature Extraction & Transformation,"Create a Python CLI that reads a FASTA file of DNA sequences, computes normalized k-mer frequencies for k=3 to 6, GC content, and dinucleotide odds ratio, then applies PCA whitening to the combined feature vectors and writes the result as a CSV. Ensure deterministic output, no external internet calls, and parameterized selection of k values and PCA components via CLI flags.",,
874237d0-d0d7-447c-8a5d-ff4233517cf1,Machine Learning & AI,Data Preparation & Feature Engineering,Feature Extraction & Transformation,"Create a Python CLI that loads raw multivariate time-series data from /app/data/sensors.csv, applies sliding-window segmentation, computes statistical (mean, std, skewness, kurtosis), frequency-domain (spectral peak, bandwidth), and time-domain (zero-crossing rate) features for each window, and writes the consolidated feature matrix to /app/output/features.csv using the exact schema.",,
84469d46-a34c-48d3-8548-eaeef88a9eb2,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Fine-tune a GPT-Neo 2.7B model using PEFT’s LoRA adapters on a legal contracts summarization dataset, with configurable adapter rank, learning rate, and batch size via CLI. After training, quantize the adapter weights to 8-bit and package the model for efficient inference, reporting ROUGE scores on a held-out test set.",,
788a5a1b-314f-470c-8fed-eb681c37e757,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Fine-tune a pretrained OpenAI CLIP model with lightweight adapter modules on a custom 10-class image dataset for zero-shot classification, providing a deterministic CLI that handles data preprocessing, adapter training with a frozen backbone, and outputs top-1/5 accuracy and confusion matrix metrics on held-out labels.",,
06ecfb66-27f2-46e0-8979-ab529bdb33ce,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Adapt a pre-trained LLaMA-7B model using LoRA adapters on /app/data/chat_dataset.json by freezing the base weights and training adapters with specified hyperparameters before applying GPTQ 4-bit quantization and exporting to GGUF. Evaluate the quantized model on /app/data/test_prompts.txt, compute BLEU and perplexity, write metrics.json, and save sample_responses.txt.",,
d9ce3928-db01-4044-a894-8f004f598a55,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,Implement a Python CLI to fine-tune a pretrained BART transformer on a dataset of long policy documents for abstractive summarization using mixed-precision training and early stopping; log metrics to Weights & Biases. Export the final model as a quantized ONNX file and evaluate using ROUGE scores on a held-out test set.,,
d59b9aab-6dd6-4f2a-a4e1-68fa8904e722,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Implement a CLI pipeline that uses Optuna to perform multi-objective hyperparameter optimization of a given PyTorch model, balancing classification accuracy and inference latency on the provided dataset. The tool must support multi-fidelity pruning, cache trials for reproducibility, and export the Pareto front configurations as JSON.",,
1b438d12-7b47-4141-a4e8-ecd836b0599e,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Build an end-to-end Optuna pipeline using its NSGA-II sampler to tune AdamW weight decay, learning rate, and warmup ratio for fine-tuning BERT on SST-2, jointly optimizing validation accuracy and GPU training time under a fixed memory cap. Record the nondominated trials as a pareto_front.json with top hyperparameter sets and their two objectives.",,
231ed5a5-1647-4bf0-b86e-516a532bb07d,Machine Learning & AI,Foundation Models & Large-Scale Systems,Inference Optimization at Scale,"Convert a pretrained T5-small to ONNX, apply post-training INT8 quantization with ONNX Runtime, and deploy the quantized model to Triton Inference Server with dynamic batching. Benchmark throughput, p50/p95 latency, and GPU memory usage across batch sizes [1,4,8,16] and concurrency levels 1–4, then write a JSON report of the results.",,
ee5ab0a0-cf6e-48ca-a3c4-3aef470d6bbe,Machine Learning & AI,Foundation Models & Large-Scale Systems,Inference Optimization at Scale,"Quantize a BART summarization model to FP16 and build TensorRT engines with dynamic shape profiles for sequence lengths [128,256,512], deploy it on NVIDIA Triton Inference Server, and implement a CLI that sends batched HTTP requests to generate summaries. Finally, record throughput, P50/P99 latency, and peak GPU memory usage in /app/metrics.json.",,
bbd26c71-bb1f-45ee-b29f-e8d2e1514563,Machine Learning & AI,Foundation Models & Large-Scale Systems,Inference Optimization at Scale,"Develop a reproducible CLI that exports a GPT-like HuggingFace model to ONNX, applies INT8 and INT4 quantization via Triton and DeepSpeed-Inference, and deploys both variants with dynamic batching. Benchmark inference on synthetic inputs across varying sequence lengths and batch sizes, capturing latency, throughput, and memory utilization in structured JSON reports.",,
6f85dd8d-a1e3-4b35-83fd-931e1cdb286e,Machine Learning & AI,Foundation Models & Large-Scale Systems,Inference Optimization at Scale,"Create a Python-based pipeline that loads a pretrained transformer model, applies 4-bit quantization using GPTQ, and deploys it via NVIDIA Triton Inference Server with dynamic batching and request coalescing. Include a benchmarking CLI that profiles throughput and latency across varying batch sizes and sequence lengths, outputting a JSON performance report.",,
3062d0fe-fd52-4c93-b066-be10223249d4,Machine Learning & AI,Foundation Models & Large-Scale Systems,Large Model Fine-Tuning & Adaptation,"Implement an end-to-end CLI pipeline that fine-tunes a 7B-parameter LLaMA-2 model on a domain-specific Q&A dataset using LoRA and 4-bit quantization, logs training metrics, and saves checkpoints. Package the fine-tuned model as a FastAPI service with endpoint latency and memory usage benchmarks under load.",,
a3b290c8-02f6-49a5-9087-ea2dc3ab4140,Machine Learning & AI,Foundation Models & Large-Scale Systems,Large Model Fine-Tuning & Adaptation,"Develop a QLoRA-based fine-tuning pipeline that loads a 7B open-source LLM, applies 4-bit quantization and LoRA adapters on a provided domain-specific text corpus, merges the adapters into the base model, and exports the final quantized model. Evaluate the adapted model’s performance via perplexity and domain-specific accuracy metrics on a held-out test set.",,
1336ef8d-0374-4c96-9c18-51b70483d814,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Create a Dockerized FastAPI endpoint hosting a provided PyTorch sentiment-analysis model, measure baseline P95 latency and throughput under simulated concurrent requests (load config given), then apply ONNX dynamic quantization, server worker tuning, and request-level caching to achieve ≥2× throughput or reduce P95 by 50%. Save detailed profiling metrics (latency percentiles, throughput, CPU/GPU utilization) for both baseline and optimized setups in results.json following the provided schema for automated verification.",,
cb379f6a-c2ac-4aec-8418-ff6dcbbe74cf,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Export a pre-trained PyTorch vision transformer to TorchScript and ONNX, apply dynamic quantization, and integrate it into a FastAPI server supporting asynchronous batch requests. Profile the service’s latency and throughput under various batch sizes and thread configurations, and implement an automated tuning script to meet specified performance targets.",,
af1ea084-89ae-46bb-a414-a37025610dc3,Machine Learning & AI,Deep Learning & Neural Network Engineering,Loss Function Design & Custom Layers,"Implement a custom PyTorch ContrastiveMarginLoss module that computes pairwise distances and uses a dynamic margin equal to the batch-wise distance standard deviation. Integrate it into a Siamese CNN to train on /app/data/omniglot_triplets.json and evaluate one-shot classification accuracy ≥80%, saving the model and metrics.",,
e8e1521b-a1cc-48e1-bc4e-93fb06fcca93,Machine Learning & AI,Deep Learning & Neural Network Engineering,Loss Function Design & Custom Layers,"Implement a PyTorch custom subspace-normalization layer that applies instance-wise learnable scaling on feature subsets and a paired CenterLoss that pulls class embeddings to their centroids while repelling others. Provide a deterministic CLI to train on synthetic classification data, output class-wise embedding distances and log both loss components independently.",,
8beff6ca-29b4-4bfd-804e-9b126ee1a80f,Machine Learning & AI,Deep Learning & Neural Network Engineering,Loss Function Design & Custom Layers,"Implement a PyTorch module providing a FourierFeatureEncoding layer with channel-wise learnable frequency scales and a companion SpectralWeightedMSE loss that emphasizes specified Fourier bands via trainable weights. Create a CLI to synthesize test sinusoidal images, process them through a simple reconstructor, compute per-band loss breakdown, and export metrics to /app/metrics.json and /app/band_errors.csv.",,
bc3559e5-94a6-4098-acc5-0be5a32cee24,Machine Learning & AI,Model Training & Optimization,Training Loop Implementation,"Implement a PyTorch training loop for a CNN on CIFAR-10 with gradient norm clipping, a one‐cycle learning rate scheduler, and early stopping. The script must checkpoint the best model, log training and validation metrics to JSON, and resume correctly from the latest checkpoint.",,
d8716679-ad83-4867-aa94-62651dc799ce,Machine Learning & AI,Model Evaluation & Validation,Metric Computation & Reporting,"Develop a CLI tool that ingests ground-truth labels and probabilistic model outputs for a multi-class classifier, computes per-class and aggregate metrics (accuracy, precision, recall, F1, ROC-AUC), calibration measures (Brier score, expected calibration error), and emits a JSON report plus CSVs for confusion matrices and calibration curves.",,
857ddd86-9828-43b3-9f1e-a19a8e80c7f0,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,Export a Hugging Face MarianMT translation model to ONNX with dynamic batch and sequence-length axes. Implement a Python CLI using onnxruntime to translate sample sentences and verify outputs match the PyTorch baseline within a specified tolerance.,,
20836b84-4c31-4cdd-acef-64ec22def167,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Create a Python CLI that loads a trained PyTorch multimodal image-text model, exports it to both scripted and traced TorchScript as well as ONNX with dynamic axes for batch and sequence lengths, then validates output consistency within a specified tolerance on sample inputs and reports file sizes and inference latencies.",,
f6a65932-bdfa-4b85-a8cc-e31de3f46bd5,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Implement a CLI tool that converts a scikit-learn preprocessing and classification Pipeline (e.g., ColumnTransformer + RandomForest) to ONNX with dynamic batch dimensions, then runs ONNX Runtime inference on a test CSV and validates prediction parity (absolute difference ≤1e-6). The script must output model.onnx and a JSON report containing inference metrics and parity checks.",,
03d5db44-fc9c-4ea9-96ac-1f6444adffae,Machine Learning & AI,Machine Learning Pipelines & Automation,Model Registry & Versioning,"Build a CLI-based pipeline that detects new model artifacts, semantic‐version tags them based on configuration and performance diffs, automatically registers them in an MLflow model registry, and generates a versioned changelog. Extend the workflow to evaluate new versions against a staging dataset, auto‐promote the best performer to production stage, and support one‐click rollback to any previous version via REST API.",,
92ff6d83-aa4e-46c8-a359-9ea7cc5e04db,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a Dockerized Python CLI project that defines a custom grid-world predator-prey environment for two agents, configures self-play with Stable Baselines3’s PPO including curriculum difficulty scaling and periodic opponent parameter swapping, and supports automatic checkpointing. After training, run 200 headless evaluation episodes and produce a JSON report with win rates, average episode length, and policy entropy.",,
3b50270a-f515-4802-b6bd-8f49b952abe3,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a self-play training pipeline using the PettingZoo ‘simple_tag’ pursuit-evasion environment with PPO from stable-baselines3, periodically swapping chaser and evader policies. Log episodic team rewards, role-switch events, and save agent checkpoints once cooperative performance exceeds a threshold, then evaluate against random baselines and output metrics.json with per-agent and joint reward statistics.",,
5abd49cf-e743-422e-9d64-ffc0c3945d58,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Create a gridworld capture-the-flag environment using PettingZoo, train two competing agent teams via Stable Baselines3 PPO in self-play with parameter sharing, log episodic win rates and cooperation metrics, and export the best team policies and training curves.",,
3412324f-afdd-4e3c-a6ec-545bae3d878a,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a Python CLI tool at /app/train_connect4.py that sets up an OpenAI Gym Connect Four environment for two DQN agents to learn via self-play with an epsilon-greedy schedule, periodically evaluating head-to-head performance. The script must save the best agent model as /app/models/best_agent.pt, record win rates over 100-episode evaluation windows in /app/metrics.json, and output a final payoff_matrix.csv documenting win/draw counts.",,
a26d9bcd-45ee-4138-9ba4-8cc269348e0d,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a self-play training framework for a two-player, turn-based Nim game with variable heap configurations, using policy-gradient agents that periodically evaluate each other via an ELO-based matchmaking scheme. Automate parallel rollouts, checkpointing of top-performing policies, and generation of win-rate and ELO progression plots for analysis.",,
a40f95d4-6f46-4d57-835b-7d2461f8a877,Machine Learning & AI,Machine Learning Pipelines & Automation,Pipeline Construction & Scheduling,"Implement an Apache Airflow DAG that orchestrates a complete daily ML workflow: ingesting raw CSV data, validating it with Great Expectations, performing feature engineering, training and evaluating an XGBoost regression model, registering the best model in MLflow, and emitting a summary report to a log or notification channel. Ensure the DAG leverages sensors, XComs for inter-task data passing, retry policies, SLA notifications, and is scheduled to run every 24 hours.",,
b6c53814-7578-4554-81da-b4cee2044b1b,Machine Learning & AI,Machine Learning Pipelines & Automation,Pipeline Construction & Scheduling,"Use Apache Airflow to build a daily DAG that ingests clickstream logs from AWS S3, orchestrates Spark-based feature extraction and Dask-driven hyperparameter tuning for a LightGBM model, logs metrics and artifacts to MLflow, conditionally registers and deploys the model to a staging Kubernetes service if validation AUC improves by ≥2%, and sends Slack notifications on success or failure with retries, SLA enforcement, and secret-managed connections.",,
583d367c-3295-4942-9a70-bea7f4beda5d,Machine Learning & AI,Machine Learning Pipelines & Automation,Reproducibility & Environment Setup,"Construct a Docker image with a conda/mamba environment that pins CPU and GPU PyTorch, CUDA toolkit, and common ML libraries via lockfiles to guarantee bitwise-identical package installs. Provide a CI pipeline that runs a fixed-seed toy training job, verifies reproducible logs, metrics, and model weights, and checks for stable Docker image digests across independent builds.",,
44344258-22bc-4e7c-99e3-1462b74f7f69,Machine Learning & AI,Model Training & Optimization,Resource Management & Parallel Training,"Implement a PyTorch DistributedDataParallel script that auto-detects available CPUs and multiple GPUs, spawns per-device processes, and trains a simple CNN with synchronized gradient reduction. The script should dynamically adjust per-GPU batch sizes based on free memory and log device-specific GPU utilization, memory usage, and per-epoch training throughput to a CSV file.",,
d56d132b-0cbc-4654-9318-2144ada5d39b,Machine Learning & AI,Model Training & Optimization,Resource Management & Parallel Training,"Create a Dockerized PyTorch pipeline-parallel training script that splits a ResNet-50 into two stages across two GPUs, uses torch.distributed RPC for microbatch scheduling and gradient checkpointing, handles automatic rollover to CPU memory when a GPU runs out of space, and logs per-step throughput, GPU utilization, and peak memory usage.",,
28b77aa4-22c5-4792-86d7-e66df1b721ad,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"In a simulated warehouse navigation environment, design and implement reward functions that balance path efficiency, collision avoidance, and battery consumption; then evaluate how different reward weightings affect the agent’s learning speed, policy robustness, and trade-offs among objectives.",,
7ce72b3e-9f64-424f-8067-bb665f1dc459,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Design and implement a multi-objective reward function in a custom gym-based logistics simulation that balances delivery time, fuel consumption, and fairness among multiple agents, and evaluate trade-offs by plotting Pareto frontiers of performance metrics across varying weight configurations.",,
5ff21f55-e252-40ff-9c7e-98dcc47b4516,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Implement and compare multiple reward functions combining extrinsic goal completion with intrinsic curiosity bonuses in a procedurally generated maze environment, training an OpenAI Gym agent under various reward-weight schedules. Automate runs for each schedule, collect path efficiency and state coverage metrics, and output a Pareto-front analysis in JSON.",,
0e41513a-caeb-47da-8165-f41701c78506,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Deploy a quantized BART summarization model as a Dockerized FastAPI microservice that supports both REST and gRPC endpoints, asynchronous dynamic batching, JWT-authenticated requests, and emits Prometheus-compatible latency and throughput metrics. Provide a CLI tool to manage the server lifecycle (start, stop, reload) and include an example client script for end-to-end testing.",,
fd48d907-fe4d-41aa-88af-31513dab7719,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Implement a FastAPI-based Docker microservice that hosts two versions of a fine-tuned Hugging Face BERT model for sentiment analysis, supports runtime model version selection via an HTTP header, and performs asynchronous batched inference. Include Prometheus-compatible endpoints for request metrics, latency breakdowns, and model load times, plus a CLI for health checks and graceful hot-reloading of models without downtime.",,
cfa43219-1a9f-40cc-b32e-c5eb575ae6b8,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Implement a FastAPI-based microservice that loads both a TensorFlow Object Detection API model and a PyTorch segmentation model, dynamically routes requests based on a JSON flag, and falls back to CPU-only inference when GPU is unavailable. Include asynchronous request batching with configurable batch size and timeout, expose Prometheus-compatible metrics at /metrics, and provide a Typer CLI for bulk image scoring reusing the same service logic.",,
ebeb4f45-9988-4948-9d64-f2fcb8b1574b,Machine Learning & AI,Deep Learning & Neural Network Engineering,Sharpness-Aware Minimization,"Create a PyTorch training script that implements the Sharpness-Aware Minimization (SAM) optimizer alongside standard SGD with momentum on CIFAR-10 using a small CNN, including a cosine annealing learning rate schedule and gradient accumulation. Evaluate and compare generalization gap, sharpness metric, and test accuracy, outputting a JSON with all metrics and model checkpoints.",,
e9077029-f774-4efb-a0de-8db60f19b677,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a Python CLI to run multiple parallel workers generating 100k transitions from OpenAI Gym’s LunarLanderContinuous-v2 into separate circular buffers, merge them into a prioritized SumTree replay buffer supporting importance-sampling-based minibatch sampling and priority updates via provided TD-errors. The tool must accept arguments for buffer size, batch size, alpha/beta exponents, and output the serialized buffer and sampling statistics logs.",,
76538d90-c15e-4027-a196-bfb0b5703959,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a Python CLI that executes OpenAI Gym rollouts using both random and heuristic policies to collect n-step trajectories stored in a prioritized replay buffer with proportional and rank-based sampling via segment trees. Include commands to generate trajectories, sample mini-batches as Torch tensors, purge stale experiences, and log buffer statistics (priority distribution, average returns) to JSON.",,
22a8ec59-f324-4ab0-b2ec-f8fbb075aec9,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a disk-backed prioritized experience replay buffer that supports million-step trajectories with proportional sampling based on TD-error priorities, on-the-fly compression, and concurrent writers. Provide a CLI with subcommands for inserting rollouts, sampling batches, and updating priorities for multi-worker RL training pipelines.",,
f8146adc-5402-4777-ae36-52750c43fd8a,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Create a Python CLI that runs parameterized rollouts in an OpenAI Gym environment, capturing state-action-reward-next transitions into a disk-backed replay buffer with fixed capacity and ring-overwrite semantics. The tool should support n-step return augmentation, prioritized experience replay via a segment-tree index, deterministic seeding, and output sampled batches along with buffer occupancy and priority distribution stats.",,
acc236c8-85b5-43ad-abe8-6aa81f926374,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a Python CLI that collects rollouts from the OpenAI Gym CartPole-v1 environment into a disk-backed prioritized experience replay buffer using a SumTree, supports proportional priority updates and both uniform and prioritized minibatch sampling, and writes buffer statistics and sampled indices to JSON files.",,
e22dba1b-9623-4e83-85c5-0b37ea69f058,Machine Learning & AI,Model Training & Optimization,Supervised & Unsupervised Learning,"Implement a CPU-only PyTorch Variational Autoencoder (VAE) training pipeline on the CIFAR-10 dataset with configurable latent dimension and β parameter, saving reconstructed and randomly sampled images. Log reconstruction loss, KL divergence, and latent distribution statistics in metrics.json and store all artifacts in a structured outputs folder.",,
56d61509-e9c2-4759-bdb0-24fe788c055b,Machine Learning & AI,Model Training & Optimization,Supervised & Unsupervised Learning,"Create a deterministic Python CLI that loads /app/data/articles.csv (with text and label columns), builds a reproducible scikit-learn pipeline of tokenization, TF-IDF vectorization with configurable n-grams, chi² feature selection, and a calibrated LinearSVC ensemble, then evaluates macro-averaged precision/recall/F1, and writes the serialized pipeline and a detailed JSON performance report to /app/output.",,
d2988391-02f8-446e-a092-678e9a27afed,Machine Learning & AI,Model Training & Optimization,Training Loop Implementation,"Implement a PyTorch training loop supporting dynamic gradient accumulation, automatic mixed precision with dynamic loss scaling, gradient norm clipping, and cosine annealing warm-restart learning rate scheduling. Include optional exponential moving average weight updates and robust checkpointing of model, optimizer, scheduler, EMA state, and RNG seeds for full reproducibility.",,
2d4ffad4-aa8a-4b4b-9885-e54b8c0bc7dc,Machine Learning & AI,Model Training & Optimization,Training Loop Implementation,"Implement a PyTorch federated averaging training loop that simulates multiple clients each performing local training with gradient clipping and optional momentum, aggregates weights via FedAvg with dynamic client sampling per round, and supports checkpointing and resume functionality. Include early stopping based on global validation metrics and detailed per-round TensorBoard logging.",,
e9f00bce-62f4-4d4a-a960-3c3cfaa5614c,Machine Learning & AI,Deep Learning & Neural Network Engineering,Training Stabilization Techniques,"Implement the Sharpness-Aware Minimization (SAM) optimizer in PyTorch and integrate optional gradient clipping along with a cosine-annealing learning-rate scheduler in a training loop, ensuring stable convergence on a sample image classification task with CPU/GPU support.",,
60b6849b-8ac0-4842-a5f3-7a478b536ea6,Machine Learning & AI,Deep Learning & Neural Network Engineering,Visualization & Debugging,"Implement a Python CLI that loads a PyTorch model and dataset, hooks a user-specified layer to collect activations on a stratified sample of inputs, applies t-SNE to reduce activations to 2D, and generates per-class colored scatter plots saved under /app/visuals. Additionally, export the 2D embeddings and aggregate activation statistics (mean, std, skewness) to JSON files following the defined schema.",,
94d9e667-bf9b-4f41-9228-8a817d89ba0d,Machine Learning & AI,Deep Learning & Neural Network Engineering,Visualization & Debugging,Create a Python CLI tool that instruments a given PyTorch model to capture per-layer activation and gradient distributions over a sample batch and generates an interactive HTML report of histograms and heatmaps to pinpoint vanishing or exploding gradients.,,
b060ec52-48b5-446a-a0c9-9093e01811cf,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Build a CLI tool that ingests a set of NORAD TLEs and a ground-station coordinates file, propagates each orbit with SGP4 over a 24-hour window, and computes visibility passes above a given elevation threshold (AOS/LOS times, max elevation, range). Write per-satellite CSV summaries and an aggregated ICS calendar of visible passes.",,
f49b78ca-fa8e-4228-8e46-02fca18df3fc,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Implement an exoplanet transit search tool that reads a stellar light curve, detrends it, and runs a Box Least Squares period search over a specified grid with careful, unit-aware time handling. Output the best-fit ephemeris (period, epoch, duration, depth) with detection metrics and a phase-folded, binned curve to standardized files.",,
06d325cb-6916-4279-9d26-2464947d95bd,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Implement an initial orbit determination and refinement pipeline that reads multi-epoch asteroid astrometry (UTC, RA, Dec, observatory) to compute a heliocentric two-body solution using Gauss’ method followed by nonlinear least-squares differential corrections. Output Keplerian elements at a target epoch, a 6×6 covariance estimate, propagated ephemerides, and postfit residual statistics.",,
c5bf29fa-81c7-418a-8853-d7ed10f7fdbf,Scientific Computing & Analysis,Domain-Specific Computation,Climate & Environmental Modeling,"Build a CLI tool that reads CF-compliant NetCDF files of monthly precipitation and potential evapotranspiration, computes the 12-month SPEI per grid cell via log-logistic fitting with robust handling of missing values, and writes a CF-compliant NetCDF of SPEI. Additionally, produce a CSV time series of global land-area fraction in drought (SPEI <= -1) for each month.",,
5ca2850e-e31e-4283-b1dd-0d9d0eaa0ae6,Software Engineering & Development,Development Tooling & Workflow Automation,Continuous Integration (CI) Pipelines,"Create a GitHub Actions workflow for a Python+Node monorepo that uses path filters to generate a dynamic job matrix, caches pip/npm, provisions a Postgres service with health checks, shards pytest across 3 parallel jobs, runs jest with coverage, and publishes a combined coverage summary. On semantic-version tags, build a multi-arch Docker image with buildx, sign it via OIDC/cosign with an attached SBOM, and upload release artifacts while skipping release steps on other pushes.",,
b7f5f5d8-cc81-43e8-b38b-0051570aafe3,Software Engineering & Development,Development Tooling & Workflow Automation,Continuous Integration (CI) Pipelines,"Create a GitHub Actions workflow for a monorepo that uses path filters and a matrix to run Python and Node.js tests (with a Postgres service), caching dependencies, and on failure triggers an automatic git-bisect job that posts the first bad commit as a PR comment. On tagged releases, build and push a signed multi-arch Docker image to GHCR with Buildx, generate CycloneDX SBOMs for both components, and fail if the vulnerability scan reports high-severity issues.",,
d9d3a32b-5f0f-40e1-b54f-c193f5f4f266,Software Engineering & Development,Development Tooling & Workflow Automation,Continuous Integration (CI) Pipelines,"Create a GitHub Actions workflow for a polyglot monorepo (server/ Python API, web/ Node frontend) that conditionally runs by path, uses a matrix, caches dependencies, and hands off built web artifacts to backend integration tests. The pipeline should start Postgres and Redis services, merge coverage to Cobertura, and on v* tags build and push a Docker image to a local registry.",,
25d6a9a0-a2d2-46b8-8d40-7122ebdeaf53,Software Engineering & Development,Development Tooling & Workflow Automation,Continuous Integration (CI) Pipelines,"Create a reusable GitHub Actions workflow (invoked via workflow_call) that builds a dynamic matrix from changed subdirectories to lint/test polyglot components (Go, Node, Python) with dependency caching, provisions PostgreSQL and MinIO services for integration tests, and builds multi-arch Docker images via buildx. On version tags, sign the image using keyless cosign via OIDC, generate an SBOM and SLSA provenance, and publish artifacts to GitHub Releases and the container registry.",,
52b7dc7f-392f-42aa-a473-40bc99466b03,Software Engineering & Development,Development Tooling & Workflow Automation,Developer Environment Setup,"Create a hermetic polyglot developer environment using Nix Flakes that exposes a dev shell with pinned Python (Poetry), Rust (cargo), and Node (pnpm), plus pre-commit and reproducible caches. Provide flake.nix and a Justfile so `nix develop` drops into a non-root shell where `just lint` and `just test` execute the configured tooling.",,
e95c7b3c-e14e-4455-8ffa-a9888652ac7a,Software Engineering & Development,Development Tooling & Workflow Automation,Developer Environment Setup,"Create a reproducible polyglot developer environment using Nix flakes and direnv for a repo combining Python 3.11, Rust 1.75, and Node 20, with a matching Docker image generated from the same flake. Pin all toolchains, wire pre-commit hooks, and ensure `make test` runs identically inside `nix develop` and `docker run`.",,
ca3305ea-6d0f-4bd3-8785-ac629f39f849,Software Engineering & Development,Development Tooling & Workflow Automation,Developer Environment Setup,"Set up a Nix flake-powered VS Code devcontainer that provides a hermetic polyglot toolchain (Rust, Python, Node.js, Go) with pinned versions, LSPs, and pre-commit hooks via direnv integration. Enable Docker Buildx/QEMU multi-arch and ccache/sccache so the same make bootstrap and make test targets work identically on x86_64 and arm64.",,
0d7deb50-070e-4df0-9c41-458e908212a4,Scientific Computing & Analysis,Domain-Specific Computation,Climate & Environmental Modeling,"Build a zero-dimensional energy balance climate model that ingests historical radiative forcing and GMST series, estimates the climate feedback and effective heat capacity via constrained least squares, then projects global-mean temperature through 2100 under provided forcing scenarios. Output the fitted parameters, hindcast skill metrics, and scenario trajectories to standardized files.",,
1bffde14-e21c-419b-8755-0f6954e7d11b,Scientific Computing & Analysis,Domain-Specific Computation,Climate & Environmental Modeling,"Create a Python CLI that reads daily gridded NetCDF temperature and precipitation and computes three ETCCDI indices—TX90p, CDD, and PRCPTOT—per grid cell for a user-specified baseline, honoring CF calendars, masks, and leap years, and writes CF-compliant NetCDF outputs. Also compute area-weighted global and region-mean time series using cell areas and save a summary CSV.",,
246a5f56-456a-4a57-ba0e-35def7ad46c3,Scientific Computing & Analysis,Domain-Specific Computation,Climate & Environmental Modeling,"Implement a two-box global energy balance model (mixed-layer plus deep ocean) driven by a provided radiative forcing time series to simulate global-mean temperature and ocean heat uptake. Calibrate feedback, heat capacities, and exchange parameters against historical GMST and OHC data, then output ECS, TCR, fitted parameters, and scenario projections.",,
991315d1-027d-4fdd-9fbf-bf76be63f4a8,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Build a Python CLI that loads an SBML metabolic model and uses COBRApy with a GLPK solver to perform FBA, then evaluates growth under multiple media conditions and all single-gene knockouts to identify essential genes. Save growth rates per condition and the essential gene list to standardized JSON/CSV outputs.",,
5aa02538-fa46-4301-8493-6a6b83700e9b,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Create a Python CLI that loads a metabolic network SBML (/app/model.xml), builds the stoichiometric matrix, and performs flux balance analysis to maximize a specified biomass reaction using linear programming. Validate mass balance and bounds, identify exchange reactions, then write the optimal flux vector and dual shadow prices to CSV files.",,
8ceec821-da9a-41e9-a3fb-fc815ada3a15,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Create a Python CLI that loads a molecular dynamics trajectory of liquid water (XYZ frames plus periodic box dimensions) and computes the O–O radial distribution function g(r), its first minimum, and coordination number (integral to the first minimum), as well as the self-diffusion coefficient from the mean-squared displacement under periodic boundaries. Write g(r) to /app/gofr.csv and a JSON report with the first-minimum position, coordination number, and diffusion coefficient to /app/results.json, verifying normalization and minimum image handling.",,
a35b8476-208e-4c1a-8b27-50d4edae7534,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Using COBRApy, load the provided SBML metabolic network, configure exchange reactions to model aerobic minimal media with glucose, and maximize biomass to compute the optimal growth rate. Then perform a single-gene deletion screen to identify essential genes under these conditions and write the growth rate and the sorted essential gene IDs to output files.",,
18e514df-89c5-40b6-aee1-71d048460056,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Build a 1D compressible gas dynamics solver for the Sod shock tube using a conservative finite-volume scheme (MUSCL-Hancock with HLLC flux and CFL control) from Riemann initial data, and write density/velocity/pressure profiles at specified times. Include a check that total mass and total energy are conserved to within a small tolerance.",,
fb120c18-e722-4ec8-96e3-d30c1df8f87d,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a 1D compressible Euler solver to simulate the Sod shock tube using a finite-volume Godunov scheme (e.g., HLLC) with CFL-controlled timestepping and positivity preservation. Output density, velocity, and pressure profiles at specified times and report L1 error against the analytic solution.",,
5e54abf4-99ce-46da-bb2b-9b40373a6dcc,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a 1D finite-volume solver for the compressible Euler equations to simulate the Sod shock tube using an HLLC Riemann solver with a TVD slope limiter, exposing a CLI to set grid size and CFL and writing CSV profiles of density, velocity, and pressure at a target time. Validate conservation of mass/momentum/energy and achieve a small L1 error versus an exact Riemann solution computed by a provided routine.",,
0c519f12-1f67-4241-b4bc-6f9d46115679,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a 1D time-dependent Schrödinger equation solver using the split-operator Fourier method to simulate a Gaussian wavepacket scattering from a rectangular potential barrier. The CLI should sweep incident energies, compute reflection/transmission probabilities with norm conservation, and validate against the analytic transmission coefficient.",,
d71a8216-fb03-4b50-9160-dc75c61584b4,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,Implement an Euler–Bernoulli beam finite element solver for a uniform clamped–clamped beam that assembles mass and stiffness matrices and computes the first three natural frequencies and mode shapes. Validate the frequencies against closed-form solutions within 2% and save frequencies and mode shapes to specified output files.,,
469e0e7e-45d6-4f79-a97b-debf8117a8c1,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Implement a Python CLI that loads A, B, C from /app/*.npy and solves A X B = C for X using factorization-based linear solves without forming the Kronecker product (e.g., via LU/QR and column/row reshaping), with an option for Tikhonov regularization. Save X to /app/output/X.npy and a metrics JSON including relative residual (target ≤ 1e-8) and simple condition estimates.",,
3fb4234c-8624-4409-8940-dea6452f050e,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Implement a randomized SVD (Halko algorithm) with configurable rank, oversampling, and power iterations to compute a low-rank approximation of a large dense or sparse matrix loaded from disk. Compare to a deterministic truncated SVD by reporting singular values, relative Frobenius reconstruction errors, and timings in a results JSON, also saving the U,S,V factors.",,
63faffeb-352c-46a6-bd8b-ecc8d340272c,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Implement a randomized low-rank SVD with oversampling and configurable power iterations to compute the top-k singular values and vectors for large dense or sparse matrices via a CLI, benchmarking accuracy and runtime against NumPy/SciPy baselines. Validate orthonormality of U and V and relative reconstruction error, writing standardized outputs to files.",,
0cc13cbf-fb2f-47b8-a584-decac0a212b9,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Write a Python script that loads a sparse SPD matrix A from /app/A.mtx and a vector b from /app/b.npy, then solves Ax=b using preconditioned conjugate gradients with an incomplete factorization (ILU/IC) or Jacobi fallback. Save x to /app/x.npy and a JSON with iteration count, final relative residual, and wall time, ensuring ||A x − b||2 / ||b||2 ≤ 1e-8.",,
d3c4e58f-477b-467f-b814-c9e2d11e7498,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Build a Python CLI that integrates systems of ODEs defined by a JSON spec using an adaptive Dormand–Prince 5(4) solver with dense output and event/root detection, automatically switching to an implicit BDF method when stiffness is detected via step-rejection heuristics. The tool should write solution snapshots and event times to files and include a test harness that verifies accuracy and performance against SciPy.integrate on provided nonstiff and stiff problems.",,
815c9669-7a3f-4f45-a8cf-83d64eafc30f,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement a Python CLI that performs 1D integration using tanh-sinh (double-exponential) quadrature with adaptive node refinement and error control to handle endpoint singularities. Use it to evaluate the integral of x^(-1/2) * log(x) over [0, 1] to at least 12 correct digits and write both the result and the function-evaluation count to /app/answer.json.",,
34375d21-9384-4d75-8d6c-65b7a2521725,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement a Python tool that loads a parameterized ODE and scalar loss from a problem module, integrates forward to produce state samples at given eval_ts, then computes dL/dθ via a reverse-time continuous adjoint solve with accurate interpolation of the forward trajectory. Output the trajectory and gradient along with a verification report that checks the adjoint gradient against central finite differences within a specified tolerance.",,
ba551f4a-a736-4133-a1db-6f66041e5d5f,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement an adaptive Gauss–Kronrod 21/10 quadrature with a best-first error priority queue that handles infinite limits and endpoint algebraic/log singularities via variable transformations, enforcing absolute/relative tolerances and a cap on function evaluations. The CLI loads an integrand from /app/integrand.py and a JSON spec of intervals and tolerances, then writes the integral, error estimate, and evaluation statistics to /app/output.json.",,
62241141-49ed-413c-bd15-76bdd6c3c3cf,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement an adaptive tanh-sinh (double-exponential) quadrature that handles endpoint singularities and infinite limits, returning integrals to specified absolute/relative tolerances while tracking function-evaluation counts. Provide a CLI that reads multiple integrals and intervals from input, computes results without external integration libraries, and writes both values and convergence traces.",,
177488a5-0915-4565-9edd-8ba6fcae67cf,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Build a Jacobian-free Newton-Krylov solver with backtracking line search to find the steady state of the 2D Bratu (nonlinear Poisson) equation on an N×N grid. The CLI should accept N and lambda, converge to a specified residual tolerance using GMRES with simple preconditioning, and write the solution field and an iteration/residual log to disk.",,
164ddf68-5362-45bc-8e05-42e08cd58e04,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Build a terminal tool that solves a system of nonlinear equations using a Jacobian-free Newton–Krylov method (Newton-GMRES with backtracking line search), loading residual(x) and an initial guess from /app/problem.py. Stop when the 2-norm of the residual is ≤1e-8 or the time budget is hit, and write the solution vector plus iteration and GMRES stats to /app/solution.json.",,
868cc7d2-db0b-4876-818f-b82963aaa332,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Implement a command-line tool that computes the minimax (L-infinity) polynomial approximation of a given function on [a,b] using the Remez exchange algorithm, with optional weighting. Output the polynomial coefficients, the achieved uniform error, and the final set of alternation points to a results file.",,
3e37a629-3502-42f2-baa6-4a2bcc7cfa05,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Implement a primal-dual interior-point solver (Mehrotra predictor–corrector) for dense convex quadratic programs that reads H, f, A, b, G, h, and bound vectors from /app/problem.npz, uses a safeguarded line search with regularization, and drives the KKT residual below 1e-6. Output the primal and dual solutions, final duality gap, and residual norms to /app/output/solution.json.",,
6ef53c4d-61d7-4c74-ba8e-440effe560a3,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Build a CLI tool that estimates logdet(A) for large sparse SPD matrices via randomized trace estimation of log(A) (Hutch++ with Chebyshev/Lanczos polynomial approximation), using reproducible seeds and batched probes to deliver a 95% confidence interval within a target relative error. The program must read Matrix Market files, validate against exact small cases, and emit a JSON report with estimate, CI, probe count, and timings.",,
e57d3d07-9a5c-48c8-899a-98dca12e46eb,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Create a terminal script that loads a symmetric positive-definite matrix from /app/A.npz and estimates log(det(A)) by approximating trace(log A) via stochastic Lanczos quadrature with Hutchinson (Rademacher) probes using a reproducible RNG seed. The tool should adaptively increase probes to meet a target confidence interval and write the estimate, probe count, and CI to /app/answer.json within a time budget.",,
35dea734-908a-4328-b10a-930b264f961f,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Implement a CLI tool that, given a symmetric positive definite sparse matrix A (Matrix Market), estimates trace(log A) via stochastic Lanczos quadrature with Hutchinson probes, supporting Rademacher, Gaussian, and Owen‑scrambled Sobol sequences. The tool adaptively increases probes to hit a target relative 95% CI, reports estimate/CI/probe count/RNG/timing to /app/results.json, and validates on small cases against a Cholesky-based exact computation.",,
da8e3e71-8793-401a-bdd3-6be2cde2baf5,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Implement a stochastic Lanczos quadrature estimator for trace(log(A)) (i.e., log det A) of a large sparse SPD matrix using Hutchinson probes (Rademacher with optional antithetic pairing), reporting the mean, standard error, and 95% CI as functions of probe count and Lanczos steps. Provide a CLI that loads a Matrix Market .mtx, runs with a reproducible seed, and writes per-probe estimates and the final summary to CSV.",,
17232145-e9fb-44ed-92fa-8e527351a8ba,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Build a CLI that reads a YAML parameter grid, generates and submits a resilient SLURM array job with a launcher mapping SLURM_ARRAY_TASK_ID to parameters, and monitors progress via squeue/sacct until completion. It must auto-requeue failed indices with increased time/memory, throttle or add dependencies based on pending reasons, and produce a CSV with per-index status, exit code, runtime, and MaxRSS.",,
b1d0c75c-f5fc-4b41-b262-83229d09a561,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Build a SLURM workflow manager that submits a 3‑stage pipeline (preprocess → job array → reduction) with dependency chaining, monitors via squeue/sacct, and automatically requeues only failed array tasks (e.g., preempted or OOM) with adjusted resources and retry limits. It must handle SIGTERM for checkpointing and produce a final JSON/CSV report of exit status, retries, elapsed time, and MaxRSS per task.",,
b9994309-b117-45bd-bb38-1717262816ef,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Build a SLURM-driven workflow that launches a job array for a parameter sweep, enforces job dependencies (build -> stage data -> array -> postreduce), detects and auto-recovers preempted/failed tasks via sacct, and aggregates per-task elapsed time and GPU allocation into results.json. Provide scripts to submit, monitor, and checkpoint outputs so requeued runs resume without redoing completed work.",,
a96e5e13-c5a7-4d9b-bb36-d58bf051c16c,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Create a SLURM workflow that runs a parameter sweep as a job array reading /app/params.csv, stages per-task inputs to node-local scratch, and records stdout/stderr per index. Implement automatic failure handling that requeues only failed array tasks once with doubled time/memory and a dependent postprocessing job that uses sacct to write state, runtime, and MaxRSS for all indices to /app/output/summary.csv only after all tasks succeed.",,
96531448-c37f-4fce-b184-bd8e8a97c506,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Create a SLURM workflow that shards a large input into 200 parts, submits a fault-tolerant job array with per-task time/memory requests that traps SIGTERM to checkpoint and automatically retries failed elements, then resumes from partial results upon requeue. Monitor progress via squeue/sacct and submit an afterok aggregation job that verifies all shards, computes per-task runtime/memory statistics, and writes a consolidated JSON report to /app/summary.json.",,
40f9546c-2e50-44d1-b967-99b2ba4a38d1,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Build an MPI-based distributed PageRank solver for sparse graphs that partitions the adjacency matrix by rows, performs power iteration with teleportation and dangling-mass handling via collective reductions, and outputs the top-k ranked nodes and convergence metrics. Provide a CLI to read an edge list, configure alpha/tolerance, verify correctness by matching NetworkX PageRank on small graphs within 1e-6, and report weak-scaling efficiency.",,
ac0d76a4-bc14-4c95-a6b2-daab533ad707,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement a distributed 2D Poisson/heat equation solver using MPI with domain decomposition and ghost-cell halo exchanges alongside a serial baseline sharing a common CLI to control grid size, iterations, and tolerance. Save residual history and the final field to standardized outputs, validate convergence and agreement with the serial solution within a set error, and demonstrate strong-scaling across process counts.",,
aa22161b-967e-4997-89f0-df4042fcae62,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement a distributed Conjugate Gradient solver for large sparse SPD matrices using MPI (mpi4py) with row-wise partitioning and halo exchanges for sparse matrix–vector products; solve Ax=b from provided Matrix Market and NumPy inputs and write the solution residual, iterations, and per-rank timing to files. Validate against a serial SciPy reference on small cases and demonstrate strong scaling across multiple processes.",,
2f67a170-4856-4394-905e-26c3659c55a6,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement an MPI-based 3D Poisson solver on a structured grid using domain decomposition and a conjugate gradient method with Jacobi preconditioning, with each rank maintaining ghost cells and performing halo exchanges each iteration. Validate against an analytical solution by reporting L2 error and residual reduction, and write per-rank timing/scaling metrics and a representative solution slice to output files.",,
018a423d-8383-44f2-a0bc-9662a34834a9,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement an MPI-based 3D Poisson solver on a uniform grid using 3D Cartesian domain decomposition with nonblocking halo exchanges and Jacobi/CG iteration, writing per-iteration residuals, timings, and a central solution slice to standardized outputs. The harness runs at 1, 2, and 4 ranks to validate against a manufactured sinusoidal solution (error threshold), ensure monotonic residual decrease, and assess near-ideal weak scaling.",,
ab48a32b-f0c9-48ec-b013-587fd188d79e,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Create a GPU-accelerated 3D FFT-based Poisson solver using CuPy that computes the potential from a density field under periodic boundary conditions, with a CPU fallback using NumPy/SciPy. The CLI should load a .npy volume, compute potential and total energy, verify relative error ≤1e-6 vs CPU on a test case, and print device info and achieved GPU speedup.",,
34cac5df-f210-4b43-a6be-22efd2518daa,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a 3D FFT-based Poisson solver with periodic boundaries accelerated on GPU using CuPy/cuFFT, supporting batched right-hand sides and single/double precision. Provide a CLI that validates against a manufactured analytic solution and reports accuracy plus speedup versus a NumPy/FFTW CPU baseline.",,
2db94bb6-e4c2-4d7e-9253-233a9a053d65,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a 3D heat diffusion solver using CuPy with a custom CUDA RawKernel (7-point stencil) alongside a NumPy CPU reference, then run both on provided initial conditions to the same final time and validate the GPU field against CPU within 1e-6 max error while saving the final array, device name, and per-backend timings/speedup. Enforce the stability constraint dt <= dx^2/(6*alpha) and use shared-memory tiling with coalesced accesses in the GPU kernel.",,
88ea3523-5d26-45e4-a7d4-d757e9daf587,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a GPU-accelerated 2D Poisson solver on a large grid using a CuPy/Numba-CUDA stencil (Jacobi or Red–Black Gauss–Seidel), and compare its runtime to a NumPy CPU baseline. The script must reach a specified residual tolerance, validate against an analytic solution, and write residual, iterations, and GPU speedup to /app/metrics.json.",,
df34c07c-d818-4783-82e5-a08fe905c558,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Build a multi-threaded Smith–Waterman local sequence alignment engine that parallelizes anti-diagonals (wavefront) with OpenMP alongside a serial baseline, exposing a CLI to align FASTA pairs and emit alignment score and traceback. Include correctness checks against a known-good implementation and a benchmark that reports GCUPS and thread-scaling.",,
37a865e1-c676-42ea-bfaf-ec9f0502ab1b,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a 2D steady-state Poisson solver on a large grid using Jacobi iterations, providing both a single-threaded baseline and a multi-threaded version (OpenMP or multiprocessing). The CLI must accept grid size and thread count, iterate until a residual threshold, and write the final field plus a convergence/timing summary that demonstrates speedup with ≥4 threads.",,
8e821cbf-d965-4c81-883d-70de91f997f6,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a Conjugate Gradient solver for large SPD sparse matrices in CSR format with both serial and OpenMP-threaded paths for SpMV and vector reductions, selectable via a CLI. Load a provided matrix/vector, solve to a tolerance, and output solution, residual norm, and per-iteration timing to validate correctness and speedup across thread counts.",,
ee348e00-ff14-4d69-b341-60c1d26fee40,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement serial and OpenMP-parallelized Conjugate Gradient for large SPD sparse matrices in CSR loaded from Matrix Market files, with optional Jacobi preconditioning and fused parallel reductions. Provide a common CLI to solve Ax=b, write residual histories and solution summaries, verify the parallel solution matches serial within tolerance, and report timing-based speedups across thread counts.",,
29ea492a-f234-4de5-96cc-113a722e273d,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement serial and shared-memory parallel PageRank for a large sparse graph loaded from disk, using thread-partitioned sparse matvec and residual-based convergence. Output the top-ranked nodes and detailed timings to demonstrate speedup over the serial baseline.",,
682b0fa3-1a14-4e6f-b033-caefe0c32d4c,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Build a DVC-backed pipeline (local remote) with dvc.yaml stages to fetch, preprocess, and analyze a dataset while pinning Python dependencies with pip-tools to a requirements.lock. Prove reproducibility by switching between two Git tags and using dvc checkout so that metrics.json and output file checksums exactly match each tag’s recorded state.",,
644c5b12-9429-45d2-9f69-b3c4e12fcced,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Build a DVC-managed analysis pipeline that versions two dataset revisions in a local DVC remote and runs a metrics script inside a conda-lock pinned environment. The run must write /app/results.json with metrics and provenance (dataset DVC hash, lockfile digest, git commit, script checksum) and reproduce bit-for-bit identical outputs across reruns.",,
d4e0ffb5-d578-4803-b56e-ba2db422ac5d,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Create a reproducible time-travel runner that checks out dataset revisions (e.g., tags data/v1 and data/v2) with DVC, resolves the exact environment via conda-lock, executes a Snakemake pipeline, and writes a provenance manifest listing git SHAs, DVC object IDs, lockfile hash, and output checksums. Generate a metric-drift report comparing the two runs and fail if any data or dependency is not pinned.",,
afce8ce1-7e30-4255-9c34-fd3651573688,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Implement a DVC-managed pipeline (preprocess → train → evaluate) with two local dataset versions and lock Python dependencies via pip-tools so reproducing on v1 yields identical artifact and metrics hashes across runs, while switching to v2 triggers only minimal stage recomputation. The run must emit an output manifest with dataset version, DVC stage checksums, and exact pip freeze, and validate at startup that installed packages match the lockfile.",,
42d607b0-b6e0-4eae-9b5b-a5f7700a713a,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Initialize a Git+DVC project tracking /app/data.csv with a local remote and a two-stage, params.yaml-driven pipeline (preprocess -> analysis) that produces metrics.json and commits the resulting dvc.lock. Pin Python dependencies via a generated lockfile (e.g., pip-tools) and run in a fresh venv; then modify the data to create a second version, check out the original DVC tag to reproduce identical metrics and checksums, and write the original data hash and metric to /app/answer.json.",,
e18e4633-b4e7-434d-8f4b-294ec6587175,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Build a small ML experiment pipeline (data → preprocess → train → eval) that uses DVC to version data and stages and MLflow (file backend) to log params, metrics, artifacts, code version, and environment. Provide a CLI to run a parameter sweep and emit a single provenance.json that links each produced model and report to its DVC hash, MLflow run ID, Git commit, code diff, and random seed, enabling exact reruns.",,
8b83766a-c491-4fcf-bec8-b356f3a81f46,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Create a DVC-driven workflow (data → preprocess → model) that logs parameters, metrics, and artifacts to MLflow, and emits a provenance.json capturing dataset checksums, code commit, DVC stage graph, environment snapshot, and MLflow run IDs. Provide a CLI to reproduce any past run from only an MLflow run ID by restoring DVC versions and the environment, then verify artifact byte equality and write a reproducibility report.",,
f7bfcadb-d67a-4b57-bfcf-dee30bad6f70,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Create a DVC-tracked pipeline (preprocess → train → evaluate) for a small scikit-learn task, and instrument each run with MLflow to log parameters, metrics, artifacts, git commit, and DVC data hashes. Prove reproducibility by rerunning dvc repro to obtain byte-identical outputs and emit a provenance report linking MLflow run IDs to the exact DVC stage versions used to produce the final metrics.",,
451315f7-4729-47d8-9e11-4d21f818e1c6,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Convert a geospatial analysis notebook that reprojects a provided shapefile and computes polygon areas under two CRSs into a headless, reproducible CLI executed via papermill/nbconvert, pinning GDAL/PROJ and setting deterministic env vars (e.g., PROJ network/grid settings and single-threaded BLAS). The run must produce identical CSV/PNG artifacts and a results.json with area summaries and SHA256 hashes across repeated clean-container executions.",,
f55d619f-8a2a-48a8-a3dd-efecbfda7ce9,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Convert a provided Jupyter notebook into a deterministic, headless analysis pipeline by parameterizing randomness, extracting it to a Python script, and orchestrating execution with a Makefile that builds a fully pinned, hashed environment (e.g., pip-tools) and runs papermill to regenerate results. The pipeline must yield byte-identical CSV/PNG outputs across reruns and emit a manifest.json capturing package lock hashes, data checksums, seeds, and system info for verification.",,
c7d59433-73c9-422b-8604-e4cb08737864,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Create a CLI pipeline that executes /app/analysis.ipynb with papermill using explicit parameters (including a fixed RNG seed), producing deterministic metrics, tables, and plots in /app/outputs and verifying bit-for-bit identical artifacts across two consecutive runs via SHA256 checksums. The run must also emit a locked requirements file and environment manifest (Python, OS, and package versions) alongside the outputs to ensure re-execution fidelity.",,
7930b1d2-4e38-40f8-b1d4-ea74578e5cce,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Refactor a provided Jupyter notebook with stochastic analyses into a deterministic, parameterized workflow that runs in a locked Python environment and produces byte-for-byte identical outputs on repeated runs. Expose a single terminal entrypoint that pins dependencies, executes the notebook (via papermill or a jupytext-converted script) with fixed seeds and constrained BLAS threads, and writes results.json plus a reproducibility checksum.",,
abddac5a-e255-406c-b179-1bbcd08e8296,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Report Generation & Automation,"Build a CLI pipeline that performs a seeded analysis on a provided dataset, exports figures and tables, and assembles a fully self-contained HTML report (embedded images, no external assets) plus a manifest with SHA256 checksums and environment metadata. Orchestrate with Makefile/Snakemake so unchanged inputs trigger cached steps and reruns produce byte-identical outputs.",,
91bd85b0-8e2d-4e2f-af34-a20e004e1ea0,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Report Generation & Automation,"Build a Makefile-driven pipeline that ingests experiment CSVs, computes grouped summaries with bootstrap CIs, renders figures/tables, and compiles a templated Markdown into a standalone HTML (and optional PDF) report via Pandoc with embedded assets. The workflow must support incremental rebuilds and include a provenance appendix (git commit, CLI args, pip freeze), writing /app/report/index.html and a machine-readable /app/results.json.",,
47e7f52a-7f64-40bb-b0c1-8000efceed93,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Build a CLI that ingests a directory of environmental sensor CSV/TSV files with mixed time zones and units, converts all measurements to SI using declared metadata, aligns timestamps to UTC, resamples to uniform 1-minute intervals, flags/removes outliers, and imputes short gaps. Write a single tidy, columnar Parquet dataset with standardized NaNs and stable column order, plus a JSON file summarizing QC metrics and unit conversions applied.",,
40cce994-7bb7-428b-a0ed-5e7901e22f14,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Build a CLI that ingests a folder of heterogeneous NetCDF climate model files, maps variables to CF-standard names, converts units to SI, reprojects to a target grid, and aligns time onto a unified daily calendar with gap filling. Output a consolidated chunked Zarr store and a manifest CSV documenting provenance, unit conversions, and optional baseline-normalized anomaly fields.",,
03a7a2c7-624a-4704-b57c-1bc8bdba00ab,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Create a CLI that ingests a directory of daily CF-netCDF climate files, harmonizes units (e.g., K→°C), decodes mixed time units/calendars, merges along time, masks fill values, removes outliers, and resamples to monthly means. Compute 1991–2020 per-gridcell climatology and z-score anomalies, then export a chunked, compressed Zarr dataset with consolidated metadata and a Parquet summary index.",,
abdb95f4-55f0-4228-bdfe-314f4ea268be,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Create a CLI tool that ingests a DICOM CT series, converts pixel data to Hounsfield Units via RescaleSlope/Intercept (handling per-slice calibration), clips to [-1024, 3071], and resamples to 1 mm isotropic voxels while preserving spatial metadata. Write a single 3D NIfTI (.nii.gz) with correct RAS affine and a JSON summary of original/resampled spacings, dimensions, and any slices skipped due to corruption.",,
df4b2dda-f533-40a5-a9d7-a6f2a3c7cdf5,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Create a Python CLI that ingests a directory of daily CF-NetCDF climate files, harmonizes variable names/attributes, converts units to a specified target, stitches a continuous time axis over a given range, and repairs single-day gaps via flagged interpolation. Compute per-calendar-month climatology over a baseline and standardized anomalies, then write a CF-compliant compressed NetCDF of the cleaned series plus a CSV of the monthly climatology.",,
1b4bbbb3-34d3-4686-be38-a7dc5fbbf4db,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Build a Python CLI that ingests a multi-band satellite GeoTIFF (with NIR and Red), computes NDVI with nodata handling, reprojects to EPSG:3857, and writes a colorized XYZ tile pyramid into an MBTiles database with correct bounds and metadata. Additionally, vectorize pixels where NDVI exceeds a threshold into simplified GeoJSON polygons and export a PNG quicklook map.",,
5547c3b1-5422-40e8-89de-be9942ff655f,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Build a Python CLI that ingests a time-series of multispectral GeoTIFFs and a polygon ROI, decodes per-pixel cloud masks from QA bands, harmonizes projection/resolution, and computes a cloud-free median NDVI composite. Output a cloud-optimized GeoTIFF with overviews, a quicklook PNG with ROI outline and scale bar, and a CSV of per-ROI summary statistics.",,
08ecaadb-7f50-4f73-993d-a8b2af152935,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Create a CLI that georectifies an unreferenced aerial image using provided ground control points (pixel ↔ lon/lat), warps to a target CRS, and outputs a tiled, compressed Cloud-Optimized GeoTIFF with correct nodata and overviews. Also produce a quicklook PNG, a GeoJSON footprint of the warped image, and a JSON report of per-point residuals and overall RMSE.",,
7c8fc36f-7574-4160-a26b-5adc2571085a,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Create a Python CLI that mosaics multispectral GeoTIFF tiles, reprojects to EPSG:3857, clips to polygons in a GeoJSON ROI, computes NDVI from specified Red/NIR bands while honoring nodata and an optional cloud mask, and saves a color-mapped NDVI PNG plus a Cloud-Optimized GeoTIFF. Also compute per-polygon zonal statistics (mean, median, std, pixel count) and write them to a GeoJSON output.",,
29de4ed3-528d-4aba-a9dd-7a89fee1b473,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Create a Python tool that reads a folder of multi-date satellite GeoTIFFs with varying CRSs and resolutions plus an AOI polygon, reprojects and clips them to a common grid, and builds a cloud-robust medoid mosaic across dates using RGB+NIR bands. Write the mosaic as a Cloud-Optimized GeoTIFF, a PNG quicklook with AOI overlay, and a JSON report of per-band mean/std and fraction of valid pixels.",,
0d8f743f-c474-414f-9417-c39ed96368ca,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Build a CLI tool that loads an irregularly sampled light curve from /app/lightcurve.csv (t, flux, sigma), computes a generalized Lomb–Scargle periodogram to identify the top periodicities with false-alarm probabilities, and produces publication-quality periodogram and phase-folded plots. Refine each candidate via weighted sinusoid fitting and write a summary CSV of frequency, period, semi-amplitude, phase, and FAP.",,
09660539-85c5-4e7b-8493-4421749f7e24,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Create a CLI tool that computes a multitaper (DPSS) power spectral density of a 1-D signal and automatically detects narrowband line components above a robust noise floor. Apply notch filtering at detected lines and save the cleaned signal, PSD before/after, and a figure highlighting the peaks removed.",,
2ba35e03-c23c-439b-8563-2bb85a772947,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Create a CLI tool that computes power spectral density estimates for multichannel signals using both Welch and multitaper (DPSS) methods, saving PSDs and 95% confidence intervals to CSV plus comparison plots. Validate normalization via Parseval’s theorem by requiring the PSD-integrated variance to match the time-domain variance within 2% and report any channels that fail.",,
8439f17f-572d-48cd-9f1a-2ec0d0083722,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Implement a Python CLI that loads a multichannel time series, applies adaptive notch filtering at mains and harmonics plus a zero-phase bandpass, then computes multitaper PSDs and magnitude-squared coherence; it must detect and report dominant peaks, band powers, spectral entropy, and a coherence matrix to /app/results.json and save publication-quality PSD/coherence plots. Include a test mode that synthesizes known signals to validate peak frequencies within ±0.2 Hz and coherence above 0.9.",,
763fa1e2-bdcc-4660-a573-8f78d5f5f70b,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Implement a matched-filter detector for transient chirp signals: read a 1D noisy time series and a template waveform, estimate the noise PSD via Welch, whiten both, and compute the matched-filter SNR time series using FFT-based convolution. Write the peak detection time and SNR to a results JSON and save plots of amplitude spectral density (pre/post whitening) and the SNR time series.",,
107b65ae-a451-44a2-9733-c86276a60d0a,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Build a Python CLI that loads a gridded NetCDF atmospheric dataset (temperature on lat–lon–pressure), computes a zonal-mean latitude–pressure cross-section and derives the tropopause pressure using the WMO lapse-rate criterion, then plots a publication-quality contour/contourf figure with an inverted log-pressure axis, labeled isotherms, and an overlaid tropopause line using Matplotlib. Save both PNG and SVG figures and export the zonal-mean fields and tropopause profile to specified output files.",,
054da7a4-04e3-451f-ad2c-470ce3d7475f,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Build a Python tool that loads a gridded NetCDF climate dataset, computes a 1981–2010 monthly climatology and anomalies for a chosen year, and generates a publication-quality, three-panel figure: (1) a global Robinson-projection contour map of annual-mean anomaly with coastlines and significance hatching, (2) an equatorial Hovmöller diagram (time vs longitude), and (3) a zonal-mean anomaly profile, all using a shared color normalization. Save both PNG and PDF outputs with consistent, colorblind-safe styling and embedded metadata.",,
33abd2c5-74d0-453e-8122-585beb43eb2d,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Create a Python CLI that reads a NetCDF surface temperature dataset, computes a 1981–2010 monthly climatology and 2016 anomalies, and produces a publication-quality multi-panel figure: a global anomaly map (Robinson projection with coastlines), a latitude–time Hovmöller, an area-weighted global-mean time series, and an anomaly histogram. Save both PNG and vector PDF with colorblind-safe palettes, labeled colorbars, and consistent typography.",,
a4537e6a-0b75-41a5-b158-d6cebc1dc673,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Create a Python script that loads a 2D velocity field (u, v) from /app/velocity.npy, computes speed and vorticity, and generates a two-panel Matplotlib figure: left panel shows a pseudocolor speed heatmap with overlaid streamlines and a sparsified quiver; right panel shows filled vorticity contours with contour lines. Save the figure as /app/flow_figure.png and /app/flow_figure.pdf with labeled colorbars, equal aspect ratio, consistent fonts, and grid-aligned axes.",,
8226cdb2-d2ed-4aeb-8738-5f7b8c2d8f76,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a 1D finite-volume solver for the linear advection equation u_t + a u_x = 0 on [0,1] with periodic boundaries, supporting both first-order upwind and second-order MUSCL-Hancock schemes with CFL-controlled time stepping and CLI selection. Validate against the exact traveling-wave solution for a smooth periodic initial condition by outputting solutions at requested times and reporting L1/L2 errors that demonstrate first- vs second-order convergence over at least three uniform grid refinements.",,
66b8d07e-1173-47ed-ae50-86573d40ba8e,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a 1D heat equation solver using the Crank–Nicolson scheme with a Thomas tridiagonal solver on a uniform grid with Dirichlet boundaries. Validate by comparing to the analytical solution u(x,t)=exp(-pi^2*t)*sin(pi*x) (alpha=1), reporting max and L2 errors at specified times and demonstrating near second-order convergence under grid refinement.",,
940d389c-088c-4d1b-bc2f-d215679fd203,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a 2D Poisson solver on the unit square using a geometric multigrid V-cycle with red-black Gauss–Seidel smoothing and second-order finite differences, with CLI options for grid size and cycle parameters. Validate via a manufactured solution (e.g., u(x,y)=sin(pi x) sin(pi y)) to demonstrate O(h^2) convergence and quantify residual reduction per cycle versus a plain Gauss–Seidel baseline.",,
6df9042b-4033-4c85-a1dd-bb9a1cc24d8d,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Create a Python CLI implementing the Aberth–Ehrlich method from scratch to simultaneously find all complex roots of a high-degree polynomial provided via JSON, writing the root estimates with residuals and convergence metrics to /app/roots.json and a Markdown summary report.",,
3fdcff1b-47ba-485f-b3b4-a543251e98fa,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a 2D Poisson solver on the unit square with Dirichlet boundaries using second-order finite differences with at least two solvers (e.g., Gauss-Seidel and Conjugate Gradient) exposed via a CLI. Validate against the analytical solution u(x,y)=sin(pi x)sin(pi y) by grid refinement (e.g., N=32,64,128), reporting L2/L∞ errors and observed order to a results file and failing if order < 1.9 or residual tolerances are unmet.",,
483c66d2-2772-4a00-9b3b-566150901b47,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a Gauss–Legendre quadrature generator using the Golub–Welsch algorithm to compute nodes and weights for arbitrary n (e.g., up to 2048) and provide a CLI to write them to disk. Validate by integrating polynomials up to degree 2n−1 over [-1, 1] and reporting the maximum absolute error against exact values, ensuring it stays below a specified tolerance.",,
a68f3cb7-80b3-416b-8d44-98e71d66d382,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Optimize a naive Python finite-element stiffness matrix assembly for a 2D Poisson problem that performs incremental CSR updates inside nested loops by profiling hotspots and refactoring to a vectorized batch COO (I,J,V) build with a single CSR conversion. Verify numerical equivalence of the assembled matrix and improved end-to-end solve time, and emit a JSON report of timings and speedups.",,
752a4df9-1afb-45c4-9b85-64c809d7ba7e,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,Profile a naive finite-element stiffness-matrix assembly for a 2D Poisson problem on triangular meshes and optimize the hotspot by vectorizing element computations and constructing the global matrix in CSR with preallocated buffers or Numba. Validate numerical equivalence within tolerance across provided meshes and emit timing and speedup metrics.,,
500c70d3-0082-488d-81ca-132a30038786,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Profile a naive nested-loop Python implementation of pairwise Euclidean distances between two sets of 128D vectors and replace the hotspot with a vectorized formulation and/or a Numba/Cython kernel using cache-friendly memory access and preallocation. Validate numerical equivalence (≤1e-8), emit before/after profiles and timing summaries, and achieve at least a 20x speedup on inputs of size Q=5000, D=50000.",,
ac2a9431-f5b2-48a2-8b09-ac1ba4d1bd9f,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Profile a naive pure-Python 3D heat equation explicit solver stepping 100 iterations on a 128^3 grid, then vectorize the stencil update, optimize memory access, and accelerate with Numba (parallel) to achieve ≥10× speedup while keeping max absolute error ≤1e-6 versus the baseline. Provide a CLI benchmark that runs pre/post-optimization versions, captures timing and max error, and writes a JSON report to /app/bench.json.",,
98122940-5b4f-48d8-a873-65c32d1c83a2,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Profile and optimize a naive 3D 7-point Jacobi solver for the Poisson equation on a uniform grid, transforming a triple-nested loop baseline into a high-performance version via cache blocking/tiling, vectorized memory access, and optional Numba or OpenMP. The CLI should run solves on several grid sizes, verify residual reduction against a reference solution with fixed boundary conditions, and print a profiling report that shows at least a 5× speedup over the baseline.",,
a6972976-346b-439e-a35e-81a6e064e71b,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a Python interval arithmetic library that guarantees enclosure for elementary functions using outward rounding and vectorized NumPy operations, with a clean API, type hints, and Sphinx docs driven by doctests. Include a CLI to evaluate expressions over named intervals and a test suite that verifies inclusion properties and monotonicity on randomized cases.",,
f70efa69-6988-41be-8abb-4e9f3cda69d8,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a Python library for lazy linear operators (matrix-free) that supports composition, adjoints, and iterative solvers (CG/LSQR) with NumPy/SciPy backends. Package it with pyproject.toml, Sphinx docs with examples and autodoc, a small CLI to apply/solve from JSON input, and unit tests verifying algebraic identities and solver accuracy.",,
1445fb81-673e-43a8-8d76-f44a103fbd8c,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a Python library that implements polynomial chaos expansion (PCE) for uncertainty propagation with Legendre/Hermite bases, supporting coefficient fitting from samples, surrogate evaluation, and moment estimation. Package it with a CLI to build/evaluate PCEs from CSV data, comprehensive unit tests, and Sphinx-based API/user docs with examples.",,
c706fccc-2499-4a13-ab1a-1e27c8139f09,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a typed Python library for uncertainty propagation via Polynomial Chaos Expansions, supporting Gaussian/Uniform inputs, sparse regression and quadrature fitting, and computing means/variances plus first/total Sobol indices. Provide a CLI that loads a black-box model from a Python module and a JSON distribution spec to write a results JSON, and include unit tests and Sphinx docs with API and examples.",,
38ac1d0d-2759-451c-833f-327e99f5a7e6,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Build a metamorphic and property-based test harness for a 2D Poisson solver that generates randomized periodic RHS fields, asserts exact recovery on single Fourier modes, checks symmetry/conservation invariants, and differential-tests against an independent finite-difference reference with convergence and error thresholds. Provide a CLI to run the suite and a CI workflow that records metrics and fails on tolerance regressions.",,
48794712-9dda-4e5e-be18-3061fb16513d,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Build a pytest + Hypothesis metamorphic testing suite for a time-integration library (explicit/implicit Runge–Kutta) that verifies order of accuracy via step-halving, checks conserved quantities on canonical systems (harmonic oscillator, Kepler), and validates A-stability on the Dahlquist test equation. Provide a CLI to run the suite with numeric tolerance gates, enforce coverage thresholds, and emit JUnit XML and coverage artifacts suitable for CI.",,
a08da7a0-23bb-4e05-b72f-c65c76c081f7,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Create a pytest + Hypothesis test harness that ingests a finite-difference PDE solver and verifies second-order accuracy via manufactured solutions, conservation and boundary-condition compliance, and monotonic error reduction under grid refinement. The suite must emit JUnit XML and a JSON convergence report and fail if the estimated order falls below 1.8 on any tested problem.",,
0a02206d-9826-400e-bd7d-23e94343ae2f,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Create an automated test/CI harness that runs a provided 1D PDE solver across successively refined grids on manufactured solutions, computes L2 errors, fits the empirical convergence order, and fails if it falls below a set tolerance. Include metamorphic tests for boundary-condition transformations and a discrete conservation check, and emit JSON and JUnit XML summaries.",,
29a6e8d8-6bbc-4bb2-acbe-985352aa3a8e,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Build a Python CLI that performs adjoint-based parameter estimation for an ODE by integrating both the forward system and its continuous-time adjoint to obtain exact gradients of a least-squares misfit. Apply it to fit the Lorenz system’s (sigma, rho, beta) to a provided noisy trajectory, and report recovered parameters along with adjoint–finite-difference gradient agreement.",,
bf389e3d-784b-4c1e-b140-62cad400ada3,Software Engineering & Development,Development Tooling & Workflow Automation,Developer Environment Setup,"Design and configure a VSCode devcontainer (Dockerfile, devcontainer.json, docker-compose.yml) for a polyglot monorepo with a Python backend, Node.js frontend, and PostgreSQL service that supports hot-reloading, unified linting (flake8, ESLint), pre-commit hooks, and a Makefile for common developer commands.",,
9f1c5cea-80b5-4bb8-b315-f743a3ff687e,Software Engineering & Development,Development Tooling & Workflow Automation,Developer Environment Setup,"Create a VSCode DevContainer and Docker Compose setup for a polyglot microservices workspace including a Node.js API, a Python background worker, and Redis, with live code reloading, named volume mounts, and consistent host-user permission mapping. Pre-install language servers, linters, formatters, and container-aware debugging configurations to enable seamless development workflows.",,
bcf3b849-d47e-464b-a16c-328c3fc9c735,Software Engineering & Development,Development Tooling & Workflow Automation,Developer Environment Setup,"Implement a Docker Compose–based development environment that brings up a Node.js API, a Python worker service, and a PostgreSQL database with hot-reloading, health-checks, and centralized environment variable injection. Provide a VSCode devcontainer.json that enables seamless in-container linting, debugging, and running project-specific CLI commands.",,
41b3c28e-409a-447b-9da1-7275b5467348,Software Engineering & Development,"Collaboration, Review & Documentation",Documentation & README Creation,"Create a CONTRIBUTING.md for a provided open-source CLI tool repository that outlines development environment setup, Git branching and pull request workflows, code style conventions (including pre-commit hook configuration), testing procedures, and the release process. Ensure the document is formatted with Markdown headers, lists, code snippets, and badges to guide new contributors through first contributions to final merges.",,
6201bdc5-d3e4-430a-9c38-744db95bbe35,Software Engineering & Development,"Testing, Validation & Quality Assurance",End-to-End (E2E) & Regression Testing,"Provide a sample monorepo containing an Express API and a React frontend; write a shell-based test harness that uses Docker Compose to launch both services, runs Playwright end-to-end tests covering user signup, login, CRUD flows, captures screenshots on failures, and emits a consolidated JSON test report to /outputs/report.json.",,
2192d8c8-6684-4784-b52c-66a1fe96ac03,Software Engineering & Development,Debugging & Issue Resolution,Environment & Configuration Fixes,"Debug a Kubernetes deployment where a Flask application enters CrashLoopBackOff due to misconfigured ConfigMap references, incorrect environment variable syntax, and improper volume mounts. Correct the Deployment and ConfigMap YAML so the pod successfully loads its configuration and reaches the Running state.",,
15aaf087-4f58-430c-9665-8f6e6bfa7626,Software Engineering & Development,Debugging & Issue Resolution,Environment & Configuration Fixes,"Debug a Java Spring Boot microservice packaged in a multi-stage Docker image that crashes on startup due to mismatched environment variable keys in application.properties, a conflicting JAR version baked into the image, and an inactive Maven profile. The agent must update the Dockerfile, correct the POM and property names, and reconfigure the startup script so that the container launches successfully and passes the provided integration tests.",,
9173ab2d-109c-4b2c-8339-e11d7cd0b9a0,Software Engineering & Development,Debugging & Issue Resolution,Environment & Configuration Fixes,"Fix a Docker-based Node.js monorepo dev environment where Yarn workspaces fail due to volume mount symlink issues and misconfigured tsconfig paths. Update Dockerfile, docker-compose.yml, and tsconfig.json to ensure module resolution, hot-reload, and passing lint/tests.",,
93344205-5386-4883-bc2c-a3a0f12332d1,Software Engineering & Development,Debugging & Issue Resolution,Logging & Observability Enhancements,"Enhance an existing Python Flask application by integrating structlog for structured JSON logging with request IDs, instrumenting key routes and functions with OpenTelemetry tracing, and exposing Prometheus metrics on a /metrics endpoint alongside a sample Grafana dashboard configuration.",,
d90b3cfb-0937-4a04-b5bd-38d5d61935cc,Software Engineering & Development,Debugging & Issue Resolution,Logging & Observability Enhancements,Enhance a sample Node.js Express microservice that processes Kafka messages by integrating OpenTelemetry for distributed tracing across HTTP request handlers and Kafka consumers/producers. Enrich structured logs with trace and span IDs using Pino and export application metrics to Prometheus.,,
0bd51e90-c674-42eb-9209-713bdbd4046b,Software Engineering & Development,Debugging & Issue Resolution,Logic & Behavior Bugs,"Identify and fix the off-by-one error in the provided Python module that computes the longest increasing subsequence of an integer array, which currently produces incorrect lengths when duplicate values or equal subsequences occur. Ensure the corrected implementation still passes all existing unit tests and runs in O(n log n) time for arrays up to length 10^5.",,
794d743b-4ec5-441e-a6f4-3ae6cf9ee5a9,Software Engineering & Development,Debugging & Issue Resolution,Logic & Behavior Bugs,"A Python script implements a sliding-window median algorithm but produces incorrect outputs on test cases with even window sizes and duplicate values. Debug and correct the logic so that insertions, deletions, and median calculations handle all edge cases and output the proper median list to /app/output.json.",,
014416d5-6d33-4f3e-85b8-657f299d3e0c,Software Engineering & Development,Debugging & Issue Resolution,Logic & Behavior Bugs,"Debug and correct a Go-based leaky-bucket rate limiter whose refill logic miscalculates token intervals, intermittently allowing bursts above the configured rate. After fixing the timing calculation, ensure all concurrent integration tests validating strict rate enforcement under variable loads pass without altering the test suite.",,
8ef9a735-e4ff-44f2-a1da-8ca1f2fd0709,Software Engineering & Development,Debugging & Issue Resolution,Logic & Behavior Bugs,"An existing Python module implements the Shunting Yard algorithm to convert infix arithmetic expressions (with +, -, *, /, ^, and parentheses) to postfix notation but fails to handle right-associative exponentiation and nested parentheses correctly. Fix the operator precedence and associativity logic so that all provided expression-conversion tests pass.",,
5c10cbcb-72f6-416e-adbe-a5234d7ca4ba,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Implement a 1D heat-equation solver with time-dependent source and mixed (Robin) boundary conditions using second-order finite differences in space and Crank–Nicolson time stepping, solving the per-step tridiagonal system via the Thomas algorithm. The CLI should ingest problem parameters and output snapshots at requested times to CSV and additionally run a mesh-refinement check to confirm ~O(Δx^2 + Δt^2) convergence.",,
b9c67c76-3001-4531-9bf9-5cd1ee3e1d44,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Implement a Python CLI that solves the 1D Fisher–KPP reaction–diffusion PDE on [0, L] with Neumann boundaries via method-of-lines (finite differences) using SciPy’s stiff integrator from a compact initial condition. Estimate the traveling wave speed from the simulation and verify it is within 5% of the theoretical minimum 2*sqrt(D*r), writing the estimated speed and error to /app/answer.json.",,
7a1314e7-5866-4c5d-b252-a8ce81488e9a,Scientific Computing & Analysis,Simulation & Modeling,Finite Element & Numerical Methods,"Implement a 1D discontinuous Galerkin solver for linear advection with periodic boundaries, selectable numerical flux (upwind/Rusanov), and SSPRK time stepping; expose CLI options for polynomial order, CFL, and final time. Output field snapshots and L2 error versus the exact shifted solution, and verify k+1 convergence across mesh refinements.",,
8196fde1-e327-4c34-bfe6-d3994c1f2ebe,Scientific Computing & Analysis,Simulation & Modeling,Finite Element & Numerical Methods,"Implement a 2D finite element solver for -∇·(k∇u)=f on a Gmsh triangular mesh with mixed Dirichlet/Neumann boundaries, assembling a sparse system and solving with Conjugate Gradient and a basic preconditioner. Validate via a manufactured solution by reporting L2 and H1-seminorm errors across at least two mesh refinements, and write both the nodal field and error summary to output files.",,
b3e5da9a-b912-4aaf-a8aa-bf2237176a10,Scientific Computing & Analysis,Simulation & Modeling,Finite Element & Numerical Methods,"Implement a sparse finite element modal analysis tool for 2D trusses: parse nodes and bar elements with A, E, and ρ, assemble global stiffness and consistent mass matrices, apply fixed DOFs, and compute the first k natural frequencies and mode shapes via eigsh. Write frequencies to an output text file and mode shapes to a mesh-compatible format (e.g., VTK/CSV).",,
3e22b584-1b8d-44a4-b766-fd771b7569e4,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Build a 1D heat-equation simulator (explicit FTCS with Dirichlet boundaries) that sweeps spatial resolution and timestep to explore CFL stability and convergence, comparing against an analytic solution. For each (dx, dt), record stability, L2 error at a fixed final time, and estimate order-of-accuracy across resolutions in a summary CSV.",,
4c7f8933-6faa-497b-9b4c-90fb4b46a514,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Build a CLI tool that runs a stochastic SIR epidemic simulation (Gillespie SSA) and performs a Sobol global sensitivity analysis over R0, mean infectious period, and initial infected fraction, reporting first- and total-order indices for peak prevalence, time-to-peak, and final size. Use Saltelli sampling with a fixed seed, parallelize simulations, and write indices and summary metrics to CSV/text outputs.",,
ef5a60e6-6536-44b5-ba9d-8d5c955b4007,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Build a Monte Carlo simulator for the 2D Ising model with periodic boundaries, sweeping temperature across a range and multiple lattice sizes to compute ensemble magnetization, energy, specific heat, susceptibility, and Binder cumulant. Estimate the critical temperature by locating the susceptibility peak and Binder cumulant crossing, saving the full per-temperature statistics and Tc estimate to outputs.",,
9db8fc47-98a5-4b12-b29d-31e7a4bbc602,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Build a Python CLI that simulates the Lotka–Volterra predator–prey ODE across thousands of parameter samples (birth, predation, mortality, efficiency) drawn via Sobol or Latin hypercube designs, recording summary metrics such as final populations, peak amplitudes, and oscillation period per run. Compute and save first-order and total Sobol sensitivity indices for each metric, along with a CSV of runs and a JSON report of indices.",,
9b133bd6-cf3d-4309-9b95-dc2904d4d511,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Implement a Python CLI that integrates the Lorenz '63 system and, for a grid of (sigma, rho) values at fixed beta, computes the largest Lyapunov exponent to map chaotic vs non-chaotic regions, writing a CSV heatmap and the estimated boundary. Assess numerical sensitivity by rerunning a subset with stricter solver tolerances and reporting deviations in the exponent.",,
8d152cdb-696f-41b0-a797-40ad45f82fda,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Build a discrete-event simulator for an M/M/c/K queue with balking at full capacity and exponential reneging, using a fixed RNG seed and automatic warm-up detection before collecting statistics across multiple replications. Output per-replication and aggregated 95% CI estimates for throughput, loss probability, mean queue length, and waiting time to standardized CSV/JSON files.",,
bd41f126-69dd-4399-9e6c-b4ebf955306d,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a discrete-event simulation of a priority M/M/c/K queue with balking and reneging, reading parameters from /app/scenario.yaml, and run batched replications with fixed RNG seeds to estimate per-class throughput, mean wait, and server utilization with 95% CIs to /app/results.json. Include a test mode that sets K→∞ and a single class to validate against the analytical M/M/c steady-state formulas within a specified tolerance.",,
9cc5f790-e71d-4baa-a8a6-ba41a0db774f,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a discrete-event simulator for an M(t)/M/c/K queue with two priority classes (preemptive-resume) and impatient customers (reneging), supporting reproducible random seeds and multi-run parameter sweeps via CLI. For each run, write CSVs with time-series queue lengths and per-class summary metrics (utilization, mean/95th-percentile wait, abandonment rate).",,
f1350dc7-4622-4435-b144-1baff7ec8bfa,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a discrete-event simulator for an open Jackson queueing network (2–4 M/M/1 nodes) with configurable arrival/service rates and routing probabilities, running multiple replications with independent RNG seeds to estimate steady-state throughput, utilization, mean queue lengths, and waiting times. For provided test cases, compare simulated metrics and 95% CIs to analytic formulas and fail if discrepancies exceed 5%, writing standardized CSV/JSON outputs.",,
f3efb591-ce31-4e3d-9dd2-cdfc24bf87b2,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Calibrate an SIR epidemic ODE model to noisy incidence data using Bayesian inference (e.g., PyMC/NumPyro with NUTS), estimating transmission and recovery rates and R0. Run multi-chain MCMC to produce posterior credible intervals and posterior predictive trajectories and save a concise summary artifact.",,
4820acf7-38ef-4f7c-b9ea-ce98a0ee44ad,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a stochastic chemical kinetics simulator that loads a reaction network from a simple JSON schema and runs both exact Gillespie SSA and an adaptive tau-leaping variant across multiple random seeds. Save ensemble trajectories and checkpointed means/variances, and report agreement metrics between the two methods within specified tolerances.",,
7adfdb7c-70e3-4904-a2cf-4eb5e025c6be,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Create a CLI tool that ingests per-study effect sizes and standard errors, runs a random-effects meta-analysis (DerSimonian–Laird with optional Hartung–Knapp adjustment), and tests for overall effect and heterogeneity (Cochran’s Q, I²). Write combined estimates, p-values, per-study weights, and a leave-one-out influence summary to standardized output files.",,
34c2152b-5e32-4155-882c-5d71fea4b40b,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Create a script that ingests stratified 2x2 contingency data (A/B by success/failure with a stratum identifier), performs a Cochran–Mantel–Haenszel test to estimate a common odds ratio with 95% CI, and reports its p-value. Additionally run the Breslow–Day test for homogeneity across strata and write the common OR, CI, and both p-values to an output JSON file.",,
e3945558-d0b9-4e53-8f2d-67c5eb8e357e,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Build a CLI tool that fits an errors-in-variables Deming regression for method-comparison data, estimating the error variance ratio from replicate measurements and optionally applying Huber M-estimation to orthogonal residuals for robustness. Output slope, intercept, their 95% CIs (bootstrap), the variance ratio estimate, and a CSV of fitted values and orthogonal residuals.",,
d4e4c09f-5e32-493e-9715-66d3887908b4,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Build a CLI tool that fits piecewise linear (segmented) regression with an unknown number of change-points on a noisy 1D dataset, selecting the number and locations via BIC-penalized dynamic programming (e.g., PELT). Save breakpoint positions, segment slopes/intercepts, fitted values and residuals, and bootstrap confidence intervals for parameters to standardized output files.",,
6492f935-289d-4e2d-83c4-f25287b5a0e1,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Build a terminal script that reads /app/series.csv (time,y) and fits a piecewise linear regression with 1–3 unknown changepoints under Huber loss using dynamic programming (or equivalent), selecting the segment count by BIC. Output /app/results.json with changepoint times, segment slopes/intercepts, BIC per model, and residual diagnostics.",,
1ed2caf8-f925-4624-8257-497ab4795ffa,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Create a CLI tool that fits a bi-exponential decay model y(t)=a1*exp(-k1 t)+a2*exp(-k2 t) using the variable-projection method: optimize k1,k2 via nonlinear search while solving a1,a2 by linear least squares at each step, enforcing a1,a2>=0 and k1,k2>0. Report parameter estimates, bootstrap 95% CIs, and predicted values at specified eval times without using high-level curve-fitting helpers.",,
b831fb16-dcf5-4490-8221-0b1e8d93b171,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Fit Planck's law to a measured spectral radiance dataset (wavelength vs intensity), jointly estimating temperature and a gray-body emissivity factor with bounds and optional instrument-response correction from a calibration file. Save parameter estimates with bootstrap confidence intervals and residual diagnostics to standardized output files.",,
00552fca-25b8-4da7-9fbc-f7e4f0ec45ee,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Build a CLI tool that ingests an irregularly timestamped sensor series, resamples to hourly, and fits a Basic Structural Model (local level + local trend + 24-hour seasonality) using a from-scratch Kalman filter/smoother with maximum-likelihood estimation of noise variances while natively handling missing points. Output the decomposed components, the seasonally adjusted series, and 48-hour forecast quantiles (5/50/95%).",,
7cb8899a-7ee7-435e-b425-3784fe7dbee7,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Create a CLI that ingests an irregularly sampled multivariate time series, estimates dominant seasonal periods via Lomb–Scargle and multitaper spectral analysis, then fits a seasonal state-space/SARIMAX model with Fourier terms to forecast a specified horizon. The tool must impute missing values, run rolling-origin backtesting, and write forecasts with 80/95% intervals and per-horizon error metrics to standardized output files.",,
dd8ec0d2-94ed-40e0-9d21-bcced3607835,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Create a CLI tool that ingests an irregularly sampled time series with gaps, detects dominant seasonal periods via a Lomb–Scargle periodogram, and performs robust STL decomposition after appropriate resampling/imputation. Fit an ARIMA model to the seasonally adjusted component to generate a 7-day forecast with 95% intervals, and write the detected periods, decomposition components, and forecast to standardized CSV outputs.",,
114ebc9b-14ca-4cd9-8b8a-df6dd347f0e7,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Create a CLI tool that ingests an irregularly sampled univariate time series with optional exogenous variables, resamples to a target frequency, applies a Box–Cox transform, and selects a SARIMAX model via stepwise AIC under stationarity/invertibility constraints. Perform multi-fold rolling-origin backtesting and output n-step forecasts with 95% intervals, residual Ljung–Box diagnostics, selected (p,d,q)(P,D,Q)s, and MASE/sMAPE metrics to standardized files.",,
66e23a93-0f92-4752-a466-53e099170979,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Implement a CLI that ingests an irregularly sampled univariate time series, estimates dominant seasonal periods via Lomb–Scargle spectral analysis, and performs STL decomposition using those periods. Fit a SARIMA model to the deseasonalized component to generate 30-step forecasts with 95% intervals, saving detected periods, decomposition components, and forecasts to disk.",,
614f6820-207d-4174-b4c8-e7457a17a799,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,Build a CLI tool that performs Bayesian inference for a stochastic SIR model using ABC-SMC to estimate transmission and recovery rates from observed daily case counts with an adaptive tolerance schedule. The program outputs weighted posterior samples and posterior predictive simulations for a fixed forecast horizon as standardized CSV files.,,
06b4e8c2-5063-4900-81b1-df187f793bc7,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Build a CLI tool that performs hierarchical Bayesian calibration of a Michaelis–Menten kinetics model across multiple temperatures, linking Vmax(T) via an Arrhenius law to jointly infer activation energy, pre-exponential factor, Km, and per-experiment noise with MCMC. Write posterior parameter summaries and posterior predictive trajectories with 95% credible intervals for each experiment to designated output files.",,
0a97ec94-eaca-48f3-a643-fec64970a558,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Create a Python tool that fits a stochastic SIR model to a provided daily incidence CSV using Particle Marginal Metropolis–Hastings with a bootstrap particle filter, jointly inferring β, γ, initial I0, and a reporting rate under Negative Binomial observation noise. Output posterior samples and 95% credible intervals for parameters plus posterior predictive incidence trajectories to standardized JSON/CSV files.",,
5502edda-b1b9-43cf-96e8-19772b7f1551,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Implement a CLI tool that calibrates an SIR ODE model to noisy daily incidence via Bayesian inference (PyMC NUTS), estimating beta, gamma, initial infections, and a reporting rate under a Negative Binomial likelihood. The program must run MCMC, compute R0 and posterior predictive trajectories with coverage metrics, and write diagnostics and posterior summaries to standardized output files.",,
6fd0e8a4-d8cb-4619-981f-64d84688f0f0,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Create a Python script that estimates a 95% confidence interval for the half-life parameter in an exponential decay experiment by fitting a non-linear model with heteroscedastic Gaussian noise and performing both profile likelihood and parametric bootstrap, then propagates the parameter uncertainty to predicted counts at specified times. Load data from /app/data/decay.csv and write a JSON summary with the CI endpoints, bootstrap distribution diagnostics, and predicted interval bands to /app/output/results.json.",,
a6f87fbe-3ee0-4e26-a058-1f0050c931cb,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,Fit a nonlinear Michaelis–Menten model to concentration–rate data and compute 95% confidence intervals for Vmax and Km using both an asymptotic (Fisher information/delta) method and a residual bootstrap. Propagate uncertainty to a prediction at a specified substrate level and write point estimates and interval bounds to a standardized results file.,,
b374e907-4abe-41e4-afb9-d79ab3d64068,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Fit a nonlinear Michaelis–Menten model with weighted least squares to enzyme kinetics data, then compute 95% profile-likelihood confidence intervals for Km and Vmax. Propagate parameter uncertainty to a specified substrate level to produce a 95% prediction interval for the reaction rate and emit all interval endpoints in a results file.",,
40ef039a-f829-4989-959b-2b3eb294910b,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Implement a CLI tool that propagates uncertainty in Steinhart–Hart temperature estimation: given correlated coefficient estimates (A,B,C with covariance) and a CSV of resistance readings with standard uncertainties, compute 68%/95% confidence intervals for T using both the delta method and Monte Carlo sampling with correlation, and write per-sample intervals plus a JSON summary. Include a simulation mode that generates synthetic datasets from a known ground truth to estimate empirical coverage for both methods.",,
b632ea52-88b6-4750-b4f1-9027c24f201d,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Build a CLI tool that computes first- and total-order Sobol indices (Jansen estimator with Saltelli sampling) for a stochastic black-box model f(x, seed) in /app/model.py under independent Uniform priors, using replicate runs and bootstrap CIs to produce a ranked list of influential parameters. The script must be robust to NaNs/infs in model outputs, respect a configurable time budget, and write both the indices with 95% intervals (JSON) and the parameter ranking (TXT).",,
2c417a35-ab30-4035-a676-e95bad45cec3,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Create a CLI tool that loads a black-box model f(x) from /app/model.py (optionally stochastic via a seed argument) and computes first- and total-order Sobol’ indices using a Saltelli design with Owen-scrambled Sobol sequences and common random numbers under a fixed evaluation budget. Output a CSV of indices with bootstrap 95% CIs and a parameter ranking by total-order effect, and include an automated self-test that recovers Ishigami indices within ±0.02.",,
b360294b-52ba-4968-a54a-3c1a5dbc9e54,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Create a CLI tool that loads a black-box model from /app/model.py and input distributions from /app/inputs.json, then computes first-order and total Sobol indices via Saltelli sampling and performs Morris screening for comparison. Output a ranked CSV of parameters by influence with bootstrap 95% confidence intervals, and save the exact sample matrices and RNG seed to /app/artifacts.npz for reproducibility.",,
4e8e558a-5068-42fe-b0f9-0df3c76113e9,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Create a Python CLI that loads a black-box model f(x) from model.py and parameter bounds from bounds.json, then computes Sobol first- and total-order indices via Saltelli sampling alongside derivative-based global sensitivity measures (DGSM) via finite-difference gradients. The tool should adaptively increase samples until 95% bootstrap CI widths for S_i fall below a threshold and write indices, CIs, and a consolidated parameter ranking to /app/results.json.",,
481267c4-3eef-48aa-929c-1104541ab04a,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Implement a Python CLI that loads a differentiable JAX model f: R^d -> R, computes derivative-based global sensitivity measures (DGSM) via automatic differentiation on quasi–Monte Carlo samples, and converts them into provable upper bounds on total Sobol indices using Poincaré constants for Uniform/Normal inputs. Write a JSON file with per-parameter DGSM, total-effect bounds, and a ranking by the bounds.",,
b89acb08-ff7d-4db8-904e-9bd6296e7a6e,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Build a CLI tool that loads a black‑box Python model and a JSON of input uncertainties (marginals plus optional correlation) and propagates them to outputs using both Latin Hypercube Monte Carlo and a sparse Polynomial Chaos Expansion. Report mean, variance, 5th/95th percentiles, and KL divergence between methods, and save the fitted PCE surrogate for reuse.",,
1e4c9e3e-6955-4df9-91e3-0f49bd1310d8,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Build a polynomial chaos expansion (total order 3) using Smolyak sparse Gauss-Hermite quadrature to propagate a 5-D Gaussian input uncertainty through a provided black-box function, returning mean/variance estimates and a surrogate evaluator. Compare the PCE estimates against a Sobol low-discrepancy Monte Carlo reference and report relative errors and sample efficiency.",,
2a43422d-1963-45a9-915a-92fe3dc5a136,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Create a script that reads a JSON file describing correlated lognormal uncertainties for R and C in an RC circuit, then propagates them through the step-response V(t)=V0*(1-exp(-t/(R*C))) to estimate the mean and variance of V(t) over a given time grid using both Monte Carlo sampling and a third-order polynomial chaos expansion. Write per-time statistics and the maximum absolute discrepancy between the two methods to /app/results.json with a fixed random seed for reproducibility.",,
cea50f44-fe9d-476b-8ea0-1d6dbe67e262,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Implement a non-intrusive polynomial chaos pipeline that reads a YAML describing independent input distributions and a black-box model CLI, then builds a sparse Legendre/Hermite PCE via stochastic collocation to propagate uncertainty and estimate the output mean, variance, and 5th/95th percentiles. Validate the PCE by comparing its moments against a fixed-seed Monte Carlo baseline and report relative errors.",,
9e0922e5-157f-442d-84f9-45259a269138,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a Chebyshev collocation spectral solver in Python to solve the 1D Poisson equation -u''=f on [-1,1] with Dirichlet boundary conditions, using numpy and scipy.linalg to construct differentiation matrices and solve the linear system. Validate spectral accuracy by solving for f(x)=sin(pi x), computing L2 and max errors for N=16,32,64 grid sizes, and output a JSON summary of errors and estimated convergence rates.",,
25954180-cbf4-4c5a-af53-c88cbfbec8ae,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Create a Python CLI that implements a two-dimensional Laplace Fast Multipole Method (FMM) using quad-tree decomposition and multipole/local expansions to evaluate potentials for N sources and targets read from JSON. Validate accuracy against direct O(N^2) summation for small N, report error and complexity metrics, and output potentials in JSON.",,
de956ad0-f919-4c6c-a0c3-4309a2eac3c6,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Implement a Python CLI that reads a full-sky HEALPix CMB temperature map, computes spherical harmonic coefficients up to ℓ=1024 using healpy, derives and Gaussian-bins the angular power spectrum Cℓ in fixed multipole intervals, then compares to a provided ΛCDM model via χ² and writes a JSON summary plus a CSV of binned Cℓ values.",,
d661ebec-cb76-4fe1-981c-b207e1b5bea9,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Build a Python CLI that ingests a theoretical CMB angular power spectrum (Cl) file, uses healpy.synfast to generate a full-sky synthetic CMB map, then computes its angular power spectrum via healpy.anafast, compares it to the input Cl, and writes out the map as a FITS file plus a JSON summary of residuals and basic statistical diagnostics.",,
39e224b5-1b0a-42bf-8ca2-c79aa9cfd2a9,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Create a terminal tool that reads UVFITS visibility data, performs convolutional gridding and FFT to generate a dirty image and point-spread function. Implement the Hogbom CLEAN algorithm to deconvolve and restore the sky brightness, then output cleaned, residual, and model FITS images along with imaging quality metrics in JSON.",,
44bb7392-7f3b-47e5-b4c2-394e5d403fbb,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Develop a Python CLI that reads a galaxy cluster mass model and source redshift distribution to simulate a full-sky weak lensing shear field, applies the Kaiser–Squires inversion to reconstruct the convergence (κ) map, and writes both shear and κ maps as HEALPix FITS with error metrics. Use NumPy, SciPy, Astropy, and healpy for spherical projections, arbitrary cluster parameters, and realistic noise modeling.",,
43c4cd09-dbd5-469e-9f0f-82e0f3a9252a,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Implement a Python CLI that constructs a Barnes–Hut octree for 3D gravitational N-body simulations and integrates positions and velocities using a symplectic leapfrog scheme with adaptive time-stepping. Validate energy and momentum conservation, compute radial density profiles at specified intervals, output periodic CSV snapshots of particle states, and write a summary JSON of diagnostics.",,
7e977ad7-4df3-4270-b955-995964630bbb,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Create a Python CLI that loads noisy predator–prey time-series from /app/data.csv, defines a Lotka–Volterra ODE model with prior distributions, and runs NUTS sampling via PyMC3/TensorFlow Probability to infer posterior parameter distributions. The tool must output /app/output.json containing posterior summaries (means, 95% credible intervals) and a set of posterior predictive trajectories with credible bands.",,
20b2f39a-cf7b-495f-8127-396cc46a8a3c,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Create a CLI tool that loads epidemiological time–series data (S, I, R) from CSV and runs Metropolis–Hastings MCMC to infer SIR model parameters β and γ under user-specified priors, outputting posterior samples, credible intervals, and trace plots. Include automated computation of Bayes factors for alternative compartmental models and support batch processing of multiple outbreak scenarios with JSON summary reports.",,
180d6202-2d70-420d-aa26-e8a5ea7eafbf,Scientific Computing & Analysis,Domain-Specific Computation,Climate & Environmental Modeling,"Implement a Python CLI that reads daily gridded temperature and precipitation NetCDF datasets, computes daily reference evapotranspiration via the Penman–Monteith equation, and calculates the Standardized Precipitation Evapotranspiration Index (SPEI) at user-specified timescales. Output monthly SPEI maps as NetCDF files and a JSON summary time series for selected grid points or station locations.",,
f34f7a90-34b9-4fb7-8c5e-c0a681e2e32d,Scientific Computing & Analysis,Domain-Specific Computation,Climate & Environmental Modeling,"Create a Python CLI that ingests daily gridded precipitation and temperature in NetCDF along with watershed boundaries in a shapefile, implements the Thornthwaite–Mather monthly water‐balance model to simulate soil moisture, evapotranspiration, and runoff per basin, and outputs per‐basin time-series CSV and diagnostic GeoTIFF maps.",,
dbca6134-937c-4200-a590-72ed55e202f8,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Create a Python CLI that reads a JSON config of parameter sets and auto-generates SLURM job array scripts to run a hybrid MPI+OpenMP application with specified CPU, GPU, and module environment loading per task. The tool must submit jobs with dependencies, monitor their status via sacct, automatically retry failures, and aggregate per-task logs and resource usage into a final summary JSON after completion.",,
13f7ee2e-7f34-40c7-8295-36a02d543dbc,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Build a CLI tool that reads a JSON-defined workflow of interdependent SLURM batch jobs, submits them with appropriate dependency flags and resource requests, polls their statuses, and upon completion aggregates stdout/stderr logs and key output metrics into a consolidated report, with configurable retry policies for failed tasks.",,
6f410144-95c6-412c-a3cd-387e70941233,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Profile a naive Python N-body Lennard–Jones force computation with cProfile to identify loop hotspots, then refactor using NumPy broadcasting or Numba JIT and memory blocking to achieve at least a 10× speedup while verifying forces and energy remain accurate within 1e-6.",,
32162f32-ca05-4036-8438-2e580ee354c1,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Create a CLI tool with a Python-based explicit finite-difference solver for the 2D heat equation, profile hotspots using cProfile and line_profiler, then optimize the core time-stepping loop via NumPy vectorization, memory blocking, and Numba JIT compilation, finally comparing pre- and post-optimization runtimes, memory footprints, and speedup metrics.",,
eb40ebe2-b02c-422b-8d82-a37215d97f08,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Create a Python CLI that reads a JSON list of SMILES, uses RDKit ETKDG and UFF to generate and optimize up to N 3D conformers per molecule, computes basic molecular descriptors (MW, logP, TPSA, rotatable bonds), clusters conformers via RMSD (e.g., Butina), and selects cluster centroids. Write per-molecule JSON with descriptors, cluster counts, and centroid SDF files under /app/output, plus a Markdown report summarizing the molecular library properties.",,
223f0174-2db9-4e71-8adb-cb10dfd69614,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Implement a Python CLI that reads an SBML model from /app/model.xml, parses the reaction network via libSBML, and performs multiple Gillespie algorithm stochastic simulations over a user-defined time. The tool should aggregate species concentration trajectories to compute mean and variance, output /app/trajectories.csv and /app/stats.json, and optionally generate time-course plots.",,
e2da635e-14dc-49ff-804f-f5940e714f68,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Create a Python CLI that ingests a molecular topology (.pdb) and trajectory (.xtc/.dcd), uses MDAnalysis to compute time-averaged radial distribution functions for user-specified atom pairs, mean squared displacement curves for selected residues, and hydrogen-bond autocorrelation lifetimes, then writes JSON summaries and publication-quality PNG plots under /app/output.",,
417e85ed-f421-42ac-9ac0-c05ed4ffbdb7,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Create a Python CLI tool that ingests a list of SMILES strings, generates and energy-minimizes 100 3D conformers per molecule using RDKit’s ETKDG and MMFF94 force field, then clusters them by RMSD with the Butina algorithm. Output a representative conformer for each cluster in /app/representatives.sdf and a JSON summary of cluster sizes, average energies, and RMSD distributions.",,
c785a399-e492-49c8-b5fd-3e2e0db48efe,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Create a Python CLI that ingests multiple netCDF climate datasets, aggregates daily data to user-specified temporal resolutions, computes anomalies against a defined baseline period, performs spatial regridding to a target grid using bilinear interpolation, and writes out a consolidated Zarr store and regional anomaly summary CSV. Implement gap-filling for missing data via temporal and spatial interpolation and enforce CF metadata conventions throughout the pipeline.",,
3ab8bc03-605c-4490-bd71-27377eff0ee7,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Develop a Python CLI that ingests a set of NetCDF climate model outputs, regrids variables to a common resolution using xESMF, computes seasonal anomalies against a climatology baseline, and fills missing data via spatiotemporal interpolation. The tool must write cleaned NetCDF files with standardized metadata and a CSV summary of seasonal anomaly statistics by region.",,
dabd28b1-f5fe-481f-acdf-8bf7183ddffb,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Implement a Python CLI that ingests an HDF5 file of nested oceanographic CTD casts, flattens the station/profile hierarchy into a tidy tabular structure, standardizes timestamps to ISO-8601, imputes missing salinity and temperature via nearest-neighbor interpolation, applies depth-based smoothing and min-max scaling, and exports the result as Parquet with a JSON metadata summary.",,
88bd1ec5-b983-4af4-87d2-5ce95a328e63,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Create a DVC-based pipeline in /app that version-controls raw and processed datasets, with stages for data cleaning, analysis, and result generation, and employs a hash-locked requirements.txt plus environment.yml to pin dependencies. Provide CLI commands to checkout past experiment versions, install exact environments, rerun pipelines reproducibly, and output checksums for all artifacts.",,
79abef51-a281-4381-b2dd-b7a6a17e532e,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Descriptive Statistics & Summarization,"Create a CLI that reads a CSV of mixed numerical and categorical columns, auto-detects types, computes numeric summaries (count, mean, median, std, skewness, kurtosis, quantiles) and categorical frequency tables, and outputs a JSON report plus histogram/bar-chart PNGs for each column.",,
6fdeef1a-51d4-4734-8d1c-288a58ca7ee2,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Descriptive Statistics & Summarization,"Implement a Python CLI that processes large CSV datasets in streaming mode to compute overall and group-wise summary statistics (mean, variance, median, 10th/90th percentiles via T-Digest, IQR) and then outputs a consolidated JSON report alongside ASCII histograms for each numeric field.",,
62ca1947-04d1-4ee7-a679-e3cd8d5248cb,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Descriptive Statistics & Summarization,"Build a Python CLI that reads a CSV with numeric and categorical fields, computes overall and per-group descriptive statistics (count, mean, median, variance, IQR, skewness), detects outliers using the 1.5×IQR rule, and writes results to summary.json. Additionally, generate histogram and boxplot SVGs and a correlation heatmap for numeric features, handling missing data and user-specified grouping keys.",,
21b1ce6d-4992-4e71-94e2-afdcc4fcc10b,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Descriptive Statistics & Summarization,"Create a Python CLI that reads a CSV with numeric and categorical columns, then for each category group computes counts, means, variances, skewness, kurtosis, quartiles, and detects outliers via Tukey’s fences; output a JSON summary, CSV tables, and generate histogram and boxplot PNG reports.",,
16f4099d-3aa2-4381-a89a-23f12b5c9120,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Create a Python CLI that uses FiPy to solve the 2D Gray–Scott reaction–diffusion PDE system with configurable feed and kill rates, grid size, and time-stepping scheme, exporting concentration snapshots and pattern metrics. Support batch JSON-driven parameter sweeps to generate multiple pattern outputs and a summary report of morphology statistics.",,
e7819bc9-7043-4f33-82ae-e250f4e48273,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Create a Python CLI that solves the 2D FitzHugh–Nagumo reaction–diffusion system on a unit square using finite-difference spatial discretization and an implicit–explicit (IMEX) time-stepping scheme with SciPy’s sparse solvers. The tool must read initial conditions and model parameters from /app/config.json, produce solution snapshots and figures, and report wave propagation speed and mass-conservation error in /app/output.json.",,
707bfdf2-f1b4-491e-8854-88565506b954,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Create an MPI-based CLI that solves the 3D Poisson equation on a structured grid via domain-decomposed finite differences and Conjugate Gradient with ghost-cell halo exchanges, then writes the solution field and strong/weak scaling metrics to /app/output.json.",,
34289011-ad2a-489f-b12c-1f88fc544bc5,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement a Python-based distributed solver (using Dask or MPI) for the 3D Gray–Scott reaction–diffusion system on a large grid with periodic boundaries, writing time‐step field snapshots to NetCDF and performing strong/weak scaling benchmarks. Include automatic error estimation against a reference solution and a CLI to configure domain size, time step, and diffusion parameters.",,
9e1234ab-a24b-43a4-95b4-c3bba555d174,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement a distributed block-Lanczos algorithm using mpi4py to compute the top-k eigenvalues and eigenvectors of a large sparse symmetric matrix loaded from /app/matrix.mtx, partitioning rows across MPI ranks for parallel matrix–vector products. Gather the Ritz values, eigenvectors, and timing metrics on rank 0 and write them to /app/eigs.json.",,
95ff534f-5297-43f3-9e76-bbf678adddff,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Create a Python CLI that fits an Arrhenius reaction‐rate model to CSV temperature–rate data via nonlinear regression, estimates parameter uncertainties using both Hessian‐based approximations and bootstrap resampling, propagates these to 95% confidence intervals on predicted reaction rates at user‐specified temperatures, and outputs a JSON summary plus Matplotlib error‐bar plots.",,
e5caa526-33a6-4785-96a0-ceca5db78077,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Implement a CLI that reads a CSV of 4-parameter Hill dose–response data with uncertainties on both concentration and signal, fits the model via total-least-squares, and computes parameter confidence intervals using bootstrap and Fisher information approaches. Output JSON with fitted parameters, 95% CI bounds, and generate PDF plots of dose–response curves with shaded confidence bands and residual error histograms.",,
50d3f04e-fe80-4a33-9db6-58084a09ed7d,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Implement a Python CLI that reads a CSV containing concentration vs time with measurement uncertainties and fits a Michaelis–Menten kinetic model via weighted least squares. Use Monte Carlo error propagation to compute 95% confidence intervals for the model parameters and predicted concentration curves, then output a JSON summary and a plot with confidence bands.",,
cbeb471c-c12a-419c-aab9-670183a0db4c,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Create a Python CLI that ingests a CSV of measurements x, y and their standard deviations, fits an orthogonal distance regression for a linear or nonlinear model, and computes 95% confidence intervals on each parameter using both analytical covariance and bootstrap resampling. The tool must output best-fit parameters, confidence limits, and propagated error bands for predictions in JSON and CSV, plus optional Matplotlib diagnostic plots.",,
282861b7-a463-417d-ba4e-248cf15b680e,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Develop a CLI pipeline tool that ingests a YAML workflow specification to orchestrate data preprocessing, model training, and evaluation, automatically versioning datasets with DVC and logging code commits, Conda environments, hyperparameters, and metrics to MLflow. Upon completion, generate an interactive provenance graph tracing data, parameters, and artifacts across runs for end-to-end auditability.",,
97aeebfc-3d41-432a-b0f2-cd549adde78f,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Implement a Dockerized CLI that uses DVC to version raw and processed data, Git to snapshot code, and MLflow to log parameter sweeps, metrics, and artifacts, then generates an HTML provenance report showing data lineage, experiment comparisons, and diffed commit history. Ensure that invoking the CLI with a --reproduce flag can recreate any logged experiment end-to-end using the tracked artifacts and parameters.",,
389ad966-5499-41b2-b8d7-624e0e4778b8,Scientific Computing & Analysis,Simulation & Modeling,Finite Element & Numerical Methods,"Create a Python CLI that loads a 2D composite material mesh from /app/mesh.msh, assembles and solves the transient non-linear heat equation with temperature-dependent anisotropic conductivity using linear finite elements and implicit Euler time stepping, applies Newton–Raphson iterations with Zienkiewicz–Zhu error estimation for adaptive mesh refinement at each step, and outputs VTK field files along with a JSON report of time-step convergence metrics and mesh statistics.",,
5d2b49d0-cde7-4ab2-8d62-6102a6453303,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Create a Python CLI using CuPy and Numba CUDA that solves the 3D heat diffusion equation on a cubic grid with explicit finite-difference time stepping entirely on the GPU. The tool should accept grid size, time step, and iteration count, benchmark GPU performance, and write the final temperature field and timing metrics to /app/results.npz.",,
f9d9cce3-0e2f-4823-8c02-7b5b67fc2f3f,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a GPU-accelerated 3D Lattice Boltzmann Method fluid solver using CuPy that reads a VTK geometry, applies D3Q19 update kernels on the GPU, and enforces periodic or no-slip boundaries. The CLI should run for specified timesteps, output velocity and pressure fields as VTK files, and produce a JSON summary of performance metrics including timing and GPU memory usage.",,
e713ecd7-4425-40fe-9fd5-ac8676a4138b,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a CUDA-accelerated spectral Poisson solver that uses cuFFT via CuPy to solve the 3D Poisson equation ∇²φ=ρ on a periodic grid. The CLI should accept JSON-configured density fields, output the potential in VTK and a JSON performance report including runtime, GFLOPS, and L∞ error against an analytic solution.",,
56a9aa9f-9df0-428d-8d39-97d56101ea96,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a Python command-line tool using CuPy that runs a 3D Lennard-Jones molecular dynamics simulation on the GPU with periodic boundary conditions, GPU-based Verlet neighbor list construction, and velocity-Verlet integration for a user-specified number of steps. The tool must compute and record the total energy and temperature time series, write final positions and velocities to /app/final_state.npz, and export the radial distribution function as /app/rdf.csv and metrics as /app/output.json.",,
8d2192ca-d3d8-40ba-b9ad-4a529b3e7833,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Develop a command-line tool that uses CUDA/CuPy to run a GPU-accelerated Metropolis–Hastings MCMC sampler for Bayesian logistic regression on large datasets, producing posterior samples, convergence diagnostics, and GPU versus CPU execution time comparisons.",,
8ae3dc92-1719-48fa-9bc6-1fbb521d7015,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Create a Python CLI that reads a CSV with a numeric response and a categorical factor, conducts both a parametric one-way ANOVA and a 10,000-iteration permutation ANOVA, applies Levene’s test for homogeneity and Shapiro–Wilk for normality, and writes /app/output.json with F-statistics, p-values, eta-squared effect sizes, and assumption test results, while saving QQ-plot and permutation distribution histogram PNGs in /app/output.",,
d82b0fdc-3069-4544-bf9a-cd081352b784,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Build a CLI tool that reads a CSV with a grouping factor and numeric response, runs Shapiro–Wilk for normality and Levene’s test for homogeneity, then performs one-way ANOVA or Welch’s ANOVA as required, computes effect sizes and conducts post-hoc pairwise tests with Holm–Bonferroni correction, and emits a JSON summary plus diagnostic plots.",,
db15ad90-2491-4b15-a7ac-1eb8a11afe26,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Create a Python CLI that reads a CSV with multiple treatment groups, performs a permutation-based one-way ANOVA by Monte Carlo resampling to compute an empirical p-value, then runs pairwise permutation tests with Holm–Bonferroni correction and outputs F-statistic, p-value, effect sizes, and significant group comparisons in JSON format.",,
72bfe312-a8fa-40e0-9832-56fcbd819878,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Implement a Python CLI that reads a CSV with one numeric outcome and one categorical group factor, runs Shapiro–Wilk and Levene tests to decide between one-way ANOVA or Kruskal–Wallis, then performs the chosen omnibus test plus all pairwise post-hoc comparisons (Tukey HSD or Dunn’s test) with Holm correction, outputting test statistics, p-values, adjusted p-values, and effect sizes in JSON.",,
af7689d1-163c-48f1-873d-64a7a51ce980,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Create a CLI that loads two co-registered GeoTIFF satellite images from different dates, computes per-pixel NDVI change, thresholds significant vegetation loss/gain, and vectorizes affected regions into a GeoJSON with area metrics. It must reproject inputs to a common CRS, generate a change-overlay PNG map, and output a summary JSON report with region statistics.",,
3f95ae32-2def-423c-b68f-14e653c9bab9,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Implement a CLI that reads two multi-band GeoTIFF satellite images from different dates, warps and aligns them to a common CRS, computes per-pixel NDVI difference, and applies Otsu thresholding to extract significant vegetation changes. Output a GeoTIFF of change magnitude, a vector shapefile of change polygons, and a JSON summary with area statistics.",,
a7dc9322-a30f-4828-8185-429ecda427eb,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Implement a Python CLI that ingests a GeoTIFF DEM and a GeoJSON LineString, reprojects the path to the DEM CRS, and samples elevations at uniformly spaced intervals. Compute local slope and aspect via finite differences and output a CSV profile (distance,elevation,slope,aspect) plus a Matplotlib PNG plot of elevation and slope versus distance.",,
f22172b2-c14e-481d-ae93-8c3d72a2b37e,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Implement a Python CLI that ingests a directory of multispectral GeoTIFFs, masks clouds using a threshold-based algorithm, computes NDVI/SAVI indices, and spatially aligns them over an AOI defined by a GeoJSON. Generate time-series mosaicked GeoTIFFs and an interactive Folium HTML map highlighting seasonal vegetation changes.",,
22874c08-08e4-441f-889a-d43e8854c996,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Implement a Python CLI that reads a directory of LiDAR .las files, bins points to generate a raster DEM, computes hillshade and slope rasters, and extracts contour lines at 10m intervals as GeoJSON. Finally assemble a standalone Leaflet HTML map overlaying the DEM, hillshade, slope colormap, and contours with interactive toggles.",,
23b07447-1b15-4f73-88d5-caf5f0ce226b,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a C++ library providing high-accuracy special functions (Bessel, Gamma, incomplete Beta) via Chebyshev expansions with Python bindings through pybind11 and Julia wrappers. Include a CMake build, Doxygen-generated API docs, Sphinx integration for Python, example notebooks, comprehensive unit tests, CI pipelines, and packaging recipes for PyPI and Conda Forge.",,
16295396-b028-4a0d-ae3e-52621ff78d19,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Design a Python package that provides a unified API for propagating uncertainties through numerical models via linear Taylor expansion, Monte Carlo sampling, and polynomial chaos expansions. Include complete Sphinx documentation with usage examples, unit tests, CI configuration, and PyPI-ready packaging.",,
8011af9b-b171-451c-b15f-a5e28dea9d7f,System Setup & Configuration,Software & Package Management,Dependency Verification & Repair,"In a Debian-based container with mixed-release APT sources and a corrupted dpkg status (half-installed/half-configured packages), restore the package manager to a healthy, consistent 'stable' state by fixing the dpkg database, correcting sources, resolving pinned/held packages, and repairing dependency conflicts. Validate by achieving a clean apt-get check/apt-get -f install run and successfully using curl to fetch an HTTPS URL with system OpenSSL.",,
5cef89b1-428b-4c3e-8bef-6e0f2a82fad3,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a Python package providing a suite of astrophysics-focused probability distributions (e.g. broken power-law, truncated log-normal) with vectorized PDF/CDF evaluation, parameter estimation routines, and optional JAX acceleration. Include Sphinx-generated API documentation, example Jupyter notebooks covering common astronomy use cases, a comprehensive test suite, and PyPI-ready packaging with continuous integration.",,
c39b5a3b-3657-40b1-bf87-3de313331127,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a Cython-accelerated Python library for multi-dimensional interpolation of scattered scientific data (linear, cubic spline, barycentric), backed by a KD-tree spatial index, complete with unit tests, CI pipelines, Sphinx API docs, example notebooks, and PyPI packaging.",,
3666f45a-1798-4e24-80ca-9bc43ea66589,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Implement a Python CLI that loads a dense matrix from /app/data.csv, performs a randomized SVD with user-specified target rank, oversampling, and power iterations using only NumPy, then writes the truncated U, S, and Vᵀ factors to /app/U.npy, /app/S.npy, /app/Vt.npy and reports reconstruction error and timing metrics in /app/metrics.json.",,
e9a2077d-3ed5-4737-9237-ec0d833c31f4,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Implement a Python CLI that loads a large sparse matrix from /app/matrix.npz and applies a randomized SVD algorithm with user-defined oversampling and power-iteration counts using only scipy.sparse and numpy operations. Output the top-k singular vectors and values as U.npy, S.npy, Vt.npy and record the spectral norm reconstruction error in /app/output.json.",,
a011b7f8-1144-4e62-a25c-b6caefc56a20,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a Python MPI-based solver for the 2D heat diffusion equation using an explicit finite-difference scheme, distributing grid rows across ranks with ghost-cell exchanges. Accept grid size and time steps from a JSON config, write the final temperature field to /app/output.npy, and report total runtime and per-rank timing metrics.",,
bc88264c-619a-4b15-a271-0f8c18b9ca90,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a Python CLI that reads initial positions and masses of N bodies from /app/bodies.csv, constructs a Barnes–Hut octree, and computes gravitational forces in parallel across CPU cores using multiprocessing, then integrates motion via a symplectic leapfrog scheme. Output trajectories as time-stamped CSV files and a JSON performance report showing speedup and scaling for varying core counts.",,
8a964256-76b1-441d-9912-80cb2da724b9,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a multithreaded Python CLI that runs parallel Monte Carlo simulations of the 2D Ising model across a range of temperatures, dividing the lattice into thread-owned blocks and performing concurrent Metropolis sweeps. Output per-temperature time-series CSVs of magnetization and energy plus a summary JSON with average observables, heat capacity, susceptibility, and thread scalability metrics.",,
f5432d22-9e82-421f-9243-4d44d54d4bb4,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Develop a Python CLI that runs a parallel N-body gravitational simulation using multiprocessing to distribute pairwise force calculations and Velocity Verlet integration, supporting configurable number of bodies and time steps. The tool must compute and log energy/momentum conservation metrics and output trajectories and summary statistics in JSON format.",,
acb1faab-8f24-4d44-87b8-e2c6fda3a523,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Develop a script and environment specification that uses Papermill to parameterize and execute /app/analysis.ipynb with a given data CSV and random seed, captures outputs to /app/output, and verifies reproducibility by comparing SHA256 checksums of the generated HTML report and metrics JSON across repeated runs.",,
30ccecd9-85e4-475f-a94e-f91e6ab95641,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Implement a Snakemake pipeline that parses a mixed Python–R Jupyter notebook, auto-generates conda environment.yml and renv.lock files, executes the notebook headlessly, and validates output cell SHA256 hashes against a provided manifest for reproducibility. Finally, bundle the notebook, lockfiles, and execution logs into a deployable archive.",,
8434eef3-682e-4512-abef-e41bff0739e3,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Implement a reproducibility runner that provisions a fresh Conda environment from environment.yml, executes each Jupyter notebook in /app/notebooks headlessly via nbconvert, and extracts JSON metrics embedded via papermill. The tool must compute SHA256 checksums of outputs, compare them against stored baselines, and output a consolidated pass/fail report indicating any divergences across runs.",,
32a27c91-c704-4f67-b486-8f24b6e72b1e,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement a Python CLI that performs adaptive multi-dimensional integration over hypercubes using the Smolyak sparse grid method, providing hierarchical error estimates and supporting arbitrary user-supplied integrand functions. The tool should output the integral result, estimated error, and evaluation metrics in a structured JSON format.",,
cb547e33-f529-432e-bd5c-948f364a6393,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Create a Python CLI that generates Chebyshev nodes and differentiation matrices to solve second-order boundary–value ODEs under Dirichlet conditions using spectral collocation. The tool should also perform Clenshaw–Curtis quadrature for user-specified functions, outputting nodal solutions, quadrature results, and error estimates in JSON.",,
f8a229d2-30a0-4ad5-a86b-b412fd8aefd8,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Build a Python CLI that constructs Chebyshev pseudospectral differentiation matrices for arbitrary collocation orders and uses them to approximate first and second derivatives of user-specified analytic functions on [–1,1], computing infinity and L2 error norms against exact derivatives. Extend the tool to solve second-order boundary-value ODEs with Dirichlet/Neumann conditions via spectral collocation, outputting solution profiles, error metrics, and eigenvalue estimates as JSON and PNG plots under /app/output.",,
62d555c0-2fd5-426b-a3e7-713dec3c9410,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Create a Python CLI that implements Smolyak sparse‐grid quadrature using nested Clenshaw–Curtis rules for multivariate integrals, allowing users to specify integrand, dimension, level, and tolerance. The tool should adaptively refine grid levels to meet error thresholds and emit a JSON with integral estimate, error, node count, plus a Markdown summary report.",,
c0f35790-cdfe-49cb-9130-306540c7f008,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Implement a Python CLI that performs nonlinear least-squares curve fitting via the Levenberg–Marquardt algorithm: it reads a CSV data file and a JSON-defined model (with initial parameter guesses), computes Jacobians by finite differences, iterates to convergence, and writes best-fit parameters, covariance matrix, χ², reduced χ², uncertainties, and iteration history to JSON.",,
10774d4e-5893-4b15-81e3-a984b745dae3,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Implement a Python CLI that sweeps the Lorenz system over ranges of σ, ρ, and β, numerically integrates each parameter set to compute the largest Lyapunov exponent for chaos detection, and writes out a JSON-formatted sensitivity matrix, convergence diagnostics, and representative phase-space snapshots.",,
43cdd1ef-dc03-4d55-b453-c678323396bc,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a Python CLI that solves the 2D shallow water equations on a rectangular grid with variable bathymetry using a finite-volume Godunov scheme with HLL flux and MUSCL reconstruction. The program reads initial conditions and simulation parameters from /app/config.json, applies reflective boundaries, integrates to a final time, and writes depth and velocity fields plus gauge time series to /app/output.",,
e3b35e19-77c8-4b09-a35b-be76d2db0a68,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a CLI that solves the 1D compressible Euler equations for Sod’s shock tube using a finite volume scheme with Roe’s approximate Riemann solver and user-specified CFL number, grid resolution, and final time. It should output CSV files of density, velocity, and pressure profiles at defined timesteps and generate corresponding plots.",,
42e1f8b4-330b-454e-8f39-0bf3858f1bda,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a Python CLI that solves the 1D Euler equations for a Sod shock tube using a second-order MUSCL–Hancock finite-volume scheme with Roe flux and van Leer limiter, adaptively updating timesteps via a CFL condition, then outputs density, velocity, and pressure profiles in CSV at user-defined times alongside L1 error metrics against the analytical solution.",,
e56b0223-d28c-41d8-8fc2-28c9850d7eea,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Implement a Python CLI that estimates the volume of a 10-dimensional hypersphere using both standard Monte Carlo and Sobol Quasi-Monte Carlo sampling to compare convergence rates. The tool should read dimension and sample counts from a JSON config, compute error estimates for each method, and output results and a convergence plot under /app/output.",,
0f40ac5b-90a3-4601-b5a9-142f8bd791d2,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Create a Python CLI that reads a JSON config defining a high-dimensional integrand over [0,1]^d, then approximates the integral using both pseudorandom Monte Carlo and Sobol quasi-Monte Carlo sampling across increasing sample sizes, computes convergence rates and error estimates, and writes a JSON summary plus a CSV of RMSE vs sample count.",,
457b4646-1165-44d7-88a8-d96656b62acc,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Create a Python CLI that performs a Monte Carlo simulation of the 2D Ising model on an L×L periodic lattice using the Metropolis algorithm, sweeping a user-specified temperature range to compute magnetization, susceptibility, and specific heat. Support JSON-configured parameter batches, reproducible seeding, per-temperature CSV outputs, and a summary JSON reporting the estimated critical temperature via finite-size scaling.",,
64dc4e6b-bd8b-4b9d-ac1d-671f606e5c1d,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Implement a Python CLI that loads concentration–response data from /app/data.csv, fits a four-parameter logistic dose–response model via scipy.optimize.least_squares with automatic initial guesses, computes covariance-based parameter uncertainties, AIC, and R², then writes fit_params.json, residuals.csv, and a high-resolution fitted_curve.csv under /app.",,
b86776d0-8b2a-486f-943d-47d1a3b953cf,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Report Generation & Automation,"Implement a CLI that runs a parameter sweep for a numerical model, collects output metrics and plots, then uses a Pandoc template to compile a PDF report with methodology, results tables, convergence plots, and embedded input/output hashes to ensure full reproducibility.",,
4b3b8861-8782-4c57-82a8-62768b10ff49,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Report Generation & Automation,"Implement a Snakemake workflow that cleans raw datasets, performs statistical analyses and generates publication-quality plots, then automatically compiles a Markdown report to PDF via Pandoc with embedded tables, figures, software versions, and runtime logs. Ensure full reproducibility by capturing environment specifications (e.g., conda YAML) and Git commit metadata within the report.",,
0d14c428-5ac7-4530-91cf-8cfed75dfd0f,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Create a Python CLI that estimates Shapley sensitivity indices for arbitrary black-box models using Monte Carlo sampling with user-defined correlated input distributions (via copulas), outputs main, interaction, and total Shapley effects in JSON, and ranks parameters by influence. Support parallel evaluation and allow reproducible sampling via a seed flag.",,
0eb4b9b5-a770-4a06-aa9e-8ab2bd8ab306,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Develop a CLI that loads a time-dependent Python model and parameter ranges from JSON, generates Saltelli samples to compute first-, second-, and total-order Sobol indices at each time step in parallel, and writes time series of indices to JSON and PNG plots. Ensure support for arbitrary model callables, convergence diagnostics, and configurable sampling sizes.",,
5adefd0a-68a2-4324-b2fd-76559563decd,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Build a Python CLI that computes Borgonovo’s moment-independent sensitivity (delta) indices for a user-provided model by Monte Carlo sampling of inputs, estimating output densities with KDE, and evaluating delta measures with bootstrap confidence intervals. The tool must output a ranked JSON summary of delta indices and generate marginal density and bar-chart plots.",,
2e28fccb-3a54-43b1-930f-25608bb34cdf,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Develop a Python CLI that ingests a time-series CSV, performs continuous wavelet transforms with user-selectable wavelets, extracts and reconstructs signal components via ridge detection, and outputs JSON summaries plus annotated scalogram images.",,
1a36d7e4-a653-4333-bcb3-421c829ff5be,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Implement a Python CLI that loads a multichannel time-series CSV, applies discrete wavelet denoising and designs Butterworth bandpass filters to isolate user-specified frequency bands, then computes Welch power spectral densities and pairwise magnitude-squared coherence across channels. The tool must output a JSON summary of dominant peaks and coherence maxima and save spectrogram PNGs for each channel and band.",,
0c9db30d-652e-4c1d-87bc-5a6e18752969,Scientific Computing & Analysis,Simulation & Modeling,Stochastic Differential Equation Solvers,"Implement a Python CLI that uses the Euler–Maruyama method to integrate a system of coupled stochastic differential equations modeling a double-well potential with additive Gaussian noise, generate Monte Carlo sample paths, estimate mean first-passage times and the stationary distribution histogram, and write trajectories to CSV and metrics to JSON.",,
12a003ac-ac27-4773-a8e5-29f2bae2a102,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Create a CLI that loads a social contact network from CSV, runs a stochastic agent-based SIR epidemic with configurable vaccination and quarantine policies, and outputs per-timestep compartment counts as CSV plus a JSON summary of peak infection, final attack rate, and estimated R₀. Ensure all randomness is seedable, support batch runs via JSON config, and report policy comparison metrics.",,
5fb8c643-698c-4541-8b48-e2ac07eb2cf7,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Develop a command-line tool that reads a JSON configuration for a 2D grid predator-prey model with random-walk movement, birth, death, and predation rules, executes multiple stochastic runs, and records time-series population counts. The tool should output JSON summary statistics along with spatial distribution snapshots (e.g., PNGs or CSVs) for each realization.",,
650ba307-14d9-4c6b-b8c1-acc284a79ff9,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a Python CLI that reads ant colony foraging parameters (grid size, nest and food source locations, agent counts, pheromone deposition/evaporation rates) from /app/config.json and simulates an agent-based foraging model on a 2D lattice with seeded random exploration and pheromone-biased movement over discrete time steps. The tool must write /app/results.json summarizing food collected and efficiency metrics, /app/pheromone.npy for the final pheromone field, and /app/trajectories.csv logging individual agent positions per step.",,
3bee9dea-9c1a-48f5-9170-d9d287ca482a,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a Python CLI that reads a chemical reaction network definition (species, stoichiometry, rate constants) from JSON and runs Gillespie’s stochastic simulation algorithm for multiple trajectories. Compute ensemble means and variances over time for each species, and output both time-series data and histogram summaries in JSON format.",,
76ca303b-95fd-4bc4-82c2-26700ba83a4d,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Set up a GitHub Actions CI pipeline for a Python finite‐difference PDE solver package that automatically runs pytest suites verifying second‐order convergence against analytic Poisson and heat equation solutions via parameterized tests, checks gradient consistency, tracks performance benchmarks, enforces code coverage ≥90%, and integrates linting/formatting checks.",,
ccbd0405-e99c-4e5b-9d25-740134ab57b9,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Implement a Python CLI that reads a multivariate time-series CSV, automatically selects the optimal VAR lag order via AIC/BIC, fits the VAR model, performs Granger causality tests for each variable pair, computes impulse response functions and forecast error variance decomposition for a user-specified horizon, and writes JSON summaries of model parameters, p-values, IRFs, FEVDs, and diagnostics.",,
70b528ae-1349-407c-a678-a085af6c62d4,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Create a CLI that reads a univariate time-series CSV (with timestamp and value), performs seasonal-trend decomposition via STL, fits a Holt–Winters Exponential Smoothing model with multiple seasonal periods to forecast the next horizon, and outputs forecast.csv and a metrics.json (including MAE, RMSE, and prediction intervals) based on a holdout period.",,
07b79295-f2fc-403b-996b-d548f6c6f39c,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Create a Python CLI that ingests a univariate time series CSV, uses STL decomposition to extract trend and seasonal components, then fits a TBATS model via grid‐search to handle multiple seasonalities. Forecast the next 30 points with 95% confidence intervals, writing decomposition results, forecast CSV, and a summary JSON of model metrics and chosen hyperparameters.",,
38a1e98b-ba87-4e11-8b61-c22b15ca6e6d,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Implement a Python CLI that loads a multivariate time-series CSV from /app/data.csv, applies STL decomposition to extract trend, seasonal, and residual components, and uses Welch’s method to estimate the power spectral density of the residuals, identifying dominant periodicities. Flag anomalies based on residual z-scores, then output a JSON summary of decomposition metrics, dominant frequencies, and anomaly timestamps, and save diagnostic CSVs and plots under /app/output.",,
9ba4534f-fa26-4782-9d5f-0bea36aefc2f,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Time-dependent Sobol Indices,"Create a Python CLI that takes a user-defined dynamic model, generates Saltelli sample sets, runs the model across a specified time grid, computes first-order and total-order Sobol sensitivity indices at each time point, and writes JSON metrics and time-series index plots to /app/output.",,
968f931a-751a-4759-a455-a61dec2b9381,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Create a Python CLI that reads a config of input distributions and a black‐box model in /app/model.py, then builds a sparse polynomial chaos expansion using Smolyak collocation to compute expansion coefficients, propagate uncertainty, and estimate output PDFs. The tool should also calculate variance‐based Sobol indices and cross‐validate results via Monte Carlo sampling, writing all outputs and convergence diagnostics to /app/results.json and /app/log.csv.",,
42809a24-fbfc-4d97-898e-a54fae03f7d9,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Implement a Python CLI that loads an SBML biochemical network, performs Latin hypercube sampling of log-normal kinetic parameters, simulates ODE time-courses for each sample, and outputs ensemble trajectories (CSV) plus JSON containing mean, variance, and 95% confidence intervals at each timepoint.",,
e73b8a2e-27bc-4f8a-a786-743404278139,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Implement a CLI entropy-mixer that collects bits from getrandom(), optional RDRAND, and CPU timing jitter, combines them via HKDF-SHA256 into a seed, and drives a ChaCha20-DRBG with fork detection and periodic reseeding to emit N bytes. Provide a health subcommand that performs basic randomness sanity checks and refuses to run if only a single untrusted source is present.",,
2cde2559-b852-4226-ae21-8badfb0c31b4,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Implement a Python CLI that reads nominal parameters and uncertainty distributions for an SIR compartmental model from JSON, propagates these uncertainties through the ODE solver using both Monte Carlo sampling and the Unscented Transform to compute 95% credible bands for S, I, and R time series. It should write time-step quantiles to /app/output/trajectories.csv, summary statistics to /app/output/summary.json, and produce Matplotlib plots of the predicted bands.",,
98f7c2f5-51bc-4e4d-b77d-c92445cab660,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Create a Python CLI that ingests a JSON configuration of distribution parameters (mean, variance, type) for a damped harmonic oscillator and performs Latin-hypercube Monte Carlo sampling to numerically integrate the ODE for each sample. Compute statistical moments and 95% confidence intervals for peak displacement and oscillation period, then write a JSON summary and a CSV of selected sample trajectories.",,
fde298e5-dce7-4e79-aabd-8143b4711117,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Create a CLI that ingests a one-dimensional time-series CSV, computes the autocorrelation function up to a user-specified lag and the power spectral density via Welch’s method, and outputs a Matplotlib figure with two aligned subplots (ACF and PSD). Also write a JSON summary with dominant frequencies, corresponding power spectral peaks, and the top autocorrelation lags above a threshold.",,
1c878dc9-fef7-45a6-b574-21220ec7f204,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Create a Python CLI that loads a global surface temperature netCDF4 file, computes monthly anomalies relative to a baseline period, and generates a multi-panel Matplotlib PDF containing a time-series of global mean anomaly, a world map contour of a selected month, and a zonal mean contour plot.",,
4fda1c36-20ac-49e1-8481-f7aea46e1318,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Implement a Python CLI that loads a 3D volumetric dataset (e.g., a .npy array), extracts iso-surfaces at multiple user-specified thresholds using skimage.measure.marching_cubes, and renders them in an interactive Plotly HTML with sliders for threshold and opacity control. The tool should support large volumes via optional downsampling and annotate surface area and volume metrics on the plot.",,
51d53f4a-07bb-4b5f-9209-c3128a29e69d,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,Analyze a stripped ELF that reconstructs an AES-128 key at runtime from scattered lookup tables and uses it to decrypt an embedded data blob. Recreate the key derivation and decryption in a standalone script to recover the original JSON config and write it to /app/config.json.,,
b08403cb-7599-423e-83b5-bf042b2b16cf,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,"Analyze a stripped x86-64 ELF that embeds a custom bytecode virtual machine for license verification; extract the bytecode and reimplement the VM in Python to compute the correct license without running the binary, writing it to /app/license.txt.",,
183a87f3-d349-4f9b-9e8f-2f15e6ac62b6,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,Analyze a stripped x86-64 ELF that validates input using a custom stack-based bytecode VM and simple anti-debug checks. Reconstruct or emulate the VM to recover the exact passphrase that yields 'ACCESS GRANTED' and write it to /app/flag.txt.,,
3099848a-d3fb-4dbb-81c8-c9979dab4e24,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,"Reverse engineer a stripped x86_64 ELF that decrypts a payload using AES-CTR, where the key and nonce are constructed at runtime from several obfuscated constants. Recover the exact key/nonce and write a CLI tool that decrypts /app/secret.enc to /app/secret.txt without modifying the binary.",,
087716af-222d-487c-b30e-d192082028b9,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,"Reverse-engineer a stripped Linux ELF that embeds a WebAssembly module inside a custom section and validates input by interpreting that WASM; locate and extract the module, reconstruct the check algorithm from its bytecode, and compute the input that makes the program reveal FLAG{...}. Write the recovered flag to /app/secret.txt and note the byte offsets used for the extraction.",,
362a6d09-e5fd-4ebf-8db1-725069ff51b7,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,Configure OpenSSH in the sandbox to require dual authentication: Ed25519 public key plus a TOTP code derived from /app/mfa_seed.txt via keyboard-interactive PAM. Implement a non-interactive client script that computes the current TOTP and successfully scp’s /secure/flag.txt to /app/result.txt as proof of access.,,
16462757-679a-409a-b431-8a4c6084a100,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Configure an OpenSSH server to require dual authentication: a CA-signed user certificate and a TOTP code via PAM. Generate a user keypair, sign it with a provided SSH CA, seed a TOTP secret for the test user, and prove that SSH access succeeds only with a valid cert plus current OTP while plain keys or incorrect codes are rejected.",,
307e6c13-6d38-4d2f-9ac4-cbafa068b4ed,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Patch a vulnerable web API that currently accepts JWTs with alg=none and HS/RS key confusion by enforcing strict RS256 verification against a local JWKS endpoint, validating iss/aud/exp, and implementing key rotation with cache invalidation. Provide CLI scripts that mint a valid token to access a protected endpoint and demonstrate that forged tokens (none, HS-using-public-key, wrong aud/iss, expired) are rejected, writing results to /app/verification.txt.",,
cc2c54bc-0160-4dc6-b5da-d4e93426c2ce,Security & Cryptography,Authentication & Access Control,Password Management & Hashing,"Refactor a legacy Flask-style auth service that stores unsalted SHA-1 password hashes to use Argon2id with per-user random salts and configurable memory/time parameters, including automatic rehash-on-login when parameters are outdated. Provide a CLI to bulk-migrate users by validating credentials from a provided login_attempts.csv, updating hashes in-place, and emit an /app/audit.json listing any accounts that could not be migrated.",,
1e713960-d23c-4c07-8937-b13d6b1e6b06,Security & Cryptography,Authentication & Access Control,Role-Based & Policy Enforcement,"Implement UNIX RBAC for a project workspace by creating dev, qa, and ops roles, enforcing a permission matrix with POSIX ACLs (including default ACL inheritance), and adding a sudoers.d rule that lets only ops run a specific appctl restart command without enabling shell escapes or env-based escalation. Provide a verifier that impersonates sample users to confirm read/write/execute behavior, ACL inheritance on new files, and denials for unauthorized sudo or file operations.",,
4ecbd492-e92e-422c-9206-03374033de49,Security & Cryptography,Authentication & Access Control,Role-Based & Policy Enforcement,"Provision role-based access on a Linux host by creating dev, ops, and audit roles with UNIX groups, POSIX ACLs, and sudoers.d policy. Enforce that devs can write to /srv/app/releases but cannot restart services, ops may only sudo systemctl restart app@* without shell escapes or env-based escalation, and auditors can read /var/log/app but not secrets, with default ACLs applied to new files.",,
52304d6e-e522-4423-a39e-349287c208f9,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Configure an OpenSSH service to support key-based session revocation by adding a revoke-key command that, given a public key or fingerprint, updates the RevokedKeys file, reloads sshd, enumerates and terminates any active sessions established with that key, and emits a machine-readable report. Verify that future logins with the revoked key are refused while unaffected users remain connected.",,
15142d11-357d-40cf-a30d-b675bf9bdce1,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Extend a JWT-based FastAPI authentication service to implement session-level revocation using per-token jti entries in Redis with TTL and refresh-token rotation with reuse detection that triggers immediate user-wide logout. Provide a CLI/endpoint to revoke all sessions for a username and verify that revoked access tokens return 401 while new logins succeed, with revocation instantly propagated via Redis pub/sub.",,
1e123cd6-baf8-45a2-b415-de80fb0fad6d,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Implement refresh-token rotation with reuse detection and a centralized, Redis-backed revocation list for a JWT-based API, propagating revocations to all workers via pub/sub. Verify that using a stolen refresh token revokes its entire chain and that rotating the JWKS signing key invalidates only old-key tokens while unaffected sessions continue.",,
c4bf7893-cc3e-44d3-a18c-ab0bbcb3eafd,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Create a terminal CLI that signs artifacts with Ed25519 producing detached .sig files and verifies downloads against a local trust store using a configurable threshold policy (e.g., require 2-of-3 maintainer signatures). Output a JSON report detailing key IDs verified, failures, and overall status, and support key rotation by marking old keys as retired while still validating past releases.",,
9b77ca7f-5efa-4f60-8e57-5e760e1d9615,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Implement a CLI tool that verifies OpenPGP cleartext-signed messages (RFC 4880) with correct canonical text handling (CRLF normalization, dash-escaping, and trailing whitespace) against a provided public keyring. The tool scans /app/messages for .asc files and outputs a per-file validity report to /app/verification.json.",,
998ca654-7119-4fb8-94d3-0ce0efd027cb,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Build a CLI that performs envelope encryption of a directory using a hybrid RSA-OAEP (recipient key) + AES-256-GCM (data) scheme in a streaming fashion (tar -> encrypt) to produce a single archive.enc with a minimal JSON header. Provide a decrypt command that uses the recipient’s RSA private key to recover the data key, verify integrity, and reconstruct the directory byte-for-byte, failing on any tag or SHA-256 manifest mismatch.",,
131877a7-f792-4780-b99c-7b4c4faadb60,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Create a CLI that performs hybrid envelope encryption for a directory: each file is encrypted with a fresh AES-256-GCM key and nonce, and the key is wrapped for multiple recipients using RSA-OAEP (SHA-256), emitting a per-file JSON manifest with wrapped keys, nonce, and tag. Implement a decrypt mode that accepts any matching recipient private key, verifies tags before writing, reconstructs paths and permissions, and aborts on any authentication failure.",,
d370b5e4-4f5f-47f5-8fb9-993b90378704,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Implement an envelope decryption tool that processes all *.enc files under /app/data: each file begins with a base64 JSON header containing an RSA-OAEP-wrapped AES-256-GCM key and 12-byte nonce, followed by raw ciphertext and tag. Use the PEM private key at /app/keys/priv.pem to unwrap keys, decrypt outputs to /app/dec preserving directory structure, and write a decrypt.log listing any files that fail authentication.",,
b9354cbb-aca1-4819-af20-ea8b286ed47c,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Use OpenSSL CMS to implement multi-recipient envelope encryption of a file with AES-256-GCM using both an RSA and an EC certificate, then demonstrate that either private key can decrypt while tampering triggers authentication failure. Automate key/cert generation, encryption, per-recipient decryption, and produce the recovered plaintext and an audit log of verification steps.",,
64f7fc06-6590-459f-ba21-2fd88d6397ff,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Build a CLI that creates a chunked SHA-256 Merkle-tree manifest for a directory (e.g., 4 KiB chunks), emitting a root hash and inclusion proofs, and a verifier that can validate a specific file or chunk without re-hashing the entire dataset. The verifier must pinpoint tampered chunks and output a minimal diff (paths and chunk indexes) with expected vs actual hashes.",,
586cb05a-3f97-4e55-a45f-f80eb5c7299b,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Implement a CLI tool that computes a deterministic SHA-256 Merkle tree over all regular files in /app/data (sorted paths), outputs the root to /app/output/root.txt, and can emit and verify inclusion proofs for any file. Use it to validate a provided set of proofs and write the paths of any tampered files to /app/output/tampered.txt.",,
edbca895-df60-47de-a158-6f2a8cf3779f,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Create an offline GPG primary certification key and add dedicated signing, encryption, and authentication subkeys; export a revocation certificate and relocate the primary key to an “offline” store. Implement a rotation that replaces the encryption subkey, updates the public keyring, and proves functionality by signing, encrypting, and decrypting test data using only the subkeys.",,
9efb5e63-65ae-40a3-b47d-930aedbd81ba,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Set up an SSH Certificate Authority that issues both user and host certificates, configure a local sshd to trust the CA, and prove access requires a signed user cert and a valid host cert signature. Rotate the CA by generating a new key, re-signing credentials, publishing a Key Revocation List for the old CA/host certs, and demonstrate that old certs are refused while new ones succeed.",,
29b86c07-6fc8-4f97-b444-f85274b6d583,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Build a user-space entropy combiner and CTR-DRBG that gathers timing jitter and kernel getrandom(), applies SP 800-90B on-line health tests to raw samples, and derives output via HKDF + AES-CTR. Provide a CLI that emits N bytes, supports reseed, blocks until a configurable entropy threshold is met, and refuses to reuse state across fork unless reseeded.",,
d4e950f7-2ccd-48ed-a573-23519d8ed6b2,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Implement a ChaCha20-based DRBG CLI seeded exclusively via Linux getrandom, with a timing-jitter collector for periodic reseeding and online health tests (FIPS continuous test and SP 800-90B repetition/adaptive proportion). Generate 512 KiB of random data to /app/out.bin and a JSON health report with reseed events and PASS/FAIL to /app/health.json.",,
7391deb5-39b4-4c63-8c90-c2f355016218,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Implement a user-space entropy collector that samples CPU timing jitter and other non-blocking sources, conditions them with SHA-256, and seeds a ChaCha20-based CSPRNG with a CLI to emit N bytes to /app/output/random.bin. Include basic health tests (repetition count and adaptive proportion) and persistent reseed state to avoid output reuse across restarts.",,
ff3fd97c-b009-47aa-9a2e-31f0c9826eb0,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Analyze a Linux RAM dump to locate a shared object mapped from a deleted path or memfd that indicates code injection. Carve the ELF from the dump, save it to /app/output/evil.so with its SHA-256, and report the hosting PID and the suspicious VMAs involved.",,
4136c335-87ee-419d-86a6-a2c6028ed35e,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Analyze a Linux memory image to locate a ChaCha20-Poly1305 key and nonce left in a suspected process’s heap, reconstruct them from little-endian 32-bit words, and decrypt /app/capture.enc into /app/plaintext.out. Record the PID and virtual address where the key was recovered in /app/findings.txt.",,
93e75374-fcf8-4fc3-ae18-a95fc498491f,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Analyze a Linux process memory dump to recover an in-memory OpenPGP private key (ASCII-armored or binary), reconstruct and import the key, and decrypt a provided ciphertext to validate the extraction.",,
c340770e-de93-4186-8141-d3fbf1fe3491,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Given a Linux process core dump and an AES-CTR–encrypted blob, recover the 32-byte AES key from memory artifacts (e.g., key schedule structures or contiguous hex bytes) and use it to decrypt the blob to plaintext. Validate success by matching the plaintext’s checksum against a provided reference.",,
5e41fb9b-5fe2-421e-b62b-2000cb1b7343,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Given a Linux process core dump produced during an active ransomware run, carve the ChaCha20-Poly1305 master key and per-file nonces from memory and use them to decrypt all samples under /app/encrypted to /app/recovered. Output a machine-readable incident report including the recovered key material, originating PID/command line, and hashes of the decrypted files.",,
68358721-240b-49f7-9f57-c11844a4b482,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Analyze BIND9 query logs and system auth logs to detect DNS tunneling via long high-entropy subdomains and elevated NXDOMAIN rates, then identify the tunneling domain, originating client IP, and time window. Write findings to /app/output/report.json and provide a CLI that prints the top 5 suspicious FQDNs with counts based on your heuristics.",,
71930ca4-f050-4228-b633-b2c55bfb5cb4,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,Analyze Suricata EVE JSON and SSH auth logs to detect a DNS TXT-based tunneling session followed by lateral movement via successful SSH login from the same source IP. Output the exfiltration domain and compromised username to /app/findings.json.,,
89a7b728-b20f-4aba-b881-524f0fe1be59,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Correlate nginx access.log, /var/log/auth.log, /var/log/cron.log, and syslog to detect a webshell-driven intrusion: identify the initial exploit request and source IP, enumerate compromised accounts via SSH, and reconstruct the timeline through persistence installation and data exfiltration. Write the attacker IP(s), first compromise timestamp, compromised usernames, path and SHA256 of the dropped payload, and the exfil destination to /app/incident_report.txt.",,
4ea4b856-bac6-400b-ba58-a7b6fa419ffd,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Implement a terminal tool that ingests DNS resolver logs and network flow summaries to detect DNS tunneling exfiltration via heuristics (label entropy, query length uniformity, periodicity) and correlate suspicious domains to source hosts. Output a ranked alert list, a chronological incident timeline, and a JSON file of IOCs (domains, client IPs, first/last seen, estimated bytes).",,
4c5b900c-a23e-4648-a379-2ab0e38af223,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Parse DNS resolver logs (e.g., BIND/Unbound) to detect DNS tunneling by flagging high-entropy, long subdomains with abnormal query/NXDOMAIN rates. Attribute offending client IPs and reconstruct the exfiltrated payload by decoding base32/base64 subdomain chunks into /app/exfiltrated.txt.",,
c51adb3f-786c-4b64-ad78-beec2b7b8b7b,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Create a terminal-based workflow that unpacks a multi-stage Linux dropper (bash + ELF), statically recovers its C2 configuration by deobfuscating an XOR+Base64 blob, and dynamically confirms behavior by tracing syscalls and outbound DNS/HTTP. Output a JSON report listing decrypted C2 domain(s), beacon interval, persistence mechanisms (e.g., ld.so.preload or cron edits), files touched, and any exfiltration paths.",,
df99c36c-2b10-4baf-8340-91971dc4362d,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,Inspect an obfuscated Linux ELF dropper that persists via /etc/ld.so.preload and exfiltrates data using DNS TXT queries. Recover and decode its embedded C2 domain (XOR+base64) to /app/iocs.txt and cleanly remove the persistence without breaking legitimate binaries.,,
6e0612db-7e43-4745-84f2-74fcf6c6713f,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Perform hybrid (static and controlled dynamic) analysis of a suspicious Linux ELF dropper that conceals its configuration via XOR+Base64 and establishes persistence via a systemd user service, using tools like objdump, strings, strace, and a local network namespace to observe behavior safely. Recover and save the decrypted config, enumerate all IOCs (C2 endpoints, file paths, service names), and produce a concise YARA rule that identifies the sample while minimizing false positives.",,
45bb7a55-e6c7-41ef-bbe9-483e5a9ea598,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Perform static and controlled dynamic analysis of a packed Go-based Linux ELF dropper that decrypts its configuration at runtime. Without contacting external hosts, recover and write its decoded C2 endpoints, mutex/campaign ID, and installed persistence artifacts (e.g., systemd unit/timer names or crontab entries) to /app/iocs.txt, and extract the embedded payload to /app/payload.bin.",,
448c2893-b7b1-4e85-94ba-c41af2950ad8,Software Engineering & Development,Feature Implementation & Algorithm Development,API Design & Integration,"Implement a Python gRPC service in /app/bridge.py that exposes BookService RPCs and translates them into calls to an external REST catalog API, mapping protobuf schemas to JSON, handling authentication tokens, retries with exponential backoff, and streaming responses for batch queries.",,
b2dfe363-0752-420e-ad2b-c31ee673622e,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Statically and/or dynamically analyze an obfuscated Linux ELF dropper at /app/samples/dropper to recover its behavior and configuration, including persistence mechanism and C2 endpoints. Decrypt the embedded config (XOR key stored in the .note.sec_key section) and write the persistence artifact path, targeted exfiltration globs, and C2 domain:port as JSON to /app/iocs.json.",,
c9881ff2-5227-4b92-bbf2-6428b6281b8f,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Correlate Apache/Nginx access logs, SSH auth logs, Zeek HTTP/conn logs, and a small pcap with mixed time zones to reconstruct the compromise timeline from first exploit to data exfiltration. Output a UTC-normalized CSV of events and a brief report identifying attacker IPs, exploited endpoint, privilege escalation, persistence, and exfiltration channel.",,
6108696c-a523-4dd6-b4bc-cd9fc7287dba,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Correlate Linux auth logs, web server access logs, Docker daemon/container JSON logs, and shell history with partial clock skew to reconstruct a unified UTC timeline of a short-lived breach from initial credential reuse through containerized payload execution to data exfiltration and a log-tampering attempt. Produce a machine-readable CSV including timestamp, event label, actor/IP, and source file, noting any time-skew adjustments applied.",,
f2341e68-f1a8-40ac-95b2-cc4b82f3757a,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Create a CLI that parses rotated nginx access logs, SSH/auth logs, and Linux auditd logs from multiple hosts, auto-normalizes timestamps (timezones, DST changes, and a known 7-minute skew), and reconstructs a single UTC incident timeline from initial web hit to privilege escalation. Output a CSV with sequence numbers, unified timestamps, actor (IP/user), correlated PIDs, and flags for suspected timestomping when file MAC times conflict with process execution events.",,
c9b04cb6-29b3-4009-9171-1118ebfd1b1b,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Reconstruct a minute-by-minute timeline of a supply-chain compromise by correlating auditd, apt/dpkg logs, pip metadata, systemd journal, and netflow/pcap artifacts from initial package install to persistence and exfiltration. Output a sorted timeline.csv and a findings.txt naming the malicious package, the first persistence write path, and the exfiltration destination IP.",,
00b3990b-6ed1-404e-849d-60f2dac8f558,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Against a sandboxed Flask web app, identify a server-side template injection sink in a preview endpoint and craft an obfuscated Jinja2 payload that writes /tmp/mark_ssti.txt and exfiltrates http://127.0.0.1:8081/flag to /app/result.txt despite a naive WAF blocking common tokens. Success is validated by the presence of the marker file and the exact flag content.",,
3068fd20-41d2-4887-83b0-f3fc8269b153,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Assess a misconfigured Docker Engine API exposed on localhost by deploying a minimal containerized payload that mounts the host filesystem read-only to retrieve a designated secret. Copy the secret to /app and then cleanly remove all created containers, images, and networks to restore the environment.",,
f31bb7a0-1534-4009-ad1c-48a6d014b3d4,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Exploit a Shellshock vulnerability in a CGI-enabled web service by sending a crafted HTTP header that executes a controlled payload to create /app/pwned.txt and print the effective UID. Then harden the server (e.g., CGI config or shell update) and verify the payload no longer executes.",,
e8611445-0649-4099-a8c3-70269a518c97,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,"Scan the provided lab subnet to discover an HTTP service on a non-standard TCP port, an SNMP agent on UDP 161, and a custom binary service on an unknown port. Use nmap (including relevant NSE scripts) and netcat/openssl to enumerate and write the HTTP title, SNMP sysName, and the custom service’s banner to /app/enum.txt.",,
3a261da6-d5a3-4651-bccc-dbdd7363e4c1,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"After a simulated compromise, build a CLI triage tool that hunts for stealthy Linux persistence (systemd timers/units, cron spools, SSH authorized_keys options, and /etc/ld.so.preload), disables any malicious entries safely, and emits a machine-readable remediation report. Validate by proving the planted persistence no longer triggers while legitimate services remain functional.",,
17264c9a-6944-44c2-ad07-ab87728661cd,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"After an authorized compromise of a Linux host, enumerate and analyze multiple persistence footholds including a masqueraded systemd unit, an SSH authorized_keys entry with a forced-command, and a cron job carrying a base64-encoded payload. Decode each mechanism, map it to its on-disk artifacts and startup triggers, generate a JSON report with indicators of compromise, and disable the persistence so it does not survive reboot.",,
b8086ed9-8ca6-407b-a2ef-5f8b5c4dbe03,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Analyze a compromised Linux host that employs layered persistence—a PATH-hijacked systemctl shim, a systemd service drop-in masquerading as a core daemon, an /etc/ld.so.preload hook, and a cron self-healer using immutable files—to identify, validate, and eradicate each mechanism. Produce a machine-readable IOC report (paths, hashes, service/timer names, environment changes) and a verification script that proves persistence does not return after service restarts.",,
ae72954f-725c-4725-87a5-874f1685b48d,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Investigate a compromised Linux host to enumerate and validate stealth persistence mechanisms (e.g., a malicious systemd drop-in, cron.d @reboot job, LD_PRELOAD via /etc/ld.so.preload, and an SSH authorized_keys forced-command backdoor), safely neutralize each, and produce a machine-readable report at /app/persistence_report.json. Ensure legitimate services and user access remain unaffected while removing only malicious artifacts.",,
c1a9bd92-ea63-4af5-b794-11d25daa865e,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"On a compromised Linux host, locate and neutralize multiple persistence mechanisms (a masqueraded systemd service, an LD_PRELOAD backdoor, and a cron-based beacon) without disrupting legitimate services, then produce /app/findings.json detailing each artifact, removal steps, and verification evidence. Confirm remediation by showing the backdoor no longer injects into sshd and that no malicious systemd timers or cron entries remain.",,
5802ae5e-0d61-4040-b3a6-3077b27f9674,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,"Starting from an unprivileged user, enumerate the host to discover a root cron job that uses tar against a writable directory and exploit tar’s wildcard/--checkpoint-action behavior to execute code as root and write a proof file. Then remediate by correcting permissions and hardening the backup command to use absolute paths and safe options so the escalation path is closed.",,
f820d943-7f9d-46eb-843c-df6ec9c3d40e,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Build a CLI that hardens a Docker Compose project by enforcing least-privilege defaults (non-root user, read-only filesystem, dropped capabilities, no-new-privileges, seccomp/AppArmor profiles, CPU/memory limits, and read-only mounts unless whitelisted) and rewrites compose.yaml in place. Provide a verification script that launches the stack and uses docker inspect to confirm each service satisfies the required constraints.",,
b0a78975-16b7-4042-89d4-d384f4cdd1ea,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Harden a Docker Compose application by rewriting its services to run as non-root with read-only root filesystems, drop all capabilities (add back only what’s required), enable no-new-privileges, apply a strict seccomp profile, and set memory/PIDs limits. Validate that the app still functions while attempts to perform privileged actions (e.g., mounting, ptrace, writing to root-owned paths) fail within the containers.",,
f3220ee1-693f-4deb-84c8-fbf2f158d320,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Harden a Docker Compose-based microservice by running containers as non-root, dropping unnecessary capabilities, enabling no-new-privileges, read-only root filesystems, strict seccomp/AppArmor profiles, and segmented networks with egress allowlists. Implement a policy-as-code linter (e.g., OPA/conftest) that validates the Compose file against these controls, and ensure the project passes the checks.",,
bc088864-bba9-4acb-b17a-cfb161418236,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Harden a Dockerized service to run rootless with user-namespace remapping, read-only rootfs and tmpfs overlays, minimal capabilities (e.g., only NET_BIND_SERVICE), no-new-privileges, custom seccomp/AppArmor profiles, and strict ulimits/cgroup constraints while preserving functionality. Provide a docker-compose setup that blocks 169.254.169.254 and non-whitelisted egress, denies hostPath mounts and Docker socket access, and verifies the container cannot write outside its volume or invoke ptrace/keyctl/mount syscalls while health checks pass.",,
6a17f0d5-f98b-472b-93f4-0fcd790433a1,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Audit a containerized service for insecure file permissions and symlink misuse: find world-readable secrets and an uploads directory that permits symlink-based writes, then harden by correcting ownership/modes, adding sticky bits where needed, and enforcing least-privilege with POSIX (default) ACLs for the service user. Demonstrate remediation by showing unprivileged users can no longer read the secrets or redirect writes via symlinks.",,
809ebd0c-a14a-415e-a4f9-15dcf4dd0499,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Audit a multi-user workspace to detect world-readable secrets and symlink-based write-escape hazards in shared paths (e.g., /tmp and a build cache), then implement a fix script that enforces least-privilege permissions and blocks symlink traversal. The solution must harden SSH/GPG key directories and files, set sticky-bit and ownership on shared directories, and ensure artifact writes cannot escape the intended workspace.",,
8122d9b8-7f4f-4b60-b194-60d7582bb0fe,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Create a Git-aware remediation tool that scans the working tree and full history for hardcoded credentials (provider patterns + entropy), migrates them to environment-driven config backed by a local dotenv/JSON store, and rewrites code to use lookups. The script must purge secrets from history, install a pre-commit hook to block future leaks, and emit a machine-readable report verifying no secrets remain and the app runs with injected env vars.",,
f5feee22-f568-4735-8a34-028e59dede46,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Build a hardening utility that audits and remediates PATH hijacking and temp-dir permission issues: locate world-writable or non-root-owned directories in $PATH, detect user-writable shadow binaries preceding system utilities, and ensure /tmp and /var/tmp have the sticky bit. It must fix ownership/permissions or remove unsafe entries, reorder PATH safely, and emit a before/after compliance report proving that no PATH entry is writable by non-root and that core tools resolve to system binaries.",,
ddb44dc5-3a47-46b5-af90-d34dc1843c51,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Identify and remediate a symlink race in a root-run log rotation script that compresses and moves files from /var/log/app, where an attacker can swap a log for a symlink to clobber or exfiltrate arbitrary files. Harden the rotation by rejecting symlinks/hardlinks and using O_NOFOLLOW-safe moves, then tighten permissions (logs 600, log dir 700) and emit a change report to /app/rotation_hardening_report.json.",,
2594fba8-2553-4c25-a8f0-dad37a0bf0b5,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Implement a policy-driven filesystem hardener that reads a YAML policy of expected owners, groups, and modes for specified paths, then audits and enforces them while stripping unsafe SUID/SGID bits and setting sticky bits on designated temp directories. It must detect and refuse symlink/hardlink escapes, correct insecure world-readable/writable permissions on secrets, and emit a machine-readable before/after report of all changes and blocks.",,
e5d05e25-b0a9-4d95-b58a-e7b3c003a39a,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Configure a stateful nftables firewall implementing a three-packet port-knocking sequence that temporarily opens SSH (port 22) for the knocking source IP, with automatic timeout and rate-limited logging of denied traffic. Provide idempotent scripts to install and persist the rules, and verify that incorrect sequences or scans never open the port and that access reverts after the timeout.",,
0367e0f0-195f-4a26-a0c6-0b7636a75548,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Harden a Linux host with nftables by implementing a default-deny, stateful firewall that permits inbound HTTPS on 8443 to a sample service, rate-limits SSH (5/s, burst 10), blocks all IPv6, and enforces an egress allowlist (DNS/HTTPS) for both the host and a container bridge subnet. Provide a persistent ruleset and a verification script that proves container isolation, denied outbound ports, and rule survival after a ruleset reload.",,
b2a4c8ed-c00a-4d55-8541-a8028d14bdfa,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Harden the host by replacing permissive rules with an nftables default-deny policy that allows only inbound TCP 8443 and rate-limited SSH from 10.42.0.0/16, permits established/related traffic, and restricts egress to DNS, NTP, and HTTPS while logging first-hit drops to /var/log/nft-blocks.log via ulogd. Ensure the rules persist across reboot via /etc/nftables.conf and verify with connectivity tests that allowed paths work and blocked paths fail.",,
6b493f86-7ef0-465a-b526-72ff725db9b5,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Implement host egress hardening using nftables: redirect all outbound TCP/80 to a local transparent proxy on 127.0.0.1:3128, allow only DNS and HTTPS to the Internet, block cloud metadata IP 169.254.169.254 and RFC1918 destinations, and set default-drop for everything else. Include a verification script that demonstrates allowed and blocked paths and writes a concise report to /app/firewall_report.txt.",,
11f4e2e0-c717-41ae-bf48-bf665632000a,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Using nftables, implement a default-deny egress policy that only allows DNS to the system resolver and HTTPS to a domain whitelist managed as an IP set resolved from /app/allowed_domains.txt, with all other outbound connections rate-limited logged and dropped. Persist the rules in /etc/nftables.conf and provide /app/update_whitelist.sh to refresh the IP set so curl to allowed domains succeeds while others are blocked.",,
fb854a74-d297-40ec-bbd6-3e852bb11143,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Harden a provided systemd service via a drop-in override that runs it as a dedicated user and applies systemd sandboxing (NoNewPrivileges, CapabilityBoundingSet, ProtectSystem=strict, PrivateTmp, ReadOnlyPaths, RestrictAddressFamilies, SystemCallFilter) while preserving its core UNIX-socket functionality. Tests confirm the service still works but cannot read /etc/shadow, write outside its working directory, bind TCP sockets, or retain elevated capabilities.",,
0a4f53d5-2d78-4aea-a5d9-86741c119f0a,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Harden a provided systemd unit for a demo HTTP service to enforce least privilege by using DynamicUser, dropping all capabilities, enabling NoNewPrivileges, sandboxing with ProtectSystem=strict/ProtectHome/PrivateTmp, restricting writable paths, and applying a strict SystemCallFilter. Demonstrate the service still functions on localhost while reads of /etc/shadow, execution of new binaries, and writes outside the allowed directory are denied, then output the final unit and a validation log to /app/result.",,
44e2f808-ea81-4bfe-beb2-13fee514e751,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Harden a provided systemd-managed file-sync service by applying systemd sandboxing and least-privilege features (DynamicUser, capability bounding, filesystem and network/address-family restrictions). Verify the service still syncs files while being unable to write outside /var/lib/sync, read /etc/shadow, spawn a shell, or bind to privileged ports.",,
233ff48e-aaa7-4f55-9858-9ccdf299a659,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Install and harden OpenSSH by creating a non-root deploy user, disabling root and password authentication, enforcing Ed25519 key-only access with modern Ciphers/MACs/KexAlgorithms, and restricting logins to that user via AllowUsers. Prove hardening by successfully logging in to localhost with the key while root/password logins fail, and write the final sshd_config and test results to /app/output.",,
4f96fd91-f0a6-4222-86be-33a2ffa0d893,Security & Cryptography,Secure Software Development,Input Validation & Sanitization,"Harden a Node.js CLI that shells out to ImageMagick using user-provided format, size, and filename by replacing string-based exec with safe argument arrays and strict schema validation. Enforce a whitelist of formats, bounded numeric dimensions, and sanitized filenames to prevent command injection while preserving legitimate conversions and exact output naming.",,
409e6daa-ca9e-4f52-a619-4d44bf1eaf9b,Security & Cryptography,Secure Software Development,Input Validation & Sanitization,"Refactor a FastAPI + SQLite microservice that currently builds SQL from query parameters to enforce strict validation and sanitization using parameterized queries and Pydantic validators (types, length limits, regex whitelists), returning 400s for disallowed input. Include a CLI verifier that exercises endpoints to prove SQLi payloads are neutralized while valid requests still return correct results.",,
83de18e0-3d54-4003-8b5b-50f2afff4717,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Identify hardcoded OAuth client secret and JWT signing key in a Node.js service, migrate them to Docker Compose secrets and a .env file with properly generated replacements, and refactor the code and compose config to consume them securely. Add a git pre-commit hook that blocks future secret leaks and demonstrate the app still authenticates and issues tokens using the rotated keys.",,
2dc62600-01a3-4791-bad0-674b5afdcda0,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Scan the repository (including full Git history) to locate hardcoded secrets, rewrite history to purge them, and migrate the values into a SOPS-encrypted secrets.yaml secured with an AGE keypair while refactoring code to read from environment variables. Verify by showing the application runs using decrypted env at runtime and that a secret scanner reports no findings in the working tree or history with only the encrypted file tracked.",,
06cea5da-8b17-4b73-80fe-6b55653f6142,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Audit a Python package that includes a Rust extension (built with maturin) using pip-audit and cargo-audit, then apply minimal semver-safe upgrades via constraints.txt and Cargo.toml updates/patches to eliminate all high/critical advisories without altering CLI behavior. Rebuild the wheel, regenerate lockfiles/SBOM, ensure tests pass, and write a JSON report of remediated CVEs to /app/vuln_report.json.",,
e0fc5d19-30d3-465b-ba21-49ea3115fef0,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Build a CLI that scans a monorepo’s Python (pip) and Node (npm) dependencies with OSV/pip-audit/npm audit, applies minimal non-breaking upgrades to eliminate high/critical CVEs, and regenerates lockfiles with hash/integrity pins. It must emit pre/post CycloneDX SBOMs, run the project tests to validate the upgrade, and fail the run if vulnerabilities persist or the build is not reproducible.",,
77fb1c12-5d27-4491-b34e-dba65fd1568a,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"In a mixed Python/Node project, use pip-audit and npm audit to identify one direct and one transitive vulnerable dependency, then remediate with minimal safe upgrades by pinning versions (requirements/constraints and package.json overrides) and regenerating lockfiles with strict hash verification. Enforce deterministic offline installs via pip.conf and .npmrc (require-hashes, npm ci with scripts disabled), generate CycloneDX SBOMs, and output a brief report of fixed CVEs and final versions.",,
a5456293-28ab-45d6-86f7-096aa274701d,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"In a polyglot monorepo (Python, Node.js, and Rust), audit dependencies with pip-audit, npm audit, and cargo audit, then apply the minimal safe upgrades and regenerate lockfiles with hashes. Emit a consolidated CycloneDX SBOM and JSON advisory report, wire a CI script to fail on new critical CVEs, and verify builds and tests still pass.",,
c7c4620f-ea56-4209-bf9b-0fac92fdbe6d,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Scan a Python + Node monorepo with pip-audit and npm audit, then apply minimal safe upgrades via constraints.txt and npm overrides to remove all High/Critical findings and regenerate lockfiles. Output a unified JSON diff of vulnerabilities before/after and enforce deterministic installs with pip --require-hashes and intact npm integrity fields.",,
90debcb5-2993-458a-b1eb-7b69f7bf17d0,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Author a custom Semgrep rule set that models taint flow across a mixed Python/Node.js codebase to detect untrusted input reaching command execution, SQL queries (string interpolation), and unsafe path joins (zip-slip). Run the rules to produce a SARIF report, refactor the code to remediate all high-severity findings, and re-run to confirm zero remaining issues.",,
e59e701d-79ea-413f-af68-abce938090ea,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Create a Semgrep taint-mode rule pack that detects flows from Flask request inputs to sqlite3 query execution (SQL injection) and to filesystem access (path traversal), outputting findings in SARIF. Run the scan on a provided Flask app, then refactor to parameterize queries and normalize/whitelist file paths, and re-scan to verify zero findings.",,
a47ebd00-c2c1-4f85-bbd9-67d61f80a278,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Install and run Bandit and Semgrep on a deliberately vulnerable Python microservice, and author custom Semgrep rules to detect ECB mode, static IVs, weak hashes, and subprocess calls with shell=True, then refactor the code to remove all findings. Produce before/after SARIF reports and a CI-failing script that exits non‑zero if any critical issues remain.",,
bf691216-c049-485b-86f2-62937c8a822e,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Run Semgrep (community security rules) and Bandit on a mixed Python/Node codebase to detect command injection, unsafe YAML loading, path traversal, and insecure temp-file/cookie settings. Fix the findings with minimal behavioral change, add a pre-commit and CI configuration that fails on reintroduction, and emit a before/after SARIF or JSON report to /app/output/findings.json.",,
763f4792-a1a0-4c76-bab9-b1a3b96f4073,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Build a correlation-driven incident responder that tails auth and web access logs to detect account takeover patterns (failed logins from IP A, success from IP B, then privileged action within 5 minutes) and, upon detection, automatically disables the user, revokes sessions, writes a firewall block, and emits both JSON and human-readable alerts with a timeline. Provide an executable CLI to replay logs from files for testing and a stateful deduplication mechanism with auto-expiry of blocks.",,
1062e2e8-c6e1-4a51-a7d8-ac019906efe0,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Build a lightweight fail2ban-style responder that tails a custom service log, detects credential-stuffing/401-flood patterns via a regex filter, and posts JSON alerts to a local webhook endpoint. On threshold breach, automatically quarantine offending IPs by appending to a persistent blocklist enforced by a provided mock-firewall script, with tests that simulate attacks and benign traffic to verify correct alerting and no false positives.",,
145d94fb-d48d-4515-afe1-9cdb02448ecd,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Configure auditd to log reads of files under /app/secrets and any subsequent outbound network connection by the same PID, then build a responder that correlates events within 10 seconds, quarantines the executable and blocks its egress via nftables. The responder must also POST a JSON alert to a local webhook and write a detailed incident record to /app/incidents/incident-*.json.",,
cf9c70d5-b1e3-43d4-b6db-c4ce5c042e53,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Create a Bash script that imports provided GPG public keys and verifies detached .sig signatures for all .tar.gz release archives in /app/releases; do not modify input files. The script must produce /app/report.json listing each archive, signer key ID, and verification status.",,
d4e485c0-18cc-4b82-9b96-20601c0bf5a4,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Implement a real-time incident responder that tails auth and HTTP logs, loads YAML rule files defining thresholds over sliding windows, and on matches emits HMAC-signed JSON alerts while executing mapped actions (append IP with TTL to /app/blocked_ips, lock a user, or disable a service) and producing a triage bundle with relevant logs, process tree, and socket info. Validation simulates brute-force SSH and repeated 403s, expecting alert files in /app/alerts, auto-expiring IP entries, and timestamped incident report directories with captured evidence.",,
77e47780-d4ca-4d75-87c3-b23b6dbd341b,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Enable persistent journald storage and configure auditd rules to log all execve by uid 0, any chmod that adds setuid/setgid bits, and writes under /app/secure. Validate by triggering events and generate /app/audit_report.json summarizing counts and the latest five matching events from both audit logs and the journal.",,
28d7b1b8-89d6-4c9a-9ea1-7b39559c85a4,Security & Cryptography,Security Monitoring & Compliance,Security Policy Compliance,"Build a lightweight compliance tool that gathers Linux system facts to JSON and evaluates them with OPA/Rego policies implementing a subset of CIS Linux controls, emitting both JUnit XML and a human-readable report in /app/report. Provide idempotent remediation scripts for failing checks (e.g., SSH root login, file permissions, password aging), re-run to reach at least 90% passing, and archive before/after evidence.",,
b641a1c2-b0b4-4d38-9ee7-6ab6f26cb9e1,Security & Cryptography,Security Monitoring & Compliance,Security Policy Compliance,"Build a terminal-based compliance scanner/remediator that evaluates a Debian/Ubuntu image against a small set of CIS Level 1 controls (SSH configuration, password/PAM policy, world-writable files, and root PATH safety), emitting a deterministic JSON report to /app/output/report.json. When invoked with --fix, apply compliant changes idempotently and record a rollback plan at /app/output/rollback.sh.",,
6559562d-fcf2-4337-a721-2fb722c27aff,Security & Cryptography,Security Monitoring & Compliance,Security Policy Compliance,"Implement a Python CLI that validates a minimal CIS Ubuntu Server baseline by auditing password/PAM policy, SSH hardening, key sysctl settings, and world-writable permissions, emitting a structured JSON pass/fail report with remediation guidance. Provide an idempotent --fix mode that backs up affected files and applies compliant configurations where safe.",,
2e0d446c-69ce-4aa2-871d-f0051d10163a,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Build a CLI that generates an SBOM for a local project, scans it with Trivy and Grype in offline mode, de-duplicates CVEs, and emits both SARIF and an HTML dashboard. Enforce a YAML-defined policy to suppress known issues and fail on configurable severity thresholds, including recommended fixed versions and dependency paths in the report.",,
c2f1ae62-28b4-4de8-af7d-194d69aa2e7f,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Create a CLI that scans a provided Docker image and its source tree with both Trivy and Grype, merges and deduplicates CVE findings, and emits SARIF plus a concise markdown summary with severity counts and fix-available mapping before/after remediation. Update the Dockerfile and dependency manifests with minimal pinned upgrades to reduce all Critical findings with fixes to zero, then prove compliance by rescanning and writing pass to /app/gate.status.",,
aaa14846-297a-459a-b5f0-115f3ab4a6ed,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Scan a provided Docker image with Trivy, output a CycloneDX SBOM (/app/report/sbom.json) and SARIF findings (/app/report/trivy.sarif), then refactor the Dockerfile and dependency pins to remediate all HIGH/CRITICAL vulnerabilities. Add a .trivyignore entry for a documented vendor-backported CVE, rebuild and rescan to verify zero remaining HIGH/CRITICAL except the ignored CVE, and write a concise remediation summary to /app/report/summary.txt.",,
f7a50c70-11ae-4c1d-af71-f839e0b2643b,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Scan a provided container image and its running service with Trivy and nmap to generate a consolidated SARIF report, then refactor the Dockerfile and service configuration to remediate all Critical findings and close an inadvertently exposed admin port. Rebuild and re-scan to verify the report shows zero Critical/High CVEs and the admin port is unreachable, saving before/after reports in /app/reports.",,
2a30d8c7-9b9a-416a-acd9-27da92ea136d,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Scan the provided container image tarball at /app/images/webapp.tar using Trivy, output a SARIF report and a CSV listing only fixable High/Critical CVEs sorted by CVSS. Then create /app/output/Dockerfile.patched that updates the base image and pinned packages to remediate all fixable findings without altering the container’s entrypoint or command.",,
4da51148-a061-461a-89ea-0921ce321aff,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,Exploit JWT algorithm confusion in a Node.js API that mistakenly accepts HS256 for tokens intended to be RS256 by using the server’s public key as the HMAC secret to forge an admin token and retrieve the admin-only secret to /app/secret.txt. Then harden the authentication middleware to strictly enforce RS256 with the correct key material while preserving normal login behavior.,,
eb515b21-ef14-4ad8-adc9-43ba015b234c,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Investigate a C logging daemon with a format-string vulnerability in printf that allows leaking stack memory; craft an input to extract FLAG{...} and write it to /app/flag.txt, then patch the code to use fixed format strings and recompile, confirming normal logging still works.",,
bc87444d-dab7-49eb-a019-9fbbf0ad30d8,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,Reproduce an XML External Entity (XXE) vulnerability in a service that parses uploaded XML files by crafting a payload to read /app/flag.txt and save the contents to /app/leak.txt. Then harden the XML parser to disable external entities and DTDs while preserving normal document handling.,,
0da3ceb9-2cac-46a2-b94b-7035a19b62d0,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Reproduce an unsafe deserialization flaw in a Python CLI that loads untrusted YAML using yaml.load by crafting a payload that triggers benign code execution (e.g., creating /app/pwned.txt). Then harden the program to use a safe loader while preserving valid configuration behavior and verify the exploit is no longer effective.",,
e23d2050-acf5-406b-a8a2-f9e64041513d,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Reproduce and mitigate a ZIP Slip directory traversal in a Python CLI that naively extracts user-submitted archives. Craft a malicious ZIP to write a marker file outside the intended directory, then patch the extractor to sanitize paths so extraction is safe and idempotent.",,
a2e732c9-2e61-4508-83dc-87be734a51a8,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Analyze a custom C-based CLI notes service with a heap use-after-free bug and develop a minimal exploit that achieves arbitrary read to extract a secret from /app/secret.bin without crashing the process. Then implement and rebuild a hardening patch (e.g., pointer invalidation and allocator checks) that eliminates the bug while preserving normal functionality.",,
c751a392-d64b-4a03-a69e-24e76e7512a9,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Analyze a hardened 64-bit ELF service to locate a format-string vulnerability, then craft a multi-stage exploit that leaks stack/libc addresses and overwrites a GOT entry to redirect execution to a hidden print_secret() routine. Write the recovered secret to /app/flag.txt after successful exploitation.",,
e90ee934-c464-4a44-9bb6-545ff7cfe949,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Develop a PoC exploit against a sandboxed 64-bit Linux ELF service with a format-string bug in its logging path: leak the stack canary and libc base, then craft a ret2libc/ROP payload that creates three marker files to prove control. Provide an automated script that launches the target, derives offsets under ASLR with NX enabled, delivers the exploit reliably, and verifies the markers.",,
a8a0db0d-136b-47fd-8c1a-36e14e1125ad,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,Develop a Python exploit that performs a CBC padding oracle attack against a provided local HTTP service to recover the plaintext of an encrypted session token and forge a valid admin token to access a protected endpoint. Include a concise analysis of the oracle behavior and implement a mitigation that removes the side-channel while preserving normal application behavior.,,
7dd8a1bf-142d-4d5e-9e85-a49d0abdb560,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,Develop a proof-of-concept that exploits JWT algorithm confusion in a local API by re-signing an RS256 token as HS256 using the service’s RSA public key to forge an admin token and trigger a privileged action that writes /app/pwned.txt. Add brief inline analysis of the root cause and mitigations (algorithm whitelisting and key-type separation).,,
efb21ec2-5c91-49a9-836d-13923f0ffb40,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Build a deliberately vulnerable C binary with a stack buffer overflow, exploit it to achieve code execution on an unprotected build, then rebuild with hardening (ASLR, NX, stack canaries, PIE, full RELRO) enabled. Programmatically verify mitigations via ELF inspection and /proc/sys checks, rerun the exploit to confirm it fails, and output a concise pass/fail report.",,
6e59d5e9-e36a-49eb-bd5e-fcf9a9da2bf5,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Build a deliberately vulnerable C service and an automated harness that compiles it twice (unhardened vs hardened with stack canaries, NX, PIE, full RELRO, and FORTIFY), verifies each mitigation via readelf/sysctl, and runs a supplied overflow input. The report must show the exploit succeeds only on the unhardened build while the hardened build safely aborts, failing the task if any mitigation is missing or ineffective.",,
bb605da8-915c-45c0-a87f-8ff6a0fd214b,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Compile and run a vulnerable C program that attempts to execute stack-injected shellcode and a companion probe that records memory addresses across multiple executions. Verify NX and ASLR are effective by confirming the shellcode attempt crashes without code execution and that address layouts vary significantly across ≥20 runs, then output a machine-readable mitigation_report.json in /app.",,
c105b818-9298-4be3-82ea-09c19551172a,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Create an automated harness that compiles a deliberately vulnerable C program under four builds (no mitigations, stack canary, NX/DEP, PIE+ASLR), runs a provided overflow exploit, and verifies exploitation only succeeds when the relevant mitigations are absent. The script must also assert mitigation presence via binary introspection (e.g., readelf/objdump symbols, GNU_STACK, PIE) and system checks (/proc/sys/kernel/randomize_va_space), outputting a machine-readable report of flags detected and exploit outcomes.",,
36d53948-c89c-449c-92b1-f05be8b05e69,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Rebuild a provided overflow-vulnerable C service with hardening (stack canaries, PIE, full RELRO, NX) and enable ASLR, then verify each mitigation via ELF/Procfs inspection. Demonstrate that the supplied working exploit succeeds pre-harden and reliably fails post-harden, recording evidence to a verification file.",,
fb85ef30-1718-47eb-8b86-07215221b28a,Security & Cryptography,Vulnerability Demonstration & Exploitation,Privilege Escalation Demonstrations,"Starting as an unprivileged user, exploit a sudoers misconfiguration that permits passwordless tar to escalate via --checkpoint-action=exec (or crafted wildcard injection), then prove root by creating /root/owned.txt. Mitigate by tightening the sudoers rule to a safe, argument-pinned form so the exploit is no longer possible.",,
d653cf93-071c-4be6-bfb5-8b89a0f6d006,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Create a Python daemon that continuously tails a mock authentication log in /app/var/log/auth.log, detects patterns of repeated failed SSH logins, queries a provided IP reputation REST API, updates a simulated firewall rule file (/app/firewall.rules) to block flagged IPs, and sends alert emails via a fake SMTP server.",,
f760a0e9-ef6d-40d3-9105-cc8ac0f00aeb,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Create a Bash-based incident response tool that watches /var/log/auth.log for SSH authentication failures and aggregates events to detect brute-force attacks, then automatically blocks offending IPs via iptables. The tool must send formatted alerts to a configured Slack webhook and log each incident as a JSON entry in /app/incidents.json with timestamp, source IP, and action taken.",,
3580fee5-9554-4d5f-bdfe-657bd5223b96,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Configure auditd with rules to log modifications to /etc/passwd, user login/logout and Docker exec events, and set up rsyslog to forward these logs securely to a remote server. Run the supplied event generator and verify correct entries were logged and forwarded, outputting a JSON summary of event types and counts.",,
a1074c0f-bdf5-4827-9845-83eb74f78f01,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Write an idempotent Bash script that configures auditd to log all file access events under /etc, sets up daily rotation for /var/log/audit/audit.log, and enables rsyslog forwarding of audit logs to localhost:514/udp. Simulate an /etc/passwd modification and verify the resulting audit event appears on the remote log endpoint.",,
e00b0e8c-712a-4c3b-8720-3ac981f6bea4,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Create an idempotent Bash script to configure auditd with rules for user authentication events, file changes in /etc, and network socket creations, forwarding logs in JSON format over TCP to a local syslog server. Include a test harness that simulates representative events, captures the forwarded logs, and verifies they conform to the expected schema and content.",,
448955fd-ff07-40f4-81ab-363054d8f1aa,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Automate the configuration of auditd to capture execve, file access, and user authentication events, then set up rsyslog to forward these logs over TLS to a remote SIEM endpoint. Generate sample events to validate end-to-end delivery and integrity by querying the centralized log store for the injected entries.",,
ba5299cf-04e5-46cf-9f61-d80430e402e3,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Cipher Cracking & Weak Encryption Analysis,"Develop a Python script that performs differential cryptanalysis on a toy 4-round SPN cipher using provided plaintext–ciphertext pairs, recovers the 32-bit master key, and writes the key in hex to /app/output/key.txt.",,
f4813cd1-5f05-4f6e-a1f3-05fa1c21862c,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Cipher Cracking & Weak Encryption Analysis,"Create a terminal tool that cracks an interleaved dual‐key Vigenère cipher by splitting the ciphertext into two alternating streams, detecting each key length via Kasiski examination, and recovering both repeating keys with frequency analysis. The tool should then reassemble and output the fully decrypted plaintext to stdout.",,
c4ad31f6-602c-4b5f-b293-97d369e162ba,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Cipher Cracking & Weak Encryption Analysis,"Implement a Python CLI tool that recovers text encrypted by an unknown monoalphabetic substitution cipher through simulated annealing over English quadgram fitness, writing the decrypted plaintext to /app/plain.txt and the recovered key mapping as JSON to /app/key_map.json.",,
c349ab5d-a4ca-4f3b-bb0b-e4c8c1abcaae,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Cipher Cracking & Weak Encryption Analysis,"Design a script that automatically recovers the 5×5 Playfair cipher key from /app/ciphertext.txt using a hill-climbing or simulated-annealing search guided by English n-gram fitness scoring, then decrypts the ciphertext and writes the plaintext to /app/plaintext.txt.",,
c21686b6-7a6b-4c4b-b1b8-e9101996b0c9,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Provide a precompiled C binary with a format string vulnerability in its untrusted printf call and write an automated exploit script that first leaks stack data, then uses the %n specifier to overwrite a GOT entry to invoke system('/bin/sh'), finally reading the flag from /app/flag.txt and writing it to /app/output/flag.txt.",,
20f16c8b-67e4-49ee-8a1d-e50219735343,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Provide a C source for a small application that naively calls printf on user input without a format string and includes a hidden get_flag() function. The agent must compile the binary, craft a format-string payload to leak a stack guard value and then overwrite the return address to invoke get_flag(), writing the recovered flag to /app/flag.txt.",,
98b283da-f4f5-46d2-8b7b-cb0b24f2c6b5,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Provide a C binary with an unsafe printf() call allowing a format-string vulnerability; write a pwntools exploit to leak a libc address, compute libc base, overwrite the GOT entry of exit() with system(), trigger a shell, and write /app/flag.txt contents to /app/pwned.txt.",,
c5968513-3fec-4d40-aba6-b5b07dfeca7a,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Create a Bash tool that ingests a Docker Compose file and emits a hardened override by applying resource constraints, dropping all Linux capabilities, enforcing seccomp and AppArmor profiles, non-root user namespaces, and read-only service filesystems. Finally, run Docker Bench for Security and output the CIS compliance results as JSON to /app/compliance.json.",,
db71c68d-a6e8-468d-9f31-10bd48ef9b11,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Develop a CLI tool that parses a docker-compose.yml to identify insecure service settings (privileged mode, broad volumes, unrestrained capabilities). The tool should auto-generate a hardened override file enforcing user namespaces, read-only filesystems, dropped capabilities and default-deny seccomp, merge and validate the final configuration, and emit a detailed JSON compliance report.",,
7c5d6477-cfd6-43d9-a13e-c136b5c5460a,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Write an idempotent Bash script that hardens the Docker daemon by updating /etc/docker/daemon.json to enable user namespace remapping, set default read-only root filesystem, drop all capabilities except NET_BIND_SERVICE, and enforce seccomp and log rotation policies. The script must restart Docker, launch a test container to verify each setting, and generate a JSON compliance report.",,
8d1a4a32-1024-4878-9571-f8a460898b47,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Develop a CLI utility that audits Kubernetes manifests for insecure PodSecurity configurations—such as containers running as root, missing resource limits, or unbounded hostPath volumes—and produces a hardened YAML with enforced securityContext settings, generated NetworkPolicy templates, and admission annotations, then validates compliance via kubectl dry-run and kubeval.",,
961fb930-7159-4fe2-ac88-d4210ceb8120,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Implement a Python tool that computes RFC 6979 deterministic ECDSA signatures over secp256k1 for each message in /app/messages.txt using the provided private key, writes DER-encoded signatures to /app/signatures.txt, then verifies each signature with the corresponding public key and outputs pass/fail results to /app/verify_results.txt.",,
5b7d7119-d9c0-447b-957a-2462ee003eb0,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Create a Python script that reads two ECDSA signatures on different messages that share the same nonce from /app/data/signatures.json, exploits the nonce reuse to recover the secp256k1 private key, and writes it as PEM to /app/output/private_key.pem. Then verify the provided test signature on /app/data/test_message.txt and output the boolean result to /app/output/verification.txt.",,
9382a7d4-1abf-4834-a8dc-0b903eaf7515,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Create a Python script that performs RSA blind signatures: it should blind each message in /app/messages.txt using the provided public key, call /app/signer.py to obtain blind signatures, unblind them, and verify the signatures against the original messages. Finally, output valid and invalid message lists to /app/results/valid.txt and /app/results/invalid.txt.",,
877c78c8-3af8-4c57-80f9-23ff4d1623df,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Create a Python script that reads an encrypted file containing a 32-byte X25519 ephemeral public key, a 12-byte ChaCha20-Poly1305 nonce, ciphertext, and 16-byte tag. It must derive the shared key using a provided X25519 private key, decrypt and authenticate the payload, handle errors on tampering or I/O, and write the plaintext to /app/plain.txt.",,
be064583-f843-4455-bc7f-0a09e87078cc,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Implement a Python CLI tool for hybrid RSA-OAEPad RSA-OAEP and AES-256-GCM file encryption that takes an input file and an RSA public key, generates a random AES key and IV, encrypts the file with AES-GCM, wraps the AES key with the public key, and outputs a single binary containing the RSA-ciphertext key, IV, tag, and encrypted data. It must also decrypt such bundles with the corresponding RSA private key, verify the GCM tag, and restore the exact original file to a specified path without any extra bytes or metadata.",,
afacca99-c31d-4029-8f06-533994ca632d,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Develop a proof-of-concept exploit for the provided 64-bit Linux ELF binary (with NX, PIE, and stack canary enabled) by first leaking a libc address via a format string bug and then building a ROP chain to spawn a shell. Write the exploit in Python using pwntools to connect to localhost:9001 and output a confirmation token upon success.",,
399c3f23-0d3b-4a25-8ecc-105488b63bc4,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Develop a Python pwntools exploit for a remote TCP service with a format-string vulnerability that lets you leak the stack canary and libc base, then craft a ROP chain to spawn a shell, read /app/flag.txt, and write its contents to /app/pwned.txt.",,
1da7e444-54c5-4267-82dc-3256d0ab821a,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,Craft a Python proof-of-concept exploit that abuses an algorithm confusion vulnerability in a provided JWT-based authentication service—forge an admin token by switching the algorithm to “none” and use it to retrieve the protected flag via HTTP requests.,,
6da46b90-93c1-4847-ae0c-90f0d254803f,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Develop a Python exploit script using pwntools to attack a 64-bit ELF binary with NX, PIE, and stack canary. The script must leak the canary and libc address via a format string, build a ROP chain via ret2csu to call system('/bin/sh'), and capture the flag, writing it to /app/output/flag.txt.",,
ea5a8641-894e-4d48-82c0-c224c5c66103,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Implement a non-interactive Bash script that scans /usr/local/bin for SUID and SGID executables, verifies each file’s SHA256 checksum against a provided whitelist manifest, and reports any mismatches in JSON format. The script must automatically strip unauthorized SUID/SGID bits and restore tampered binaries from a trusted reference directory under /app/reference.",,
6f9d0379-f709-4eab-a643-75abb2e2e92b,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Implement a Python CLI that loads /app/manifest.json containing file paths, expected SHA-256 hashes, and an HMAC-SHA256 signature, verifies the manifest’s authenticity using the key in /app/key.txt, then computes each /app/data/* file’s SHA-256 and compares it to the manifest. Produce /app/integrity_report.json summarizing verified, missing, modified, and unexpected files.",,
07e32fe4-796a-4483-a10f-d9c9625900bb,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Implement a tool that builds a SHA-256 Merkle tree over all files in /app/data, outputs the root hash and JSON-formatted inclusion proofs for specified files, and verifies those proofs against the stored root to detect tampering.",,
894abdcb-2690-4777-95fc-3c8c93159fb8,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Create a tool that chunks files under /app/data into fixed-size blocks, computes SHA-256 hashes for each block, and assembles a Merkle tree in a JSON manifest with leaf and internal node hashes. Provide a verification mode that loads the manifest and reports any mismatches, missing files, or tampering.",,
0441ca00-4c3f-4066-88a8-e8ab7439bbd8,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Create a Bash or Python script that recursively scans a target directory and splits any file larger than 1 MiB into fixed-size blocks, computing SHA-256 for each block and recording offsets and hashes in a manifest. Provide a verify mode that reads the manifest, recomputes block hashes in the directory, and reports any missing or corrupted blocks per file.",,
f7562c37-3310-4f8e-9324-47a8c01d5922,Security & Cryptography,Secure Software Development,Input Validation & Sanitization,"Given a vulnerable C HTTP server that builds SQL queries and file paths directly from user input, patch the code to implement prepared SQLite statements, whitelist allowed file paths, and add robust bounds checking on all buffers. Ensure the modified server compiles without warnings and passes provided tests for SQL injection and directory traversal prevention.",,
03ee2c89-29b3-482b-a8db-bed18f0d8726,Security & Cryptography,Secure Software Development,Input Validation & Sanitization,"Enhance the provided Node.js Express application by integrating a schema-driven validator to enforce strict type checks, length limits, and disallow prototype-polluting keys on all JSON bodies and query parameters. Supply a suite of malicious and edge-case payload tests verifying that the server rejects or sanitizes inputs correctly without any injection or object overwrite vulnerabilities, and outputs consistent error responses.",,
f8a746e3-8d21-4867-a511-bd10949ec0f0,Security & Cryptography,Secure Software Development,Input Validation & Sanitization,"Patch a Python CSV-processing script that currently builds and executes shell commands from untrusted fields: enforce row-level schema validation with jsonschema, sanitize each cell against injection patterns, apply shlex.quote when spawning subprocesses, and include tests demonstrating rejected malicious rows and correct handling of valid data.",,
9ab3ceed-9364-439a-8e96-5d9e4c648310,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Build a Bash script that bootstraps a three-tier PKI (root CA, intermediate CA, server certificates) using OpenSSL, issues and signs CSRs for a list of hostnames from a YAML file, generates a CRL and OCSP responder, and rotates the intermediate CA and all leaf certificates on demand. Include tests that validate the full certificate chain, CRL and OCSP stapling responses with openssl commands.",,
2a2696b1-b07b-4f38-b094-beae3ff5e52d,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Develop a Bash script that uses OpenSSL to create a root CA and intermediate CA, issue and sign TLS certificates for specified hostnames, revoke a chosen certificate by updating a CRL, and verify certificate chains and revocation status. All keys, certs, CRLs, and verification reports must be organized under /app/pki.",,
bad6c4fa-970a-4cb3-9cf3-06eabe2389cf,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Develop a CLI tool that generates an RSA key pair, uses Shamir’s Secret Sharing to split the private key into N shares with a threshold of M, then reconstructs and verifies the key from provided shares. Store the original keys, all shares, the reconstructed key, and a verification log under /app.",,
075f5c82-1e7b-4330-a299-83d895cb9e43,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Develop a script that consolidates and normalizes auth, syslog, and firewall logs, detects SSH brute-force patterns (e.g., ≥5 failed login attempts within 10 minutes) followed by a successful access, then extracts subsequent shell commands and outbound connections, outputting a structured incident timeline and summary of suspicious activity.",,
adf238ec-d78c-4b35-965b-9ee722353ac2,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Build a Python tool that ingests SSH auth logs, sudo logs, and network flow records to detect suspicious command executions followed by unauthorized outbound connections (potential reverse shells). The tool must correlate events across logs by PID and timestamp and generate a JSON incident report including suspect commands, destination IPs, and a severity score.",,
a040d085-ad26-45c8-9407-041bd8303fd0,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Instrument the provided Linux ELF sample under strace to capture file, network, and process syscalls, then reverse-engineer its custom XOR-based C2 protocol by decoding network payloads to extract hardcoded command domains and decrypted beacon messages; output the domains to /app/c2_domains.txt and beacons to /app/beacons.json.",,
4e68152e-0132-421b-99b1-4231ebd4a8c8,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Create a Bash script that executes the provided ELF malware sample under strace and tcpdump in a Docker sandbox to capture all filesystem operations, network connections, and spawned processes. Parse the resulting strace logs and pcap file to produce a JSON timeline of suspicious syscalls, extracted C2 domains, and created or modified file artifacts at /app/report.json.",,
914350d5-c981-405b-92d4-a1e56290c556,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Create a script that takes a Linux ELF malware sample, unpacks it if packed (e.g., UPX), performs static analysis (objdump or readelf) to list imported functions and strings, then runs the binary in a sandbox under strace to capture file, process, and network syscalls. Correlate static and dynamic findings to identify suspicious behavior—such as dropped files, execve calls, and outbound connections—and output a structured JSON report summarizing these indicators.",,
1d0db37f-dbf3-42ff-bf8d-cb8226658acc,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Analyze a Linux ELF malware sample embedding XOR-obfuscated strings: statically extract the XOR key and deobfuscate to reveal C2 domains and commands. Then dynamically execute it under strace in a sandbox to capture its filesystem modifications and network connections, and output a JSON report summarizing all artifacts.",,
5e756f11-1507-4077-b39d-a17f265482bd,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Create a shell script that installs and configures libpam-google-authenticator for a designated user, updates the SSH PAM configuration to require both a static password and a TOTP code, and generates a provisioning URI plus ASCII QR code in the output directory. Then use pamtester (or expect) with a generated valid one-time password to simulate and verify an SSH login, producing a JSON summary with the provisioning URI, test credentials, and authentication result.",,
97762c20-6153-4cfb-a09b-5b210a3aa2a7,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Create a Python CLI tool that implements the OAuth 2.0 Device Authorization Grant against the supplied mock server: fetch and display device/user codes, poll the token endpoint with exponential backoff, handle approval, denial and expiration, securely persist access and refresh tokens, and finally fetch a protected resource, writing the result to /app/output.json.",,
60852d76-d0ac-4913-ae8d-cc57c23f8928,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Implement a mock OAuth2 authorization and resource server in Docker, then write commands to register a PKCE client, perform the authorization flow to obtain and refresh a JWT access token, and call a protected endpoint. Save the final greeting JSON response to /app/output.json.",,
e695714d-e0bf-4a41-a8a2-b80c930f004a,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Implement a port-knocking scheme using iptables to conceal the SSH service behind a sequence of three TCP knock ports. Upon a correct knock sequence from a client IP, dynamically open port 22 for 60 seconds and log all knock attempts and SSH connections.",,
b2a477a8-449f-4610-9d59-39765c5bbad8,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Password Hash Cracking,"Design a script that reads /app/data/users.json containing usernames and scrypt-based salted hashes, then fetches the application pepper from /app/secret/pepper.txt and reformats entries for hashcat. Use the provided wordlist to perform a dictionary attack and output a CSV of cracked username:plaintext pairs to /app/output/cracked.csv.",,
8a2bef2e-ab62-496f-ab58-da564cda2e54,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Password Hash Cracking,"Implement a Python utility that parses a mock /app/shadow file containing salted SHA-512 Linux password hashes, extracts salts and hashes, and then uses a provided wordlist plus simple leetspeak mangling rules (e.g. a→@, e→3) and a fallback numeric-suffix brute-force (2–4 digits) to recover plaintexts. Leverage multiprocessing to speed up cracking and output a JSON mapping of username to password at /app/cracked.json.",,
b408bce6-0648-490e-9161-b69a2a749f1b,Security & Cryptography,Authentication & Access Control,Password Management & Hashing,"Implement a Python CLI that reads /app/users.csv (username,password), uses a global pepper from /app/pepper.txt and Argon2id (time=3,memory=64MB,parallelism=2) to salt and hash each password into encoded strings, then writes a JSON array of {username,hash} to /app/passwords.json and provides a ‘verify’ subcommand to authenticate a given username:password against the stored hashes, printing success or failure.",,
210d1b16-4d73-46b2-bfb1-60d89d748be4,Security & Cryptography,Authentication & Access Control,Password Management & Hashing,"Create a shell-based migration utility that converts legacy SHA-1 or MD5 password hashes in a provided shadow-style file to Argon2id with per-user random salts and configurable parameters, writing the updated shadow file and verifying each hash upgrade by simulating user authentication using a provided password list. The script must preserve user metadata, handle unsupported hash formats, and produce a structured JSON report detailing migration successes, failures, and performance metrics.",,
c19c6a09-27d4-4548-9916-a2f3631b3fa7,Security & Cryptography,Authentication & Access Control,Password Management & Hashing,"Develop a Python script that audits a JSON-based user store of salted PBKDF2-HMAC-SHA256 hashes against a given wordlist to identify weak credentials, then rehashes all passwords with Argon2id using configured parameters. Output the updated user JSON with new hashes and a migration report listing flagged weak passwords, old vs new iteration counts, and salt reuse checks.",,
f673ebbd-246e-4127-ba57-0d88e041b20d,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Develop a Bash test harness that compiles a supplied buffer-overflow vulnerable C program under varying hardening options (RELRO, PIE, NX, stack canaries) and automatically runs a provided exploit against each binary to detect success or failure. The script should produce a concise report mapping each mitigation flag combination to exploitation outcome (prevented or not).",,
6171b9c6-3bfa-4a7c-a36c-65e5e73ec713,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Implement an idempotent Bash script that compiles a provided x86-64 ELF vulnerable to GOT overwrite twice—once unprotected and once with full RELRO and immediate binding—automatically runs the original exploit against both binaries, and writes a JSON report to /app/mitigation_results.json indicating which version is exploitable.",,
51dec548-d8de-4a73-960e-5ceb57d6933d,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Write a shell script that inspects a provided ELF binary using readelf and objdump to verify that NX, PIE, full RELRO, and stack canaries are enabled, and checks /proc/sys/kernel/randomize_va_space for ASLR status as well as retpoline mitigations in dmesg. The script must output a JSON summary of each mitigation and attempt a sample return-to-libc exploit against a supplied vulnerable binary to confirm the patches prevent exploitation.",,
8767ce3a-1733-4af2-9140-d31df2c1d9f6,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,"Implement a two-stage Python tool that mass-scans a given IPv4 /24 network for specified TCP ports using masscan with bandwidth constraints, then asynchronously banner-grabs detected open ports with Python sockets to identify service names and versions. The tool should infer operating system based on banner fingerprints and output a consolidated JSON inventory of host, port, service, version, and OS guess.",,
9bd5a85f-cf0d-4a66-8cfb-4c4f0f5f3ff6,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,"Create a Bash script that reads CIDR ranges from /app/targets.txt and runs masscan at a user-defined rate to scan the top 500 TCP ports, then parses JSON output to launch nmap service/version scans with default NSE vulnerability scripts. Aggregate all findings into /app/scan_results.json and cross-reference discovered service versions against a provided /app/cve_db.json to generate /app/vulnerability_report.csv listing host, port, service, version, and matched CVEs.",,
5d87ce3d-b88c-46a3-9b14-de35c4827db4,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Create a Python script that enumerates post-exploit persistence artifacts on a compromised Linux host—scanning systemd services and timers, system and user cron/at jobs, login/profile scripts, and loaded kernel modules—and generates /app/persistence_report.json with metadata (artifact path, type, schedule/trigger, owner) and mitigation recommendations. The script must then safely disable or remove each identified entry idempotently and log all actions to /app/persistence_audit.log.",,
6571ffc6-83d0-4361-9290-9d42c69aa440,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Identify all persistence mechanisms—including hidden cron jobs, tampered systemd unit files, and malicious PAM modules—in the provided compromised Linux sandbox, disable them, and regain a clean shell. Produce a markdown report listing each discovered artifact with its filesystem path, the commands used to neutralize it, and recommended remediation steps.",,
de8fa07d-73bb-4650-90b8-ddf4f297cad0,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Design an idempotent Bash script that scans a Linux sandbox for seeded post-exploitation artifacts—malicious cron jobs, hidden systemd unit files, rc.local tweaks, and unauthorized SSH authorized_keys entries—and outputs a structured JSON report at /app/persistence_report.json listing each artifact’s type, path, and SHA256 hash. The script must only read from /app_target or container root and must not alter any system files.",,
36463b63-c17d-437b-acfc-62c2fd1f5cf4,Security & Cryptography,Vulnerability Demonstration & Exploitation,Privilege Escalation Demonstrations,"Simulate a misconfigured SUID C binary in /app/vuln/bin with a world-writable home directory; craft and compile an LD_PRELOAD shared library to hook execve and spawn a root shell, then read /root/flag.txt and write its contents to /app/pwned.txt.",,
e6f342bf-6ff5-42c3-b73b-ec36097d1486,Security & Cryptography,Vulnerability Demonstration & Exploitation,Privilege Escalation Demonstrations,"Locate a world-writable root cron job script in /etc/cron.d, inject a malicious payload to escalate privileges, and extract the contents of /root/flag.txt. Your exploit should automate modifying the cron script, triggering its execution, and saving the recovered flag to /app/output/flag.txt.",,
ff6434e6-7e18-46cb-b5c6-8d0d09faea31,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,"Develop a Bash script that exploits an insecure root cron job writing logs to a world-writable /tmp path by atomically creating a symlink to overwrite /usr/local/bin/pwn with a root shell payload, then triggers the cron execution and runs the planted script to capture /root/flag.txt into /app/flag.txt.",,
4d86b51a-9dbe-4f6a-b564-b96e3eb2d7f3,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,"Simulate a scenario with a root-owned cron job executing scripts in /app/cron.hourly, where that directory is writable by the user; exploit this misconfiguration by injecting a malicious shell script to obtain root privileges and write the flag to /app/flag.txt.",,
01bb3e61-4fe4-4fa6-9066-a05742744550,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,Provision a Docker sandbox with a misconfigured sudoers rule allowing passwordless execution of a root-owned backup script that uses an insecure TMPDIR and unvalidated PATH. Exploit these flaws to escalate privileges to root and read /root/root.txt.,,
2c756166-4aa1-4d49-b153-1598ecdd2a6c,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,A sandboxed Linux host includes a misconfigured systemd service that executes a binary from a user-writable directory. Exploit this weakness to escalate to root and write the contents of /root/flag.txt to /app/output/flag.txt.,,
d59d885f-de9c-4fd9-a57d-79e0b83c082c,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Protocol Analysis & Exploit Detection,"Create a Python script that parses a provided PCAP of SMTP traffic, identifies STARTTLS handshakes, extracts and inspects server X.509 certificates for expired, self-signed, or weak-signature issues, and outputs a CSV report of host/port and detected vulnerabilities.",,
bd4529e2-61e6-4b6c-8f99-a01a151f2e8b,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Protocol Analysis & Exploit Detection,"Implement a script that parses a provided PCAP of TLS traffic using tshark or Scapy to detect SSLv3 handshake downgrades and weak cipher suites (e.g., RC4, 3DES). Output a JSON report enumerating vulnerable session IDs, the specific issues detected, and recommended mitigations.",,
1751cafb-fb06-4fe7-ab88-93acc57cfc4e,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Develop a Go CLI tool that collects entropy from at least three distinct system sources (e.g., rdtsc jitter, disk I/O latency, and /dev/urandom), mixes them via a SHA-512–based entropy pool, seeds an HMAC-DRBG per NIST SP800-90A, and writes 4096 bytes of random data to /app/random.bin. It must also produce a JSON report estimating the min-entropy contributed by each source.",,
b9a945bf-89ff-4f1f-aaa8-11f277de8fdd,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Implement a user-space entropy collector in Python that samples high-resolution timestamp jitter and per-CPU interrupt counters, pools and whitens the bits via a SHA-512 based extractor, then uses HKDF to expand the seed into a ChaCha20 keystream of N bytes. The script must accept a byte length argument, emit hex-encoded output, and pass a reference SHA-256 hash check on a fixed test vector.",,
fa9599a0-c8a1-4807-9f3f-238164efdc39,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,"Reverse-engineer a stripped ELF binary embedding a custom stack-based virtual machine and encrypted flag; recover the VM instruction set by static disassembly, implement an emulator to execute its bytecode, and output the decrypted flag.",,
fc556376-0ba5-41ae-9b11-84e9cec9978f,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,"Analyze the provided stripped 64-bit ELF executable to reverse its custom stream cipher: determine the key-scheduling algorithm from disassembly, implement the identical cipher in a Python script to decrypt the appended ciphertext blob, and recover the hidden flag.",,
a16c94b0-29ec-4868-979b-48e84b2df8a4,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,"Reverse engineer the provided stripped x86_64 ELF binary, which employs simple anti‐debugging and a custom XOR encryption routine, to locate and decrypt the embedded secret key. Extract the recovered key and write it to /app/secret.txt without modifying the original executable.",,
8c14c34a-0417-406f-b358-9c4bbe8d01e5,Security & Cryptography,Authentication & Access Control,Role-Based & Policy Enforcement,"Create a tool that reads a JSON mapping of Unix user groups to allowed systemctl service operations (start, stop, restart) and generates corresponding polkit rule files in /etc/polkit-1/rules.d/. Then run an automated test harness that impersonates each group and verifies enforcement by attempting both permitted and prohibited service commands.",,
b2e4b4c0-5161-4dd9-b749-f96546dd2175,Security & Cryptography,Authentication & Access Control,Role-Based & Policy Enforcement,"Develop a Bash script that reads a YAML policy file defining user-to-role mappings and role-based permissions on specified directory hierarchies, then applies and enforces POSIX ACLs with default inheritance under /app/projects. The script must recursively validate current ACLs against the policy, remediate violations, and output a compliance report summarizing each path’s effective permissions.",,
62b8ac14-efa0-4ee9-81ea-6dd2c0f835dc,Security & Cryptography,Authentication & Access Control,Role-Based & Policy Enforcement,"Develop a Python tool that ingests AWS IAM role definitions and live policies via AWS CLI (or a LocalStack sandbox), compares them against a provided least-privilege baseline, and flags roles with wildcard actions or resource overreach. The tool must auto-generate JSON-formatted diffs and suggested aws iam update-role-policy commands to remediate each violation.",,
9bbd332e-8873-4a4e-ab1e-0cc1841877f5,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Implement a Python CLI tool that scans a Git repository for hardcoded cloud credentials (AWS/GCP/Azure), rotates them via the provider APIs into a secrets vault (e.g., HashiCorp Vault or AWS Secrets Manager), replaces the in-code secrets with secure references (environment variables or vault fetch calls), and commits changes to a new branch. Validate the refactored code by running its test suite against the vault-backed configuration and output a JSON report of rotated keys, replaced file paths, and vault URIs to /app/output/report.json.",,
95470edd-95d0-4fec-bbde-b15970d9d8c4,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Develop a Bash script that scans the /app codebase for hardcoded AWS or GCP credentials and rotates compromised keys by generating new short-lived tokens via AWS CLI or gcloud. Store the new tokens in HashiCorp Vault, update source files to retrieve credentials from environment variables and configure the CI pipeline (e.g., GitHub Actions) to fetch secrets at build time, then remove all plaintext secrets from the repository.",,
608d0c87-9c99-45d6-ab2e-c5611d5cd7cc,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Implement a CLI tool that scans a Git repo (current files and history) for hardcoded secrets matching configurable regexes, extracts them into a JSON vault file, and purges them from history using git-filter-repo. Replace all in-code occurrences with environment variable references, update config loaders, and run the provided test suite to ensure no plaintext secrets remain and secret-loading behavior still passes.",,
1763391d-c61f-40c5-90e8-785c1d869801,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Create a Bash script that audits a Go module for known CVEs using go list -m -u all and go vulncheck, automatically updates dependencies to the lowest non-vulnerable versions, runs go mod tidy, then re-scans to ensure no vulnerabilities remain. Output a summary report detailing each upgrade, the CVEs resolved, and the final vulnerability status.",,
73967541-b97f-427d-aee0-20aa181df35d,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Implement a Bash pipeline that clones a given Git repository, generates a CycloneDX SBOM with syft, scans for high-severity CVEs using grype, auto-updates the dependency manifest to the nearest patched versions, rebuilds and runs the project’s tests, and produces a JSON report comparing baseline vs. remediated vulnerability counts along with the list of upgraded packages.",,
c65a805f-7ec5-4e44-b379-b38eb14d6fb6,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Implement a shell script that uses Syft to generate a CycloneDX SBOM for a Go project, scans for vulnerabilities with Grype, automatically bumps vulnerable module versions in go.mod and go.sum to the latest semver-compatible secure releases, rebuilds the binary, and outputs a summary report of patched modules and any remaining issues.",,
d4a60c04-6a87-4d94-8525-880e702bff61,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Implement a Bash script that generates a CycloneDX SBOM for a Python project using Syft, scans it with Grype against a provided severity policy to identify and filter high-risk CVEs, then pins safe dependency versions via pip-tools and regenerates requirements.txt. The script must output a JSON vulnerability report, the updated requirements.txt, and a Markdown compliance summary.",,
5ea054f6-817e-4bc9-9fae-82013d916060,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Implement a non-interactive Bash script that generates a CycloneDX SBOM for a Node.js project, scans its dependencies using npm audit and Snyk, then automatically upgrades any vulnerable packages to the nearest safe release and produces a deterministic JSON report of all detected CVEs and applied updates. The script must also verify each package’s integrity against the checksums in package-lock.json and exit with an error if any integrity mismatch or unresolved high-severity vulnerability remains.",,
776b1c9b-6a21-4bb1-82c9-54817d6573ca,Security & Cryptography,Security Monitoring & Compliance,Security Policy Compliance,"Implement a Python-based audit tool that reads a JSON specification of NIST SP800-53 controls with associated shell commands, executes each check to verify system settings (e.g., auditd, password policy, firewall rules), and outputs both CSV and JSON reports with pass/fail statuses and optional remediation scripts for non-compliant controls.",,
202f2ba5-f973-4c48-b372-bd7730ef5a31,Security & Cryptography,Security Monitoring & Compliance,Security Policy Compliance,"Develop a Python script that loads Docker image tarballs under /app/images and evaluates each against the CIS Docker Benchmark v1.2 controls—verifying root user usage, privileged mode, dropped capabilities, read-only root filesystem, seccomp profile, and SELinux labels. The script should output a UTF-8 CSV with columns for image name, control ID, description, and pass/fail status.",,
9a54cdad-6d77-4a37-a8be-c0e3a8199dce,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Implement a CLI tool that manages JWT sessions stored in a SQLite database (with jti, user_id, iat, exp fields): it must list active sessions, revoke sessions by jti (inserting them into a blacklist table), purge expired tokens, and validate a given JWT by checking its signature and blacklist status.",,
2a267c1a-ea1c-4395-9a05-f7987a672956,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Implement a CLI tool that connects to a Redis-backed session store, scans for sessions older than a specified age or belonging to a compromised user list, deletes those sessions to revoke access, simulates HTTP requests using revoked tokens to confirm denial, and outputs a JSON summary of revoked and remaining sessions.",,
7970d045-dce6-427a-b3b0-cdcf9d016949,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Implement a Python CLI that issues HMAC-signed JWT access and refresh tokens stored in a SQLite database, provides commands to list active sessions, revoke specific tokens or all sessions for a user, automatically purges expired tokens, and supports key rotation without invalidating still‐valid sessions.",,
8fd31457-c3a6-4356-9ae8-cce812d382fc,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Develop a Python Flask microservice that issues RS256-signed JWT access and refresh tokens, persists refresh tokens in an SQLite-backed store, and implements an endpoint to revoke sessions by blacklisting token identifiers. Include an automated test script that simulates login, token refresh, logout, and verifies that revoked or expired tokens are rejected with HTTP 401.",,
ae0780ab-9cce-4e2f-94bd-abf050ae8499,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Implement a Python CLI tool that uses Semgrep to scan a mixed-language codebase for insecure patterns such as MD5/SHA1 usage, hard-coded secrets, and deprecated crypto libraries. The tool should output findings in JSON and generate patch files upgrading algorithms to modern alternatives and externalizing credentials to environment variables.",,
8ddcb3b4-cbdd-4472-a6d6-fbeecbfd3a94,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Build a CLI script that runs Bandit on Python, SpotBugs on Java, and ESLint security rules on JavaScript within a provided multi-language project, converting each report into SARIF format and merging them. Deduplicate findings by file path and CWE ID, then output a prioritized CSV listing severity, location, and suggested remediation steps.",,
ac549346-ae38-4952-97f3-b46e9aaeec77,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Develop an idempotent Bash script to apply CIS-level hardening to a mock LAMP stack under /app by securing Apache (enforcing TLS 1.2+, HSTS, disabling unused modules), tightening php.ini (disabling dangerous functions), removing default virtual hosts, and hardening systemd unit files with dropped capabilities and ProtectHome settings. The script must only modify files within /app, log each action with timestamps, and generate a concise summary report of all applied changes.",,
36e735e5-9770-4cf3-b6e0-7c57c9e417d6,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Develop a Python tool that profiles a specified systemd service at runtime (via strace or audit logs) to generate and compile a minimal AppArmor profile, applies and enforces it, and validates enforcement by detecting blocked operations during a controlled test run.",,
e3c0e7ee-576d-4a1a-9da3-164f29351603,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Create a script that audits all installed systemd service unit files, applies sandboxing directives (NoNewPrivileges, PrivateTmp, ProtectSystem, ProtectHome, etc.) to essential services, disables or masks unused ones, and reloads the daemon. The tool must backup originals, validate service health post-hardening, and output a JSON compliance report with before/after settings.",,
16602a21-e5e2-46da-bc5c-b55baa05f610,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Given an insecure systemd unit file at /app/service/app.service, generate and install a hardened override file under /etc/systemd/system/app.service.d/ that enforces security directives (PrivateTmp=yes, ProtectSystem=full, ProtectHome=read-only, NoNewPrivileges=yes, CapabilityBoundingSet) and applies a basic seccomp syscall filter. Reload systemd, start the service, and write its active status (active/inactive) to /app/output/status.txt.",,
1b195010-4674-43fb-b8bb-042072d62bbe,Security & Cryptography,Network & System Penetration Testing,TCP Idle Scan,"Develop a Python script that performs a TCP Idle scan by selecting an idle “zombie” host, verifying its predictable IPID sequence, then probing a target’s TCP port range and inferring open, closed, or filtered ports from IPID increments. The tool must output a JSON report listing each port’s status and the zombie host’s IPID data used to derive results.",,
48a40c38-ab10-4b7b-a50d-daab1cf51146,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Create a Python tool that ingests Windows NTFS MFT records, EVTX event logs, and Prefetch artifacts to extract file creation, process execution, and service start events, normalizes all timestamps to UTC, and correlates them into a unified chronological timeline. Flag and annotate anomalous entries such as unsigned binary executions or registry Run key modifications, and output the timeline as CSV plus a JSON summary of suspicious events.",,
1a883669-d735-4109-b030-54bc237bef62,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Parse /app/logs/auth.log, /app/logs/syslog, and a mounted disk image (/app/disk.img) to extract SSH login attempts, sudo commands, and file creation/deletion timestamps, then correlate these events into a single chronological sequence. Output the reconstructed timeline as JSONL sorted by timestamp to /app/timeline.jsonl.",,
d8dad229-dd78-4ec9-9f1c-2d19c0eb3318,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Create a script that scans a list of Docker images and live hosts using Trivy and Nmap, deduplicates and correlates vulnerabilities and open ports by CVSS severity, and outputs a consolidated JSON report. Additionally, generate a remediation guide with suggested package upgrade or container base-image update commands for all high and critical issues.",,
45e08750-7d29-41c6-9b01-a2850f9e1be7,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Implement a Bash script that runs Nmap with version and vulnerability NSE scripts against targets listed in /app/targets.txt, parses the XML output to extract host:port, service/version, and detected CVEs, then produces a JSON report grouped by host and a Markdown remediation guide including issue descriptions and patch links.",,
11f18e54-b73b-45e3-92b1-1c50e80bf9a3,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Develop a Bash or Python script that uses Trivy to scan the supplied Docker image for vulnerabilities, parses the JSON results to extract all high and critical CVEs, and generates a CSV report listing package names, installed and fixed versions, and severity counts. The script should then update the Dockerfile to reference the latest patched base image tag, handle private registry authentication, and log all operations to /app/scan.log.",,
18370c0a-2b4e-4113-8742-8febb825db61,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Automate building the provided Docker image and running vulnerability scans with both Trivy and Grype. Merge and deduplicate findings into a unified JSON report sorted by severity, including summary statistics and remediation URLs.",,
33709d39-90ee-4ab8-becc-78abb240e267,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Create a terminal pipeline that runs Nmap, Trivy, and Nikto scans against a supplied Docker-Compose service, normalizes and filters vulnerabilities by CVSS score, correlates findings with CWE IDs, and outputs both a unified JSON report and a Markdown summary with prioritized remediation guidance.",,
01eb5bcc-fed0-47d4-8772-2b719344b03b,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Code Cleanup & Refactoring,"Refactor a small C CLI utility currently implemented with extensive macros and global state into a modular architecture using opaque structs, function pointers, and .c/.h separation, preserving identical CLI behavior and output. Replace unsafe string handling with bounded APIs, remove dead code, add const-correctness, and keep -O2 performance within 5% of the original.",,
c8cdce77-a58f-4ba7-9a88-1e030f8e07fe,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Dependency Modernization,"Upgrade a legacy Django 1.11 project to Django 4.2 LTS by replacing deprecated APIs (url() → path/re_path, MIDDLEWARE_CLASSES → MIDDLEWARE, ugettext → gettext), updating settings, and adjusting project/app structure as needed. The application must start successfully, apply migrations cleanly, and pass the existing tests without behavior changes.",,
238a2732-af0e-468f-b378-6fd13696329a,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Performance Profiling & Optimization,"Profile a Go CLI that aggregates per-key metrics from a large NDJSON stream but suffers from excessive allocations, JSON decoding hotspots, and goroutine leaks. Use pprof and benchmarks to identify bottlenecks, then refactor to a streaming, buffered design (pre-sized maps, sync.Pool, proper backpressure) to cut memory churn and achieve at least 2× throughput without changing outputs.",,
f03cb3da-e866-4728-94b1-948b9a765b7e,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Performance Profiling & Optimization,"Profile a Python CLI that computes PageRank on a large graph using pure Python lists and nested loops, identifying CPU and memory hot spots. Refactor it to use efficient sparse matrix operations and streaming I/O to achieve at least a 5× speedup while preserving identical CLI behavior and output.",,
e0539bc8-134d-4f2d-ab83-218e57101cc1,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Performance Profiling & Optimization,"Profile a Python HTTP access-log analyzer that is CPU-bound and memory-heavy, then refactor it to stream input, remove regex hot spots, and parallelize safe stages to achieve at least 5× throughput with identical CLI and outputs. Add a --profile flag that emits cProfile and memory reports to /app/profile/ while preserving deterministic ordering.",,
9db76131-0756-4d29-b5ef-700a3cf4dc0e,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Performance Profiling & Optimization,"Profile a Rust log aggregation tool that is slow due to repeated string allocations and O(n^2) lookups, then refactor it to use zero-copy slice parsing and hash-based indexing to reduce runtime and peak memory by at least 3x without changing output. Provide before/after flamegraphs and memory measurements to demonstrate the optimization.",,
4e24d6dd-92e5-4bd5-a22c-c8cf6c7cb661,Software Engineering & Development,"Collaboration, Review & Documentation",Change Log & Release Notes,"Write a POSIX-compliant script at /app/bin/release-notes that analyzes git history since the last tag using Conventional Commits to calculate the next SemVer, update CHANGELOG.md in Keep a Changelog format (rolling Unreleased → version), and output a Markdown release body with compare links. It must support monorepos (packages/*) by generating per-package sections, highlight BREAKING CHANGE footers and deprecations, and return non-zero if it encounters malformed commit messages or missing tag anchors.",,
f14d352c-3491-49ac-996e-fdae64bbd471,Software Engineering & Development,"Collaboration, Review & Documentation",Project Management & Issue Tracking,"Build an offline Git-based issue workflow: given a repo with commits/branches and a backlog.csv, implement a CLI that imports the backlog into issues/*.md with YAML metadata, auto-labels via rules.yaml, links duplicates, and auto-closes issues when commits reference 'fixes #ID'. The tool must generate a Kanban board HTML and a burndown.csv for a specified milestone, matching expected counts and state transitions.",,
bd24ec51-44d2-4a8c-a8b5-20cf4427b9e1,Software Engineering & Development,"Collaboration, Review & Documentation",Project Management & Issue Tracking,"Using the distributed issue tracker git-bug, migrate a backlog exported as /app/export/issues.csv into the Git repo at /app/repo, applying label and milestone mappings from /app/policy.yml, deduplicating and linking related issues, and closing items automatically based on a test results JSON. Generate a release-notes.md grouped by milestone from the closed issues, with commit cross-references resolved to short SHAs.",,
5239c4bb-3fda-4d8d-b644-46f4ed8cfa07,Software Engineering & Development,Debugging & Issue Resolution,Logging & Observability Enhancements,"Enhance a Python FastAPI gateway and a background worker to emit OpenTelemetry traces, structured JSON logs, and Prometheus metrics. Propagate W3C trace-context across HTTP and Redis queue boundaries, correlate logs with trace_id/span_id and a request_id, redact PII (emails/tokens), export to a local OTLP collector, and satisfy tests that verify span topology, error statuses, and metric cardinalities.",,
327df3a4-1027-4c0c-b3ce-87ede24f37c8,Software Engineering & Development,Debugging & Issue Resolution,Runtime Error Debugging,"Debug a C++ network daemon that consistently segfaults on the second configuration reload (SIGHUP) due to a use-after-free of a shared configuration object. Reproduce the crash, inspect the core with gdb and run under AddressSanitizer to pinpoint the invalid access, then fix ownership/lifetime and verify that multiple consecutive reloads complete without crashes or leaks.",,
89d3cd5b-f472-4a22-86e2-e74a2017fc5d,Software Engineering & Development,Debugging & Issue Resolution,Runtime Error Debugging,"Diagnose and fix a heap-buffer-overflow that triggers a segmentation fault in a C-based PNG decoder CLI when processing a specific image. Reproduce the crash, use gdb and AddressSanitizer to pinpoint the faulty scanline index arithmetic, patch the logic, and verify decoding succeeds without memory errors.",,
8b825ee5-7ea7-45e3-8228-1935aee6d367,Software Engineering & Development,Debugging & Issue Resolution,Runtime Error Debugging,"Diagnose and fix an intermittent SIGSEGV in a multithreaded C++ log collector caused by a use-after-free in an async callback. Reproduce under load, pinpoint with AddressSanitizer/gdb, and patch object ownership/lifetimes to eliminate the crash and pass a stress test.",,
65d38880-6fd7-4644-a0ab-5f29cc514fb4,Software Engineering & Development,Development Tooling & Workflow Automation,Build Tool Configuration,"Configure Bazel (with Bzlmod) for a polyglot monorepo (Python, TypeScript, and Go) that builds, tests, and packages each component, including a custom Starlark rule to stamp git version metadata into binaries. Ensure hermetic, reproducible builds with remote-cache fallback and a //:release target that emits signed tarballs and a CycloneDX SBOM.",,
bd84a189-1bba-4929-a80d-8185874dcb53,Software Engineering & Development,Development Tooling & Workflow Automation,Build Tool Configuration,"Configure a Bazel monorepo to build a Go CLI and a TypeScript library, vendoring dependencies (Go modules and npm) for offline, hermetic builds and running unit tests for both. Provide WORKSPACE/BUILD files so that bazel build //... and bazel test //... produce reproducible, versioned artifacts in a clean container.",,
f7fea38b-8d54-4ffc-83d8-deecd618104a,Software Engineering & Development,Development Tooling & Workflow Automation,Build Tool Configuration,"Configure a Bazel workspace for a polyglot monorepo (Go, Python, and TypeScript) that generates language bindings from a shared .proto, defines reproducible build/test targets, and produces versioned artifacts. Enable hermetic toolchains, a local HTTP remote cache, and build stamping from git via a small Starlark macro so incremental builds and cache hits are verifiable.",,
b280ac04-40c5-46bf-8be8-34dae5356dbc,Software Engineering & Development,Development Tooling & Workflow Automation,Build Tool Configuration,"Configure a Meson+Ninja build for a small C library and CLI that builds shared and static variants, generates a pkg-config file, and embeds a git-derived version string. Add debug/release options toggling sanitizers, wire up unit tests, and ensure `meson dist` produces a bit-for-bit reproducible source tarball with fixed timestamps and sorted file order.",,
fc4a9169-f5ef-4176-a03b-ebdbbed815d3,Software Engineering & Development,Development Tooling & Workflow Automation,Build Tool Configuration,"Create a CMake build for a C++ library that generates a version header from git metadata, fetches fmt via FetchContent, and installs exportable targets with both a CMake package config and a pkg-config .pc file for downstream consumption. The harness should build out-of-tree, run ctest, install to /app/dist, then compile a separate consumer using find_package or pkg-config, and verify incremental builds are no-ops and the reported version matches the latest git tag.",,
a8b60f64-083f-4e97-8541-c3b04e2e7e5c,Software Engineering & Development,Development Tooling & Workflow Automation,Toolchain Customization & Extensions,"Build a custom clang-tidy module that implements a check (e.g., modernize-avoid-raw-new) to flag and auto-fix uses of new/delete by suggesting std::make_unique/make_shared, and integrate it into a CMake project with a .clang-tidy config and a script to run it on the codebase. Include unit tests for the check and ensure the plugin builds and runs entirely within the sandbox.",,
08a44022-5a36-4aec-b2e5-a16aecc775e2,Software Engineering & Development,Feature Implementation & Algorithm Development,API Design & Integration,"Implement an HTTP gateway that exposes a REST+SSE API on localhost:8080 and transparently bridges to a local gRPC service at 127.0.0.1:50051, translating unary and streaming RPCs into JSON and server-sent events. Ensure consistent gRPC→HTTP error mapping, request deadlines via headers, idempotency keys for POSTs, and auto-generate an OpenAPI spec for the REST facade.",,
ec759269-a7c0-4cd9-8c82-43c64e45f30f,Software Engineering & Development,Feature Implementation & Algorithm Development,API Design & Integration,"Implement an HTTP-to-gRPC gateway that reads a provided OpenAPI spec and matching .proto, translating REST requests into gRPC calls (including server-streaming exposed as Server-Sent Events) and mapping errors to correct HTTP codes. The gateway must validate requests/responses against OpenAPI, support path/query/header mapping, and preserve backward compatibility for both v1 and v1beta routes.",,
e4e4aa20-f579-4ca9-9aa3-44fb75f2f3e5,Software Engineering & Development,Feature Implementation & Algorithm Development,Algorithm Implementation,"Implement a KLL streaming quantile sketch with configurable error (epsilon) that supports insert, merge, serialize/deserialize, and percentile queries, exposing both a small library and a CLI that reads floats from stdin and returns requested quantiles. Provide deterministic tests verifying accuracy bounds against exact quantiles on synthetic and adversarial streams.",,
128a21f6-ff18-443a-ad20-4aa7257f4909,Software Engineering & Development,Feature Implementation & Algorithm Development,Code Generation & Automation Utilities,"Build a CLI that scans a polyglot monorepo (Python, Node.js, Go) to detect service roots and generate optimized multi-stage Dockerfiles and matching .dockerignore files using lockfiles for deterministic caching and stable layer ordering. Provide a validate subcommand that builds each image and outputs a summary of image sizes, cache efficiency, and hadolint violations.",,
cad24160-0880-423f-8464-9dc4916668e1,Software Engineering & Development,Feature Implementation & Algorithm Development,Code Generation & Automation Utilities,"Create a CLI tool that scans a repository for Dockerfiles and generates a GitHub Actions workflow YAML that builds and pushes a multi-architecture image matrix for each Dockerfile (respecting ARG defaults and build contexts). The tool must validate the YAML, support dry-run and overwrite modes, and output both the workflow at .github/workflows/build.yml and a machine-readable summary report.",,
6af6cde8-69a1-4b64-89d4-606749f58fd6,Software Engineering & Development,Feature Implementation & Algorithm Development,Feature Extension & Enhancement,"Extend a minimal HTTP JSON TODO service by adding optimistic concurrency via ETag/If-Match on PUT/PATCH, stable cursor-based pagination for GET /todos, and a /metrics endpoint exporting request counts and p95 latency. Ensure thread-safe handling under concurrent clients and persistence across restarts using a write-ahead log.",,
1a49683b-971e-4cc8-8a90-54a6445af0c9,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Build a CLI tool that verifies a release artifact by validating a signed checksums manifest (detached OpenPGP signature against a pinned keyring) and, if present, a Minisign/Signify signature, confirming digests across multiple algorithms (SHA-256/512, BLAKE2b), and emitting a fail-closed JSON report with signer identities, algorithms, and timestamps. Handle revoked/expired keys, ambiguous filenames, and newline/whitespace normalization, and return non-zero on any verification failure.",,
d220e167-5bf4-4d59-a081-7e791d39eb3d,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Build a minimal TUF-secured release flow: generate root, targets, snapshot, and timestamp metadata with a 2-of-3 threshold for targets, sign a target artifact, and implement a client that downloads and verifies the artifact enforcing expiry and key rotation. The verifier must fail on expired metadata, insufficient signature threshold, or tampered targets, and exit 0 only when all checks pass.",,
d11a5249-8d98-4c32-b57d-d38e813670c7,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Build an offline CLI that signs deployment tarballs with Ed25519 and emits a DSSE JSON attestation (including SHA-256, builder ID, and timestamp), with a keygen and public keyring export. Implement a verifier that enforces a JSON trust policy (allowed keys per release channel, expiry window, and revocation list) and fails on any tampering or policy violation.",,
485a0eb8-d2d2-448c-91ad-d893fc7aeba1,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Implement a pair of CLIs that produce and verify a signed release manifest: the signer walks /app/build, generates a reproducible SHA-256 manifest, wraps it in a DSSE JSON envelope, and signs it with an Ed25519 key derived from a passphrase. The verifier must validate the signature with the public key, detect tampering or missing files via the manifest, and only copy artifacts to /app/deploy upon successful verification.",,
ff4bcaab-881a-4e9d-ab1e-9e83b08a686a,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Build a CLI that ingests a polyglot repo (npm, pip, and Cargo), parses their lockfiles to map dependencies to SPDX license IDs, and emits a unified SPDX 2.3 SBOM at /app/sbom.spdx.json. Enforce a policy.yaml with allow/deny lists and per-package exceptions plus OSV vulnerability thresholds, verify each dependency’s LICENSE presence or resolvable URL, produce /app/compliance_report.json with remediation suggestions, and exit non-zero on any violation.",,
8b44d798-78ff-4c9c-96ae-36400404753c,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Build a CLI that scans a polyglot monorepo (Python/Poetry, Node/pnpm, and Go modules), resolves all transitive dependencies, normalizes their SPDX license expressions, and enforces an allowlist/denylist with per-package exceptions. The tool must output an SPDX 2.3 SBOM and a deterministic THIRD_PARTY_NOTICES.md with license texts and source URLs, run offline from lockfiles, and ship a CI workflow that fails the build on violations.",,
8377c823-c7c2-4c44-b6bc-0b4346794f2a,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Implement a CLI that audits a polyglot repo (Python/Node/Rust) by parsing poetry.lock, package-lock.json, and Cargo.lock to resolve all transitive dependencies offline, extracting SPDX license identifiers from local metadata. It must generate a CycloneDX SBOM and a consolidated THIRD_PARTY_NOTICES.txt, enforce a policy forbidding AGPL/SSPL/GPL-3.0-only and unknown licenses unless explicitly allowlisted, and exit non-zero on violations.",,
11a0e7b7-ac24-464b-b5aa-2b2311d9fdcb,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Set up a polyglot repo (Python, Node.js, Rust) with a CI-like script that generates an SPDX SBOM, scans for CVEs and license terms, enforces a policy banning copyleft licenses and high-severity vulnerabilities, and fails if violations are found. Remediate by pinning or replacing flagged dependencies, regenerate lockfiles, and produce a machine-readable compliance report under /app/compliance/report.json.",,
7f522043-b113-4538-a9f8-5e8917474d9c,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Create a resilient HTTP proxy that fronts multiple flaky upstreams, implementing bounded retries with exponential backoff and jitter, a circuit breaker with half-open recovery, and request hedging; when all upstreams fail, serve stale cache entries (cache-aside) and surface structured errors. Add idempotency-key handling for POST requests and a /metrics endpoint exposing success/failure counts so tests can inject chaos and verify graceful degradation and self-healing.",,
3ba41cf3-9336-475e-8f90-a9d22ffa7671,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a crash-safe transactional outbox for a toy Orders service using SQLite and a background dispatcher: persist orders and outbox records atomically, then reliably deliver them to an append-only mock broker with idempotency keys, exponential backoff with jitter, and a retry budget. After simulated crashes and restarts, the system must guarantee at-least-once delivery without duplicate observable publishes and reconcile any in-flight work.",,
0eb829f2-1f6d-4002-b3d4-06b20ed166ba,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a local SQS-like durable task queue with visibility timeouts, exponential backoff with jitter, idempotency-key deduplication, and a dead-letter queue; provide a worker that can be killed mid-run and must resume without double-processing. The harness injects crashes, network-like delays, and duplicates to verify eventual processing and no duplicate side effects via a persisted checksum ledger.",,
8ed8148e-7b0e-4866-a185-81e5a007abd1,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a resilient webhook relay daemon that reads events from /app/queue.jsonl and delivers them to a flaky HTTP endpoint using capped exponential backoff with jitter, a circuit breaker (with half-open probing), and a token-bucket rate limiter. On persistent failure it must dead-letter events, serve stale-but-valid cached results, and guarantee idempotent, exactly-once visible delivery across restarts via checkpointed offsets and idempotency keys.",,
be389498-e754-48f8-93ba-3625ab8b4fd5,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Secure Coding Practices,"Audit and harden a Python backup/restore utility that creates and extracts tar archives, currently vulnerable to Zip Slip path traversal and a --post-hook command injection via shell=True. Constrain extraction to a specified base directory, sanitize tar members, replace shell execution with safe subprocess invocation and an allowlist, and add tests that confirm malicious archives cannot escape the sandbox while preserving normal behavior.",,
e894fb16-5037-497a-9826-d2d4e66dcfc8,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Secure Coding Practices,"Given an intentionally vulnerable Node.js microservice/CLI in /app, remediate prototype pollution in JSON merging, command injection in child_process usage, and ReDoS in a user-supplied regex. Replace unsafe patterns with secure alternatives, add regression tests, and ensure npm audit reports no high/critical issues.",,
cc9584b4-b3d6-41c4-a8d3-e8cd32070f15,Software Engineering & Development,Software Architecture & Design Patterns,Codebase Architecture Documentation,"Build a CLI that analyzes a polyglot monorepo (Python, Go, Node) to generate a cross-language dependency graph and a C4 Container diagram, writing docs/architecture.md and SVG diagrams with components annotated by primary git authorship and service boundaries. Include a CI mode that fails on new dependency cycles or components missing ADR links, and provide a deterministic make target to regenerate all artifacts.",,
dcf1b664-74c6-43cf-8af8-3cc35da737e5,Software Engineering & Development,Software Architecture & Design Patterns,Codebase Architecture Documentation,"Build a CLI that scans a polyglot monorepo (Python, Go, Node.js) and its docker-compose.yml to produce C4 Container/Component diagrams, a module import matrix, and a cross-service topology, exporting PlantUML/SVG and Markdown docs. The tool must enforce layer rules from a config by failing on forbidden imports and append an ADR entry whenever dependency topology changes are detected.",,
9c509685-fc23-41d7-8e4d-82b4059ce8ad,Software Engineering & Development,Software Architecture & Design Patterns,Codebase Architecture Documentation,"Create a script that scans a polyglot repo (Python and Node) to generate /app/docs containing a C4-style container diagram inferred from docker-compose.yml, per-service module dependency graphs, and a consolidated architecture README. The script must be idempotent, detect and list circular dependencies, and output diagrams in both Mermaid and PlantUML formats.",,
0922cd72-f1dc-44f0-9b3b-fe8f538d3825,Software Engineering & Development,Software Architecture & Design Patterns,Codebase Architecture Documentation,"Given a polyglot microservices monorepo with docker-compose, build a tool that parses source imports and compose files to generate a cross-service architecture diagram and per-language package dependency graph, emitting Graphviz artifacts and a Markdown overview. The tool must detect cycles and boundary violations and fail CI when found, with tests verifying required nodes/edges and report contents.",,
6f874fa0-c4ec-4cc4-829b-7bf4bddfeb15,Software Engineering & Development,Software Architecture & Design Patterns,Refactoring for Maintainability,"Refactor a small Flask microservice in /app to a ports-and-adapters (hexagonal) architecture by extracting domain logic into pure modules, introducing repository/service interfaces, and isolating framework/infrastructure behind adapters. Preserve the exact REST API and CLI behavior and response formats while removing global state and adding dependency injection seams for testability.",,
fb9e1f83-6351-4a6b-b1d3-20123aef8dac,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design a hexagonal architecture (ports and adapters) for a feature-flag evaluation service. Define the domain module and interfaces (FlagStore, TargetingRuleEngine, Evaluator), implement separate adapters for JSON-file persistence and an HTTP query endpoint, and a composition root that wires dependencies while keeping the domain free of I/O or framework dependencies.",,
a709b827-3828-4bbd-9523-9c010e00b85b,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design a pluggable feature-flag evaluation engine with clean module boundaries: Strategy (targeting/rollout), Store (flag/state persistence), and AuditSink (decision logging) wired via dependency inversion. Define interfaces and data flow, load implementations from a TOML config at runtime, and provide a CLI that evaluates flags for user contexts without the core depending on concrete classes.",,
46691ab8-b834-401a-a1eb-cf4fd92ee076,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design a plugin-based data pipeline with strict layering (domain: Stage/DAG interfaces, application: orchestrator, infrastructure: adapters) where stages are discovered dynamically and wired from a YAML-defined DAG. Implement CSVReader, Filter, Aggregate, and JSONWriter stages and provide a static dependency check that fails if any stage module imports the orchestrator or adapters.",,
b834d715-db67-425a-8e15-77c3b0367615,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design and implement a hexagonal architecture for an inventory reservations system: define domain entities and ports for commands, queries, time, and event publishing, keeping the core framework-agnostic. Provide interchangeable adapters for persistence (SQLite and in-memory) and I/O (HTTP and CLI) wired via a lightweight DI container so tests can swap adapters without modifying the domain.",,
94cde19f-cdd3-4066-9cca-489d2657f99c,Software Engineering & Development,"Testing, Validation & Quality Assurance",Continuous Testing Integration,"Create a GitHub Actions workflow for a polyglot monorepo (Python, Node.js, and Go) that caches dependencies, runs unit and integration tests (integration via docker-compose Postgres), aggregates JUnit and coverage across languages into a single report, and fails if combined coverage is below 85% while uploading artifacts. Implement a sharding-and-retry runner that splits slow tests across two matrix shards and retries failures once, marking the job as unstable via an output file when a retry passes.",,
99705414-8c13-4b9d-8f90-9fb98d1896a4,Software Engineering & Development,"Testing, Validation & Quality Assurance",Continuous Testing Integration,"Integrate mutation testing and coverage gating into a tox-driven pipeline that runs unit and integration tests across Python 3.10–3.12, emitting JUnit and coverage XML to /app/artifacts and merging per-environment results. Implement path-aware test selection and dependency caching so only affected tests run on changes, and fail the pipeline if mutation score < 85% or coverage < 90%.",,
deaa2d3c-3639-4a28-bea0-268bcc5d1281,Software Engineering & Development,"Testing, Validation & Quality Assurance",End-to-End (E2E) & Regression Testing,"Build a Dockerized E2E and regression test harness that launches a three-service sample app (frontend, API, Postgres) via docker-compose, seeds test data, and runs headless Playwright tests against localhost. Include golden JSON and visual snapshot assertions, collect screenshots/HAR/logs on failure, and provide a single CI-friendly script that exits nonzero on any diff.",,
bfa26a18-b432-4e6f-acf4-53dfd5675ab4,Software Engineering & Development,"Testing, Validation & Quality Assurance",End-to-End (E2E) & Regression Testing,"Create a migration regression harness that spins up a temporary PostgreSQL instance, applies upgrade/downgrade paths across a set of SQL migrations, seeds data, and verifies invariants by comparing normalized query results and schema digests to golden snapshots. Include a CLI to run the full matrix (all from→to versions), detect drift and irreversibility, and optionally update snapshots.",,
eafbfb74-2b0b-47d6-a85c-ad370f559eab,Software Engineering & Development,"Testing, Validation & Quality Assurance",End-to-End (E2E) & Regression Testing,"Create a regression harness that runs the same Playwright E2E suite against two app versions (baseline vs candidate) via docker-compose, capturing API response snapshots and page screenshots, then producing semantic diffs and visual diffs in /app/artifacts. Implement retry-based flake detection with automatic quarantine list generation and emit a JUnit XML summary suitable for CI.",,
a8c0d3fd-14c1-442e-a394-9a72226a19e0,Software Engineering & Development,"Testing, Validation & Quality Assurance",End-to-End (E2E) & Regression Testing,"Design an automated cross-version E2E regression harness that spins up vN and vN-1 of a sample service (HTTP + gRPC) with docker-compose, replays recorded interactions, and validates API responses, protobuf/JSON schemas, DB state, and log invariants. Integrate OpenAPI/Buf breaking-change checks and emit JUnit and HTML reports to fail the pipeline on incompatibilities.",,
77066704-8911-4d28-9415-a99c87f94402,Software Engineering & Development,"Testing, Validation & Quality Assurance",End-to-End (E2E) & Regression Testing,"Implement an E2E regression harness that launches two Dockerized versions (v1 and v2) of a FastAPI service against a fresh Postgres, applies Alembic migrations, seeds fixtures, replays a recorded HTTP trace, and diffs normalized JSON responses to detect behavior drift. The runner must produce JUnit XML and a readable diff, ignoring nondeterministic fields (ids/timestamps/order), and exit nonzero on any semantic mismatch.",,
bfe72e0f-b8f4-4feb-b537-c20f119c58e1,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Build a cassette-driven GraphQL mock server that captures live queries/responses, redacts secrets, and replays them offline with deterministic seeding. Include a CLI to inject schema drift, latency/jitter, and controlled error rates so client tests can verify resilience and schema-compatibility via golden snapshots.",,
0ed054b1-03c0-40e6-b96e-ca8cb379bf05,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Create a spec-driven mock HTTP service that reads an OpenAPI 3.0 spec from /app/spec.yaml and deterministically generates synthetic responses from schema examples and constraints, with toggles for error injection, pagination, and rate limits. Include fixtures and a test harness that validate a client’s handling of boundary values, idempotency keys, and retry/backoff behavior using only the mock service.",,
d057e0b4-9d1b-45f0-822f-cf8e7e47988e,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Implement a local S3-compatible mock server that supports CreateBucket, PutObject, GetObject, and ListObjects while simulating eventual consistency and fault injection (configurable latency, transient 500s, and delayed listings). Provide fixtures that generate synthetic objects with edge-case keys and varied payload sizes, and emit structured logs to validate client retry/backoff and read-after-write behavior.",,
447445ef-fdde-474a-916a-db0572904f99,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Implement a local mock payment gateway and webhook relay that mimics Stripe-style semantics: create/confirm payment intents, idempotency-key enforcement, HMAC-signed webhooks with rotating secrets, and deterministic fake card numbers that trigger specific error paths. Provide a seedable synthetic data generator and runtime toggles to simulate latency, network flakiness, 3DS challenge flows, rate limits, and partial outages to validate client robustness.",,
b31c9d00-d2f1-435d-8a02-29bbb6268736,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Configure a Python+TypeScript monorepo to enforce strict static analysis: mypy --strict (with custom stub packages for a vendored library), flake8 with a custom plugin forbidding naive datetime usage, and ESLint/TypeScript rules requiring explicit return types. Refactor the codebase to eliminate all violations, wire the tools into pre-commit and a CI script that produces /app/lint_report.json and fails on any new issues.",,
aabfa929-e0d7-450b-89e5-8b9629cc9348,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Create and integrate a custom Flake8 plugin that flags timezone-naive datetime usage, mutable default arguments, and broad exception handlers in a small Python repo. Configure pyproject.toml so flake8 (with the plugin) and mypy --strict both run clean after refactoring the code to satisfy all checks.",,
10c3a45c-9913-45ea-a455-3db603d91135,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Implement a custom Flake8 plugin that flags calls where the return value of any function decorated with @must_use is ignored, emitting code MUU100 at the call site. Register the plugin and provide a script that runs flake8 on /app/src and writes a SARIF report to /app/lint.sarif.",,
49e4384d-fc73-4fa3-a1f7-8da412868133,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Implement a custom flake8 plugin that flags functions and methods using mutable default arguments (lists, dicts, sets, and comprehensions), supporting per-line noqa and exemptions for dataclasses field(default_factory=...). Integrate it via setup.cfg, run it over a small Python package with seeded violations, and make the codebase pass with a combination of fixes and justified ignores.",,
cfe3e5b2-7f80-4567-be30-1eb63f6ef43e,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Set up a cross-language lint/type pipeline for a Python+TypeScript monorepo using mypy (strict), flake8, and ESLint with typescript-eslint, plus custom analyzers that compare an OpenAPI spec to implemented HTTP routes to flag missing or undocumented endpoints. Integrate via pre-commit and a make lint target that emits a single consolidated JSON report and exits nonzero on any violations.",,
77cd6422-53eb-445a-8c09-f292a1c4aa20,Software Engineering & Development,"Testing, Validation & Quality Assurance",Unit & Integration Test Implementation,"Create a comprehensive pytest test suite for a cron expression parser and scheduler, including unit tests for ranges/steps/lists, W/L/# modifiers, invalid inputs, and timezone/DST edge cases, plus property-based tests that verify monotonic and gap-free next_run sequences. Add integration tests that exercise the CLI with stdin/files to validate output formatting, error messages, and exit codes, targeting at least 90% line and branch coverage.",,
ba169781-c203-4307-bcb7-da544c9bb133,Software Engineering & Development,"Testing, Validation & Quality Assurance",Unit & Integration Test Implementation,"Implement unit and integration tests with pytest, pytest-asyncio, and Hypothesis for an asyncio WebSocket chat server skeleton, verifying message routing, rate limiting, heartbeat timeouts, and graceful disconnects. Tests must spin up the server on localhost, connect multiple clients concurrently, assert broadcast ordering and backpressure handling, and run deterministically without external network access.",,
c4aa144c-109e-4cb0-b365-089b5e05507a,Software Engineering & Development,"Testing, Validation & Quality Assurance",Unit & Integration Test Implementation,"Implement unit tests for a timezone-aware recurring event scheduler to verify next_occurrence and occurrences_between across DST forward/back transitions, month-end rollovers, and timezone changes using IANA zoneinfo and frozen time. Add integration tests that run the provided CLI against a fixtures.yaml of recurrence rules to assert deterministic outputs and round-trip serialization across multiple timezones.",,
0bfd1a83-20c7-4a21-8dce-1e3b659f0728,Software Engineering & Development,"Testing, Validation & Quality Assurance",Unit & Integration Test Implementation,"Write a comprehensive pytest + Hypothesis suite for an existing Python CRDT library (e.g., LWW-Element-Set and OR-Map) that verifies merge algebra (commutativity, associativity, idempotence), serialization round-trips, and tombstone semantics. Tests should generate randomized concurrent operation sequences across multiple replicas, simulate partitions and merges, and assert eventual consistency and order-independence in end-to-end scenarios.",,
ea2a965d-6b43-4d96-b082-265a556a23e3,Software Engineering & Development,Feature Implementation & Algorithm Development,Algorithm Implementation,"Create a Python CLI tool that reads two text files, computes the minimal edit script using Myers’ diff algorithm in O((N+M)D) time, and writes a unified diff with correct hunk headers to stdout. Ensure it handles inputs up to 100k lines efficiently under 2 seconds per file pair.",,
47f4f6b4-5cd5-4286-80d5-94087f11b0c3,Software Engineering & Development,Feature Implementation & Algorithm Development,Algorithm Implementation,"Implement Dinic’s maximum flow algorithm with capacity scaling in C++: read a directed graph from /app/input.txt (n, m, followed by m edges u v c), compute max flow from node 1 to node n for n≤10^5, m≤10^6, and write the max flow value and per-edge flows to /app/output.txt.",,
fb6af83f-3b02-41ca-9026-c9e3fe157dd8,Software Engineering & Development,Feature Implementation & Algorithm Development,Algorithm Implementation,Implement /app/solution.py with a function count_distinct_palindromes(s: str) -> int that builds a palindromic tree (Eertree) to count all distinct palindromic substrings modulo 10^9+7 in O(n) time and memory for |s| up to 10^6. The implementation must run in a single pass without external libraries.,,
f5e2a2e3-5824-4450-9553-b07079d18858,Software Engineering & Development,Feature Implementation & Algorithm Development,Algorithm Implementation,"Implement the Aho–Corasick algorithm in Python to perform multi-pattern Unicode string matching with time complexity O(n + total_pattern_length + matches), reading patterns from /app/data/patterns.txt and text from /app/data/text.txt and writing a JSON mapping each pattern to its sorted list of match positions to /app/data/matches.json. Do not use regular expressions or external libraries for pattern matching, and enforce iterative trie construction and traversal without recursion.",,
190c8e12-b9ec-4c69-8099-8e8a9f6d7610,Software Engineering & Development,Feature Implementation & Algorithm Development,API Design & Integration,"Implement a Node.js Express gateway that validates JWT Bearer tokens, proxies calls to two local mock microservices (/users and /orders), aggregates user info and orders at GET /api/users/:id/orders, and serves an OpenAPI v3 spec at /openapi.json. Add in-memory TTL caching for user lookups, proper error mapping, and satisfy the provided integration test suite.",,
cddf0b6f-98d5-45cf-aa29-c60c3b7018fc,Software Engineering & Development,Feature Implementation & Algorithm Development,API Design & Integration,"Implement a Node.js Apollo GraphQL server that integrates two provided REST services (/api/users and /api/transactions) into a unified schema with User, Transaction, and Summary types. Support nested queries for user transaction history with pagination, caching via DataLoader, and proper error propagation in resolvers.",,
9e764e7e-5473-4e70-a89f-37c97c76b722,Software Engineering & Development,Feature Implementation & Algorithm Development,API Design & Integration,"Implement a Node.js aggregator microservice that authenticates via JWT, fetches user profiles from a GraphQL backend and payment records from a SOAP endpoint, merges and normalizes results, and exposes a paginated RESTful /users/{id}/account endpoint. Generate OpenAPI documentation, handle error mappings and timeouts gracefully, and include an automated integration test suite using mock GraphQL and SOAP servers.",,
0de0d849-afa1-48e6-a11e-d49ce5df133d,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Architecture & Modularization,"Given a legacy single-file Python CLI tool at /app/tool.py, refactor it into a package with separate modules for commands, utilities, and configuration, implementing a plugin registry that discovers and loads sub-modules dynamically at startup. Update the entry-point script and tests to reflect the new package layout while preserving existing behavior.",,
7c814869-19f3-48ed-832a-71abea725e58,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Architecture & Modularization,"Refactor a monolithic Python CLI tool that handles data transformations for multiple file formats into a plugin-based architecture, separating the core framework from file-format plugins and enabling dynamic discovery and registration of new plugins.",,
6a4c3788-155b-4ba2-a463-829b51a14cd2,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Architecture & Modularization,"Refactor a legacy Python monolithic CLI tool into a plugin-driven architecture that dynamically discovers and loads subcommands from separate modules, preserving all existing behaviors and tests. Provide a plugin scaffold generator and an automated test suite to verify modular loading, version isolation, and conflict detection.",,
a058055f-af98-4be8-8124-eb815c220aed,Software Engineering & Development,Development Tooling & Workflow Automation,Build Tool Configuration,"Configure a TypeScript monorepo using Yarn workspaces and Lerna to hoist shared dependencies, enable incremental builds via caching, and implement a Git-driven release pipeline that auto-generates per-package changelogs and publishes only changed packages to npm.",,
9497703b-73b8-4f86-8001-cdff41d429bf,Software Engineering & Development,Development Tooling & Workflow Automation,Build Tool Configuration,"Configure Poetry for a Python monorepo with two interdependent packages (core and cli), define dev/test dependency groups, and add custom scripts for linting, testing, and building wheels. Integrate a dynamic versioning plugin and ensure generation of reproducible lockfiles across multiple Python environments.",,
27d2bfbf-fa28-4c3a-8571-85857bfdaf63,Software Engineering & Development,Development Tooling & Workflow Automation,Build Tool Configuration,Set up an npm monorepo using Yarn Workspaces to manage multiple TypeScript packages with custom tsconfig path mappings and a build script that compiles packages in dependency order. Configure semantic-release in GitHub Actions for automated semantic version bumps and changelog generation upon merging to main.,,
0c22a209-e716-4453-8212-a95b16a29364,Software Engineering & Development,"Collaboration, Review & Documentation",Change Log & Release Notes,"Implement a command-line tool that scans a multi-package monorepo for conventional commits since the last semver tag, groups changes by package and commit type (features, fixes, docs, breaking), updates each package’s CHANGELOG.md following Keep a Changelog, and outputs a consolidated release-notes.md summarizing all updates.",,
de72eac8-5b5f-4d1b-9727-0b662a66608c,Software Engineering & Development,"Collaboration, Review & Documentation",Change Log & Release Notes,"Implement a Python CLI tool that, given two git tags or date ranges, fetches merged pull requests and closed issues from the GitHub API, groups them by change type based on labels (e.g., Added, Fixed, Security), aggregates unique contributors, and generates a CHANGELOG.md adhering to the Keep a Changelog specification.",,
c4d2e7ef-4ea2-4afb-b926-6d6c555afa60,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Code Cleanup & Refactoring,"Detect duplicated code blocks of five or more lines in a codebase via AST normalization, extract them as reusable functions in a new utilities module, and refactor source files to replace duplicates with calls to these new functions.",,
f7ba04b8-c252-4600-b509-639035565c53,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Code Cleanup & Refactoring,"Refactor a legacy Flask application monolith (app.py) with inline SQL and bulky route handlers into a structured package using Flask Blueprints and SQLAlchemy models while preserving existing endpoints. Ensure PEP8 compliance, consistent naming, modular directory layout, and add pytest tests to confirm unchanged behavior.",,
a478638b-4c3f-4457-a875-451fba3e6cf9,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Code Cleanup & Refactoring,"Refactor a legacy Python CLI tool in /app/tool.py that handles multiple subcommands in a single file by extracting each command handler into its own module under /app/commands, consolidating shared error handling into a common exceptions module, removing dead code and unused imports, enforcing PEP8 naming and style, and adding comprehensive module-level docstrings. Ensure that the refactored code runs identically and passes all existing integration tests for each subcommand.",,
7914a033-461f-4ea7-9154-196b7592aefb,Software Engineering & Development,Feature Implementation & Algorithm Development,Code Generation & Automation Utilities,"Implement a Python CLI script at /app/generator.py that reads a JSON schema file defining entities (names and typed fields) and auto-generates Python dataclasses and SQLAlchemy models in /app/models.py. The tool must also produce an Alembic migration stub under migrations/versions/<timestamp>_initial.py reflecting the schema changes, and accept the schema path via a --schema argument.",,
326a3386-bcfa-43bd-af42-254c11b4bbaf,Software Engineering & Development,Feature Implementation & Algorithm Development,Code Generation & Automation Utilities,"Implement a Node.js CLI named api-scaffold that reads an OpenAPI 3.0 JSON spec and generates Express.js route handlers with Joi validation, corresponding EJS-based controller stubs, a Dockerfile, and a GitHub Actions CI workflow. The tool must support custom template overrides via a --template-dir flag and output a manifest of generated files with checksums.",,
332f975b-d135-4cd0-af42-e261d412a541,Software Engineering & Development,Feature Implementation & Algorithm Development,Code Generation & Automation Utilities,"Create a CLI tool that reads JSON schema files for request and response types and scaffolds fully typed Express.js route handlers with input-validation middleware, OpenAPI snippets, and Jest test stubs. Support custom file templates, schema-to-TypeScript interface generation, and configurable output paths.",,
62c34ca5-50ee-40b4-8df0-b9a677c7671b,Software Engineering & Development,"Collaboration, Review & Documentation",Code Review & Peer Feedback,"Implement a CLI tool that clones a Git repository, checks out a specified pull request using the GitHub CLI, runs configurable linters and type checkers against only the changed files, then aggregates all findings into an inline Markdown formatted review report. The report should map violations to diff hunks, include summary statistics and actionable suggestions, and be output to review_report.md.",,
4e0cc117-642c-4d49-a2f2-542fef14f9f0,Software Engineering & Development,"Collaboration, Review & Documentation",Code Review & Peer Feedback,"Clone the sample repository and review the provided pull request that refactors a Node.js Express API from JavaScript to TypeScript; identify at least five issues covering type coverage gaps, error handling holes, missing tests, and documentation inconsistencies, leave inline review comments via the GitHub CLI, and conclude by approving the PR or requesting changes with a summary comment.",,
56986b1c-c184-4f9c-95a8-31ef93b51a2a,Software Engineering & Development,"Collaboration, Review & Documentation",Code Review & Peer Feedback,"Implement a CLI code review assistant that takes two Git commit refs, analyzes diffs for style violations, missing documentation, complexity hotspots, and security concerns, and generates an annotated Markdown review with inline comments. Allow custom rule definitions in YAML and produce a JSON summary of all review items including file, line number, comment, and severity.",,
32fb7ba3-4573-479e-9593-ab332a46da59,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Implement a CLI utility that generates a file manifest of all ELF binaries in /usr/local/bin, computes SHA-256 checksums, and cryptographically signs the manifest with an RSA key; in verify mode it must validate the manifest signature and ensure no binaries have been altered.",,
daa98ac8-c1ca-4b51-a3bf-cafb27415380,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Implement a Python CLI tool with a ""sign"" mode that scans a directory of build artifacts, computes their SHA256 hashes into a JSON manifest, and signs the manifest using a provided RSA or ECDSA private key PEM. In ""verify"" mode, the tool validates the manifest’s signature with the corresponding public key, re-hashes each artifact to confirm integrity, and emits a structured JSON report of any mismatches.",,
b5a1c14c-5733-4127-91bf-0cd756187fdb,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Implement a Python CLI tool that generates or loads an RSA key pair in /app/keys, computes SHA256 checksums of all files under /app/src, writes a checksum manifest, signs it with the private key to produce manifest.sig, and then verifies the signature with the public key, exiting non-zero if verification fails.",,
24a06416-5ba9-4724-a2d2-26eb0c911762,Software Engineering & Development,Software Architecture & Design Patterns,Codebase Architecture Documentation,"Implement a CLI tool that scans a Python project’s source tree to extract module import graphs, class inheritance hierarchies, and function call relations, then auto-generates a PlantUML component diagram along with a Markdown report of dependencies and complexity metrics. The tool should detect and report any circular dependencies among core packages and integrate with Git hooks to keep architecture docs up to date.",,
f23dcc58-11d4-48ee-8338-a889036e4869,Software Engineering & Development,Development Tooling & Workflow Automation,Continuous Integration (CI) Pipelines,"Implement a GitHub Actions workflow for a Rust project that builds the code, runs unit tests and Criterion benchmarks, compares results against a baseline stored as a previous-artifact JSON, and annotates pull requests with performance regressions or improvements.",,
007a9e72-5bef-45c1-b9fc-998b7c95b593,Software Engineering & Development,Development Tooling & Workflow Automation,Continuous Integration (CI) Pipelines,"Create a GitLab CI configuration (.gitlab-ci.yml) for a Java Maven project that caches dependencies, runs Checkstyle linting, executes JUnit tests in parallel, performs a SonarQube code analysis, and builds plus tags a Docker image for deployment. Ensure the pipeline uses appropriate cache keys, triggers non-blocking quality checks, and only pushes images on tagged releases.",,
5d0dfb2e-4d8a-4bfc-b4f3-e381cd2c8217,Software Engineering & Development,Development Tooling & Workflow Automation,Continuous Integration (CI) Pipelines,"Implement a GitHub Actions CI workflow for a multi-language monorepo that dynamically detects changed services, builds a job matrix to compile Go modules, run Python tests and lint JavaScript packages, caches per-service dependencies, uploads test artifacts, and posts a summary comment on the PR with failed modules. Include conditional deployments on version tags and secret-managed code coverage reporting to Codecov.",,
87874037-b3ff-487a-81ae-14704c4d9ea6,Software Engineering & Development,Development Tooling & Workflow Automation,Continuous Integration (CI) Pipelines,"Write a GitLab CI configuration that first builds a Rust library crate and pushes it to a mock local registry service container, then runs a Python tox test matrix (3.7–3.10) to build and validate a ctypes-based wrapper wheel with a minimum coverage gate and cached dependencies. Finally, on protected branches only, publish generated Sphinx documentation to GitLab Pages.",,
458c3660-05ce-4bcd-a366-81e5e08c4833,Software Engineering & Development,"Testing, Validation & Quality Assurance",Continuous Testing Integration,"Implement a GitHub Actions CI workflow that caches dependencies for a polyglot repository, runs linters and unit tests for Python and Node.js in parallel Docker containers, and collects JUnit XML reports. Extend the pipeline with a Docker Compose–based end-to-end integration test stage, enforce coverage thresholds, and fail the build on unmet criteria.",,
90405636-3f0c-4b93-9919-c280ad35734a,Software Engineering & Development,"Testing, Validation & Quality Assurance",Continuous Testing Integration,"Implement a GitHub Actions workflow in .github/workflows/ci.yml that runs pytest-based unit and integration tests across Python 3.8–3.11, measures coverage with coverage.py, caches dependencies for speed, uploads reports to Codecov, and fails the build if coverage falls below 90%.",,
edbeec48-e198-483a-92e0-804449450bc6,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Implement a Python CLI tool in /app/generate_spdx.py that parses requirements.txt, package.json, and go.mod to collect all direct and transitive dependencies with versions and license metadata. Validate each license against the SPDX license list and output an SPDX 2.2 SBOM JSON at /app/spdx_sbom.json, listing any dependencies with missing or unrecognized licenses.",,
2dc81eaf-8199-4b5c-bd35-cfee9297fc0a,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Implement a shell script at /app/license_checker.sh that loads allowed license identifiers from /app/policy.json; scans Python requirements.txt (using pip-licenses) and Node package-lock.json (using license-checker) to detect any disallowed or unknown licenses. The script must output a colorized compliance summary, emit an SPDX SBOM to /app/dependency.spdx, and exit with a non-zero status on any policy violations.",,
d3673496-63e5-4031-a4f2-b7dd3f387738,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Dependency Modernization,"Upgrade a Maven-based Java Spring Boot 1.x web service to Spring Boot 2.x by updating POM dependencies, refactoring deprecated APIs, and adjusting configuration properties per the official migration guide. Ensure all unit and integration tests pass under the new dependency set without modifying any test code.",,
58be24fa-87f0-4309-b7ef-01d2765ccf05,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Dependency Modernization,Upgrade a Vue.js monorepo from Vue 2 and Vue CLI 3 to Vue 3 and Vite by refactoring components to the Composition API and updating all package.json dependencies across packages. Ensure that each package’s build and test suite passes unchanged functionality under the new stack.,,
0ed0a593-90c6-425f-bed1-dceb216e76b1,Software Engineering & Development,Software Architecture & Design Patterns,Design Pattern Implementation,"Implement a Python CLI calculator that applies the Strategy pattern with a Factory to dynamically load arithmetic and string operation plugins from a directory. The main script must auto-discover, register, and execute new operations dropped into the plugins folder without modifying the core code.",,
0a4cee5c-ab9e-412f-b0c0-3f8f259fef60,Software Engineering & Development,Software Architecture & Design Patterns,Design Pattern Implementation,"Implement a Python HTTP request pipeline using the Chain of Responsibility pattern, where handlers for authentication, validation, routing, and logging are modular classes wired via a JSON configuration. The program must load simulated requests from /app/requests.json, process each through the configured chain, and write structured responses to /app/responses.json.",,
7e768001-145e-43ef-b228-b01e6dd755e0,Software Engineering & Development,Development Tooling & Workflow Automation,Developer Environment Setup,"Write a Dockerfile and VSCode DevContainer configuration that provisions a reproducible x86_64 container capable of cross-compiling and emulating ARM64 binaries via QEMU binfmt support, preinstalled with build-essential, CMake, Ninja, and Git. The environment should automatically register QEMU, compile a sample ARM64 HelloWorld program, and verify it runs correctly under emulation.",,
17b0c004-4828-48a9-825e-791717e1e1fc,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Create a Dockerized Python/Flask mock payment gateway exposing /charge, /refund, and /status endpoints with configurable success/failure rates, HTTP error injections, timeouts, and idempotency key handling. Include fixtures or scripts to launch the service and generate synthetic transaction logs for testing client retry logic and error recovery.",,
07ea6a18-584d-4593-84a8-a73c4e1888c0,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Implement a Python-based mock HTTP streaming service that simulates an external IoT sensor endpoint by emitting configurable JSON Lines events at a defined rate, supporting custom JSON Schema definitions, timestamp offsets, and injection of controlled anomalies (e.g., missing fields, out-of-range values, or malformed payloads). Provide a CLI that loads schema and anomaly schedules from YAML, writes static fixtures to /app/data/fixtures/, and validates all outputs against the loaded schemas with detailed error reports.",,
ffe49138-0b6b-4360-bedc-cbf0cbc070c8,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Implement a Dockerized mock payment gateway service that reads a YAML config defining transaction success/failure rates, latency distributions, and error codes, exposing a REST API compatible with Stripe’s charge and refund endpoints. The service should support dynamic behavior profiles and record all request-response logs for integration tests.",,
bf53bd9f-706d-4013-bae7-e14de488a406,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Implement a configurable Python-based HTTP mock server that simulates a downstream microservice by generating JSON responses, timeouts, HTTP errors, and rate limits on specified endpoints. Provide a CLI and YAML scenario files to define custom response behaviors and record request logs for integration tests.",,
17e2a481-ae4d-4b3c-b64a-d4910c05f3a5,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Performance Profiling & Optimization,"Given a legacy Python script that merges, deduplicates, and sorts millions of JSON-lines records across multiple large files using nested loops and full in-memory loading, profile CPU and memory usage with cProfile and memory_profiler then refactor to use streaming algorithms and generators to reduce runtime and peak memory. Validate that the optimized version produces identical output within a 60-second time limit and under 1 GB of RAM.",,
3ac60e42-2768-4ed4-a1b0-ab6c7db6a8e0,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Performance Profiling & Optimization,"Profile an existing Node.js CSV processing service to identify CPU and memory hotspots using the V8 profiler, then refactor it to use streaming, worker threads, and more efficient data structures to reduce peak memory usage below 50 MB and increase throughput by at least 3×, while preserving output correctness.",,
6f3217f3-9ccd-4306-b5f2-8c111fa12719,Software Engineering & Development,"Code Maintenance, Refactoring & Optimization",Performance Profiling & Optimization,"Given a Python ETL script that reads a multi-gigabyte JSONL file, transforms entries with nested JSON parsing, and writes results, profile with memory_profiler and cProfile to identify CPU and memory bottlenecks. Refactor to use iterative streaming (ijson), optimized parsing, and concurrency (multiprocessing or asyncio), then output before-and-after runtime and peak memory usage metrics in JSON.",,
2baf5dfd-7b5f-4401-99fc-6308fbabd878,Software Engineering & Development,"Collaboration, Review & Documentation",Project Management & Issue Tracking,"Implement a CLI tool that uses the GitHub API to auto-triage issues: it should label issues inactive for a configurable period as 'stale', post reminder comments, and close them after a second threshold. Generate both JSON and CSV summary reports of all actions taken.",,
8ace8f48-47d5-4fd7-a298-6729f7610d0f,Software Engineering & Development,"Collaboration, Review & Documentation",Project Management & Issue Tracking,"Implement a Python-based CLI that reads a JSON file defining new and stale GitHub issues, uses the GitHub CLI (gh) to batch-create, label, assign, and close issues based on a ‘stale’ flag and age threshold, and writes a Markdown summary report to /app/data/issue_report.md.",,
199bb9b1-0d54-492e-8c27-7419b2334cc7,Software Engineering & Development,"Collaboration, Review & Documentation",Project Management & Issue Tracking,"Implement a CLI tool that reads a YAML file of tasks in /app/issues.yaml, uses the GitHub CLI to idempotently create or update GitHub issues (including summary, description, labels, and assignees), transitions issues through a specified workflow state mapping, and outputs a consolidated report JSON of created, updated, and failed operations to /app/issues_report.json.",,
e0a37b3a-1375-47e4-b05f-c825987d8ab1,Software Engineering & Development,"Collaboration, Review & Documentation",Project Management & Issue Tracking,"Create a CLI script that retrieves open GitHub issues, applies labels and assignees based on keyword mappings defined in a YAML config, and posts a summary comment on each updated issue. Ensure idempotent behavior so rerunning the tool skips already-triaged issues without duplicating labels or comments.",,
7bd0b2ae-1a11-4166-b7c1-7c870c8475ae,Software Engineering & Development,"Collaboration, Review & Documentation",Project Management & Issue Tracking,"Implement a CLI tool that fetches GitHub issues and pull requests merged between two repository tags, groups them by label into features, bug fixes, and chores, and generates a formatted CHANGELOG.md in the project root.",,
461ee99f-aa02-4e43-8d02-18a597f28a8d,Software Engineering & Development,Software Architecture & Design Patterns,Refactoring for Maintainability,"Given a monolithic Python Flask application where route handlers, business logic, and database calls are all in a single file, refactor it by applying the Factory and Repository patterns. Extract Blueprints for routes, service modules for logic, and a data-access layer while preserving the existing HTTP interface and automated tests.",,
b670bc6b-1388-4a0d-8eee-ebe8b6a925fe,Software Engineering & Development,Software Architecture & Design Patterns,Refactoring for Maintainability,"Refactor a monolithic Python Flask application that combines routes, business logic, and data access in a single file into a modular structure using Blueprints, service and repository layers, and dependency injection. Ensure all existing endpoints function identically and that the full test suite passes without modification.",,
2854c084-3daa-4f94-84eb-13b7b36aff50,Software Engineering & Development,Software Architecture & Design Patterns,Refactoring for Maintainability,"Given a monolithic Node.js Express API with mixed route handlers and data access, restructure the code to apply the Repository pattern and dependency injection via Inversify, extracting business logic into services and decoupling the data layer modules. Preserve all existing API endpoints and behaviors while introducing comprehensive unit tests for each service to validate refactored components.",,
f5b9a9aa-92ab-4dfd-b37a-97bcd1dec211,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a Python ResilientKVClient that connects to two Redis instances with idempotent get/set methods, applying exponential backoff with jitter on network errors and automatically failing over to the secondary after five retries while logging each attempt to /app/logs/client.log. Provide a CLI script that reads batch operations from /app/ops.txt, skips malformed lines gracefully, and include a Docker Compose setup to simulate Redis node failures for automated testing.",,
db1a1c7a-6678-4555-aa2c-9d048d9d3072,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a Python HTTP client wrapper using the circuit breaker pattern with per-endpoint failure tracking, adaptive exponential backoff with jitter, and half-open recovery trials, emitting structured metrics. Provide a Docker-based Toxiproxy test harness that simulates latencies, timeouts, and failures to automatically validate retry and failover behaviors under load.",,
954c30fe-75f9-40e9-8e0d-7e2122fed637,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a Python HTTP client wrapper that supports jittered exponential backoff retries, a sliding-window circuit breaker with configurable thresholds, and pluggable fallback handlers while exporting Prometheus metrics. Provide a CLI that loads backend endpoints from /app/config/backends.json, simulates intermittent failures, and demonstrates graceful degradation.",,
90b83622-de81-495c-b639-27bbcfc9ea0e,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a Python HTTP client library at /app/client.py that provides reliable REST calls with configurable retry policies (including exponential backoff with jitter), a circuit breaker to stop cascading failures, and automatic failover to secondary endpoints. Include logging of metrics, customizable timeouts, and automated tests that simulate transient errors to verify retries and graceful degradation.",,
66274159-35a2-4e18-9ef1-e0ffda96dbfb,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a Python CLI wrapper that executes arbitrary subprocess commands with configurable retries, exponential backoff and jitter, and a circuit breaker that stops retries after N consecutive failures, logging each attempt’s metadata to JSON. Provide automated tests simulating flaky commands to validate correct retry timing, jitter behavior, and circuit breaker activation.",,
cfc4bc43-abe5-42c5-b412-c1ae17dce573,Software Engineering & Development,Debugging & Issue Resolution,Runtime Error Debugging,"Diagnose and fix an intermittent segmentation fault in a multithreaded C++ application handling JSON parsing, using AddressSanitizer and GDB to uncover data races or use-after-free bugs, then submit a patched version with thread-safe modifications and a brief root-cause report.",,
e8d3ba49-83f9-472f-88a1-58fcf8b994d3,Software Engineering & Development,Debugging & Issue Resolution,Runtime Error Debugging,Diagnose and fix a segmentation fault in a C++ linked list implementation by using gdb and AddressSanitizer to identify a double-free and correct the destructor and pointer handling.,,
f70e5e5f-ae67-4d66-9af2-e193687590bd,Software Engineering & Development,Debugging & Issue Resolution,Runtime Error Debugging,"A multi-threaded C++ connection-pool service sporadically segfaults under concurrent load; the agent must reproduce the crash in the provided harness, analyze AddressSanitizer and gdb output to pinpoint the data race, and implement a thread-safe fix to prevent invalid memory access.",,
667800db-201f-4ba6-abcc-977a7b62d00d,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Secure Coding Practices,"Provide a Node.js Express application seeded with intentional SQL injection and XSS vulnerabilities; implement a CLI-driven patcher that identifies unsafe string concatenations in database queries and HTML rendering, refactors them to use parameterized queries and a secure templating engine, and validates fixes via automated tests.",,
9fc2eb7f-be8d-4a4e-b419-e11d2023a82b,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Secure Coding Practices,"Create a Git pre-commit hook in Python that scans staged code for insecure patterns such as eval() usage, shell calls with unsanitized input, or hardcoded secrets using regex rules, blocking commits with violations and outputting custom violation messages. Provide a configuration file to whitelist allowed patterns and integrate the hook into .git/hooks/pre-commit.",,
872164bf-e282-485d-9733-28c96355d94e,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Secure Coding Practices,"Implement a Python CLI tool that statically analyzes a codebase’s AST to identify insecure subprocess invocations using shell=True or unsanitized string arguments. The tool should generate a JSON report with file locations, code snippets, and produce a patch transforming those calls into secure list-based invocations.",,
6b814f78-0538-4ef3-b24e-c8ecd7c1052a,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Create a flake8 plugin named flake8-complexity that enforces per-function cyclomatic complexity thresholds, limits nested list/dict comprehensions to two levels, and verifies NumPy-style docstrings. The plugin must read rules from setup.cfg, emit custom error codes in flake8 format, and support an --auto-fix flag that generates patch files for whitespace and import-order corrections.",,
c38464a3-ec7a-4292-8346-958d3049c314,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Develop a custom flake8 plugin that enforces project conventions—banning wildcard imports outside test modules, flagging mutable default arguments, and requiring type annotations on all public functions—exposing distinct error codes and offering auto‐fix suggestions via the AST API.",,
5766aa18-13d0-4c6f-9f9b-f7c2780a3124,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Create a Dockerized CLI tool that scans the /app/src directory with flake8 (using a provided flake8.ini), mypy (strict mode), and a custom regex-based linter for banned patterns (e.g., TODO comments or print statements), then aggregates and classifies all findings into /app/report.json with per-file, per-tool violation counts and severities. The script should exit with code 0 if no violations are found or with the total count of violations otherwise.",,
7aa66e6b-b740-4f81-b0ed-15faf05c7d1f,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Create a custom Flake8 plugin that identifies Python functions using mutable default arguments, package it as an installable module, configure .flake8 to enable the rule, and run the linter on a sample codebase to produce a JSON-formatted report of all violations.",,
79a4b5af-5e60-436f-830c-33103e633365,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design and implement a Python-based plugin-driven data processing pipeline with clearly defined modules: a core engine, plugin interface definitions, dynamic loader, and configuration manager, ensuring inversion of control and separation of concerns. Provide a module dependency graph and enforce initialization and teardown order for plugins loaded from /app/plugins.",,
e01d79ad-757a-4ff7-a15e-20e84fcce723,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design a pluggable CLI data-processing pipeline composed of independent ingestion, validation, transformation, and export modules, specifying clear interfaces, data contracts, error handling, and dependency boundaries so new formats or steps can be added without modifying the core engine.",,
e6045add-7721-4191-9ca5-ff68bf3b40bc,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Implement a Python event-sourcing library that defines aggregate roots, an append-only event store with configurable backend adapters (using SQLite by default), snapshotting and transactional commits, and expose a CLI for appending events, replaying streams, and querying aggregate state by ID.",,
b87cad9d-d47e-46a1-ad7e-c7d3129757b2,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Create a Python ETL framework with separate modules for extractors, transformers, and loaders, each defined by abstract interfaces in interfaces.py. Implement plugin classes (e.g., CSV and JSON extractors, filter and map transformers, SQLite loader), dynamically assemble pipelines from a YAML config, and verify data flow correctness via unit tests.",,
30c0b7af-f06a-4488-88ec-1723169400ac,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design and implement a modular CLI backup utility where each stage (file discovery, compression, encryption, storage) is a pluggable module implementing a common interface and loaded dynamically via a JSON configuration. Specify clear module interfaces, dependency relationships, and the data flow pipeline so that new compression or storage backends can be added without modifying core logic.",,
8e3ed754-0a0a-43c8-9f3d-2888929a7e1b,Software Engineering & Development,Development Tooling & Workflow Automation,Toolchain Customization & Extensions,"Create a Pylint plugin that parses Python AST to detect blocking I/O calls inside async functions, emits warnings with suggested asyncio.to_thread wrappers, and supports configuration and installation via pyproject.toml with accompanying unit tests.",,
315489fc-40de-43df-b48b-dd73ef754b90,Software Engineering & Development,Development Tooling & Workflow Automation,Toolchain Customization & Extensions,"Write a custom plugin for the Python Language Server (pylsp) that enforces type hints on all function signatures (code TYPE001) and flags missing docstrings (code DOC002). Provide a shell script that installs pylsp, enables the plugin, runs it on sample Python files, and outputs JSON-formatted diagnostics.",,
e35774d5-fff0-472e-a9f4-e898d7f95aff,Software Engineering & Development,"Testing, Validation & Quality Assurance",Unit & Integration Test Implementation,"Write pytest unit tests for a JSON Schema resolver module that uses networkx to detect cycles and resolves $ref pointers (mocking filesystem and HTTP requests), and integration tests that invoke its CLI on various schemas to verify correct resolution, error reporting, and cycle detection.",,
251418a4-c75c-4a01-a34f-4ab98c2218ed,Software Engineering & Development,"Testing, Validation & Quality Assurance",Unit & Integration Test Implementation,"Write pytest test modules for a Python CLI utility that archives and encrypts directories using tar and GPG; tests should mock subprocess calls, verify correct command invocations under both success and failure scenarios, and use temporary file fixtures to simulate streaming input and output.",,
29f0cde2-6681-4f50-a903-4c6a8f77608b,Software Engineering & Development,"Testing, Validation & Quality Assurance",Unit & Integration Test Implementation,"Write pytest unit tests for a Python CLI HTTP downloader that supports concurrent downloads, exponential backoff retries, and resuming partial transfers, using mocks to simulate network failures and verifying exit codes and logs. Additionally, implement integration tests using a local HTTP server to validate actual file downloads, concurrent chunking, and resume behavior across interruptions.",,
caa1878d-634b-4b38-9ab8-4aafa084d0a2,Software Engineering & Development,Development Tooling & Workflow Automation,Version Control & Branching,"Implement a script that automates git bisect to find performance regressions by running a provided benchmark at each step, marking commits as good or bad based on configurable thresholds, and outputting the commit hash introducing the slowdown.",,
b090e01e-6bd8-4e4d-857d-ec6b2a7600a2,Software Engineering & Development,Development Tooling & Workflow Automation,Version Control & Branching,"Using Git, perform an interactive rebase on the feature/login branch to squash WIP and fixup commits into logical units and resolve any conflicts in src/auth.js. Then force-push the cleaned branch to origin and create a draft pull request against main using the GitHub CLI.",,
cbaa3e92-d644-45e3-8751-782325618441,Software Engineering & Development,Development Tooling & Workflow Automation,Version Control & Branching,Write a shell-based CLI tool that automates creating a release branch by cherry-picking bugfix commits matching a user-specified regex from 'main' into a new 'release/x.y' branch. The tool should automatically resolve whitespace and import-order conflicts using a custom Git merge driver and generate a Markdown-formatted changelog from the applied commit messages.,,
bd1117a2-1f64-4edd-90df-eb3b54bcab31,System Setup & Configuration,Cloud & Remote Environment Configuration,Cloud CLI Setup,"Install and configure AWS CLI, gcloud, and Azure CLI to use local emulators (LocalStack, gcloud Pub/Sub emulator, and Azurite) with isolated named profiles and custom endpoints, persisting settings in the standard credential/config files. Validate by switching profiles and creating a test S3 bucket, Pub/Sub topic/subscription, and Azure Blob container, then listing them to confirm connectivity.",,
e84bb8f3-8955-4373-8b48-f2bc6d6a3269,System Setup & Configuration,Cloud & Remote Environment Configuration,Remote Session & SSH Configuration,"Provision a bastion and an internal SSH service, create OpenSSH user and host CAs, and configure both servers to accept only CA-signed keys (password auth off), installing host certificates and @cert-authority entries in known_hosts. Add a client ~/.ssh/config with ProxyJump so 'ssh internal-via-bastion' works, verify scp through the jump, and demonstrate a local port forward (15432 -> internal:5432) established via the bastion.",,
4ecfe69e-8c24-4b8c-b686-fa53289460a4,System Setup & Configuration,Cloud & Remote Environment Configuration,Remote Session & SSH Configuration,"Provision two OpenSSH servers (bastion and private) on an isolated network and configure the client to reach the private host only via the bastion using ProxyJump with per-host identities in ~/.ssh/config. Disable password authentication, hash and pin host keys in known_hosts, block direct access to the private host, and verify by copying a file and executing a remote command through the jump while confirming direct SSH to the private host fails.",,
cc7d1125-755c-47e7-bfde-dab4d105ab10,System Setup & Configuration,Software & Package Management,Dependency Verification & Repair,"Recover a Debian/Ubuntu system from an interrupted apt upgrade that left dpkg in a broken state by repairing the package database, clearing partial installs, and resolving held/unmet dependencies with correct version pinning. Validate the fix by installing and running a provided CLI that initially fails due to missing libssl/libffi SONAMEs, ensuring compatibility libraries are installed properly without manual symlinks.",,
6f1a4785-b6f9-49b4-9484-a71b7ff71c3f,System Setup & Configuration,Cloud & Remote Environment Configuration,Remote Session & SSH Configuration,"Provision two local OpenSSH daemons as a bastion (port 2222) and an internal host (port 2223), create an SSH CA, sign both host keys and a user certificate, and configure the servers to accept only CA-signed certs (no passwords or raw public keys). Configure the client with @cert-authority and hashed known_hosts plus a ~/.ssh/config using ProxyJump and ControlMaster to reach the internal host via the bastion, verifying SSH and SCP work with StrictHostKeyChecking=yes.",,
1eae7700-89cd-4c63-a668-121740b79cf7,System Setup & Configuration,Cloud & Remote Environment Configuration,Remote Session & SSH Configuration,"Provision two local OpenSSH servers representing a bastion (port 2222) and an internal host (port 2223). Configure certificate-based SSH using a user CA and a host CA, disable passwords, require ProxyJump through the bastion, pre-populate known_hosts with @cert-authority entries, and verify that a single ssh command using the signed client key reaches the internal host via the bastion and creates /tmp/ok.",,
84f471e3-3c07-4883-a4c3-eef23911f81d,System Setup & Configuration,Cloud & Remote Environment Configuration,Remote Session & SSH Configuration,"Stand up two local sshd instances (bastion on one port, app on another), configure ProxyJump through the bastion, and implement OpenSSH certificate-based auth by creating a user CA to sign the client key and a host CA to sign the app host key; configure sshd and the client with hashed known_hosts using @cert-authority for non-interactive trust. Verify that connecting to the app via the bastion works passwordlessly without host-key prompts and that access breaks when certs expire or principals don’t match.",,
e1e6323c-3f6b-4a61-86fe-31e7593abd8e,System Setup & Configuration,Cloud & Remote Environment Configuration,Resource Provisioning & Management,"Provision an AWS-like stack on LocalStack using Terraform: an S3 bucket with versioning and SSE, an SNS topic, and an SQS queue subscribed to the topic via least-privilege IAM policies and resource tags. Configure AWS CLI to target LocalStack and demonstrate end-to-end by uploading to S3, publishing to SNS, verifying the message in SQS, and exporting a JSON summary of created ARNs.",,
eb6fc5eb-d33e-4e22-9157-68a176047207,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Create a 3 GiB sparse file as a loop device, partition it with GPT into two volumes (512 MiB ext4 labeled DATA and the remainder as a LUKS-encrypted XFS labeled SECRET) and set proper labels/UUIDs. Configure /etc/crypttab and /etc/fstab to unlock and mount them at /mnt/data and /mnt/secret by UUID, then verify persistence by detaching/reattaching the loop device and remounting without using device paths.",,
3855949e-a97a-4a8b-a6e6-4bfba223b71d,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Create a 3GB sparse disk image, attach it as a loop device, and partition it with GPT into a small unencrypted FAT32 partition and a LUKS2-encrypted data partition containing an LVM PV/VG/LV formatted as ext4. Mount the LV at /mnt/secure with restrictive options and persist the configuration via /etc/crypttab and /etc/fstab using UUIDs/labels, verifying it remounts correctly after detaching and reattaching the loop device.",,
bd94ead8-01a3-4b03-9f0e-a82880ed7c3c,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Provision a 3 GiB loopback disk image and partition it with GPT into: 512 MiB EFI System (vfat, label EFI), 2 GiB Linux filesystem (ext4, label DATA), and the remainder as Linux swap. Format and label each partition, mount EFI at /mnt/efi and DATA at /mnt/data, enable swap, and persist the setup using PARTUUID-based entries in /etc/fstab so all mounts reattach correctly after unmounting and remounting.",,
6e480bdd-208b-42e5-be16-078b6db251c9,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Provision an encrypted LVM-on-LUKS volume backed by a sparse loop device: create a GPT partition on the loop device, initialize it with LUKS using a keyfile, build a VG with two LVs (data and logs), format, and mount at /srv/secure/{data,logs}. Persist the setup via /etc/crypttab and /etc/fstab using UUIDs so it can be unlocked and mounted non-interactively and verified with mount -a after reattaching the loop device.",,
207aa28b-9150-40a9-98f0-b4867209bde7,System Setup & Configuration,Filesystem & Storage Management,Filesystem Permissions & Quotas,"Create a loopback-backed XFS filesystem mounted at /mnt/projects with pquota enabled and configure project quotas for two directories (/mnt/projects/build-cache and /mnt/projects/datasets) via /etc/projid and /etc/projects, setting soft/hard limits of 500MB and 1GB with a 7-day grace period. Apply setgid and default ACLs so group 'research' has rwx on both trees, then verify quota enforcement with xfs_quota reports and writes that exceed the limits.",,
2a5e5c6d-92b2-4e2c-bedd-381faaeccf47,System Setup & Configuration,Filesystem & Storage Management,Filesystem Permissions & Quotas,"Create a loopback-backed XFS filesystem mounted at /srv/projects with project quotas (prjquota) enabled, defining two directory-scoped projects via /etc/projects and /etc/projid with distinct soft/hard limits, and configuring setgid plus default ACLs for collaborative inheritance. Verify enforcement by filling each project until soft/hard limits and grace periods trigger, confirming with xfs_quota reports and observed EDQUOT failures.",,
029d5c66-f132-48ec-87fe-24489ae31052,System Setup & Configuration,Filesystem & Storage Management,Filesystem Permissions & Quotas,"Create a loopback-backed XFS volume mounted at /mnt/projects with project quotas enabled, defining project IDs for team-a (200 MiB) and scratch (50 MiB) and enforcing hard limits. Configure a shared dir with setgid and default POSIX ACLs for group inheritance, a scratch dropbox with the sticky bit, and a logs dir marked append-only via chattr, then verify quota and permission behavior with automated writes.",,
196bf81f-401f-4f8b-a2db-89dd90266f7b,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Configure a host-wide nftables firewall with default-drop policy using inet and ip6 tables: allow established/related, loopback, necessary ICMP/ICMPv6 (ND, RA, RS, PTB), and open SSH (22) and HTTP (8080) only on IPv4, with rate-limited new connections. Make the rules persistent across reboots and enable logging of dropped packets to /var/log/nftables-drop.log; verify IPv4 HTTP works while IPv6 HTTP is blocked and ICMPv6 neighbor discovery still functions.",,
1fd00472-e5d5-4c39-bed0-02b4b8e3a10d,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Configure nftables to enforce a default-deny host firewall with stateful rules. Allow loopback/established traffic, port-forward 80→8080 to a local service, restrict SSH on 2222 to 10.0.0.0/24 with rate limiting, block outbound SMTP except to smtp.example.net, log drops with prefix TB-FW, ensure persistence across reboots, and verify behavior over IPv4/IPv6 with curl/nc tests.",,
371a35a3-626b-47d5-8694-7d399e55b227,System Setup & Configuration,Software & Package Management,Dependency Verification & Repair,"Resolve a C++ runtime symbol version mismatch by installing a compatible libstdc++ (e.g., GLIBCXX_3.4.26+) on a Debian-based system where a precompiled binary fails with 'version GLIBCXX_3.4.26 not found'. Configure apt pinning/backports to upgrade only libstdc++6 and required dependencies without a full dist-upgrade, then validate the binary runs and ldd shows no unresolved symbols.",,
c86ca43f-0916-4fae-9d23-009390d6fcc4,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Configure nftables to enforce a host firewall with default drop on inbound traffic, allowing established/related and loopback, permitting HTTP/HTTPS to a local nginx, and opening SSH only after a correct 3-step UDP port-knock (1111→2222→3333 within 10s) with rate-limited access. Make the rules persistent across reboots and include a verification script that demonstrates SSH is closed before knocking, opens for 30 seconds after the sequence, then automatically closes again.",,
133f7c2e-6b3c-4d4e-a0f5-3126ffcbf3ab,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Create three network namespaces (ns1, rtr, ns2) connected by veth pairs, assign dual-stack IPv4/IPv6 addresses, enable forwarding and policy routing on the router, and run dnsmasq to provide DHCPv4, SLAAC/DHCPv6, and DNS. Verify both hosts obtain leases, resolve a custom domain, and reach each other through the router.",,
944595c0-1a1f-41f6-ba10-31e4c9d7a9d5,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Using iproute2 and network namespaces, build a routed lab with three namespaces (hostA, router, hostB): create veth links, assign static IPv4/IPv6, configure per-namespace DNS via a dnsmasq bound to the router, add policy-based routing and default routes, enable IPv4 forwarding/NAT on the router, and verify end-to-end connectivity and name resolution.",,
780e2d0c-c0ce-435b-be5b-737e448b66f7,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Build a three-namespace topology (client–router–server) with mismatched MTUs and ICMP “Fragmentation Needed” filtered, then diagnose a stalled TCP connection using tracepath/ping and tcpdump to pinpoint a PMTU blackhole. Fix the issue by permitting ICMP or enabling TCP MSS clamping and verify successful HTTP transfer end-to-end.",,
7eb31b56-ab48-4016-9822-fdccbfc2e2c7,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Create a three-namespace topology (client-router-server) where the router drops ICMP Fragmentation Needed, producing a PMTU blackhole that causes HTTPS requests to hang. Use ping with DF, traceroute, and tcpdump to confirm the issue, then fix it by enabling TCP MSS clamping (or lowering MTU) on the router and verify curl completes successfully.",,
5573c684-54e7-4aa0-9648-187a616d47ac,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Create three network namespaces (client, router, server) linked by veth; drop ICMP 'Fragmentation Needed' on the router to simulate a PMTU black hole that causes HTTP transfers to hang. Diagnose with ping -M do, traceroute, ss, and tcpdump, then fix by enabling TCP MSS clamping on the router and verify a large curl from client to server succeeds.",,
d01fd323-0d75-4d67-a15e-8d6ed6b1ec94,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Diagnose and fix stalled large file downloads caused by PMTU blackholing: use tcpdump, tracepath, and curl to confirm ICMP “Fragmentation Needed” is being dropped and that the interface MTU is misconfigured. Restore connectivity by allowing the required ICMP through iptables and/or clamping TCP MSS, then verify the transfer completes.",,
f1eff590-26f5-4ab9-b3c1-05dc6b91d885,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Simulate and diagnose a path MTU black hole using Linux network namespaces by creating a multi-hop topology with mismatched MTUs and blocking ICMP “Fragmentation Needed,” causing large TCP transfers to stall. Use ping with DF, traceroute, tcpdump, and curl to pinpoint the issue, then fix it by allowing ICMP or applying TCP MSS clamping and verify sustained transfers succeed.",,
08aad376-2611-4650-8703-4add474778e8,System Setup & Configuration,Operating System Configuration,Environment Variables & Profiles,"Create a unified environment manager that reads variables and PATH entries from ~/.config/envvars.yaml and generates shell-agnostic snippets sourced by both Bash and Zsh for login, non-login, interactive, and non-interactive sessions. Provide an envsync command to rebuild the snippets and verify PATH precedence, LANG/LC_ALL, and HTTP(S)_PROXY/NO_PROXY persist across new shells and subprocesses.",,
e0f98e9b-29a3-46b3-8ea8-70011b714d34,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Create a cgroups v2-backed systemd slice (tb-limited.slice) enforcing CPUQuota and MemoryMax, run a resource-hungry service (e.g., stress-ng via tb-hog.service) within it, and schedule it with a systemd timer that adds a randomized delay. Verify enforcement by observing throttling/OOM-kill behavior, automatic restarts, and corroborating logs via journald and systemd-cgtop.",,
d05b1315-2326-4510-9431-d360946531bb,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Create a dedicated cgroup v2 slice (batch.slice) and a templated systemd service (batch@.service) that runs a CPU/memory-intensive script under strict limits (CPUAffinity to specific cores, CPUQuota=25%, MemoryMax=150M, TasksMax=32) with automatic restart on OOM. Trigger it via a systemd timer every 2 minutes and verify via cpu.stat/memory.events that throttling and OOM handling occurred, with logs persisted to /var/log/batch/.",,
902f9a89-7fe4-41fd-9405-602f9cb61b95,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Create a sandboxed systemd service and timer that runs a worker script under cgroups v2 with CPUQuota=40%, MemoryMax=200M, CPUAffinity pinned to one core, TasksMax, and hardening options (NoNewPrivileges, PrivateTmp, ProtectSystem=strict), logging to both the journal and /var/log/worker.log. Enable and verify the limits by starting the unit, inspecting cgroup metrics, and demonstrating the timer’s persistence and randomized delay.",,
77d29579-db9e-4403-88ba-2c70f5d29d78,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Create a systemd slice and templated service constrained by cgroup v2 (e.g., CPUQuota and MemoryMax) and trigger it via a Persistent=true systemd timer to run periodic batch jobs. Verify scheduled execution, enforced resource limits, automatic restart-on-failure behavior, and logs accessible with journalctl.",,
5f49833d-16d3-47e2-9a11-7bee51c68cd0,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Define and enable a custom systemd slice (bench.slice) with cgroup v2 limits (CPUQuota=40%, MemoryMax=512M) and a service (bench-workload.service) bound to it that runs a CPU/memory stress script with Restart=always and hardened sandboxing. Add a systemd timer to schedule the workload every 5 minutes, log output to /var/log/bench-workload.log, and verify enforcement by inspecting cgroup stats for CPU throttling and memory limits.",,
62f21a46-fc60-4a31-b7fa-38008f66e763,System Setup & Configuration,Operating System Configuration,System Parameters & Kernel Settings,Configure persistent kernel core dump handling by setting kernel.core_pattern to pipe to a custom collector script that stores and compresses cores under /var/lib/cores with metadata. Create and enable a systemd service that runs a small crashing test binary with LimitCORE=infinity to verify capture and persistence across reboots.,,
772dfc83-de7c-4c47-b0ce-a884e79983fc,System Setup & Configuration,Operating System Configuration,System Parameters & Kernel Settings,"Configure system-wide core dump handling by setting kernel.core_pattern to pipe crashes into a custom /usr/local/bin/core_collector that compresses dumps under /var/cores with metadata, and disable systemd-coredump while enforcing fs.suid_dumpable=0. Persist ulimit core=0 for all users except a dedicated systemd service that overrides to unlimited, then verify by crashing a test binary from both contexts and confirming only the service produces a compressed core in /var/cores.",,
88d601ca-e940-4baf-b50a-948bcd031fba,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Create a socket-activated systemd service (myapp.socket/myapp.service) for a simple HTTP server that initially fails to start, enable persistent journald storage, and use journalctl to pinpoint the root causes (bad WorkingDirectory and missing RuntimeDirectory). Correct the unit (User/Group, WorkingDirectory, RuntimeDirectory, LimitNOFILE), set journald rate limiting, and verify the socket serves 127.0.0.1:8080 with clean, non-repeating logs.",,
074016bf-330d-43be-9c9f-c675d18771ec,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Create a systemd service and timer that runs a backup script every minute, where the initial run fails due to a missing WorkingDirectory and permission errors. Use journalctl to diagnose the failures, fix the unit (User/Group, WorkingDirectory/RuntimeDirectory, ExecStart), and verify via logs that subsequent timer invocations complete successfully with stdout/stderr captured in journald.",,
28322208-14f4-4b84-b222-f497bd3ba883,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Debug a crash-looping systemd service 'img-resizer.service' by inspecting journald and its app logs to pinpoint failures caused by PrivateTmp and a missing RuntimeDirectory (socket at /tmp/img.sock and unwritable log path). Fix the unit to use /run/img-resizer via RuntimeDirectory=, correct User/Group and dependencies, reload systemd, and confirm the service stays active and the UNIX socket handles a test request.",,
b0cb7a54-fc6f-40bc-aea4-329e421c53c4,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Debug a systemd unit 'imgsvc.service' that crash-loops on startup: journald reveals 'listen tcp :80: bind: permission denied' and write failures due to DynamicUser=yes. Update the unit to grant AmbientCapabilities=CAP_NET_BIND_SERVICE and define a RuntimeDirectory with correct permissions, then verify it binds to 0.0.0.0:80 and runs cleanly with logs visible in journald.",,
30466ab1-ae22-4af1-8dda-a6b085a001ef,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure OpenLDAP (slapd) with a base DN (dc=tb,dc=local), enabling StartTLS on 389 and LDAPS on 636 with a self-signed certificate, plus the memberOf/refint overlays and proper indexing. Create an OU and a test user with a salted hashed password, run slapd in the background, and verify authenticated ldapsearch/ldapmodify operations over TLS return expected entries.",,
eda3564f-7558-4ee7-8e37-91dd23dedc3e,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure the Mosquitto MQTT broker with plaintext (1883) and TLS (8883) listeners, password-based authentication, and persistence managed via systemd. Generate a self-signed certificate, enable the service on boot, and verify pub/sub functionality using mosquitto_pub and mosquitto_sub over both transports.",,
1e095ff0-7824-4029-9623-b8c314641059,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Create a socket-activated, templated systemd service (echo@.socket/echo@.service) for a tiny Python HTTP echo server that runs as an unprivileged user and starts on-demand when connections arrive, with instances bound to ports via the instance name. Enable sockets for ports 8081 and 9091, ensure After=network-online.target with basic hardening, and verify curl requests trigger the service and return a response while logs appear in journald.",,
0286c8a8-8408-43e8-bc3c-9caee689987b,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Create a socket-activated, templated systemd service that spawns per-connection instances of a tiny Python HTTP responder via Accept=yes on port 8080 using the inherited socket (fd 3). Verify on-demand activation with curl, that each instance exits after one request, and enable the socket to start at boot.",,
c738a0ff-aff1-4170-b882-b15ca3f419f6,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Implement a socket-activated, per-connection systemd service (using a .socket and a templated .service) that runs a minimal HTTP echo server bound to 127.0.0.1:8085 with DynamicUser and strict sandboxing. Validate that a curl request triggers on-demand startup, serves a response, then the service stops after an idle timeout while the socket remains listening.",,
c4f9f331-595a-480b-9559-8715aa056bfd,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Implement a systemd socket-activated, per-connection echo service: echo.socket listens on 127.0.0.1:12345 with Accept=yes, and echo@.service (Type=simple, StandardInput/Output=socket) runs /bin/cat with DynamicUser and strict sandboxing. Enable the socket, verify with nc 127.0.0.1 12345 that input is echoed, and confirm each connection spawns and exits a separate instance recorded in the journal.",,
7bf8af15-01ba-46b0-b8b4-ced4d963a6b2,System Setup & Configuration,Software & Package Management,Dependency Verification & Repair,"Diagnose and repair missing 32-bit runtime libraries for a provided 32-bit ELF binary (/app/bin/hello32) by enabling i386 multiarch on Debian/Ubuntu, installing required :i386 packages (e.g., libc6, libstdc++6, libgcc-s1), and refreshing the linker cache. Prove the fix by ensuring ldd shows no ""not found"" entries, the binary executes successfully, and saving the resolved ldd map to /app/output/ldd-hello32.txt.",,
b1aa3e63-c171-448b-9e51-13ef62007def,System Setup & Configuration,Software & Package Management,Package Installation & Removal,"Create a GPG-signed local APT repository served over HTTP, build and publish a hello-terminal-bench .deb to it, add the repository to sources.list with its key, then install the package using apt. Finally, remove and purge the package and verify its maintainer scripts executed by logging to a known file.",,
1e0166e9-0ab4-4f20-9700-c42e1aa4269a,System Setup & Configuration,Software & Package Management,Repository Configuration,"Create a local APT repository at /repo, serve it over HTTPS via nginx, and sign its Release/InRelease files with a newly generated GPG key; publish and index a minimal hello-world .deb. Add the repo to apt sources using signed-by, confirm apt update and package installation succeed, then demonstrate that altering the signed metadata causes apt to refuse the repo until the correct signature/key is restored.",,
58582822-3a5d-4f33-a098-bbb1792487fa,System Setup & Configuration,Software & Package Management,Repository Configuration,"Create a locally hosted, GPG-signed APT repository (served on localhost) containing a provided .deb, add it to sources using the signed-by option with a keyring in /usr/share/keyrings, and install the package from it. Demonstrate that apt rejects the repo before the key is configured and succeeds after the correct keyring is installed and referenced.",,
bdc841e1-1ede-40cc-8c11-5922628a62c9,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Create a shell-based monitor that induces CPU, memory, and disk load, samples vmstat and iostat at 1s intervals for 60s, captures top/ps snapshots, and writes /app/metrics.jsonl plus /app/resource_report.txt. The script must auto-classify the host as CPU-, memory-, or I/O-bound (verifying an injected I/O-bound scenario) and include at least one actionable tuning recommendation.",,
3c74ff12-3957-4d94-a08b-3c5b5bfe8e5a,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Create an automated profiler that runs a short, reproducible workload and samples top, ps, iostat -x, and vmstat at 1-second intervals for 60 seconds, writing CSV logs and a human-readable summary. Based on thresholds (CPU idle, iowait, swap-in/out, disk util/await), classify the bottleneck as CPU-, memory-, or disk-bound and emit one concrete tuning recommendation (e.g., adjust vm.swappiness or revisit the I/O scheduler).",,
2fffb1ee-1b04-47b0-a73b-3f2880a22428,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Create triage.sh that concurrently samples vmstat 1, iostat -xz 1, pidstat/top in batch mode for ~30s, computes averages, classifies the dominant bottleneck (CPU, memory, or I/O) using clear thresholds, and writes both a human-readable report and summary.csv of key metrics. Validate by reproducing three synthetic loads (stress-ng for CPU and memory; fio for disk) and ensure the script labels each correctly and prints tuning hints (e.g., swappiness/read-ahead adjustments) for the detected bottleneck.",,
28b601f4-709f-4d13-98c6-e108448bbcff,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Install and enable sysstat, then create a monitor.sh that samples CPU (user/system/iowait), memory (free/swap), and disk I/O (%util, await) every 5s for 3 minutes using vmstat, iostat, and ps, logging to /var/log/bench-monitor/. After completion, emit a summary.txt flagging thresholds (CPU >85%, iowait >10%, disk %util >80%), listing top 5 CPU and memory processes, and providing brief tuning recommendations.",,
7a5ffe07-c27b-4909-ab95-356bf6f62c90,System Setup & Configuration,User & Access Management,Authentication & Access Control,"Configure OpenSSH to require certificate-based user authentication using a locally generated OpenSSH CA, with TrustedUserCAKeys set and PasswordAuthentication/PubkeyAuthentication disabled. Create one valid signed client cert and one revoked cert via RevokedKeys, then verify only the non-revoked certificate can log in.",,
42addd8c-4691-48af-b2ab-53d9a0166d29,System Setup & Configuration,User & Access Management,Authentication & Access Control,"Configure OpenSSH to use an internal user CA for certificate-based logins, creating and trusting a CA key, generating and signing a client key for a new devops user, and disabling password and plain public-key authentication for that account via a Match block on port 2222. Add a least-privilege sudoers policy so devops can run only systemctl status and journalctl without a password, and verify both successful cert login and expected failures for password/unsigned keys.",,
9f5dc599-13d8-43b1-aa17-d9bd0cbc75a7,System Setup & Configuration,User & Access Management,Authentication & Access Control,"Set up OpenSSH certificate-based authentication by creating a local SSH CA, signing both the server host key and a user key, and configuring sshd to trust the CA via TrustedUserCAKeys while disabling raw public-key logins. Define two principals (admin and deploy) with per-principal restrictions (e.g., ForceCommand for deploy and full shell for admin) and verify that only a signed certificate with the correct principal can log in while unsigned or wrong-principal attempts are denied.",,
e3b93aa2-b923-4361-9942-105ae2719dae,System Setup & Configuration,User & Access Management,Authentication & Access Control,"Set up OpenSSH to use a user certificate authority for authentication: generate a CA keypair, sign a user’s key with a principal, configure sshd with TrustedUserCAKeys and AuthorizedPrincipalsFile, and disable password/non-cert public key logins. Verify the user can SSH to localhost using the signed certificate while ordinary keys and passwords are rejected.",,
63dbcd84-7726-437c-8035-ac8ef4231287,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Create a collaborative workspace at /data/projects owned by group dev with setgid, where POSIX ACLs grant dev rwX on all current and future content and interns r-X only, while a subdirectory /data/projects/secret explicitly denies user bob all access regardless of group membership. Ensure default ACLs and the mask preserve intended permissions and inheritance for newly created files and directories.",,
8b1a9e63-8de0-4f59-a09c-0126c0f35d7b,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Create a multi-purpose project area at /srv/projects/acme with three subdirectories using POSIX ACLs: incoming as a write-only 'blind dropbox' (root:submitters, 1733, sticky bit) where only file owners and the reviewers group can read their own uploads; shared as a setgid devs workspace where new files inherit devs:rwx and qa:r-x; and secrets owned by svc-ci where only svc-ci has rwx and leads have r-x, others denied. Ensure inheritance with default ACLs and mask tuning, verify effective permissions with getfacl and by creating test files as representative users.",,
e3610beb-79b3-44ba-bcaa-6967ed8e3cab,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Create a multi-team workspace in /srv/work using POSIX ACLs, default ACLs, setgid directories, and sticky bits so new files inherit the correct group and permissions: alpha/ and beta/ are rwX for their teams, read-only to the other team, ops has rwX everywhere, dropbox/ is write-only for all except owners and ops, and secrets/ is ops-only. Validate effective rights and inheritance by creating test files as alice, bob, carol, and an ops user via su, and confirming expected access with getfacl and targeted read/write attempts.",,
d54e3371-71a0-4dbb-a38d-84c477a0a014,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Create a multi-tenant /data/workspace with subdirectories shared, dropbox, and pii using POSIX ACLs plus setgid/sticky bits to enforce role-specific access (dev/audit/intern): shared RWX for dev+audit with interns read-only, dropbox write-only for interns with sticky, and pii RWX for dev, read-only for audit, no access for interns. Configure default ACLs so new content inherits correctly and adjust the ACL mask to demonstrate effective permission reduction where required.",,
7e7e749a-263c-48f7-a5a7-7661db5e2404,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Provision a collaborative workspace at /srv/projects/alpha with users (alice, bob, charlie) and groups (dev, qa), enforcing via POSIX ACLs and setgid that dev has rwX, qa has r-X, while a secrets subdirectory is accessible only to alice. Configure default ACLs so new files inherit these rights, set the sticky bit on an uploads subdirectory, and validate effective permissions with getfacl and test file operations.",,
803482fd-3001-46ec-b546-68c57dd6ae75,System Setup & Configuration,User & Access Management,User & Group Administration,"Bulk onboard users from /app/new_hires.csv by creating accounts with per-user private groups, specified shells, home directories seeded from /etc/skel, and installed SSH authorized_keys; enforce password expiry on first login and set default umask to 027 for new users. Create dev and ops groups with least-privilege sudo rules in /etc/sudoers.d and emit a JSON report summarizing each user’s UID, group memberships, home permissions, and sudo access.",,
e60f0777-c61b-4e94-a139-4d6872c3fecd,System Setup & Configuration,User & Access Management,User & Group Administration,"Provision role-based local accounts with granular sudo and login constraints. Create groups dev, ops, and wheel and users alice (dev), bob (ops), and backup (service); configure sudoers so ops can run systemctl and journalctl without a password, only wheel may su to root, dev may only run docker via sudo, set backup’s shell to /usr/sbin/nologin with no home, and ensure new users inherit a custom /etc/skel.",,
c8ae7872-33a8-4779-a1d3-0965f7c9f18b,System Setup & Configuration,User & Access Management,User & Group Administration,"Provision users dev-amy and dev-bob with private groups and homes under /srv/home (0750) from a custom /etc/skel, create groups eng and contractors, and configure /srv/eng/share setgid with default ACLs so eng has rwx and contractors r-x (inherit). Require both users to change passwords on first login and set dev-bob’s account to expire in 30 days.",,
7b036ad1-c5bf-47c8-9862-8652a34166f9,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,"Assemble a minimal Debian-based cloud image from scratch using debootstrap, package it into a bootable qcow2 with ext4 and GRUB, and enable cloud-init. Export the image to /app/images/debian-cloud.qcow2 and verify it by booting with QEMU using a NoCloud seed that creates a known user and hostname.",,
4f5c0518-d0ab-4e6b-865b-45b73aca9ce7,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,"Build a bootable Debian 12 cloud-init image from scratch by creating a minimal rootfs with debootstrap, adding kernel/initramfs, OpenSSH, and cloud-init, then installing GRUB into a qcow2 disk and compressing it to /app/images/debian12-cloud.qcow2.zst with a sha256 checksum. Generate a NoCloud seed ISO that provisions user tb with an SSH key, and verify by booting the qcow2 in QEMU with host port 2222 forwarded and successful SSH login.",,
f782a815-f7f2-4fc9-82c6-87ab35fbb078,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,"Build a bootable Ubuntu 22.04 cloud image (qcow2) from scratch using debootstrap, installing cloud-init and OpenSSH, and configuring GRUB for virtio on /dev/vda. Generate a NoCloud seed ISO that creates a sudo user 'tb' on first boot, then export both artifacts to /app/images/ for reuse.",,
0b719755-06be-44b9-9e9b-c45097602dc7,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,"Create a minimal Debian qcow2 VM image from scratch using debootstrap, configuring fstab, GRUB for serial console, a non-root tb user with SSH access, and cloud-init. Export the qcow2 and a cloud-init seed ISO, then boot with QEMU to verify SSH connectivity via host port forwarding.",,
820a9eb7-273a-4fa5-830c-917d9fbc5d78,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Provision an Ubuntu cloud-image VM with QEMU and cloud-init (NoCloud) to create a tb-admin user with a provided SSH public key, preinstall nginx, and serve a custom index.html reachable via host port 8080. After verifying SSH and HTTP access, create a named external qcow2 snapshot, change the site, then revert to the snapshot to demonstrate full VM state rollback.",,
9f797d3c-3f06-460a-8a89-346b1388e7cc,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Provision an Ubuntu cloud-image VM with QEMU/KVM using a NoCloud cloud-init seed that creates a tbuser with an SSH key, enables the qemu-guest-agent, and runs a first-boot script to install and start Nginx serving a custom index.html. Forward host ports 2222->22 and 8080->80, verify SSH and HTTP from the host, and store the qcow2 disk and seed ISO under /app/vm.",,
88a24a17-cc4e-41e7-b185-9ab356c33098,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Provision an Ubuntu cloud-image VM with libvirt/KVM using cloud-init to create user 'tb' (password 'benchmarkpass'), inject an SSH public key, set hostname tb-vm, and enable qemu-guest-agent. Create an isolated libvirt network with a static VM IP and host port-forwarding 2222->22, autostart the VM, and verify SSH connectivity and hostname via a test script.",,
70e59c0a-68b2-4c5c-9db8-ff4c42a52693,System Setup & Configuration,User & Access Management,Authentication & Access Control,"Configure SSH to use certificate-based authentication with an OpenSSH CA: generate and secure a CA key, sign both user and host keys with appropriate principals and validity windows, update sshd and client configurations to trust the CA, and verify that only signed keys can connect while unsigned or expired keys are rejected.",,
011f87f8-6b14-4c75-9bc0-856369a7d8a0,System Setup & Configuration,Filesystem & Storage Management,Backup & Snapshot Management,"Create two loopback files to serve as virtual disks, initialize a ZFS pool named 'datazfs' with a compressed dataset and set quotas, then configure automatic hourly snapshots and a 24-hour retention policy using systemd timers. Simulate file changes and deletions, verify snapshots are created on schedule, restore a deleted file from an earlier snapshot, and confirm that snapshots older than 24 hours are pruned automatically.",,
a3bfa581-5f4e-4fc0-afca-410432c65ead,System Setup & Configuration,Filesystem & Storage Management,Backup & Snapshot Management,"Implement a consistent backup pipeline for a MySQL database on an ext4 LVM logical volume: quiesce the database, create and mount an LVM snapshot, rsync data to /backups/mysql, then unmount and remove the snapshot while retaining the last seven backups. Automate via shell scripts and cron, produce detailed logs, and verify restoration by mounting a snapshot and recovering a sample database.",,
1f9582f0-e873-412f-a98f-cd525ce03116,System Setup & Configuration,Filesystem & Storage Management,Backup & Snapshot Management,"Provision an LVM thin pool on a secondary disk, create a /data logical volume, and schedule hourly thin snapshots with retention of six hours via cron. Configure incremental lvm send/receive replication of the latest three snapshots to a remote backup server over SSH, then verify snapshot creation, pruning, remote integrity, and restore one snapshot to a recovery mount.",,
287c3a89-6997-42aa-90dc-92a9ad155c10,System Setup & Configuration,Filesystem & Storage Management,Backup & Snapshot Management,"Configure borgbackup to create encrypted, deduplicated incremental snapshots of /etc and /home to a remote SSH repository, schedule backups with a systemd timer, and implement automatic pruning per hourly/daily/weekly retention policies. Verify backup integrity by performing test restores and logging checksums of restored files.",,
d57d436a-23b1-4b38-988e-24a5aeee627b,System Setup & Configuration,Filesystem & Storage Management,Backup & Snapshot Management,"Initialize a ZFS pool on loopback devices with compression and create datasets under /data. Schedule hourly and daily snapshots via cron, configure incremental zfs send/receive to a secondary backup pool with a 7-daily/4-weekly retention policy, then verify restoring a file from an old snapshot and report pool health, snapshot counts, and transfer stats.",,
1da39e22-65ac-4aa6-a514-7bec3a46c686,System Setup & Configuration,Cloud & Remote Environment Configuration,Cloud CLI Setup,"Configure AWS CLI v2 for SSO authentication using a provided SSO start URL and region, install and configure the aws-sso-util tool to automate session caching and token refresh for two distinct account-role pairs. Verify successful profiles by running aws sts get-caller-identity for each and writing all JSON responses to /app/output/profiles_identity.json.",,
ddbd2da2-8b98-4f83-b540-7aaeeadcbf1b,System Setup & Configuration,Cloud & Remote Environment Configuration,Cloud CLI Setup,"Install and configure AWS CLI v2 with IAM Identity Center (SSO) to handle authentication for three separate AWS accounts via named profiles, including custom session durations and automatic credential caching. Validate by listing S3 buckets and uploading distinct test files using each profile to confirm proper cross-account access.",,
b11d02ff-281b-4497-be41-e09c1217f50c,System Setup & Configuration,Cloud & Remote Environment Configuration,Cloud CLI Setup,"Configure AWS CLI v2 to authenticate via AWS SSO for two AWS accounts by creating named profiles with distinct sso_start_url, sso_region, sso_account_id and sso_role_name settings that support token caching and auto-refresh. Verify each profile by listing S3 buckets and describing EC2 instances, and document profile switching and token refresh behaviors.",,
fae6086a-6659-4eac-bac3-984f2d343775,System Setup & Configuration,Virtualization & Containerization,Container Setup & Management,"Configure Docker with QEMU user-static to support cross-building Linux containers, then build and push AMD64 and ARM64 variants of a sample web application, create and publish a multi-architecture manifest, and verify pulls on both architectures.",,
bcd706c3-2c2c-43b6-b3dd-bcc699b38975,System Setup & Configuration,Virtualization & Containerization,Container Setup & Management,"Deploy and configure a private Docker registry secured with a self-signed TLS certificate and HTTP Basic Auth, then configure the Docker daemon to trust its CA. Build a multi-stage Go service image, enable Docker Content Trust to sign and push the image, verify a secure pull, and demonstrate that pulling an unsigned image fails.",,
442e6289-28b9-4531-be1c-586177152105,System Setup & Configuration,Virtualization & Containerization,Container Setup & Management,"Create Dockerfiles for a Node.js frontend and a Python Flask API, then define a Docker Compose setup that builds these images on a user-defined bridge network with persistent named volumes and environment variables injected from a .env file, and deploy an Nginx reverse proxy service that load-balances HTTP requests with healthchecks. Simulate backend failures by stopping one service, scale replicas to restore capacity, verify zero-downtime operation, and collect container statuses, logs, and test results into a final report.",,
9f8f5c55-f0d6-4e01-9426-fce2fa820e08,System Setup & Configuration,Software & Package Management,Dependency Verification & Repair,"Simulate a Debian system with mixed stable, backports and experimental repositories causing package conflicts and unmet dependencies; the agent must identify conflicting packages, adjust /etc/apt/sources.list and /etc/apt/preferences.d/, run apt-get update, apt-get -f install and dpkg --configure -a to fully repair the system, then produce a report detailing conflicts detected and resolution steps taken.",,
9fd87047-ef14-487d-b9e2-e2af0b5ac889,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Simulate two new block devices with loopback files and create an mdadm RAID1 array, then partition it into /boot and /root ext4 filesystems, mount them under /mnt, and persist in /etc/fstab. Next, simulate a disk failure, remove and re-add the failed device, rebuild the array, and verify filesystem integrity post-recovery.",,
edcf8b8e-4263-4459-a455-3fff222f7c2b,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Simulate two disks using loopback files, build an mdadm RAID1 array, partition it into a small ext4 boot and larger XFS data slice, format and mount them under /mnt/boot and /mnt/data, add persistent UUID-based /etc/fstab entries, and verify mounts on reboot. Then simulate a drive failure by detaching one loop device, rebuild the array, and confirm recovery and data integrity.",,
142e2dda-b1b9-4bde-b827-d598f6a26a91,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"On a blank block device, create a GPT partition layout with a BIOS boot partition, an EFI system partition, and an LVM physical volume; format and mount the /boot and EFI partitions, initialize LVM to create separate root and swap logical volumes, then configure /etc/fstab using UUIDs and activate swap. Verify that partitions, LVs, and mounts persist across simulated reboots within the Docker sandbox.",,
354e4a96-e841-4a3d-96e4-14b448f44119,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Using a sparse loopback file, create a GPT-repartitioned virtual block device with two partitions formatted as ext4 and xfs, assign descriptive PARTLABELs, and mount them under /mnt/storage and /mnt/backup with noatime and specific filesystem options. Configure /etc/fstab entries using PARTLABEL and demonstrate persistence across loop device detach/reattach and system reboots via fstab and a complementary systemd automount unit.",,
d6fa2944-e3fa-4b51-b308-e32fa0109432,System Setup & Configuration,Operating System Configuration,Environment Variables & Profiles,"Use direnv and Mozilla SOPS to implement per-directory encrypted environment variables: when entering a project directory, the .env file is decrypted and loaded into the shell automatically, and unloaded on exit. Provide a bootstrap script to install and configure direnv in the user’s shell profile, import the GPG key, and verify that decrypted secrets are never stored on disk in plaintext.",,
d8ebf4fd-d2ea-4173-b7f4-3837b14f0ff8,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Provision a drop-box directory at /srv/dropbox owned by root with group “dropbox” granted only write/execute (no read) permissions via POSIX ACLs and the sticky bit so members can upload but cannot list directory contents. Create sample dropbox users to test file uploads, verify listing restrictions, and perform root retrieval to confirm ACL enforcement.",,
605796b6-d162-4ab1-9eca-5edf5a3f2f15,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Configure a shared /opt/shared directory owned by root:devops with the setgid bit and default ACLs granting alice and bob full rwx, auditors read-only, and no access to others, ensuring all new files and subdirectories inherit these settings. Verify by creating test files as each user and inspecting permissions using getfacl and access attempts.",,
4373f014-8fe7-453a-a5c9-a81c4e74be7d,System Setup & Configuration,Filesystem & Storage Management,Filesystem Permissions & Quotas,"Enable and configure project quotas on an XFS partition mounted at /srv/projects to enforce a 10G limit per team directory. Set default POSIX ACLs so new files grant rwx to the ""developers"" group and apply the immutable attribute via chattr to archived logs, verifying quota usage, ACL inheritance, and immutability with CLI tools.",,
df5b593a-49a7-4f37-9826-0274fe96296b,System Setup & Configuration,Filesystem & Storage Management,Filesystem Permissions & Quotas,"Enable XFS project quotas on /mnt/shared to limit each project group to 10 GB with 80% and 9 GB warning thresholds, apply default POSIX ACLs for group inheritance, and automate daily quota reports via cron. Verify enforcement by simulating over-quota writes, capturing error messages, and reviewing generated reports.",,
bd7b02ae-4269-4fb9-99e4-040de5aa83bf,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Implement a dynamic nftables-based firewall that integrates with ipset to automatically fetch and apply daily blocklists from an external threat feed via a systemd timer, dropping all incoming traffic from malicious IPs. Configure rules to allow HTTP/S and SSH with rate limiting, log dropped packets, rotate logs via logrotate, and verify blocklist updates and traffic enforcement.",,
3d98e563-13cd-48cc-98c3-7af15136e402,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Configure firewalld with three zones (trusted, dmz, public), assign interfaces eth0 and eth1 appropriately, allow SSH and HTTPS-mTLS only in trusted, allow DNS in dmz, block all in public, and add a rich rule to rate-limit HTTP to 20 connections per minute. Enable info-level logging for dropped packets and verify the configuration using firewall-cmd status checks and simulated traffic with curl and netcat.",,
d4dc1650-5ebe-4431-9872-09b35994a119,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Implement an iptables-based firewall that uses a custom three-port knock sequence to dynamically open SSH, blocks all unsolicited traffic by default, and rate-limits failed connection attempts. Configure persistent logging of knock attempts and rule sets, provide scripts to backup/restore firewall rules, and verify access via a knock client and unauthorized probes.",,
d65b9cb8-e388-4623-9041-e889e63204fb,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,Use Docker Buildx with QEMU emulation to build and push a multi-architecture (amd64 and arm64) Docker image for a Go HTTP server via a multi-stage Dockerfile; register it under a manifest list in a local registry and verify pulls and container runs on both architectures.,,
74158136-e469-4d9e-b4eb-f8b3c6cb7463,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,"Use debootstrap to assemble a minimal Ubuntu root filesystem, chroot in to install and configure SSH, cloud-init, and a non-root user, then convert the directory into a QCOW2 disk image and validate it boots successfully under QEMU.",,
d2d54798-1a7e-4591-b30c-a2aa0ff03b63,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Configure a multi-homed Linux host with two network interfaces, each assigned a static IP and default gateway, then implement policy-based routing using ip rule and ip route so traffic from each source address uses its respective gateway. Configure per-interface DNS servers via systemd-resolved or netplan and validate correct routing and name resolution with traceroute and dig tests.",,
ae61f5a1-f80d-4f71-8731-216ce3f7ce67,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Configure a Linux bonded network interface (bond0) in active-backup mode using two physical NICs, assigning a static IPv4 address and default route. Simulate NIC failure by toggling link state, verify uninterrupted connectivity via ping, and extract syslog entries confirming failover events.",,
0f3e983b-da8d-4f24-904b-c4d729226568,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Configure two Ethernet interfaces into an active-backup bond with static IPv4 and IPv6 addresses, create a VLAN-tagged bridge on top for a VM network, add custom routing tables for policy-based routing, and verify connectivity using ping and traceroute.",,
3080f96c-4ff3-42e9-a77b-0307369109cc,System Setup & Configuration,System Monitoring & Diagnostics,Log Analysis & Troubleshooting,"Analyze log file sizes under /var/log to identify the top three services generating the most log data over the past week, then update the rsyslog configuration to drop DEBUG-level messages from the highest-volume service, reload rsyslog, and confirm log volume reduction via new growth statistics.",,
c1c7b87c-3d13-4260-8432-972285c03148,System Setup & Configuration,System Monitoring & Diagnostics,Log Analysis & Troubleshooting,"Develop a Bash/AWK utility that scans rotated /var/log/auth.log and journalctl entries from the last 48 hours, identifies SSH brute-force attempts by grouping failed logins per IP, enriches each IP with offline GeoIP country data, and outputs both a CSV timeline and an ASCII world map highlighting attack origins. Configure it as a systemd timer to run hourly and validate by simulating login failures from multiple virtual hosts to ensure the report updates correctly.",,
4e6e4937-5ca6-4642-a014-5fa891f99115,System Setup & Configuration,System Monitoring & Diagnostics,Log Analysis & Troubleshooting,"Write a shell script to parse /var/log/auth.log, detect IP addresses with more than 5 failed SSH login attempts in a ten-minute window, and auto-generate iptables rules to block them. Schedule the script via cron and produce a daily summary report listing the offending IPs and counts.",,
b68720a2-2894-4742-be8e-89865362ac3d,System Setup & Configuration,System Monitoring & Diagnostics,Log Analysis & Troubleshooting,"Configure persistent journald storage and custom logrotate rules for /var/log/syslog. Develop a script that parses syslog and journalctl logs to identify and correlate OOM kills, kernel panics, and service crashes over the past week, producing a CSV report of timestamps, event types, and counts.",,
113bc7c0-1f0f-420b-a672-5303668a34e2,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Develop a Bash script that gathers CPU, memory, and disk I/O metrics via vmstat, iostat, and free at 1-second intervals over a two-minute window, then parses the data to compute average, peak, and 95th percentile values for each metric and outputs both a CSV file and a human-readable summary report.",,
2b2ce0fc-16cc-4486-9cf3-ba9ee017723c,System Setup & Configuration,System Monitoring & Diagnostics,Log Analysis & Troubleshooting,"Develop a shell script that parses syslog, auth.log, and kernel logs for the past 24 hours, counts kernel OOM events, high load warnings, and SSH authentication failures hourly, and outputs a CSV summary and JSON alert report. Schedule the script via a systemd timer and configure email notifications to be sent when any metric exceeds defined thresholds.",,
3cbd9e77-56bd-4dc9-b009-180991591b91,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Create a sample memory-leaking C service managed by systemd, configure persistent journald storage and rate limiting, then simulate high load to trigger an OOM kill. Use journalctl and coredumpctl with GDB to analyze the cause, and update the unit file with watchdog and auto-restart directives to demonstrate automated recovery.",,
a65f196a-1434-49e2-b7a4-5dc4a7094e92,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Diagnose and fix Fail2ban's SSH jail misconfiguration by analyzing /var/log/auth.log and /var/log/fail2ban.log (including rotated logs), adjust the filter regex and jail.local settings, reload Fail2ban, and verify SSH attacker IPs are correctly banned via iptables. Ensure bans persist across logrotate events and service restarts.",,
169545f2-c1c5-4af3-a3b4-b1a2d1ec9eb2,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Create two Linux network namespaces connected by a veth pair with mismatched MTUs, then diagnose failed ICMP and TCP traffic using ping, tracepath, and tcpdump to identify fragmentation issues. Adjust MTU and apply TCP MSS clamping to restore end-to-end connectivity and verify resolution.",,
2b665dea-1931-4c3e-b6d0-f8a8eb6529de,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Simulate a Path MTU black‐hole by creating two Linux network namespaces connected via a veth pair with ICMP fragmentation-needed messages dropped, then use ping, tracepath, and tcpdump to detect the MTU mismatch and restore connectivity by adjusting MTU or enabling ICMP responses.",,
8ff7ada5-e665-4ec6-a79c-4c5010651cd6,System Setup & Configuration,Software & Package Management,Package Installation & Removal,"On a Debian Bullseye sandbox, configure apt pinning to selectively install a backported version of PostgreSQL 14 alongside stable packages, install it, then adjust pin priorities to downgrade to PostgreSQL 13 from the main repo. Verify by querying 'psql --version' before and after downgrade and ensuring no residual 14 packages remain.",,
6d0848a6-f131-4670-8712-452fc59e4d11,System Setup & Configuration,Software & Package Management,Package Installation & Removal,"Set up a custom Debian package repository using reprepro or aptly, generate and GPG-sign a sample .deb, and serve it over HTTP. Configure a client to trust the repo key, then automate installation, upgrade, holding, downgrading, and removal of the package via apt, verifying logs and package states after each operation.",,
6c5b8f89-9e96-4a23-86aa-6149f558f6e1,System Setup & Configuration,System Monitoring & Diagnostics,Performance Tuning,"Configure a Linux system to maximize NVMe SSD performance by tuning the I/O scheduler, block device queue depth, and filesystem mount options, and by pinning fio workload threads to dedicated CPU cores. Benchmark sequential and random read/write workloads with fio before and after tuning, then produce a report comparing IOPS, throughput, and latency improvements.",,
11802224-fc07-4300-86fd-906c1cc785fe,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Configure two systemd slices named high-priority.slice and low-priority.slice with distinct CPU and memory share settings. Migrate selected long-running processes into each slice, simulate load with stress-ng, monitor resource allocation via systemd-cgtop, and generate a report demonstrating enforced isolation.",,
5764305d-f3c2-4f75-b765-605fed2a610f,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Define two custom systemd slices with distinct CPU and memory cgroup v2 limits, then assign a long-running batch job and an interactive shell to each slice. Validate resource isolation by executing stress tests and monitoring usage via systemd-cgtop.",,
03d3f341-ecb9-4bc4-bb53-1045813b84bf,System Setup & Configuration,Cloud & Remote Environment Configuration,Remote Session & SSH Configuration,"Deploy an SSH certificate authority to issue and trust host and user certificates: generate CA keys, sign host/user public keys, configure sshd and ssh clients to trust the CA, then validate certificate-based authentication and enforce revocation via a CRL.",,
7bf2858a-94b0-470a-9117-b1dbc8665bf4,System Setup & Configuration,Cloud & Remote Environment Configuration,Remote Session & SSH Configuration,"Set up an SSH bastion host using OpenSSH Certificate Authority–signed host and user keys, disable password authentication, configure client-side ProxyJump, and enforce per-user forced commands. Verify by connecting through the bastion to an internal VM, executing allowed commands, and inspecting logs for certificate usage and restriction enforcement.",,
ad2ea4d2-9ad5-4d3d-9163-0dca3e3a634d,System Setup & Configuration,Cloud & Remote Environment Configuration,Remote Session & SSH Configuration,"Provision a bastion host and an internal app host using key-based and host-based authentication, configure the client’s ~/.ssh/config with ProxyJump, ControlMaster, and agent forwarding while restricting commands via authorized_keys. Implement a systemd service for a persistent reverse SSH tunnel exposing the internal app’s HTTP port on the bastion, and verify multi-hop SSH access, file copying, command execution, and port forwarding functionality.",,
2c13380d-cafb-478f-a8b8-bbd98158b2cf,System Setup & Configuration,Software & Package Management,Repository Configuration,"Deploy an internal Debian APT repository using aptly and Nginx: initialize and sign the repo with GPG keys, publish snapshots over HTTP with basic authentication. Configure a client container to trust the repository key, install a custom .deb, update the package in the repo, refresh the snapshot, and verify the client can upgrade to the new version.",,
6ba03973-be02-4b8f-8b65-822d56e4c7f4,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Configure sysstat's sar to collect CPU, memory, and I/O statistics at one-minute intervals for a 12-hour period; then generate and parse sar reports to determine the hour with the highest average CPU usage, memory pressure, and disk utilization. Supply the sar logs, generated reports, and a concise summary highlighting these peak periods and recommending basic tuning steps.",,
b4744535-e49c-43cb-a4f4-d816beadb1a5,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Develop a shell script that collects CPU, memory, and disk I/O metrics every 30 seconds for 24 hours using vmstat and iostat, outputs results to a CSV file, and then uses gnuplot to generate time-series plots highlighting utilization trends and peak load periods. Provide the script, sample CSV data, generated graphs, and a brief report identifying the top three resource bottlenecks observed.",,
72e0db8b-2dc0-471f-92b3-cecf48ec5c07,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Install and configure sysstat to record system metrics every minute with one-week retention. Simulate CPU, memory, disk, and network load, then use sar to generate and parse hourly CPU, memory, IO, and network utilization reports into JSON, verifying that induced load periods match peaks.",,
22301c75-f6a8-442f-a107-c4f0639938b3,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Develop a Bash tool that samples CPU usage, memory consumption, and disk I/O latency every second over a 60-second window using top, free, and iostat, identifies the top three resource-hungry processes, and outputs a JSON report; integrate this in a cron job and verify detection by generating synthetic high-load processes.",,
66c59d9e-efe5-4d11-911a-a5d499102aaa,System Setup & Configuration,Cloud & Remote Environment Configuration,Resource Provisioning & Management,"Using Terraform, provision a new VPC with public and private subnets, deploy an Application Load Balancer with health checks, an auto-scaling group of EC2 instances serving a basic HTTP page via user data, and a multi-AZ RDS MySQL database with automated backups and security groups. Verify the ALB endpoint responds correctly, test RDS connectivity from the EC2 instances, and output the Terraform plan, state file, resource endpoints, and an estimated monthly cost summary.",,
17b56c99-0856-4448-9992-0725536b36f2,System Setup & Configuration,Cloud & Remote Environment Configuration,Resource Provisioning & Management,"Use Terraform to provision an IPSec VPN tunnel between an AWS VPC and a Google Cloud VPC, including dynamic retrieval of AWS VPN endpoint IPs and automatic BGP peer configuration on both sides. Deploy test VMs in each VPC, confirm route propagation and end-to-end ping connectivity, and output the VPN tunnel health status to /app/output/vpn_status.json.",,
3fcc4f40-f8ab-49fe-973a-8ee18a8e9156,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure an Apache Kafka cluster with systemd-managed Zookeeper and brokers across three nodes, secured with TLS encryption and SASL authentication. Create a topic and perform producer and consumer tests to validate end-to-end messaging and cluster health.",,
a2ce46ae-cfbb-4eae-8bbd-e17d33655901,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure HashiCorp Vault as a systemd service using the file storage backend, initialize and unseal it with generated keys, create a read-only policy, and verify storing and retrieving a secret via the vault CLI.",,
cf648240-b8cb-4357-9974-a3a77faeac70,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure RabbitMQ server with the management plugin and enable it as a systemd service. Generate self-signed TLS certificates, set up a virtual host and user with specific permissions, then verify secure connectivity by publishing and consuming a test message and querying the management API.",,
6cdedb2b-4d60-478a-a818-89fd494ae388,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure WireGuard as a systemd‐managed VPN service on a Linux host: generate server and two client keypairs and configs, apply firewall rules, enable the wg-quick service, and verify secure tunneling by exchanging traffic between the clients.",,
69c9232c-68be-4828-908c-9a4cb4651077,System Setup & Configuration,Operating System Configuration,System Parameters & Kernel Settings,Optimize the Linux TCP/IP stack by enabling BBR congestion control and adjusting net.core and net.ipv4 sysctl parameters via /etc/sysctl.d/ with persistent boot-time settings. Benchmark network throughput and latency using iperf3 to validate improvements over default values.,,
4b436016-0623-4573-9625-9d0e9f32a817,System Setup & Configuration,Operating System Configuration,System Parameters & Kernel Settings,"Configure kernel boot parameters and sysctl to isolate CPU cores and enable real-time scheduling for low-latency workloads, set ulimit and cgroup limits for RT priority, then benchmark with cyclictest to verify reduced latency and produce jitter statistics.",,
65075be1-bc23-41d0-8794-14a522d1e7f3,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Create a systemd path unit that watches /opt/uploads for new files and triggers a service unit to compress and archive them into /data/archives, plus a timer unit for daily full-archive runs. Configure proper user permissions, dependencies, and restart policies, then validate functionality via file-creation tests and journal log inspection.",,
22f00248-9e5d-4d74-b837-8975090b037a,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Implement a systemd path and service unit pair that watches a directory (e.g. /opt/uploads) for new files and automatically runs an archiving script to compress them into dated tarballs under /var/backups/uploads with journald and file logging. Enable and test by simulating file creation events, then verify the archive tarballs and corresponding log entries are produced as expected.",,
fb0cf31d-0df0-49c6-8114-7e564545945c,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Define a systemd.path and associated .service to watch /opt/secure-drop for new files. The service should encrypt dropped files with a GPG key under an unprivileged user, move encrypted outputs to /opt/secure-archive, remove the plaintext, and include proper dependencies, Restart policy, and resource controls; verify by dropping a test file.",,
06f783d5-7aea-4e47-a2d8-c0abc1bfac0e,System Setup & Configuration,User & Access Management,User & Group Administration,"Enable per-user and per-group disk quotas on the /home ext4 filesystem by configuring soft and hard limits with a grace period. Create test users, consume disk space to trigger warnings and hard-limit enforcement, verify quota reports, enforcement behavior, and any notification emails.",,
cbd0daec-eb81-4358-b312-893a2fb16ffb,System Setup & Configuration,User & Access Management,User & Group Administration,"Automate the provisioning of time-limited guest user accounts with customizable expiration dates, home directories pre-populated with example files, and group memberships. Implement a CLI tool that creates, audits, and purges these accounts, enforces directory permissions, and logs actions to syslog.",,
0a015ece-1292-4592-aa0b-29beef09b797,System Setup & Configuration,User & Access Management,User & Group Administration,"Create a new 'deploy' UNIX group and add three users with SSH key–based authentication and customized home directories via /etc/skel. Configure default and directory ACLs on /var/www/app to grant the 'deploy' group read/write permissions with inheritance, enforce a global umask of 027, and verify access and ACL propagation for both existing and newly created users.",,
0fa06b35-06e4-41a3-beeb-647530026df9,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Provision two QEMU/KVM VMs on an isolated libvirt network with dnsmasq-based DHCP/DNS and SSH key authentication, set CPU and memory quotas, and configure port forwarding for host access. Validate that the client VM acquires the correct IP, resolves custom hostnames, and allows SSH connections via forwarded ports, then produce a report on network connectivity and resource allocation.",,
2b43d2af-36c5-48d6-ad6e-85d411630186,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Provision an Ubuntu 22.04 VM using libvirt and virt-install with cloud-init to configure a sudo user with SSH key access, assign a static IP, format and mount an attached second disk, and install Docker. Verify SSH connectivity, network settings, disk mount, and that `docker run hello-world` succeeds.",,
d0edb295-612c-4716-93a8-74df2659ab78,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Use Vagrant with the libvirt provider to provision three VMs: one running dnsmasq as a combined DHCP and DNS server, and two clients obtaining static leases. Configure an isolated network, verify clients receive the correct IPs and hostnames, and ensure DNS resolution between all machines.",,
2964c9a5-97c7-469f-b0dd-a8312bace525,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Using Vagrant and the libvirt provider, provision a PXE‐boot TFTP/HTTP server VM serving a custom Kickstart for CentOS 8 network installation, then spin up a second VM that boots via PXE to perform the automated install. Validate by retrieving the Kickstart file at /vagrant/ks.cfg, confirming the guest completes installation and boots to shell, and logging its assigned IP to /vagrant/guest_ip.txt on the host.",,
