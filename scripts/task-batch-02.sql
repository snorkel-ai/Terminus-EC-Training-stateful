-- Batch 2 of 8: Inserting tasks 201 to 400

INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Encoding & Compression', 'Create a script that reassembles a split ZIP in /app/parts (dataset.zip.001, .002...), verifies integrity, and extracts its contents. Auto-detect and convert all text files to UTF-8 with LF line endings (leaving binaries unchanged), then repack the normalized tree into a deterministic /app/normalized.tar.xz with sorted entries, fixed timestamps/permissions, and write a SHA-256 manifest to /app/manifest.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Encoding & Compression', 'Create a script that scans /app/inbox for .eml or mbox files, decodes MIME parts (base64 and quoted-printable) while honoring per-part charsets (UTF-8, ISO-8859-1, Windows-1252, UTF-16LE), and extracts only CSV or CSV.GZ attachments. Convert all text to UTF-8 with LF line endings, decompress .gz attachments, deduplicate identical rows, and write a single merged /app/combined.csv.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Encoding & Compression', 'Create two scripts: one that normalizes a directory by auto-detecting and converting text file encodings to UTF-8 with LF line endings (leaving binaries intact) and then produces a deterministic tar.gz (lexicographic order, fixed uid/gid/uname/gname, mtime from SOURCE_DATE_EPOCH) along with a MANIFEST.sha256 of pre/post hashes. The second script verifies determinism by re-packing and comparing the tarball and manifest, reporting any mismatches.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Encoding & Compression', 'Implement a script that recursively normalizes a mixed-encoding dataset in /app/inbox: detect each text file’s encoding (BOM-aware; fallback heuristic), convert to UTF-8 without BOM, normalize Unicode to NFC, unify line endings to LF, and transparently gunzip any *.gz logs. Package the result as a deterministic tar.gz at /app/normalized.tar.gz (sorted entries, uid/gid=0, mtime=0) and write /app/manifest.csv summarizing original_path, output_path, original_encoding, original_eol, was_gzipped, bytes_before, bytes_after, and sha256_after.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'File Format Conversion', 'Create a CLI script that reads all multi-document YAML files in /app/k8s (resolving anchors/aliases) and converts each document into a normalized JSON object with dot-notated keys, outputting a consolidated JSON Lines file at /app/resources.jsonl. Then convert that JSONL to Parquet at /app/resources.parquet with inferred column types, lexicographically ordered columns, and an added source_filename field.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'File Format Conversion', 'Create a CLI that converts a directory of heterogeneous CSV files (mixed encodings: UTF-8/UTF-16/ISO-8859-1; varying delimiters and decimal separators) into a single UTF-8 Parquet dataset at /app/output using a provided schema.yml for field names and types. The tool must auto-detect each file’s encoding and dialect, standardize dates and numerics, and write a detection_summary.json reporting per-file encoding, delimiter, quotechar, decimal separator, and any type coercions.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'File Format Conversion', 'Create a script that converts a directory of YAML documents that use anchors, aliases, and merge keys into a single NDJSON file, fully resolving all references and merges. Each line must be a canonicalized JSON object with deterministically sorted keys, ISO-8601-normalized timestamps, and an added source field containing the original filename.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'File Format Conversion', 'Create a script that converts all XML files in /app/input_xml (with multiple namespaces) into YAML files in /app/yaml, representing attributes with an @ prefix, text with _text, preserving child order, and turning repeated tags into sequences. If any element named Data contains base64 text, decode it to /app/blobs/<stem>_<n>.bin and replace the YAML value with the relative blob path.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Schema Inference & Validation', 'Create a CLI script that infers a JSON Schema (Draft 2020-12) from all NDJSON files in /app/samples, unioning fields and types, distinguishing integer vs number, detecting nullability, min/max, enum for low-cardinality strings, and formats (date-time, uuid, email). Validate /app/new_records.jsonl against the inferred schema, writing the schema to /app/schema.json and a newline-delimited list of invalid record indices with short reasons to /app/invalid.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Schema Inference & Validation', 'Create a command-line tool that scans /app/datasets for mixed CSV and JSONL files, infers a unified typed schema (nullability, unions, enums from low-cardinality strings, and date/time/decimal detection) and emits a JSON Schema Draft 2020-12 file. Validate every record against the schema with a detailed per-file report of failures (row number and reason), and write normalized, UTF-8, type-coerced Parquet outputs conforming to the inferred schema.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Schema Inference & Validation', 'Create a script that infers a relational schema from CSVs in /app/training (column types, primary keys, and foreign keys via uniqueness and value-domain overlap). Validate CSVs in /app/incoming against the inferred schema, writing /app/schema.json and /app/report.txt with type mismatches, duplicate PKs, and FK violations, handling delimiter and encoding detection.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Schema Inference & Validation', 'Implement a CLI that infers a JSON Schema (Draft 2020-12) from /app/samples/*.jsonl by detecting nested field types (including unions), required/optional via coverage threshold, numeric min/max, and common string formats (date-time, email, uuid), then writes /app/schema.json. Validate /app/target.jsonl against the inferred schema and produce /app/validation_report.json with per-record JSON Pointer paths of violations and a summary of counts by rule.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Schema Inference & Validation', 'Infer a column schema from a corpus of heterogeneous delimited files in /app/samples (auto-detect delimiter, header presence, and encoding), determining data types, null tokens, and required fields (present in ≥98% of rows), and emit an Arrow-compatible schema to /app/schema.json. Validate /app/batch.csv against that schema, writing /app/invalid_rows.csv with columns row,field,error for all violations and also produce a normalized UTF-8, comma-delimited, headered file of the valid rows at /app/valid.csv.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Text & Log Parsing', 'Create a script that parses multiple timestamped lsof snapshots in /app/snapshots, correlates PIDs across files to compute per-process file-descriptor deltas and type breakdowns (REG/SOCK/FIFO), and flags processes with monotonically increasing counts as potential leaks. Write a ranked summary to /app/leaks.txt listing PID, command, total growth, and per-type growth for the top offenders.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Text & Log Parsing', 'Create a script that scans /app/logs for application logs (including rotated .log and .log.gz files) with RFC3339 timestamps and multi-line Java stack traces, grouping each exception event as the ERROR line plus its following stack frames and normalizing all timestamps to UTC. Output /app/errors.csv listing exception_type, sha1_message_signature (message with volatile values like hex addresses stripped), first_seen, last_seen, count, top_3_frames (semicolon-separated), and up to five associated reqId values (comma-separated).', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Text & Log Parsing', 'Create a script that scans /app/logs for web access logs in mixed formats (Apache combined, Nginx default, and JSON-lines), including rotated .gz files, normalizes them to a common schema, and writes a timestamp-sorted /app/normalized.ndjson. Then compute per-hour aggregates (requests, unique sessions using a 30-minute inactivity window, 4xx/5xx rates, and P50/P95 latency) and save a 2-space-indented JSON report to /app/traffic_report.json.', NULL, ARRAY['web']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Text & Log Parsing', 'Implement a script that scans /app/logs for mixed-format server logs (nginx access, JSON app logs, and syslog; some gzipped), correlates events by a shared request_id, and normalizes timestamps to UTC to reconstruct per-request timelines. Output timeline.csv with per-request start/end/status and phase durations, plus slow_requests.txt listing the 20 slowest requests with the inferred bottleneck phase.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File Parsing & Format Conversion', 'Text & Log Parsing', 'Ingest mixed-format service logs from /app/services/* (Apache/Nginx text, JSON app logs, and RFC5424 syslog), normalize core fields, and correlate events by request_id to reconstruct per-request timelines and end-to-end latencies. Output traces.jsonl (one record per request with ordered spans and missing-service gaps) and summary.csv with per-endpoint counts, mean, and P95 latency.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Archival & Backup Scripting', 'Create a Bash script that performs rotating, hard-link deduplicated snapshots of /app/source into /app/backups using rsync --link-dest, honoring patterns from /app/.backupignore and default excludes (.git, node_modules, *.tmp). Each run must atomically create a timestamped snapshot, enforce a 7-daily/4-weekly/6-monthly retention policy with pruning, emit a manifest with SHA-256 for new/changed files, compute total and dedup-saved bytes, and append a CSV summary to /app/backup_report.csv.', 'hard', ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Archival & Backup Scripting', 'Create a POSIX shell backup tool that performs rsync-based hard-link snapshots of /data into /repo/YYYY-MM-DD using --link-dest for incrementals, generates a JSON manifest with per-file SHA256 and total logical size, then zstd-compresses and age-encrypts the manifest with a provided public key. Implement verify and restore modes that reconstruct the latest snapshot into /restore (preserving sparse files, symlinks, permissions, and mtimes) and enforce GFS retention (7 daily, 4 weekly, 6 monthly) while producing a human-readable report.txt.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Archival & Backup Scripting', 'Implement a Bash snapshot-backup tool that reads /app/backup.toml for include/exclude globs and a retention policy, creates timestamped rsync snapshots with --link-dest under /app/backups, then tars each snapshot, compresses with zstd, and encrypts with age using a provided public key. Provide verify and restore modes that generate/validate a SHA256 manifest per snapshot and prune snapshots per policy.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Archival & Backup Scripting', 'Write a command-line script that creates time-stamped snapshot backups of /app/source, using rsync with --link-dest for unchanged files and packing small files (<256 KiB) into a single zstd-compressed tar encrypted with GPG, honoring exclude patterns from /app/.backupignore and preserving permissions, symlinks, xattrs, and ACLs. Implement a restore mode that reconstructs to /app/restore from a chosen snapshot by merging the snapshot tree with the decrypted tarball and verifies integrity against a SHA-256 manifest, pruning old snapshots according to /app/retention.yaml.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Archival & Backup Scripting', 'Write a script that creates timestamped, rsync-based snapshot backups of /app/source into /app/snapshots using hard links for unchanged files, enforces a retention policy defined in /app/retention.json (daily/weekly/monthly), and emits a per-snapshot manifest with SHA256 checksums and sizes. Include restore and verify modes: restore a named snapshot to /app/restore and scan all snapshots to produce /app/verify_report.txt listing missing files and any checksum mismatches.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Batch File Operations', 'Create a command-line script that scans /app/photos for JPEG/HEIC images, extracts EXIF capture timestamp and camera model, renames each to YYYYMMDD_HHMMSS_{make-model}.{ext} (collisions resolved with _01, _02...), de-duplicates by SHA256 hash, and moves files into /app/library/YYYY/MM/ directories. Produce a CSV at /app/ingest_log.csv listing original_path,new_path,hash,was_duplicate,source_timestamp_used (exif|mtime), and write a JSON summary (/app/summary.json) with counts by camera and month.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Batch File Operations', 'Create a script that recursively scans /app/photos, reads EXIF capture time and camera model from image files, renames them to YYYYMMDD_HHMMSS_[Model]_[seq].ext, and moves them into /app/library/YYYY/MM/DD/. Exact duplicates (by SHA-256) should be moved to /app/duplicates and /app/manifest.csv must map each original path to its final path and status (moved, duplicate, exif_fallback).', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Batch File Operations', 'Create a script that scans /app/photos, renames images to YYYY-MM-DD_HHMMSS_{camera}.ext using EXIF (falling back to mtime), and moves them into /app/library/YYYY/MM/DD while leaving non-images untouched. Detect exact and near-duplicate photos via perceptual hashing, keep a single canonical copy in the dated folder, move duplicates to /app/library/_duplicates, and write a manifest CSV mapping original paths to final locations with hashes and duplicate-of entries.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Batch File Operations', 'Create two CLI scripts: one scans /app/input for images/videos, extracts capture date from EXIF or filename fallback, deduplicates by perceptual hash, moves a canonical copy to /app/library/YYYY/MM/ with a normalized slug while replacing duplicates with relative symlinks, and writes a manifest.json. The second script uses manifest.json to fully restore the original directory layout and filenames.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Batch File Operations', 'Write a script that scans /app/incoming for images/videos, extracts capture timestamps from embedded metadata (falling back to file mtime), and batch renames/moves them to /app/library/YYYY/MM/YYYYMMDD_HHMMSS_{counter}.{ext}, keeping sidecar files (.xmp/.srt) in sync. On timestamp collisions, deterministically order and increment the counter without gaps and output /app/manifest.csv mapping old_path,new_path for every moved file.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'File Discovery & Search', 'Create a command-line tool that scans /app/project to identify orphaned media assets (e.g., png/jpg/svg/gif/pdf/mp4) not referenced by any Markdown/HTML/YAML/CSV files via relative links, front matter, or image tags. The tool must respect .gitignore rules, safely handle symlinks, decode URL-encoded paths, and output orphaned files sorted by size descending to /app/orphans.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'File Discovery & Search', 'Create a script that recursively scans /app/docs for Markdown files, extracts relative image links (e.g., ![...](./img/foo.png)), and verifies that each referenced file exists (ignoring absolute URLs and anchors). Write a JSON array to /app/missing_images_report.json listing missing references with fields: md_file, line, ref, and resolved_path, sorted by md_file then line.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'File Discovery & Search', 'Create a script that recursively scans /app/workspace for filenames that normalize to identical casefolded NFC forms (to detect Unicode confusables/collisions) and flags names containing invisible or bidirectional control characters. Write /app/filename_audit.csv listing original absolute path, normalized form, issue type(s), and any colliding peers, sorted deterministically.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'File Discovery & Search', 'Scan /app/docs for Markdown files, extract relative image and link targets, canonicalize paths, and compare against the real files under /app/docs (excluding hidden and build artifacts). Write /app/report.json with two sorted arrays: missing_references (referenced but absent) and orphan_files (present but never referenced), using paths relative to /app/docs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'File Discovery & Search', 'Write a script that recursively scans /app/site, finds all asset files under /app/site/assets (extensions: png,jpg,jpeg,svg,gif,mp3,mp4,pdf,webp) and reports those not referenced by any Markdown/HTML/CSS/JS file in the project. Ignore directories .git, node_modules, dist, and build; output a sorted newline-separated list of orphan paths to /app/orphans.txt.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Metadata Extraction & Logging', 'Build a CLI that recursively scans a directory and emits a deterministic JSONL manifest per entry (path, type, size, mode, uid/gid, nlink, inode, mtime, SHA-256 for files, symlink targets, and summarized xattrs/ACLs), plus anomalies.csv flagging world-writable/SUID/SGID files, broken symlinks, future timestamps, and duplicate content by hash. Provide a subcommand to diff two manifests and output delta.csv enumerating added/removed/changed items with standardized change reasons for audit.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Metadata Extraction & Logging', 'Create a script that recursively inventories /app/project, extracting normalized metadata for every file, directory, and symlink (path, type, size, mode octal, uid/gid, mtime in UTC ISO 8601, inode+device), computing SHA-256 only for regular files ≤50 MB and recording symlink targets, while skipping paths ignored by the repo’s .gitignore. Write a deterministic, path-sorted JSON Lines manifest to /app/manifest.jsonl and a /app/summary.txt with counts by type, total bytes, detected hardlink groups, and duplicate files grouped by content hash.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Metadata Extraction & Logging', 'Implement a CLI that recursively audits a directory and writes a JSONL snapshot of each item’s metadata (path, type, size, permissions, owner/group, mtime/ctime, inode, link count, device, xattrs if available) plus a SHA-256 for regular files. When given a prior snapshot, generate a changes report listing added/removed/modified files with old/new metadata and per-extension aggregates, avoiding symlink loops and not crossing filesystem boundaries.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Metadata Extraction & Logging', 'Write a script that recursively audits /app/site and produces /app/manifest.csv in deterministic path order with per-entry path, type, mode (octal), uid, gid, size, mtime (UTC ISO), inode, nlink, and either sha256 for regular files or symlink_target for symlinks. Additionally, generate /app/anomalies.log listing any world-writable entries, files with setuid/setgid bits, and broken symlinks, one issue per line.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'File System Operations', 'Metadata Extraction & Logging', 'Write a script that recursively scans /app/data, producing a manifest (CSV) of every path with type, size, mtime (UTC), permissions (octal), uid/gid, inode, hardlink count, and SHA-256 for regular files, plus symlink targets. Generate a separate report that groups hard-linked files and content-duplicate files (same hash but different inodes) and flags world-writable or SUID/SGID entries.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'API Data Fetching & Posting', 'Build a command-line tool that fetches all tickets updated since the last run from a GitHub-like REST API using pagination and ETag-based conditional requests, storing normalized records in /app/issues.sqlite. After syncing, compute a summary (new/updated counts, per-label totals, top 3 authors) and POST it as JSON to a provided webhook URL, honoring rate-limit headers with retry/backoff and writing the exact payload to /app/sync_report.json.', NULL, ARRAY['rest', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'API Data Fetching & Posting', 'Create a command-line script that reads SKUs from /app/skus.csv and an API key from the environment, then queries a paginated inventory/pricing REST API with conditional GETs (ETag/If-None-Match) and backoff for 429 to produce /app/inventory.csv. For any items below the reorder threshold in the input, batch POST a JSON payload to a /reorders endpoint and write the response to /app/reorder_response.json.', NULL, ARRAY['api', 'rest']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'API Data Fetching & Posting', 'Implement a CLI that submits a batch job to a REST API (POST returns 202 + Location), then polls with exponential backoff and ETag/Retry-After handling to download paginated JSON results into a SQLite database with idempotent upserts. Compute daily aggregates and POST an HMAC-signed summary to a webhook, persisting a resume cursor and writing only OK or ERROR to /app/result.txt.', NULL, ARRAY['rest', 'api', 'database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'API Data Fetching & Posting', 'Write a CLI that reads SKUs from /app/skus.csv, authenticates via OAuth2 to a provided mock REST API, and fetches product metadata through paginated endpoints while respecting rate limits using retries and ETag-based conditional requests. Normalize and deduplicate variants, then POST an idempotent batched inventory snapshot to a submission endpoint and emit /app/run_report.json summarizing cache hits, retries, and per-batch results.', NULL, ARRAY['rest', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'API Data Fetching & Posting', 'Write a script that reads /app/cities.txt, fetches the last 48 hours of PM2.5/PM10 per city from a public air-quality API (e.g., Open-Meteo AQ) using curl or Python requests with ETag-based caching and retry-on-429, aggregates per-city min/mean/max, and writes /app/aq_summary.csv. Then POST a signed (HMAC-SHA256) JSON summary to a provided local webhook endpoint and print the returned confirmation ID.', NULL, ARRAY['api', 'python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Cloud Storage Interaction', 'Against a local S3-compatible endpoint (MinIO) with credentials in /app/.env, implement a CLI-driven sync that uploads /app/dataset to a bucket, applies per-file metadata and content-type from /app/metadata.csv, enforces multipart uploads for files >8 MB, and verifies integrity by re-downloading and comparing SHA-256. Emit /app/report.json listing key, size, content-type, user metadata, ETag, sha256_ok, and 10-minute presigned URLs for the five largest objects.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Cloud Storage Interaction', 'Build a policy-driven cross-cloud sync tool that mirrors an AWS S3 prefix to a GCS bucket, preserving Content-Type/Cache-Control and applying include/exclude and rename rules from /app/policy.yaml; use checksum-aware diffing that reconciles S3 ETags (including multipart) with GCS CRC32C/MD5 to avoid redundant transfers. Support dry-run and apply modes, persist a local SQLite manifest for idempotency, and write /app/report.json listing created/updated/deleted/skipped objects and any conflicts.', NULL, ARRAY['cloud', 'aws']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Cloud Storage Interaction', 'Create a command-line tool that syncs /app/dataset to both an AWS S3 bucket and a GCS bucket, reading include/exclude rules from /app/.syncignore and per-file metadata (Content-Type, Cache-Control, custom tags/labels) from /app/metadata.json. The script must perform a dry-run and then an actual run, preserve metadata, use multipart/resumable uploads, verify integrity via checksums (ETag/MD5 for S3 and CRC32C for GCS), and emit a machine-readable reconciliation report at /app/sync_report.json listing created/updated/skipped objects and any mismatches across clouds.', NULL, ARRAY['aws']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Cloud Storage Interaction', 'Create a script that audits and reconciles a Google Cloud Storage bucket prefix to match an AWS S3 bucket prefix: copy missing/outdated objects, preserve Content-Type and user metadata, and delete GCS extras only if not modified in the last 10 minutes. Output /app/audit_report.csv listing key, action (copied, updated, deleted, skipped), source ETag, destination hash, and size, with exponential backoff retries for transient errors.', NULL, ARRAY['cloud', 'aws']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Cloud Storage Interaction', 'Write a script that uses AWS CLI against a provided S3-compatible endpoint to perform an idempotent two-way sync between the remote prefix s3://tb-datasets/projects and /app/cache, honoring patterns from /app/.syncignore and verifying integrity via ETag/MD5. Persist object metadata (Content-Type, Cache-Control) to /app/cache/_metadata.json and emit /app/sync_report.txt with counts of added, updated, and removed items; delete locals only when a --prune flag is given.', NULL, ARRAY['aws']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Database Query & Export', 'Create a CLI script that connects to a PostgreSQL database using credentials from /app/db.env, runs a parameterized denormalizing query over customers, orders, and payments to produce per-customer summaries (first/last order, order count, total paid, outstanding balance) with emails masked and reconciliation checks enforced. Export results as partitioned NDJSON files by last_name initial under /app/export/ and write a manifest.json with per-partition row counts, min/max timestamps, and SHA256 checksums.', NULL, ARRAY['postgresql', 'database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Database Query & Export', 'Create a command-line script that connects to a PostgreSQL database using credentials from /app/db.env, queries paid invoices between two dates (joining invoices, customers, and payments), masks PII (email SHA256, phone last 4), normalizes timestamps to UTC ISO-8601, and exports the result as month-partitioned NDJSON gzip files in /app/export sorted by invoice_id. Write a _manifest.json in the same folder with the query inputs, partition file names, row counts, and SHA256 checksums of each gzip.', NULL, ARRAY['postgresql', 'database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Database Query & Export', 'Create a script that connects to a PostgreSQL database via psql and computes per-customer lifecycle metrics over the last 3 years—first_order_at, last_order_at, total_orders, lifetime_gross_revenue, refunds_amount, net_revenue, and avg_days_between_orders—using CTEs, window functions, and UTC-normalized timestamps while excluding test/fraudulent activity. Export the result sorted by customer_id to /app/customer_ltv.csv using COPY with a header and exactly those columns.', NULL, ARRAY['postgresql', 'database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Database Query & Export', 'Implement a terminal-run script that reads credentials from environment variables, connects to PostgreSQL and MongoDB, reconciles active users by email with at least one paid order in the last 90 days, and exports a flattened dataset to /app/output/users_aggregate.csv and /app/output/users_aggregate.parquet with deterministic ordering. Provide a PostgreSQL .sql file to create a materialized view and indexes used by the export, and ensure the script uses server-side COPY for CSV and batched streaming for Parquet to support million-row exports.', NULL, ARRAY['postgresql', 'mongodb', 'sql']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Database Query & Export', 'Spin up local Postgres and MongoDB with seed data, then implement a CLI script that joins Postgres orders to MongoDB user profiles by user_id, computes 30/60/90-day LTV and signup-month cohorts per acquisition_channel, and exports results to a partitioned Parquet dataset plus a summary CSV. The script must support incremental runs via a persisted watermark (last_order_ts) and perform idempotent upserts of partitions.', NULL, ARRAY['mongodb']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Remote Pipeline Execution', 'Create a Bash script that reads SSH credentials and paths from /app/remote.toml, uploads /app/input/* to a remote server, triggers a Nextflow pipeline there in a detached session, and polls its status until success/failure with a timeout. On completion, download the produced artifacts to /app/output and write /app/run_report.json containing run_id, status, start/end timestamps, and SHA256 checksums for each artifact.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Remote Pipeline Execution', 'Create a CLI that SSHes into a remote SLURM head node, renders a batch script from a local YAML, submits it with sbatch, and robustly monitors the job by polling squeue/sacct and tailing logs (including retrying if preempted). On completion, scp the results back, verify checksums from a manifest, and write a run_report.json with job ID, final state, runtime, and artifact hashes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Remote Pipeline Execution', 'Create a CLI that submits a SLURM job array to process CSV shards listed in /app/manifest.json, capturing the sbatch JobID and polling squeue/sacct until every task completes successfully. When done, fetch each task’s output via scp into /app/results, verify SHA256 checksums from the manifest, and merge the outputs into /app/final.parquet in deterministic shard order; exit non-zero if any task fails or times out.', 'hard', NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Remote Pipeline Execution', 'Implement a CLI that snapshots a local pipeline directory, syncs it to a remote host over SSH/SCP, launches it in a detached session with a unique run ID, and continuously monitors status/logs with automatic reconnect after SSH drops. On completion or timeout, fetch artifacts and emit /app/run_summary.json containing run ID, start/stop times, exit code, SHA256 of outputs, and a flag indicating if execution was skipped due to idempotent content-hash deduplication.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Integration with External Systems', 'Remote Pipeline Execution', 'Implement a CLI tool that reads an SSH inventory and a jobs.json describing data partitions, then dispatches a processing script to multiple hosts via rsync+ssh, launches jobs under nohup with a unique run_id, and periodically polls remote status/logs until completion with bounded retries. On success it collects artifacts into /app/results/{run_id} and writes a summary manifest (per-host status, duration, and stderr tail), supporting resume and cancel by run_id.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Markdown/HTML/Text Conversion', 'Build a CLI that converts a folder of Markdown notes (with YAML front matter, [[wiki-links]], reference-style links, and images) into a single self-contained HTML and a PDF: rewrite intra-note links to anchors, deduplicate references, number sections/figures/tables, apply a supplied BibTeX+CSL, and inline all assets. Also emit search_index.json mapping each heading to its text snippet and anchor.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Markdown/HTML/Text Conversion', 'Build a command-line tool that migrates a static HTML site in /app/site to a markdown-first repo: convert each article HTML to Markdown with YAML front matter (title/date/tags), mirror images locally and rewrite internal links to .md. Generate index.md as a site map and report.txt listing broken links and missing assets.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Markdown/HTML/Text Conversion', 'Create a script that compiles a directory of Markdown notes (with YAML front matter and [[WikiLinks]]) into a self-contained HTML site and a JSONL plain-text search index. Resolve {{include:...}} directives, convert wikilinks to relative paths, inline local images as data URIs, and output a broken-link report.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Markdown/HTML/Text Conversion', 'Create a script that converts all Markdown files under /app/pages into self-contained HTML, rendering fenced mermaid and graphviz code blocks to inline SVG (using mermaid-cli and dot) and converting the remainder via pandoc. It must rewrite cross-file links to .html, preserve front-matter metadata as meta tags, and generate a tag index page from YAML front matter.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Markdown/HTML/Text Conversion', 'Create a script that scans /app/posts/*.md (with YAML front matter: title, date, tags), converts each to a standalone HTML article in /app/site via pandoc, preserving code fences and rewriting relative links using a BASE_URL. Also generate an Atom feed at /app/site/atom.xml listing the 20 most recent posts with RFC 3339 UTC timestamps, canonical URLs, and a summary taken from the first paragraph.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Pattern Extraction & Regex Matching', 'Create a command-line script that recursively scans /app/logs (including .gz files), uses regular expressions to parse heterogeneous log lines into structured fields (timestamp in multiple formats, level, message) and extract entities (IPv4/IPv6, emails, GUIDs, request/user IDs). Redact PII by masking emails and Luhn-valid credit card numbers with stable pseudonyms, write redacted_logs.ndjson, and output templates.csv by normalizing messages to regex-derived templates (replace numbers/hex/IDs/IPs with placeholders) with aggregated counts.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Pattern Extraction & Regex Matching', 'Create a command-line script that scans all .txt files in /app/contracts for calendar dates written in diverse styles (YYYY-MM-DD, MM/DD/YYYY, DD Mon YYYY, Mon DD, YYYY, DDth of Month ’YY, and ranges like Jan 3–5, 2024) using regexes that handle ordinal suffixes, commas, stray punctuation, and Unicode dashes. Normalize each concrete date to YYYY-MM-DD, expand ranges into individual dates, and write a CSV to /app/contract_dates.csv with columns file,line_number,original_snippet,normalized_date, sorted by file then normalized_date.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Pattern Extraction & Regex Matching', 'Create a script that scans /app/paper for .tex and .bib files, uses regex to extract citation keys from LaTeX citation commands (handling optional arguments and comma-separated lists), and extracts BibTeX entry keys. Write /app/citation_audit.txt listing ordered unique cited keys, missing citations (cited but absent in .bib), unused .bib entries, and per-file citation counts.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Pattern Extraction & Regex Matching', 'Scan /app/docs for Markdown files and use regex to extract external URLs, bare domain mentions, and email addresses from prose while excluding fenced code blocks and inline code. Also detect reference-style link labels to report undefined and unused labels, writing links.csv (type,value,first_file,count) and ref_audit.txt with the findings.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Pattern Extraction & Regex Matching', 'Write a script that scans all Markdown files under /app/docs and, using only regex-based parsing, extracts every fenced code block (```lang ... ```) with its language tag, 1-based start/end line numbers, and any inline TODO: ... comments inside or on immediately adjacent lines, producing /app/blocks.csv with columns file_path, block_index, language, start_line, end_line, todos (semicolon-separated). Also perform an in-place substitution that wraps any shell code block containing a line matching rm\s+-rf\s+[^;]+ in <!-- DANGEROUS --> ... <!-- /DANGEROUS --> markers without altering code content.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Report & Document Generation', 'Create a CLI that profiles all CSV/TSV files in /app/data, infers column types, computes per-column quality metrics (null %, distinct count, numeric stats, text length ranges, top values), and flags mixed-type anomalies and candidate ID/date columns. Output a readable /app/profile.md and a structured /app/profile.json summarizing per-file results and a cross-file schema reconciliation section.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Report & Document Generation', 'Create a command-line script that scans /app/adr for Markdown Architecture Decision Records with YAML front matter (id, title, date, status, supersedes/superseded_by), validates cross-references, and generates /app/adr_index.md. The report must include a chronological table, sections grouped by status, and ASCII supersession chains for each lineage with deterministic ordering.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Report & Document Generation', 'Generate release notes by parsing a Git repo at /app/repo using Conventional Commits, producing /app/RELEASE_NOTES.md and a machine-readable /app/release.json for the latest tag range (or last 50 commits if no tags). Categorize entries by type and scope, detect BREAKING CHANGE footers, count contributors, and convert issue/PR references (e.g., #123) into links.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Report & Document Generation', 'Implement a script that scans Nginx-style logs in /app/logs/*.log and a release timeline in /app/releases.json to detect outage windows where per-minute 5xx response rate exceeds a given threshold and attribute each window to the nearest release. Generate a Markdown incident report (/app/incident_report.md) with a timeline and a CSV (/app/incident_windows.csv) with start,end,duration,peak_rate,top_errors,release_sha, sorted chronologically.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Report & Document Generation', 'Write a command-line script that scans a Git repository at /app/repo and generates /app/RELEASE_NOTES.md for the tag range specified in /app/range.txt by parsing Conventional Commits and cross-referencing issue/PR titles from /app/issues.json. The Markdown must include grouped sections by type and scope, a BREAKING CHANGES section from footers or ! commits, an alphabetically ordered contributor summary with commit counts, and deterministic ordering within each section.', NULL, ARRAY['git']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Template Rendering & Macro Expansion', 'Create a CLI that renders Jinja2 templates in /app/templates using layered variables from /app/config/base.yaml, /app/config/env/*.yaml, and /app/config/secrets.json, and for each locale in /app/locales.csv merges the matching /app/i18n/<locale>.yaml. It must support simple macros for pluralization and date formatting, fail on unresolved placeholders, emit outputs to /app/build/<locale>/ preserving paths, and write /app/build_manifest.json listing each file with its locale and SHA256.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Template Rendering & Macro Expansion', 'Create a CLI that renders a directory of Markdown pages with YAML front matter through Jinja2 layouts/includes/macros, applying variable precedence of page > section defaults > global defaults > environment and custom filters (datefmt, slugify, markdown). Write HTML to /app/dist mirroring the source tree and emit a manifest.json mapping each source file to its chosen layout and output path.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Template Rendering & Macro Expansion', 'Create a script that renders all Jinja2 templates under /app/templates to /app/build using layered variables from /app/defaults.yaml, environment variables, and optional per-template .vars.yaml files (per-template > env > defaults), preserving directory structure and failing on undefined variables. Implement custom filters slug (kebab-case) and sha256_file(path under /app/assets), support {% include %}, and write a manifest.json in /app/build listing each output and its SHA-256.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Template Rendering & Macro Expansion', 'Implement a preprocessor that renders a set of .tmpl files into environment-specific configs by expanding user-defined macros, {{ENV_VAR}} placeholders, and conditional blocks from a vars.yml inventory, with nested include support and cycle detection. Output dev, staging, and prod variants to /app/build and exit non-zero if any placeholder remains unresolved.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Data Processing & Scripting', 'Text & Document Processing', 'Template Rendering & Macro Expansion', 'Implement a two-stage renderer that processes all .tmpl files under /app/templates: first expand ${VAR} using envsubst limited to a whitelist in /app/allowed_env.txt, then render Jinja2 with values from /app/values.yml and custom filters (slugify, to_kebab, join_path). Write outputs to /app/rendered preserving structure and produce /app/report.json with per-file SHA256 and any unresolved placeholders, exiting non-zero if any remain.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Exception Handling & Recovery', 'Diagnose and fix a Node.js CLI that crashes with unhandled promise rejections when the upstream API stalls or returns invalid JSON by adding robust async error handling, per-request timeouts, and a retry-with-exponential-backoff fallback. Ensure it surfaces clear messages, writes a partial cached result when available, and exits with a nonzero code on unrecoverable errors; verify using the provided flaky server and integration tests.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Exception Handling & Recovery', 'Fix a Python CLI downloader that crashes on transient HTTP errors and leaves corrupted partial files by adding robust try/except handling with timeouts, retry-with-exponential-backoff, mirror fallback, and safe atomic writes that can resume from .part files. Verify by simulating failures and confirming the final artifact matches a provided checksum.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Exception Handling & Recovery', 'Fix a Python ETL loader that crashes on malformed CSV rows, encoding errors, and SQLite constraint violations by adding robust try/except handling, per-row validation, and a dead-letter output. The job should complete with partial success, write rejected rows to /app/bad_rows.csv, and exit zero once all recoverable errors are handled.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Exception Handling & Recovery', 'Harden a Python CLI that crashes with BrokenPipeError when its output is piped to another process (e.g., head) by adding robust EPIPE/SIGPIPE handling and a clean shutdown path. Verify it emits no stack trace, exits successfully, and does not leave partial lines in the downstream output.', 'hard', ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Exception Handling & Recovery', 'Harden a Python CLI that ingests a directory of JSON Lines files into SQLite; it currently crashes on malformed JSON, oversized records, missing keys, and SQLITE_BUSY/locked errors. Add robust try/except and validation to quarantine bad lines, apply bounded retries with exponential backoff for transient DB errors, fall back to defaults for missing fields, and produce a deterministic /app/ingest_summary.json so the run completes without uncaught exceptions.', 'hard', ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Interactive Debugger Usage', 'Debug an intermittent crash in a multithreaded C program by using gdb to reproduce the failure, inspect thread states, and set conditional breakpoints and memory watchpoints to trace a use-after-free. Patch the lifetime bug and verify stability by running the provided stress test until it passes consistently.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Interactive Debugger Usage', 'Diagnose and fix a sporadic SIGSEGV in a multithreaded C ring-buffer logger by reproducing under load, attaching with gdb, and using thread-aware stepping and watchpoints on head/tail indices to find the out-of-bounds write. Patch the bug using proper atomics/locking and verify stability with a stress test.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Interactive Debugger Usage', 'Reproduce and debug an intermittent segmentation fault in a minimal C HTTP chunked-encoding parser by running it under gdb with a crafted malformed request, stepping through the state machine and inspecting buffer pointers to locate an out-of-bounds write. Implement the fix with proper bounds checks/index corrections, recompile, and verify the parser handles the input without crashing and produces correct output.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Interactive Debugger Usage', 'Track down an intermittent segmentation fault in a multi-threaded C log processor by using gdb to reproduce, inspect per-thread backtraces, and set watchpoints on a shared ring buffer to catch the corrupting write. Fix the use-after-free in the consumer, rebuild, and verify stability under a provided parallel stress test.', NULL, ARRAY['parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Interactive Debugger Usage', 'Use gdb to diagnose and fix a sporadic crash in a multithreaded C ring buffer that only fails under -O2 by setting thread-aware breakpoints and watchpoints to catch an out-of-bounds write caused by missing synchronization. Implement correct memory ordering or locking and verify stability by running the provided stress harness until it completes without errors.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Logic & Algorithmic Bugs', 'Diagnose and fix a Rust implementation of topological sort that yields incorrect or nondeterministic orders by mutating a set during iteration and miscounting in-degrees. Implement a correct queue-based Kahn’s algorithm and add a regression test covering cycles, duplicate edges, and deterministic ordering.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Logic & Algorithmic Bugs', 'Fix a Rust CLI’s Dijkstra implementation that returns incorrect shortest-path distances on graphs with zero-weight and parallel edges due to premature visited-marking and missing decrease-key handling. Correct the relaxation and priority-queue logic, add regression tests, and verify outputs on provided fixtures.', NULL, ARRAY['rust', 'parallel']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Logic & Algorithmic Bugs', 'Identify and fix a Python topological sort implementation that returns incorrect orders and occasionally fails to detect cycles due to flawed in-degree updates and non-deterministic node selection. Implement a deterministic Kahn’s algorithm with explicit cycle detection and verify stable ordering across repeated runs on provided DAGs.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Logic & Algorithmic Bugs', 'Repair a shortest-path tool that returns wrong Dijkstra distances on graphs with zero-weight edges due to stale priority-queue entries and off-by-one node indexing. Update the algorithm to correctly handle decrease-key via ignoring stale heap nodes and proper indexing so outputs match provided golden results across multiple graphs, including disconnected cases.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Runtime & Compilation Errors', 'A Rust CLI builds successfully but crashes with SIGSEGV only in --release. Use RUST_BACKTRACE with AddressSanitizer or Miri to locate undefined behavior inside an unsafe block, fix the memory error, and verify cargo test and cargo run complete without crashes.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Runtime & Compilation Errors', 'Diagnose a C++17 CLI tool that compiles but intermittently segfaults on large inputs. Use AddressSanitizer/UBSan and gdb to trace iterator invalidation from std::vector reallocation in a loop, refactor the code to avoid undefined behavior, and verify by running the provided corpus without crashes.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Runtime & Compilation Errors', 'Diagnose and repair a C++ CLI tool that crashes under -O2 with a SIGSEGV due to vector iterator invalidation in a custom deduplication routine. Use AddressSanitizer or gdb to pinpoint the fault, refactor the loop to avoid invalidated iterators, then rebuild with -O2 and verify the program completes on the provided dataset without crashing.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Runtime & Compilation Errors', 'Repair a Rust CLI that fails to compile due to OpenSSL linkage errors and then panics at runtime when a config file is absent by switching TLS dependencies to rustls, fixing Cargo feature flags, and making config loading non-panicking. Verify by building on stable, running cargo test, and executing the binary with and without a config file.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Code Debugging & Error Resolution', 'Runtime & Compilation Errors', 'Repair a flaky multithreaded C11 program that randomly segfaults under -O2 by reproducing the crash, using AddressSanitizer/ThreadSanitizer to locate a data race/use-after-free, and identifying the offending code paths. Implement proper synchronization and lifetime management so the binary runs reliably and passes a provided stress test.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Automation & Cron Job Failures', 'Diagnose a nightly cron job that runs a Python ETL (CSV to Parquet) but fails under cron with ModuleNotFoundError and missing files due to minimal PATH, unset locale, and relative paths. Fix the job by using a virtualenv and absolute paths via a wrapper script, exporting PATH/LANG/TZ, ensuring execute permissions and logging, and verify success by running it under a simulated cron environment.', NULL, ARRAY['python', 'logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Automation & Cron Job Failures', 'Diagnose a nightly cron-scheduled CSV-to-JSON ETL that works manually but fails under cron due to CRLF line endings, a bad shebang, and reliance on relative paths/implicit virtualenv activation. Convert line endings, fix executable/shebang and use absolute paths to the venv’s Python, then verify the job runs from cron and writes the expected outputs and logs.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Automation & Cron Job Failures', 'Diagnose why a nightly cron job defined in /etc/cron.d/etl that should transform /app/input/*.csv into /app/out/data.parquet never produces output. Identify and fix cron-specific issues (PATH/virtualenv, working directory/relative paths, stale flock lockfile) and dependency/import errors so the job runs under cron; verify by forcing a run and ensuring the Parquet is generated.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Automation & Cron Job Failures', 'Investigate a nightly ETL cron job that succeeds interactively but fails under cron by reproducing the cron environment, inspecting mail/cron logs, and pinpointing issues like missing PATH/virtualenv, % expansion in the command, relative paths, or SSH key permission denials. Fix the job by correcting the cron entry (escaping %, adding absolute paths and required environment), adjusting file permissions, and verifying via a forced run and persisted logs.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Automation & Cron Job Failures', 'Investigate why a nightly cron job that runs /app/etl/run_pipeline.sh succeeds interactively but fails under cron due to missing virtualenv activation, PATH differences, non-UTF-8 locale, and a stale lock blocking retries. Make the job cron-safe by using absolute paths and a venv-aware shebang, exporting LANG/LC_ALL, adding flock-based locking, correcting permissions, and verifying execution/logging when triggered by cron.', NULL, ARRAY['logging']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Data Format & Schema Mismatches', 'Debug a failing ETL that joins newline-delimited JSON to CSV lookups after an upstream change made id string-typed and some nested fields optional. Update the ingest and normalization steps to handle schema drift (type coercion, defaulting missing nested fields, dropping unknown columns) and emit a Parquet file that conforms to the provided JSON Schema.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Data Format & Schema Mismatches', 'Diagnose a Spark job that crashes when reading a partitioned Parquet dataset because certain partitions were written with conflicting types for the same columns (e.g., id as int in some, string in others, differing decimal scales). Create a command-line repair tool that scans partitions, infers a unified schema, rewrites or casts offending files, and verifies the job completes with a stable row count.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Data Format & Schema Mismatches', 'Diagnose and fix a Python CSV-to-Parquet conversion script that crashes because different input shards use inconsistent schemas (missing columns, reordered headers, mixed numeric/string types, and dual date formats). Implement a normalization step that defines a canonical schema, coerces/validates types, fills defaults for absent fields, and produces a single readable Parquet dataset verified by a provided reader script.', 'hard', ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Data Format & Schema Mismatches', 'Diagnose and fix a failing ETL step where a pandas CSV loader expects comma-delimited UTF-8 with headers id,event_time,amount, but input partitions are mixed: semicolon-delimited ISO-8859-1 with BOM, and some months rename amount to total_amount or omit it entirely. Implement robust delimiter/encoding detection, header alias mapping, and default value/backfill logic, then emit Parquet conforming to a provided schema and verify via a schema-validation script.', NULL, ARRAY['pandas']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Data Format & Schema Mismatches', 'Diagnose and fix a failing Python ETL that ingests NDJSON into a SQLite table where some shards emit objects missing required fields, integers as strings, or an array instead of an object. Implement a loader that validates against a provided JSON Schema, coerces types and fills defaults, quarantines irreparable records to /app/bad_rows.ndjson, and completes the load without errors.', 'hard', ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'I/O & File Handling Errors', 'A log aggregation ETL that tails /var/log/app.log misses data after rotation and crashes on reading gzipped archives due to stale file handles and incorrect decompression. Diagnose and fix the pipeline to detect log rotation (reopen on inode change), read both .log and .log.*.gz with correct permissions, and emit a complete deduplicated JSONL to /app/out.jsonl for a target date.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'I/O & File Handling Errors', 'Debug a Python ETL that merges CSVs from input/ into a single Parquet but crashes with UnicodeDecodeError and FileNotFoundError because it assumes UTF-8 and only matches *.csv while some inputs are .csv.gz and Windows-1252 or UTF-8-BOM encoded. Implement robust file discovery and decoding (support .csv/.csv.gz, handle BOM and cp1252 fallback) and ensure the output writes to out/ with proper permissions, then rerun to pass row-count and schema checks.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'I/O & File Handling Errors', 'Diagnose and fix a Python log ETL that hangs or fails with UnicodeDecodeError when consuming gzipped records from a named pipe and rotating .gz files because it treats FIFOs like regular files, seeks on non-seekable streams, and assumes UTF-8. Make the reader stream-safe, BOM/encoding-aware, and tolerant of concatenated/partial gzip members, then verify it emits a single UTF-8, LF-normalized output.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'I/O & File Handling Errors', 'Diagnose and fix a file-descriptor leak in a Python ETL that globs and processes thousands of (optionally gzipped) JSON Lines files, causing intermittent ''Too many open files'' errors. Refactor to use context managers and bounded concurrency, then verify the full dataset ingests without EMFILE failures.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'I/O & File Handling Errors', 'Diagnose why a JSONL merge ETL script silently skips inputs and corrupts records when traversing a directory tree containing spaces/newlines in filenames, symlinks, and mixed UTF-8/Latin-1 encodings. Repair the script to robustly discover files and handle .jsonl and .jsonl.gz, safely read/normalize encodings, and write a single deduplicated UTF-8 newline-delimited output to /app/merged.jsonl.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Pipeline Stage Failures', 'Debug a GNU Make–driven ETL where a CSV→JSON→SQLite pipeline intermittently fails because a normalization step writes to a .tmp file and downstream rules consume stale outputs due to misdeclared targets and misordered prerequisites. Fix the Makefile by declaring correct outputs, ordering dependencies (including any order-only deps), and verify that a full run and incremental rebuilds execute the correct stages end-to-end.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Pipeline Stage Failures', 'Debug a Snakemake ETL where a normalization step writes gzipped CSVs while declaring .csv outputs, causing downstream aggregation to miss inputs and the DAG to misorder. Fix the rule I/O patterns, compression settings, and dependencies so the pipeline runs end-to-end and emits the expected final summary.csv.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Pipeline Stage Failures', 'Debug a broken Snakemake-based ETL where a mid-pipeline ''normalize -> join -> partition'' stage fails because the normalize step emits NDJSON while the join expects a JSON array and sometimes runs before normalize completes. Identify and fix misdeclared dependencies and the schema mismatch so the pipeline orders correctly and the final partitioned Parquet output passes a row-count validation.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Pipeline Stage Failures', 'Diagnose a Snakemake ETL where a mid-pipeline rule now outputs gzipped TSV files while downstream rules still expect plain TSV, leading to a no-op aggregation and an empty final report. Align I/O patterns and shell commands across affected rules, rebuild the DAG, and verify the corrected output.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Data & Pipeline Debugging', 'Pipeline Stage Failures', 'Diagnose and fix a Snakemake data pipeline where a mid-stage rule fails because its declared outputs don’t match the files written by the upstream step (gzip enabled, wrong suffix and temp directory), causing MissingOutputException. Align input/output patterns and compression flags, add any missing dependencies, and run the workflow end-to-end to produce /app/out/summary.csv.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Build Configuration & Toolchain Issues', 'Diagnose a CMake project whose shared plugin fails to link and cannot be loaded at runtime due to missing -fPIC objects and incorrect RPATH/SONAME. Update CMakeLists.txt to enable POSITION_INDEPENDENT_CODE, correct link order, and set a proper INSTALL_RPATH so the host executable can dlopen the plugin and pass the provided test.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Build Configuration & Toolchain Issues', 'Diagnose a CMake-based C++ project that fails to link on a clean environment due to missing transitive dependencies and non-PIC objects in a shared library. Fix CMakeLists.txt to use imported targets with correct PUBLIC/INTERFACE scopes and enable POSITION_INDEPENDENT_CODE, then rebuild and verify by running the provided demo binary.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Build Configuration & Toolchain Issues', 'Diagnose and fix a CMake project that fails to build a shared plugin because a bundled static library is compiled without position-independent code, causing relocation errors at link time. Update the build to ensure all static libraries linked into shared targets are built with -fPIC (e.g., setting POSITION_INDEPENDENT_CODE and propagating flags) and verify the plugin builds and loads with a small test program.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Build Configuration & Toolchain Issues', 'Diagnose and repair a CMake-based C++ project that fails to link a shared library due to non-PIC static dependencies and whose test binary cannot locate the built .so at runtime. Modify CMake to build static libs with POSITION_INDEPENDENT_CODE and set correct RPATH/INSTALL_RPATH so the library links and the tests execute successfully.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Build Configuration & Toolchain Issues', 'Fix a CMake-based C++ project that fails to build shared libraries due to missing -fPIC and unresolved OpenMP symbols when using Clang. Diagnose the errors and update the CMake configuration to enable position independent code and link the correct OpenMP runtime so the project compiles and tests run successfully.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Package Installation Failures', 'Diagnose and fix an npm install failure for the sharp image library where native module build via node-gyp breaks due to missing toolchain and system libraries or incompatible Node ABI/prebuilt binaries. Install the necessary build tools and libvips (or align Node version so prebuilt binaries work), then verify by running a Node script that loads sharp and successfully resizes an image.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Package Installation Failures', 'Diagnose and fix why pip install lxml fails due to missing system headers and build tools (libxml2/libxslt, zlib, compiler). After repair, install lxml successfully and verify by running a provided test script that parses XML without errors.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Package Installation Failures', 'Diagnose and repair a failing npm install of node-canvas that errors with node-gyp and missing libcairo/Pango headers by installing the correct system build tools and configuring pkg-config (and, if necessary, pinning to a compatible Node ABI). Verify the fix by successfully installing the package and rendering a PNG to /app/out.png using a provided test script.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Package Installation Failures', 'Diagnose and repair a pip install failure for pygraphviz on a minimal Linux image where the build cannot locate Graphviz headers/libraries. Install the required system packages and set appropriate env vars so the wheel builds, then verify by generating a PNG from a simple graph.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Package Installation Failures', 'In an Alpine Linux container, diagnose and fix pip install cryptography failing by installing the Rust toolchain and OpenSSL/musl development headers, and configuring the build environment so a source build succeeds. Verify by importing cryptography and generating an Ed25519 keypair in a short Python script.', NULL, ARRAY['container', 'cryptography', 'rust', 'python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'System Library & Path Errors', 'Diagnose a Python + GDAL/PROJ setup where importing osgeo.gdal fails with a libgdal.so load error or missing grid files because the shared libraries and data directories aren’t on the search path. Fix by correctly wiring PATH/LD_LIBRARY_PATH/PKG_CONFIG_PATH and GDAL_DATA/PROJ_LIB (or adding an rpath) and verify by importing GDAL and performing a coordinate transform.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'System Library & Path Errors', 'Diagnose and fix a prebuilt CLI in /app/bin/remote-sync that fails with ''error while loading shared libraries: libssl.so.1.1'' due to an OpenSSL ABI mismatch. Provide a compatible libssl/libcrypto and configure the dynamic linker (e.g., rpath/LD_LIBRARY_PATH or ldconfig) so ldd resolves all libraries and the CLI completes its test run.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'System Library & Path Errors', 'Diagnose and repair a Pillow import failure caused by a missing or mislinked system libjpeg (e.g., ''libjpeg.so.X: cannot open shared object file''). Install or relink the correct library and rebuild or reinstall Pillow, then verify JPEG load/save works in a short script.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'System Library & Path Errors', 'Diagnose and repair a prebuilt ELF CLI in /app/bin that fails with ''error while loading shared libraries: libfoo.so.X: cannot open shared object file'' due to a missing or misconfigured runtime library search path. Locate the correct library directory and fix the binary via RPATH (patchelf) or environment (LD_LIBRARY_PATH) so the tool executes a provided command successfully.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'System Library & Path Errors', 'Diagnose why the prebuilt CLI at /app/bin/tool fails to start with missing libssl/libstdc++ errors due to ABI/version mismatches and incorrect library search paths. Repair by vendoring compatible shared libraries and fixing the loader path (RPATH/RUNPATH or LD_LIBRARY_PATH via patchelf or a wrapper) so the tool runs and its self-test completes successfully.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Version Incompatibility', 'Diagnose a Node.js project that fails with a ''module was compiled against a different Node-API/ABI'' error due to a mismatch between the installed Node version and native addon binaries (e.g., sharp/sqlite3). Align versions by switching Node via nvm/asdf or rebuilding addons, then verify the app runs a provided command successfully.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Version Incompatibility', 'Diagnose a Rust workspace that fails to build because the pinned dependencies require a newer Rust toolchain/edition than the installed rustc and cargo. Resolve by activating a compatible toolchain (e.g., via rustup or a directory override) or re-resolving to compatible crate versions, then build and run the tests successfully.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Version Incompatibility', 'Diagnose and fix a Node.js TypeScript project where builds/tests fail under Node 20 due to incompatible versions of TypeScript, ts-node/ts-jest, and Jest (ESM/CJS loader and peer-dependency errors). Align and pin a compatible toolchain or update configs for ESM/CJS correctly, then verify npm run build and npm test succeed.', NULL, ARRAY['typescript']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Version Incompatibility', 'Diagnose and fix a Node.js project that fails to start due to a native addon compiled for an incompatible Node-API/ABI (e.g., “Module version mismatch” or “Module did not self-register”). Align the Node.js/runtime version and rebuild the addons (or select a compatible prebuilt) so the program runs and the addon loads successfully.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Dependency & Build Troubleshooting', 'Version Incompatibility', 'Diagnose and fix a Rust project’s build failure where the openssl-sys crate is incompatible with the system OpenSSL version (e.g., libssl3 vs libssl1.1). Apply a minimal remedy (pin a compatible crate version, install matching OpenSSL dev headers, or enable the vendored feature), then rebuild and verify the binary performs a successful HTTPS request.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Configuration File Parsing & Validation', 'Diagnose a failing Go HTTP service that crashes on startup due to a YAML configuration using anchors/aliases, merge keys (<<), and ${ENV} placeholders that its parser does not support. Normalize the config by materializing merges, expanding environment variables, fixing type mismatches against a provided JSON Schema, and verify the service boots and passes the health-check script.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Configuration File Parsing & Validation', 'Diagnose and fix a CI pipeline failure caused by a YAML config that mixes tabs, YAML 1.1 booleans (on/off), merge keys/anchors, and unexpanded ${VAR} placeholders that the runner’s parser rejects. Normalize indentation, quote literals per YAML 1.2, inline merged sections, supply safe defaults for env placeholders, and verify with yamllint and a successful dry-run of the pipeline.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Configuration File Parsing & Validation', 'Diagnose and fix a broken Docker Compose v2 YAML that misuses anchors/merge keys and ${VAR} interpolation, triggering schema/type errors on docker compose. Refactor to a valid v2 schema (e.g., via x- extension fields and correct quoting), supply a minimal .env, and verify with docker compose config and a successful service start.', NULL, ARRAY['docker']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Configuration File Parsing & Validation', 'Diagnose why Prometheus fails to start by fixing prometheus.yml and the referenced rules/*.yml: tabs, a UTF-8 BOM, inconsistent indentation, and a stringified numeric scrape_interval cause YAML parsing and schema validation errors. Normalize the files (no tabs/BOM), correct types and rule paths to satisfy the Prometheus schema, and verify with promtool check config and promtool check rules.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Configuration File Parsing & Validation', 'Diagnose why a Prometheus server fails to start due to a malformed prometheus.yml (bad indentation, duplicate scrape_configs, and invalid relabel_configs). Fix the YAML so promtool check config passes and the server can start and scrape a bundled dummy target, verified by a successful GET of /-/ready.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Cross-Platform Environment Differences', 'Diagnose a Python CLI project that runs on macOS/Windows but fails on Linux due to case-mismatched imports and CRLF-terminated helper scripts causing /bin/sh^M errors. Make it Linux-portable by correcting import/module casing and normalizing line endings and path handling, then verify the CLI executes successfully end-to-end.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Cross-Platform Environment Differences', 'Diagnose a Python CLI that crashes with UnicodeEncodeError on Linux but works on macOS due to running under the C/POSIX locale. Generate and set a UTF-8 locale in the container (e.g., en_US.UTF-8), update startup config to export LANG/LC_ALL, and verify it correctly processes non-ASCII filenames.', NULL, ARRAY['python', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Cross-Platform Environment Differences', 'Diagnose why a Node.js project that builds on Windows/macOS fails in the Linux container due to CRLF shebangs, case-insensitive import paths, and Windows-only path separators in package scripts, and make it fully portable. Verify by normalizing line endings, fixing import path casing, updating scripts to cross-platform commands, and ensuring npm ci && npm run build && npm test complete successfully in the container.', NULL, ARRAY['container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Cross-Platform Environment Differences', 'Diagnose why project entrypoint scripts run on Windows/macOS but fail in Linux containers with errors like ''/usr/bin/env: python\r: No such file or directory'' or ''Permission denied''. Normalize line endings to LF, fix shebangs, set executable bits, and add .gitattributes rules to enforce cross-platform-safe endings, then verify the scripts execute successfully.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Cross-Platform Environment Differences', 'Investigate a Python CLI project that works on Windows but fails on Linux with a python^M shebang error and a ModuleNotFoundError from a case-mismatched import. Fix by converting CRLF to LF, correcting import/file casing, and adding .gitattributes rules to enforce LF line endings and case-consistent paths.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Environment Variable Misconfiguration', 'A Node.js Express app crashes at startup with ''Missing ENV: DATABASE_URL, JWT_SECRET'' even though a .env file exists. Diagnose why environment variables are not loaded in the containerized runtime, load or export them correctly so the app starts, and verify the /health endpoint returns 200.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Environment Variable Misconfiguration', 'A local API test suite times out because HTTP_PROXY/HTTPS_PROXY force localhost traffic through an external proxy and NO_PROXY is misconfigured. Diagnose and fix the proxy-related environment variables (including IPv4/IPv6 loopbacks and custom ports) so requests reach the local service and the test script completes successfully.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Environment Variable Misconfiguration', 'Diagnose and fix a CLI application’s UnicodeDecodeError caused by running under the POSIX C locale with LANG/LC_* unset or misconfigured. Configure and activate a UTF-8 locale and appropriate environment variables so the program can read and print UTF-8 (including emojis) without errors.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Environment Variable Misconfiguration', 'Diagnose and fix a CLI tool that crashes on Unicode filenames due to a non-UTF-8 locale by correctly configuring LANG/LC_ALL and generating the required UTF-8 locale in the container. Persist the fix for both interactive and non-interactive shells, then verify the tool processes files with accented characters without errors.', NULL, ARRAY['container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Environment Variable Misconfiguration', 'Diagnose why both curl and a Python requests client fail HTTPS verification against a provided local TLS service, tracing it to a missing CA trust path. Configure SSL_CERT_FILE or SSL_CERT_DIR to point at the bundled CA bundle so both tools succeed, and verify by performing a successful GET request.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Virtual Environment & Container Issues', 'Diagnose a Docker image where a preinstalled Conda environment is not used at runtime, causing imports to fail because the container launches with a non-login shell that never activates Conda. Fix the Dockerfile/entrypoint to reliably run under the intended Conda env (e.g., conda run -n app or sourcing conda.sh) and verify by executing a provided script that imports numpy and prints its version.', NULL, ARRAY['docker', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Virtual Environment & Container Issues', 'Diagnose and fix a relocated Python virtual environment whose scripts and sys.path still reference an old absolute interpreter path, causing entry points and imports to fail. Recreate or patch the venv so it binds to the container’s Python and current path, then verify by activating it and successfully running the project’s console script and an import/version check.', NULL, ARRAY['python', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Virtual Environment & Container Issues', 'Fix a Poetry-managed Python app in Docker where `poetry run` fails because Poetry is bound to a stale global virtualenv created with a different Python version outside the container. Reconfigure Poetry to create an in-project venv with the container’s interpreter, rebuild the environment cleanly, and verify the app’s CLI executes end-to-end.', NULL, ARRAY['python', 'docker', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Virtual Environment & Container Issues', 'In a Docker image, a prebuilt Python virtualenv was moved to a new path, causing console_scripts to fail with ''bad interpreter'' and C-extension imports to break due to a mismatched sys.base_prefix. Diagnose and re-home the venv without reinstalling packages by fixing pyvenv.cfg, rewriting shebangs and activation scripts, cleaning conflicting PYTHONPATH/site-packages, and verify by running a bundled CLI and importing a compiled wheel (e.g., numpy).', NULL, ARRAY['docker', 'python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Environment & Configuration Debugging', 'Virtual Environment & Container Issues', 'In an Alpine-based Docker container, diagnose why importing a pip-installed C-extension fails due to manylinux/glibc vs musl incompatibility. Resolve by ensuring compatible musllinux wheels or required runtime libraries (or switching base image) and verify the fix with a successful import and small test run.', NULL, ARRAY['docker', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'API Request & Response Issues', 'Diagnose and fix intermittent HMAC-signed API request failures to a local microservice caused by mismatched JSON canonicalization and header normalization between client and server. Update the client to produce a canonical UTF-8 JSON body with stable key order and correct Content-Type/Date headers before signing, then verify end-to-end and add a regression test.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'API Request & Response Issues', 'Diagnose why a POST JSON request to a REST API fails after an HTTP redirect (e.g., 301/302 to HTTPS) because the client changes the method or drops the body, leading to 405/400 responses. Fix the client or invocation to target the canonical base URL or preserve method/body on redirect (use 307/308 semantics), and verify the corrected request succeeds with the expected JSON response.', NULL, ARRAY['rest', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'API Request & Response Issues', 'Diagnose why a Python CLI using requests gets 401 and 415 from a local OAuth2-protected REST API: the token exchange is incorrectly sent as JSON instead of application/x-www-form-urlencoded and subsequent requests pass the token as a query param instead of Authorization: Bearer. Fix the payload encoding and header usage, then verify by successfully calling a paginated endpoint while honoring Retry-After to avoid 429s.', NULL, ARRAY['python', 'rest', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'API Request & Response Issues', 'Diagnose why a provided CLI client receives 401 ''signature mismatch'' from a mock HMAC-signed REST API by auditing canonicalization (query param order, header inclusion, body hashing) and timestamp/nonce handling. Correct the signing logic and required headers so POST /v1/payments returns 201, then verify by GETting the created resource and writing its id to /app/payment_id.txt.', NULL, ARRAY['rest', 'api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Connection & Timeout Errors', 'Diagnose and fix slow HTTP requests caused by the system preferring IPv6 (AAAA) addresses that are unroutable, leading to connection timeouts before IPv4 fallback. Reconfigure address selection, routing, or resolver settings so connections to a dual-stack host complete quickly without timeouts.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Connection & Timeout Errors', 'Diagnose why curl/http clients to a local service on localhost:5000 time out because global proxy settings force localhost traffic through an unreachable HTTP(S) proxy. Remove or correctly scope the proxy configuration (e.g., NO_PROXY, environment vars, tool configs) and verify direct local connectivity works from curl and a sample client.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Connection & Timeout Errors', 'Diagnose why outgoing HTTP requests from a CLI client to a local/internal API consistently time out due to misconfigured proxy environment variables (HTTP_PROXY/HTTPS_PROXY/NO_PROXY) that route localhost/intranet traffic through a dead proxy. Correct the environment and client/server settings so direct connections to 127.0.0.1 and internal hostnames bypass the proxy and succeed, verifying with curl and a simple script.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Connection & Timeout Errors', 'Investigate persistent timeouts when a local microservice calls an internal API and discover they are caused by inherited HTTP(S)_PROXY environment variables pointing to a dead proxy. Reconfigure NO_PROXY or unset the proxy so direct connections succeed, and verify with curl and a test run.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Connection & Timeout Errors', 'Investigate why a client app’s HTTP requests to an internal service stall before timing out: the hostname resolves to IPv6 while the server only binds on IPv4. Fix the mismatch (e.g., enable dual-stack binding or force IPv4 resolution) and verify low-latency success with the provided test script.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Proxy, SSL & Certificate Errors', 'A Python client fails mutual TLS to a Flask service behind an Nginx reverse proxy because the issued certificates lack SAN/extendedKeyUsage and the proxy serves an incomplete certificate chain. Regenerate CA/server/client certs with proper SAN and EKU, configure Nginx to present the full chain and require client auth, update the client trust store, and verify successful requests with curl and a provided test script.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Proxy, SSL & Certificate Errors', 'Diagnose and fix a Node.js service that fails on outbound HTTPS due to an intercepting proxy and missing CA trust while also misrouting internal calls through the proxy. Configure HTTP(S)_PROXY and NO_PROXY correctly and provide the proxy’s root CA to Node (e.g., NODE_EXTRA_CA_CERTS) so external requests succeed via the proxy and internal hosts bypass it, verified by two test fetches.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Proxy, SSL & Certificate Errors', 'Diagnose and fix an Nginx reverse proxy that returns 502 due to a failed TLS handshake with an HTTPS upstream caused by disabled SNI and an untrusted/intermediate-missing CA chain. Update the proxy’s TLS settings (enable SNI, set the correct upstream host, provide a trusted CA bundle) and verify that curling the proxied endpoint over HTTPS succeeds.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Proxy, SSL & Certificate Errors', 'Diagnose and repair a Maven-based Java project that fails to download dependencies through a corporate HTTPS proxy performing TLS interception. Import the provided root CA into the JVM truststore, configure authenticated proxy settings without disabling SSL verification, and verify mvn dependency:resolve succeeds.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Proxy, SSL & Certificate Errors', 'Fix a broken mutual TLS setup on an Nginx reverse proxy fronting a local API: clients see handshake failures and ''unknown ca'' errors due to an incomplete server certificate chain and verification against the wrong client CA. Rebuild and reference the correct fullchain, configure nginx to trust the proper client CA, issue a client certificate/key, reload, and verify curl with the client cert succeeds while requests without it are rejected.', NULL, ARRAY['api']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Service Availability & Health Checks', 'Diagnose a FastAPI service managed by supervisord that never becomes healthy because it binds only to 127.0.0.1 and its /healthz endpoint crashes on missing environment configuration. Reconfigure binding to 0.0.0.0 and make the health check independent of external services, then verify the container healthcheck and curl to /healthz return 200.', NULL, ARRAY['container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Service Availability & Health Checks', 'Diagnose a Nginx→Gunicorn→Flask stack that never passes its health check because Nginx proxies to a nonexistent unix socket, Gunicorn is listening on TCP port 8001, and the /health endpoint hard-depends on a missing database. Reconfigure the upstream to the correct port and make the health route shallow so the service reports healthy and curl to /health returns 200.', 'hard', ARRAY['database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Service Availability & Health Checks', 'Diagnose a Python FastAPI service that returns 500 on /health only when started by systemd due to an incorrect working directory and missing environment variables. Fix the systemd unit (WorkingDirectory, Environment/EnvironmentFile, ExecStart, dependencies) and any file paths so the service is active and curl localhost/health returns 200.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Service Availability & Health Checks', 'Diagnose an Nginx-proxied FastAPI service whose /health endpoint returns intermittent 502s due to IPv6/IPv4 mismatch (upstream resolving to ::1 while the app binds only to 127.0.0.1). Adjust the app bind address or Nginx upstream to ensure consistent HTTP 200 health checks across restarts.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Network & Service Debugging', 'Service Availability & Health Checks', 'Diagnose and fix a misconfigured reverse proxy that causes a healthy backend service to fail its /healthz check (e.g., wrong upstream port, missing Host/X-Forwarded headers, or TLS-to-HTTP mismatch). Correct the proxy and service configs and reload them so curl http://localhost/healthz returns 200 with the expected body.', NULL, ARRAY['backend']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'CPU & Memory Profiling', 'Profile a C log-parsing utility that becomes slow and runs out of memory on a large dataset due to quadratic string concatenation and leaked allocations. Use Valgrind (memcheck/massif) or perf/callgrind to pinpoint hotspots, refactor to buffered/streamed processing and proper frees, and verify identical output with markedly lower peak RSS and faster runtime.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'CPU & Memory Profiling', 'Profile a C++ image-processing CLI that becomes CPU-bound and steadily grows memory during a large batch, using perf and Valgrind (callgrind/massif) to pinpoint an O(n^2) hot loop and unbounded container growth. Implement fixes to achieve at least 2x faster runtime and reduce peak RSS by 50% or more, verified by a provided bench.sh baseline/after comparison.', NULL, ARRAY['container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'CPU & Memory Profiling', 'Profile a Go HTTP log aggregator that shows steadily rising memory usage and high CPU under sustained load using pprof (heap and CPU profiles) to uncover a goroutine leak and an O(n^2) JSON concatenation hotspot. Implement fixes (proper context cancellation, bounded channels, and bytes.Buffer-based assembly) and verify with the provided load test that throughput improves and peak RSS remains bounded.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'CPU & Memory Profiling', 'Profile a Python CSV-to-JSON pipeline that pegs a CPU core and steadily increases RSS on large inputs. Use cProfile and tracemalloc to locate an O(n^2) dedup step and an unbounded cache, refactor to a streaming/chunked approach with bounded caching, and verify at least 2× speedup and <200 MB peak memory on a 1M-row dataset.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'CPU & Memory Profiling', 'Profile a mixed Python+C log-processing tool to locate CPU hotspots and memory bloat using cProfile, perf, and Valgrind (memcheck/massif). Eliminate an O(n^2) Python loop and fix a C-side leak so the job completes ≥2x faster with ≥50% lower peak RSS while preserving identical output.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'I/O & Disk Bottlenecks', 'Diagnose a C-based log aggregator that is extremely slow due to 1-byte read() calls and an fsync/flush on every line. Refactor it to use buffered streaming and batched writes (e.g., setvbuf/FILE* or coalesced writev) and verify /app/bench.sh runs at least 5x faster without changing output.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'I/O & Disk Bottlenecks', 'Diagnose a Python SQLite ingestion script that is painfully slow due to per-row transactions causing fsync storms and page cache thrashing. Use strace/iostat to confirm the I/O bottleneck, then optimize by batching transactions and enabling WAL with appropriate PRAGMAs to achieve >5× speedup while preserving identical database contents.', NULL, ARRAY['python', 'database']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'I/O & Disk Bottlenecks', 'Diagnose a Python log-processing CLI that is extremely slow because it writes output one line at a time with fsync after each write and a tiny buffer. Rework it to batch and buffer writes and use atomic rename on completion, remove unnecessary fsyncs, and verify at least a 5x speedup on the provided dataset with byte-for-byte identical output.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'I/O & Disk Bottlenecks', 'Diagnose and fix a severe disk I/O bottleneck in a Python-based SQLite bulk loader that inserts rows individually (autocommit on), triggering per-row fsyncs and tiny writes. Optimize by batching transactions and enabling WAL with appropriate PRAGMAs (e.g., synchronous=NORMAL, page/cache tuning) to achieve a measurable speedup while preserving identical dataset contents.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'I/O & Disk Bottlenecks', 'Diagnose why a Python log-processor that splits records per user is extremely slow due to per-line open/flush/close and tiny writes causing fsync storms. Use strace/iostat to pinpoint the issue, then refactor to maintain buffered file handles and batch writes, verifying identical output and improved runtime.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Network Performance Tuning', 'Diagnose a severe throughput collapse and sporadic stalls across a VXLAN tunnel caused by an MTU black hole (broken PMTUD), using ping with DF and tcpdump to determine the effective path MTU. Apply a fix by setting appropriate interface MTUs and TCP MSS clamping so iperf3 throughput improves at least 3x without packet loss, and write the discovered MTU/MSS to /app/mtu_report.txt.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Network Performance Tuning', 'Diagnose and fix severely limited throughput between two containers on a high-RTT simulated link by identifying TCP window/buffer and congestion-control misconfiguration. Measure with iperf3 and ss/tcpdump, then tune sysctl (enable window scaling, raise rmem/wmem and tcp_rmem/tcp_wmem, switch to BBR with fq, adjust MTU/MSS if needed) and verify higher goodput with fewer retransmits.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Network Performance Tuning', 'Diagnose and optimize a gRPC microservice’s network stack under a simulated 80 ms RTT and 1% packet loss to cut p99 latency by at least 50% without reducing throughput. Apply and verify kernel- and app-level tuning (e.g., congestion control/qdisc, HTTP/2 flow-control windows, TCP keepalive/Nagle, MTU/MSS) using the provided load generator and report.', NULL, ARRAY['grpc']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Network Performance Tuning', 'Diagnose and optimize poor TCP throughput between two local endpoints under simulated WAN latency by measuring with iperf3, inspecting kernel TCP settings, and identifying buffer/congestion-control bottlenecks. Apply sysctl/qdisc tuning (e.g., enable BBR, adjust rmem/wmem and net.core.{r,w}mem_max, set fq qdisc) and verify at least a 2× throughput improvement.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Network Performance Tuning', 'Diagnose why a Python asyncio TCP client/server for log shipping achieves poor throughput and high p99 latency due to tiny writes triggering Nagle/delayed-ACK interactions and lack of connection reuse. Tune by enabling TCP_NODELAY, batching into 64KB frames, increasing socket buffers and enabling keep-alive/pooling, then verify a 5–10× throughput gain and sub-20ms p99 with the provided load generator.', NULL, ARRAY['python']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Parallelization & Concurrency Bugs', 'Diagnose a deadlock and throughput collapse in a Rust Tokio-based pipeline where a Mutex is held across await points and a bounded mpsc channel backpressures a blocking file writer. Refactor to avoid cross-await locks and move blocking I/O to spawn_blocking or a dedicated thread pool, then verify no hangs under a provided stress script and achieve at least 3× higher throughput.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Parallelization & Concurrency Bugs', 'Diagnose a throughput collapse in a Java service where CompletableFuture chains run on a fixed-size ExecutorService, causing thread-starvation deadlocks under load. Refactor the scheduling (e.g., non-blocking composition or separate executors for nested tasks) so the load test completes without timeouts and throughput improves by at least 2x.', NULL, ARRAY['java']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Parallelization & Concurrency Bugs', 'Diagnose and fix a deadlock and goroutine leak in a Go fan-out/fan-in worker pool where misordered channel closes and blocking sends during cancellation stall the pipeline under load. Correct the synchronization (context propagation, channel buffering, and close/drain order) so the provided stress test finishes under the time limit and go test -race shows no leaks or races.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Parallelization & Concurrency Bugs', 'Diagnose and fix a deadlock in a Go-based concurrent log processor where workers hold a mutex while sending to a results channel, creating a circular wait with the aggregator that acquires the same lock. Refactor to avoid holding locks across channel operations (e.g., copy before send or introduce a dispatcher) and verify under a stress harness that prior hangs disappear and throughput improves.', NULL, NULL);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Performance & Resource Optimization', 'Parallelization & Concurrency Bugs', 'Diagnose and fix an intermittent deadlock in a Rust Tokio service caused by holding a std::sync::Mutex across await points and doing blocking file I/O inside async tasks, leading to hangs under load. Refactor to use tokio::sync::Mutex/RwLock and spawn_blocking for I/O, add cancellation timeouts, and verify via a stress script, cargo test, and tokio-console traces.', NULL, ARRAY['rust']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Root Cause Analysis & Postmortem Debugging', 'Dependency & Environment Audit', 'Diagnose why a Node.js project’s native addon (e.g., sharp or grpc) fails to load with errors like GLIBC_x.y not found or wrong ELF class inside the container. Audit Node ABI vs compiled binaries and system libc/libstdc++ versions, rebuild or pin a compatible binary with node-gyp and verify the addon loads in a minimal script.', NULL, ARRAY['grpc', 'container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Root Cause Analysis & Postmortem Debugging', 'Dependency & Environment Audit', 'Diagnose why the prebuilt /app/server web binary exits on launch with “No such file or directory” and fix it by auditing dynamic library dependencies and environment drift (e.g., missing libsqlite3 due to CGO). Install or rebuild with the correct dependencies (or static linking), verify the /health endpoint responds, and write a brief postmortem to /app/POSTMORTEM.md.', NULL, ARRAY['web']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Root Cause Analysis & Postmortem Debugging', 'Dependency & Environment Audit', 'Investigate a prebuilt C++ CLI tool that fails at startup with a “GLIBCXX_x.y not found” error inside the container. Identify the ABI mismatch between the binary and the system libstdc++/glibc, remediate by aligning runtime libraries or rebuilding, and verify the tool runs successfully end-to-end.', NULL, ARRAY['container']);
INSERT INTO task_inspiration (category, subcategory, subsubcategory, description, difficulty, tags) VALUES ('Debugging & Troubleshooting', 'Root Cause Analysis & Postmortem Debugging', 'Dependency & Environment Audit', 'Investigate why importing a pip-installed C++ extension (e.g., scikit-learn) now fails with GLIBCXX/CXXABI symbol errors after a base image or compiler runtime change by auditing the system’s libstdc++/libgcc versus the wheel’s required ABI. Resolve by aligning the C++ runtime or installing compatible wheels/pins, then verify with a minimal script that imports and exercises the package.', NULL, NULL);
