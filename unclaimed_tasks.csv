id,category,subcategory,subsubcategory,description,difficulty,tags
9a541ce3-593a-446f-bf69-a5cb44682a6d,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,"Fix cross-compilation configuration to build a static ARMv7 ELF binary from provided C source. Then validate with readelf and qemu-arm that the binary’s ELF header reflects ARMv7, has no dynamic dependencies, and outputs the expected text when run.",,
d24c17f0-b523-4201-9aa8-6607e663f198,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,Repair a CMake-based C shared library that leaks internal symbols and lacks proper SONAME/versioning by enforcing hidden visibility and a GNU ld version script. Validate that the built lib has SONAME libfoo.so.1 and exports only the intended API symbols under version FOO_1.0 (checked via nm/readelf) and that a minimal client links and runs successfully.,,
02eaed24-fc17-4297-9bdf-4ef9ced8c87f,Build & Dependency Management,Build Troubleshooting & Repair,Build Output Validation,"Validate reproducible builds for a C/C++ project by building twice under different environments (e.g., varied timestamps or locales), comparing sha256 checksums of the resulting binaries, and then eliminate sources of non-determinism by applying flags like SOURCE_DATE_EPOCH, -fdebug-prefix-map, and -frandom-seed to achieve identical outputs.",,
626458c4-0384-42f1-8771-de8e3d116758,Build & Dependency Management,Build Troubleshooting & Repair,Compiler & Linker Errors,"A CMake-based C++ project using Boost.Asio and OpenSSL fails at link time due to missing SSL and crypto libraries. Update CMakeLists.txt (or build invocation) to correctly find and link OpenSSL and required Boost components, then verify the resulting HTTPS client connects to example.com and prints the HTTP status code.",,
9cff9d5e-6c07-4b65-a428-99c15efa2222,Build & Dependency Management,Build Troubleshooting & Repair,Compiler & Linker Errors,"Diagnose and fix linking errors in a Bazel build for a mixed Java/C++ JNI project, where native libraries report 'undefined symbol Java_com_example_MyClass_nativeMethod'. Update BUILD.bazel rules to include correct cc_library dependencies, apply -shared linkopts, and configure include and runtime paths so the binaries load without LD_LIBRARY_PATH.",,
ef842a7d-813c-4517-8a36-18b715855451,Build & Dependency Management,Build Troubleshooting & Repair,Configuration & Environment Issues,"Set up and configure a cross-compiling environment in a Docker sandbox to build a CMake-based C project for the ARMv7 target, diagnosing and fixing toolchain file misconfigurations, incorrect CC/CXX/SYSROOT environment variables, and missing cross-compiler packages. Then rebuild the project, run the resulting ARM binary under QEMU, and verify it prints the expected output.",,
3ca94130-8b92-4f25-8017-eb0015e29ce6,Build & Dependency Management,Build Troubleshooting & Repair,Configuration & Environment Issues,"Diagnose and fix a Meson-based C project that fails to detect SDL2 because it is installed under a non-standard prefix (/opt/sdl2). Configure environment variables (e.g., PKG_CONFIG_PATH and LD_LIBRARY_PATH) and, if needed, a Meson cross file so the project configures, builds, and the resulting binary links against /opt/sdl2 as verified by ldd.",,
51c7c08a-145f-4160-ba2b-ecb0773239e3,Build & Dependency Management,Build Troubleshooting & Repair,Configuration & Environment Issues,"In a Debian-based Docker sandbox, install and configure an aarch64-linux-gnu cross-compiler toolchain, set CMAKE_TOOLCHAIN_FILE, CC, CXX, SYSROOT, and PKG_CONFIG_PATH to resolve missing include and library paths, and build the CMake-based project for ARM64. Verify the resulting binary runs under QEMU-aarch64 and prints the expected token.",,
89a3682b-5a04-4ffb-985b-3f58e545e0c7,Build & Dependency Management,Continuous Integration & Automation,CI Configuration & Maintenance,"Configure a GitHub Actions workflow that builds and tests a Rust project in a matrix (Linux and macOS) with sccache and dependency caching, then on tags performs two clean release builds and asserts the binaries are bit-for-bit identical before uploading them as artifacts. The pipeline must also generate and upload an SBOM for each artifact and fail if reproducibility or SBOM generation checks fail.",,
acbbbb45-f549-44d6-9a72-46f4e39283d2,Build & Dependency Management,Continuous Integration & Automation,CI Configuration & Maintenance,"Fix and harden a GitHub Actions workflow for a CMake-based C project by pinning actions to SHAs, enabling ccache with cache restore/save across a gcc/clang matrix, and splitting build/test/release with minimal permissions and concurrency cancellation. Validate locally with act that pushes run build+test across the matrix and that tagging v* produces an uploaded release artifact.",,
b200346c-e6fc-4d49-9949-7ab77fac3f00,Build & Dependency Management,Dependency Management,Dependency Installation & Version Control,"Resolve peerDependency conflicts in a Yarn v3 Plug'n'Play monorepo by using resolutions and packageExtensions to align versions of React, Webpack loaders, and ESLint plugins. Produce a reproducible install (yarn.lock) and verify the workspace builds and lints successfully under Node 20.",,
c24cdce5-7f82-4449-8918-53a0a402ddd7,Build & Dependency Management,Dependency Management,Dependency Resolution & Conflict Fixing,"Resolve a Rust Cargo workspace that fails to compile due to transitive version/feature conflicts between reqwest, openssl-sys, and tokio plus a system OpenSSL 1.1 vs 3.0 mismatch. Pin compatible crate versions, adjust features and Cargo patches, configure pkg-config to link the intended OpenSSL, vendor dependencies for offline build, and validate by building and running a CLI that performs an HTTPS request.",,
069e3982-9322-496e-8bfb-c4229c82f76b,Build & Dependency Management,Dependency Management,Dependency Resolution & Conflict Fixing,"Implement a CLI tool that scans a mixed Gradle/Maven Java project for conflicting transitive JAR versions causing duplicate classes, then automatically generates and injects a dependencyManagement or resolutionStrategy snippet to enforce consistent versions and update the build files accordingly.",,
b2086247-1990-4dbe-baff-69682324c773,Build & Dependency Management,Dependency Management,Lockfile & Manifest Maintenance,Resolve peerDependency conflicts in a Yarn v3 workspaces monorepo by aligning manifest ranges and regenerating a deterministic yarn.lock with Corepack enabled so yarn install --immutable succeeds on Linux. Prove reproducibility by performing two clean installs that yield identical resolved versions and an unchanged install-state file.,,
c75d663b-a8a7-45cb-abeb-61b44a63c008,Build & Dependency Management,Language & Ecosystem-Specific Build Management,C/C++ & Systems Builds,Create a CMake superbuild that compiles vendored zlib and libpng via ExternalProject_Add and then builds a C++ CLI (pngdim) that links them. Ensure correct SONAME and RUNPATH so the produced binary runs in the sandbox and transforms a provided PNG to /app/out.png with an expected SHA256.,,
a71eb1f6-ef8a-4aed-a908-73c7e9743ce0,Build & Dependency Management,Language & Ecosystem-Specific Build Management,C/C++ & Systems Builds,"Configure a CMake-based C project to produce bit-for-bit reproducible builds by enabling deterministic archives and stripping build paths (e.g., SOURCE_DATE_EPOCH, ar D, -ffile-prefix-map/-fdebug-prefix-map) with split DWARF. Build twice in different directories and verify identical SHA-256 digests while ensuring no absolute build paths remain in the binary.",,
585f16e9-ef35-4e4d-9cd7-13769db30599,Build & Dependency Management,Language & Ecosystem-Specific Build Management,C/C++ & Systems Builds,Write a POSIX shell script that cross-compiles a CMake-based C project into static and shared libraries for both x86_64-linux-gnu and armv7-linux-gnueabihf using provided toolchain files and installs each build into separate staging directories. Then generate a combined pkg-config index merging metadata for both architectures and verify correct linkage by building and running sample executables against each library variant.,,
dd6be65a-73b8-4197-93fa-bdde30633481,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Configure a multi-module Maven project to produce reproducible, deterministic JARs by normalizing timestamps, sorting entries, and stripping non-essential metadata using the Maven Reproducible Builds Plugin. After two clean builds in separate directories, verify the byte-for-byte equality of all generated artifacts.",,
8f891fee-624c-4427-abcd-3d369379dbb9,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Configure and build a mixed-language (Java + Kotlin) multi-module Maven project using toolchains to compile one legacy module with JDK 8 and the rest with JDK 17, wiring Lombok and MapStruct as annotation processors on the correct processor path. Produce a deterministic, shaded CLI artifact with relocated dependencies and attached sources/javadoc, publish to the local Maven repository, and verify by building and running a tiny consumer project that imports the library and executes the CLI.",,
6396072e-626b-4db9-94d4-45f0aba3b87a,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Create a Maven multi-module project combining Java and Kotlin submodules, configure the kotlin-maven-plugin, and produce a multi-release JAR that contains legacy implementation for Java 8 and modern code under META-INF/versions/11. Validate by building under JDK 8 and JDK 11 and running the appropriate module-specific features via the Surefire plugin.",,
682f9326-6867-446e-bfee-a60ce8d2c4c8,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Implement a Maven multi-module build that compiles Java and Kotlin modules, generates Protobuf sources, executes SpotBugs and JUnit5 tests with a minimum 85% coverage threshold, assembles a shaded uber-jar, and deploys snapshots and releases to a Nexus repository using custom staging profiles. Ensure build reproducibility by locking plugin and dependency versions via the Maven Enforcer plugin and verify offline builds with a mirrored local repository.",,
fdcfb252-49b5-4f4c-8970-d58c2581227d,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Configure a Dockerized multi-module Maven project using the Maven Toolchains plugin to compile and test the same codebase against both Java 8 and Java 17, emitting artifacts into separate target subdirectories. Validate each build by inspecting class file major versions and ensuring all tests pass under both JDKs.",,
4f8bba66-220c-409c-bc32-faacbc258a09,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Java & JVM-Based Builds,"Configure a multi-module Gradle (Kotlin DSL) Java/Kotlin project to build offline against a pre-seeded local Maven repository, enable dependency locking and verification, and produce a deterministic shaded fat JAR targeting JDK 17. Verify by building twice with the same SOURCE_DATE_EPOCH to obtain identical SHA256 sums and by running the JAR to print its git-derived version.",,
2800d9b1-47b2-4650-b49a-1414af354989,Build & Dependency Management,Language & Ecosystem-Specific Build Management,JavaScript & Frontend Builds,"Create a pnpm monorepo with two TypeScript packages (‘lib’ and ‘app’), configure esbuild to emit both CJS and ESM outputs with declaration files for ‘lib’, and bundle ‘app’ into /dist with hashed filenames. Verify that workspace protocol aliases resolve correctly in the app and generate a manifest.json mapping entrypoints to the output files.",,
ea9d38ea-8ce2-4d23-9ebb-f37d02ee4bfc,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Python Builds & Packaging,"Use Docker’s manylinux2014 image to build Python wheels for a project with Cython extensions, configuring build options solely via pyproject.toml and running auditwheel repair to ensure compliance. Then automate testing by installing each wheel in isolated venvs for Python 3.7–3.10 and executing a sample import and function call.",,
29857d5c-a68a-423e-b794-debdf284f2ca,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Python Builds & Packaging,"Develop a release automation script that parses Conventional Commits since the last git tag to determine the next semantic version, updates pyproject.toml and the package __init__.py, then builds sdist and wheel via PEP 517 build, runs twine check, and publishes to Test PyPI. Finally, the script must create a fresh virtualenv, install the package from Test PyPI, and verify the import and version output.",,
60b6b512-56a5-4d1c-af97-02af706f2097,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Python Builds & Packaging,"Implement a Python CLI that migrates a legacy setup.py project into a PEP 517 pyproject.toml preserving all metadata, dependencies, entry points, and package data, then builds both sdist and wheel via the build module. The tool must normalize timestamps, sort file listings, and verify SHA256 checksums of artifacts across two runs to guarantee reproducible, deterministic builds.",,
f2cf83db-0b98-4fda-9e4f-459895dc0631,Build & Dependency Management,Language & Ecosystem-Specific Build Management,Rust/Go/Other Modern Toolchains,"Refactor a provided multi-crate Rust project into a Cargo workspace, vendor all dependencies with cargo vendor, and configure .cargo/config.toml so the project builds fully offline. Cross-compile a static x86_64-unknown-linux-musl release binary with feature ""cli"" (default-features=false) and verify by running cargo test --workspace and executing the binary to emit a deterministic SHA256.",,
24b1b3e5-5b55-46a0-a95d-df0dac681af3,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Implement a CI script that, based on the git branch, applies different build configurations: on 'dev' branches builds include debug symbols and are tagged '-dev' in the version header, while on 'main' builds enable optimizations, strip symbols, update semantic version from the latest tag, and produce packaged release artifacts under /dist. Validate by running builds on both branch contexts in Docker, verifying version strings and artifact contents accordingly.",,
06beb7e4-7592-4fcf-a472-f7ccf68bd752,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Implement a Git-aware Makefile for a Rust CLI that enforces branch-specific builds: main produces a stripped LTO release with version from the latest tag and a sha256 checksums.txt; staging enables a telemetry-staging feature and adds an -rc suffix; feature/* appends +branch.sha and writes to /app/dist/feature, while release/* fails if Cargo.toml version doesn’t match the tag. The harness will check out different branches and verify artifact names, --version output, and the presence of checksums only on main.",,
ce71531e-d0b1-48af-8e57-24a49fbcb95d,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Implement a shell-based build orchestrator that reads branch-specific policies from a JSON file to automatically apply different compiler flags, dependency injections, and artifact naming based on the current Git branch. The tool must reject and cleanly report any builds that don’t conform to the defined staging, release, and production rules across three sample branches.",,
2a98e3ad-2899-4cfa-8398-3137ba5bfd4a,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Develop a POSIX-compliant build wrapper that detects the current Git branch and invokes CMake with branch-specific build types (Debug for feature/*, RelWithDebInfo for staging, Release+strip for main), automatically appending branch suffixes to the project version. After compilation, verify the binary’s symbol table, size reduction, and embedded version metadata to ensure the correct flags and suffix were applied per branch rule.",,
7790614a-4402-41e5-b055-16d5bb7ae920,Build & Dependency Management,Release Engineering & Version Control Integration,Branch-Based Build Rules,"Implement a Git-aware build script that enforces branch-specific rules: feature/* runs tests only and emits a -SNAPSHOT artifact, staging builds produce debug binaries with embedded staging config, and main requires an annotated tag to create a stripped release tarball with semver from the tag and a SHA256 checksum in /app/dist. Validate by creating branches and tags and showing the correct artifacts and version strings are generated for each branch.",,
3d22c1c0-8e7f-41dd-b6f9-8b62051f565b,Build & Dependency Management,Release Engineering & Version Control Integration,Reproducible Release Provenance,"Compile and package release binaries for Linux x86_64, ARM64, and Windows in separate Docker sandboxes, generate SHA256 checksums, GPG detach signatures, and SPDX SBOMs for each. Then perform a second independent build to verify bit-for-bit reproducibility and bundle all artifacts, signatures, and SBOMs into an in-toto provenance statement, confirming integrity and authenticity.",,
788102de-4552-4f51-ac90-24e81d5b15fc,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Implement a POSIX-compliant release automation script that checks out a provided git tag, builds artifacts for multiple platforms, generates SHA256 and SHA512 checksum files, and signs both artifacts and checksums with a GPG key from /env/keys. The script must then verify all signatures against a public keyring, produce a manifest.json with artifact metadata and signature statuses, and prepare a versioned release directory for distribution.",,
c1acc84f-be6b-42eb-b51a-fbfd7aa811c4,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Create an offline release pipeline that signs a Git tag for a provided source tree, builds a normalized tar.gz and binary, and generates SHA256SUMS along with both GPG (.asc) and minisign signatures for the artifacts. Provide a verify.sh that validates the tag signature against a supplied public key, checks checksums and signatures, and confirms the binary’s embedded commit hash matches the signed tag.",,
3ce981d3-aea0-466b-80ea-6f8a31a743a2,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Implement a release pipeline that signs the vX.Y.Z Git tag and a SHA256SUMS file with GPG, builds a binary embedding git describe/commit hash, and provides verify.sh to validate the tag signature, the embedded version against the tag, the checksum signature, and the artifact hashes. The task must detect and fail on any tampering with either artifacts or checksums.",,
e48f72b4-210d-45bc-98b8-566f5cd43f98,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Create a release automation script that cross-compiles a Go project for Linux amd64 and arm64, packages the binaries into tar.gz archives, generates SHA256SUMS, and digitally signs the checksum manifest and Git tag with a specified GPG key. Provide a verify.sh script that validates the GPG signatures, confirms the integrity of the checksums against the archives, and verifies the authenticity of the signed Git tag.",,
de8e270e-8d29-47f8-9cfc-1f710348b821,Build & Dependency Management,Release Engineering & Version Control Integration,Signed & Verified Builds,"Configure a Dockerized signing environment that uses a hardware-backed GPG key (e.g., YubiKey) with gpg-agent to detach-sign multiple built artifacts (.tar.gz, .zip, .deb), generate SHA256 checksums, and publish them to /dist as .asc and .sha256 files. Also implement a verify.sh script that fetches the public key via WKD, validates both signatures and checksums, and fails cleanly on any mismatch or missing artifact.",,
2130a558-cbe7-4510-a02c-95b5e92cb652,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"Develop a shell-based release manager that scans a monorepo for crates and package.json files, bumps each module’s semantic version based on Conventional Commits and commits the version updates. Then it creates annotated git tags per module and generates a consolidated CHANGELOG.md with links to the merged PRs.",,
2466540a-4876-45e0-8448-dd6ebd3e5891,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"Create a cross-platform release script that reads a YAML manifest of target platforms, runs builds inside per-platform Docker containers, computes SHA256 checksums and GPG-signs each artifact, then tags the commit with a semantic version, creates or updates a GitHub release via the API, and attaches the signed artifacts. The script must be idempotent—skipping existing tags or uploads—handle API rate limits with exponential backoff, and validate all manifest entries with clear error reporting before starting.",,
1b32b22b-b7eb-41e3-93c0-513eeebcd636,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"In a Git monorepo with a Rust workspace of multiple crates, implement a release script that parses Conventional Commits since the last per‑crate tag, bumps versions in Cargo.toml/Cargo.lock with dependency propagation, writes per‑crate and aggregate changelogs, and creates annotated tags (v{crate}-{version}) plus a workspace tag. The run must support dry‑run vs apply, handle prerelease channels (e.g., -beta) and BREAKING CHANGE semantics, be idempotent on a second run, and leave the workspace building successfully at the new versions.",,
322a3d26-1836-4292-b59e-9d75f2b9075f,Build & Dependency Management,Release Engineering & Version Control Integration,Version Tagging & Release Automation,"Develop a POSIX-compliant release automation script that determines major, minor, patch, or prerelease versions (alpha/beta) from Conventional Commits plus a --pre flag, updates both package.json and setup.py with the computed version and prerelease identifier, generates a unified changelog, creates annotated git tags, and builds npm packages and Python wheels. The script must place versioned artifacts and tags in /releases, robustly handle missing or malformed tag histories, and validate consistency of versions across both language ecosystems.",,
c4cbe0e7-8be2-4fe9-b6d7-84f978991543,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Cross-compile the Go project in /src for linux/amd64, linux/arm64, and windows/amd64 targets with CGO disabled into versioned binaries, package each artifact into tar.gz or zip (including README and LICENSE), then generate SHA256SUMS.txt and a GPG-signed SHA256SUMS.txt.asc signature file.",,
1628ebe2-8742-4b51-b41b-256e4cf27820,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Configure a CMake project and use CPack to produce both .deb and .rpm packages for a small C/C++ CLI, including /usr/bin binary, a man(1) page, bash completion, and a separate -dbg package with split debug symbols. Validate package metadata (version from git tag), ownership/permissions, dependencies, and contents via dpkg-deb and rpm queries, and by extracting to a temporary root to confirm correct install paths.",,
69cda8ed-8a02-4079-88ee-026a170db619,Build & Dependency Management,Source Compilation & Build Systems,Artifact Generation & Packaging,"Package a small C library built with CMake into two Debian packages: a versioned runtime shared library with correct SONAME (e.g., libfoo2) and a -dev package containing headers and a pkg-config file, using debhelper and dpkg-buildpackage. Install the .debs and verify by compiling and running a tiny consumer that links via pkg-config against the installed library.",,
d816e628-6aac-4e20-b42a-1d63b3462f37,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Configure a CMake-based build for /app/engine using Ninja, CMakePresets.json, and a cross-compiling toolchain file to produce both native (x86_64) and ARMv7 binaries with an ENABLE_SIMD option that toggles sources and compile definitions. The workflow must emit compile_commands.json, run ctest, and generate relocatable cpack TGZ packages for each configuration, verifying the ARM artifact is an ARM ELF and the native build links against system zlib via find_package(ZLIB).",,
7f7c24fe-aa2e-4234-bf95-75f048e564a5,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Configure a CMake/Ninja project to run a two-stage Profile-Guided Optimization workflow: first build instrumented binaries and execute a provided training script to generate profiles, then rebuild using those profiles to emit an optimized executable at a fixed path. Verify that the profile was consumed (via build logs/artifacts) and that the optimized binary demonstrates a measurable runtime improvement over a baseline build.",,
6287b90a-760f-4c75-bb7d-0f4dd44589cd,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Replace the project's Autotools build with Meson + Ninja, adding a subproject wrap for a missing dependency, installing headers, and generating a pkg-config file, and then add a Meson cross file to support armv7hf cross-compilation with hard-float. Verify by building native and cross variants, running the native tests, and using qemu-arm to execute a sample program linked against the cross-built shared library while pkg-config resolves the correct paths.",,
e139df25-f52e-4ba9-b5fe-91cd1e6d9f55,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Configure a Bazel workspace for a polyglot (Java, Go, Python) project with custom toolchains and remote caching, and define Bazelrc profiles for development and release builds. Provide a script that builds all //... targets using a specified profile and captures the Build Event Protocol output in JSON.",,
b5b0bbc5-49ee-4af2-a915-d0dc08b877cc,Build & Dependency Management,Source Compilation & Build Systems,Build System Configuration,"Configure a CMake superbuild that fetches and builds pinned zlib and libpng from source via FetchContent/ExternalProject, then builds a small C/C++ image utility that links to them. Install targets with an exported CMake package (MyImgToolConfig.cmake), verify find_package works from a separate minimal project, and run the utility on a provided PNG sample.",,
728df3b9-1b6a-4b2e-8713-10b48acca390,Build & Dependency Management,Source Compilation & Build Systems,Cross-Compilation & Multi-Platform Builds,"Cross-compile the provided CMake-based CLI to produce three artifacts: x86_64-linux-musl (fully static), aarch64-linux-gnu, and x86_64-w64-mingw32. Verify correctness by inspecting ELF/PE headers and running the ARM64 build under qemu-aarch64 and the Windows build under wine, ensuring the musl binary has no glibc dependency and all builds honor a fixed SOURCE_DATE_EPOCH.",,
fb8a76dc-4c84-4d19-9518-226d376800aa,Build & Dependency Management,Source Compilation & Build Systems,Cross-Compilation & Multi-Platform Builds,"Cross-compile the ripgrep Rust project into statically-linked binaries for x86_64-unknown-linux-musl and aarch64-unknown-linux-musl from an x86_64 host, packaging each artifact with a LICENSE file and SHA256 checksum. Validate the ARM64 build by executing it under qemu-aarch64 on a provided test corpus and verifying the expected grep results.",,
a657066f-1f6d-4ff4-aad8-6cc5ec5b7971,Build & Dependency Management,Source Compilation & Build Systems,Manual Compilation,"Compile all C sources under /src into position-independent object files using gcc with -O2, -fPIC, -Wall, and -Werror; then archive them into libfoo.a and link them into a SONAME-versioned shared library libfoo.so.1.0.0 (with SONAME libfoo.so.1). Next, compile a test program that links against this shared library using an rpath to its directory and verify it runs and outputs the expected result.",,
98c0259a-ec94-4f1f-94ab-d80a6a8b419a,Build & Dependency Management,Source Compilation & Build Systems,Manual Compilation,"Compile a C program in /src manually using gcc for two targets: x86_64-linux-gnu and armv7-linux-gnueabihf, applying -static, -O2, and target-specific sysroots. Then verify each statically linked binary under QEMU in Docker to confirm correct execution and identical outputs.",,
0835c043-a6fb-42f5-b51d-4fbc43c9b88e,Build & Dependency Management,Source Compilation & Build Systems,Manual Compilation,"Perform a two-phase profile-guided optimization build of the C program in /app/pgotask: first compile with -fprofile-generate and run it over the input corpus in /app/corpus to emit profiles, then recompile with -fprofile-use to produce /app/bin/app_pgo. Verify by timing both pre- and post-PGO binaries on the same workload and writing the speedup and file sizes to /app/pgo_report.txt.",,
e79205fc-86d4-428c-9d7c-39f5548199f9,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Build Configuration & Toolchain Issues,"Diagnose a CMake project whose shared plugin fails to link and cannot be loaded at runtime due to missing -fPIC objects and incorrect RPATH/SONAME. Update CMakeLists.txt to enable POSITION_INDEPENDENT_CODE, correct link order, and set a proper INSTALL_RPATH so the host executable can dlopen the plugin and pass the provided test.",,
b6ad0055-d1cf-4fc0-a8d5-03592c59380b,Debugging & Troubleshooting,Dependency & Build Troubleshooting,System Library & Path Errors,"Diagnose and fix build errors in a CMake-based C++ project where OpenSSL and zlib are installed in non-standard prefixes under /opt/extra by correctly configuring environment variables and CMakeLists to locate headers and libraries, ensuring both Debug and Release builds complete and all ctest cases pass.",,
c44daf03-3c32-4b51-b1ab-eac762180392,Debugging & Troubleshooting,Dependency & Build Troubleshooting,System Library & Path Errors,"Diagnose and fix a Go CLI that uses cgo for image processing (libjpeg and libpng) but fails to build and run due to missing pkg-config files and incorrect CGO_CFLAGS/LDFLAGS. Install and link the proper dev packages in the Docker sandbox, adjust environment variables, and verify the binary correctly processes sample images in /data.",,
b8730aa5-c47e-49e9-86e7-f3dfd237606c,Debugging & Troubleshooting,Dependency & Build Troubleshooting,Version Incompatibility,"Diagnose a Rust workspace that fails to build because the pinned dependencies require a newer Rust toolchain/edition than the installed rustc and cargo. Resolve by activating a compatible toolchain (e.g., via rustup or a directory override) or re-resolving to compatible crate versions, then build and run the tests successfully.",,
081bdf25-1b7d-449e-ad3b-51656956983b,Debugging & Troubleshooting,Environment & Configuration Debugging,Configuration File Parsing & Validation,"Diagnose and fix a Helm chart values.yaml containing misplaced YAML anchors, duplicate keys, and deprecated API fields to restore proper rendering of a multi-service deployment; validate with helm lint and helm template to ensure output manifests match the provided schema.",,
cbf5f9a5-2df2-4d94-97bd-75476b8ba094,Debugging & Troubleshooting,Environment & Configuration Debugging,Cross-Platform Environment Differences,"Diagnose and fix a Node.js CLI project whose shell scripts and npm tasks fail on Windows due to CRLF line endings, hard-coded POSIX commands, and improper path separations. Update scripts and configurations so the tool builds and runs seamlessly on both Linux and Windows environments.",,
9507ce46-3098-40eb-a664-3426374b6a4a,Debugging & Troubleshooting,Environment & Configuration Debugging,Virtual Environment & Container Issues,"Analyze and correct a Python Conda environment bundled in a Dockerfile that fails to import C-extensions due to ABI mismatches and conflicting package versions. Update environment.yml, channels, and multi-stage build steps to produce a minimal image under 500 MB where all pytest tests pass.",,
25f2b4a7-8b3c-4af4-8318-72845c280340,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Debug and fix a Go CLI tool in /app/client.go that interacts with a protected REST API but fails with 401 Unauthorized and 422 Unprocessable Entity errors due to missing Bearer token header and incorrect JSON struct tags. Use httputil to inspect raw requests, correct the Authorization header formatting, align JSON tags with the API schema, implement exponential backoff retries on 429 Too Many Requests by parsing the Retry-After header, and output the aggregated items array to /output/result.json.",,
069e6f4d-dd20-458a-8957-f585f4f7c98f,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Diagnose and fix a Node.js HTTP client’s mismanagement of chunked Transfer-Encoding causing truncated JSON responses and silent failures during paginated API calls. Implement proper chunk aggregation, error handling for malformed chunks, and ensure retry logic respects the Retry-After header, then validate with the provided integration tests.",,
89d944d6-f7e1-496e-a6cb-f194102eb08c,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Diagnose why a Python CLI using requests gets 401 and 415 from a local OAuth2-protected REST API: the token exchange is incorrectly sent as JSON instead of application/x-www-form-urlencoded and subsequent requests pass the token as a query param instead of Authorization: Bearer. Fix the payload encoding and header usage, then verify by successfully calling a paginated endpoint while honoring Retry-After to avoid 429s.",,
e92097fc-225d-45d8-b080-9d22fd45c678,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Diagnose why a provided CLI client receives 401 'signature mismatch' from a mock HMAC-signed REST API by auditing canonicalization (query param order, header inclusion, body hashing) and timestamp/nonce handling. Correct the signing logic and required headers so POST /v1/payments returns 201, then verify by GETting the created resource and writing its id to /app/payment_id.txt.",,
9c086cc7-cb15-462c-8b7a-62607d5948da,Debugging & Troubleshooting,Network & Service Debugging,API Request & Response Issues,"Diagnose and fix a Python client that intermittently receives 401 Unauthorized errors from a mock OAuth2-protected API by correcting its token acquisition, caching, and refresh logic. Ensure proper retry with exponential backoff and validate successful authenticated requests after token expiry simulation.",,
7ff993fe-02f0-4bb9-978b-ff62815f8094,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Diagnose intermittent outbound HTTP request timeouts in a Node.js microservice under high concurrency by analyzing socket metrics, identifying OS ephemeral port exhaustion and absent keep-alive connections. Implement sysctl tuning and HTTP agent pooling, and supply a Bash load-test script that verifies zero timeouts and outputs connection stats in JSON.",,
610418d5-8908-4e84-b717-02030e0b6cd7,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Investigate why a client app’s HTTP requests to an internal service stall before timing out: the hostname resolves to IPv6 while the server only binds on IPv4. Fix the mismatch (e.g., enable dual-stack binding or force IPv4 resolution) and verify low-latency success with the provided test script.",,
937af724-367b-47e9-a504-532fefa26f4a,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Investigate persistent timeouts when a local microservice calls an internal API and discover they are caused by inherited HTTP(S)_PROXY environment variables pointing to a dead proxy. Reconfigure NO_PROXY or unset the proxy so direct connections succeed, and verify with curl and a test run.",,
2bb29e8b-56e0-46e6-9887-da30870dae51,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Diagnose and repair intermittent HTTP request timeouts between two Docker containers caused by an MTU mismatch on the bridge network. Reconfigure Docker network MTU or enable path MTU discovery, adjusting system settings so that large HTTP payload transfers reliably succeed under test scenarios.",,
d02fda27-8f45-4e99-b67a-7ad4181f80a4,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Diagnose why outgoing HTTP requests from a CLI client to a local/internal API consistently time out due to misconfigured proxy environment variables (HTTP_PROXY/HTTPS_PROXY/NO_PROXY) that route localhost/intranet traffic through a dead proxy. Correct the environment and client/server settings so direct connections to 127.0.0.1 and internal hostnames bypass the proxy and succeed, verifying with curl and a simple script.",,
43914bc3-52d4-4152-a7c2-9e87c25a7bcc,Debugging & Troubleshooting,Network & Service Debugging,Connection & Timeout Errors,"Diagnose and fix slow HTTP requests caused by the system preferring IPv6 (AAAA) addresses that are unroutable, leading to connection timeouts before IPv4 fallback. Reconfigure address selection, routing, or resolver settings so connections to a dual-stack host complete quickly without timeouts.",,
b04f7e4b-c4ac-494d-8bb5-1a4be48929f2,Debugging & Troubleshooting,Network & Service Debugging,"Proxy, SSL & Certificate Errors","Diagnose and repair an HAProxy reverse proxy that is dropping HTTPS connections for multiple domains due to an expired wildcard certificate, missing SNI configuration, and incompatible cipher suites. Update haproxy.cfg with the renewed certificate, enable SNI host-based backend selection, adjust TLS cipher settings, reload the service, and validate end-to-end secure connections.",,
2bc44715-4107-4e3b-b98e-5af3df0f1807,Debugging & Troubleshooting,Network & Service Debugging,"Proxy, SSL & Certificate Errors","Fix a broken mutual TLS setup on an Nginx reverse proxy fronting a local API: clients see handshake failures and 'unknown ca' errors due to an incomplete server certificate chain and verification against the wrong client CA. Rebuild and reference the correct fullchain, configure nginx to trust the proper client CA, issue a client certificate/key, reload, and verify curl with the client cert succeeds while requests without it are rejected.",,
c3261a5c-7f2e-432c-a0fa-648a99770549,Debugging & Troubleshooting,Network & Service Debugging,"Proxy, SSL & Certificate Errors","Diagnose and repair a misconfigured Nginx reverse proxy that is blocking mutual TLS authentication with a backend gRPC service by correcting the certificate chain, enabling ssl_trusted_certificate and proxy_ssl_server_name, and updating client_certificate settings. Verify successful mutual TLS calls using grpcurl and curl and document the validation steps.",,
09560491-b8d1-4d16-8008-e5d4c88f66f0,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,"Diagnose and fix a misconfigured reverse proxy that causes a healthy backend service to fail its /healthz check (e.g., wrong upstream port, missing Host/X-Forwarded headers, or TLS-to-HTTP mismatch). Correct the proxy and service configs and reload them so curl http://localhost/healthz returns 200 with the expected body.",,
ab30f2e5-f0bb-4675-9929-f38d07fc6178,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,"Diagnose and correct liveness and readiness probe failures in a Kubernetes-deployed Spring Boot microservice by fixing health endpoint implementations, adjusting probe timeouts and initial delays, and tuning resource requests so that rolling updates complete without downtime.",,
3fc257e0-1572-42b6-9e94-fc628aebfec1,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,"Diagnose a Docker Compose stack where a Node.js API behind an Nginx proxy fails its health checks due to misconfigured probe endpoints and improper startup dependencies. Fix the Docker healthcheck definitions, Nginx config, and service ordering so that all containers report healthy and the /healthz endpoint returns HTTP 200 within 15 seconds.",,
3069f428-49d1-43f1-b475-88a798f49ce7,Debugging & Troubleshooting,Network & Service Debugging,Service Availability & Health Checks,Diagnose an Nginx-proxied FastAPI service whose /health endpoint returns intermittent 502s due to IPv6/IPv4 mismatch (upstream resolving to ::1 while the app binds only to 127.0.0.1). Adjust the app bind address or Nginx upstream to ensure consistent HTTP 200 health checks across restarts.,,
1fc78324-dc48-4450-9867-b05ab1c70371,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a Python ETL script that loads multi-gigabyte CSVs using cProfile and memory_profiler to pinpoint I/O and transformation hotspots. Refactor it to use generator-based streaming, chunked processing, and optimized libraries so peak memory stays below 500 MB and total runtime is under 60 seconds.",,
be17d313-6d86-41f2-8ba2-33936b8281d5,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a Go HTTP microservice using pprof to identify memory leaks and surviving goroutines caused by unclosed response bodies and never-closed channels. Fix the code to properly close resources, eliminate goroutine leaks, and verify reduced memory footprint and improved request throughput.",,
dcaa6c21-9f0f-445e-a338-defbe106a3a7,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a mixed Python+C log-processing tool to locate CPU hotspots and memory bloat using cProfile, perf, and Valgrind (memcheck/massif). Eliminate an O(n^2) Python loop and fix a C-side leak so the job completes ≥2x faster with ≥50% lower peak RSS while preserving identical output.",,
ec4fd0c2-c956-4e65-8813-43d6b8cbd2ee,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a Go HTTP log aggregator that shows steadily rising memory usage and high CPU under sustained load using pprof (heap and CPU profiles) to uncover a goroutine leak and an O(n^2) JSON concatenation hotspot. Implement fixes (proper context cancellation, bounded channels, and bytes.Buffer-based assembly) and verify with the provided load test that throughput improves and peak RSS remains bounded.",,
c0c13fda-fd2f-4c16-8b5a-dfd10f274e0f,Debugging & Troubleshooting,Performance & Resource Optimization,CPU & Memory Profiling,"Profile a C log-parsing utility that becomes slow and runs out of memory on a large dataset due to quadratic string concatenation and leaked allocations. Use Valgrind (memcheck/massif) or perf/callgrind to pinpoint hotspots, refactor to buffered/streamed processing and proper frees, and verify identical output with markedly lower peak RSS and faster runtime.",,
eddac8bb-720f-42a0-8441-b3481a73aee5,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose and optimize a Python ETL pipeline that repeatedly reloads large CSV files causing severe disk thrashing under high-volume workloads. Implement file streaming, SQLite-based caching, and chunked processing to reduce disk I/O by at least 70%, achieve sustained throughput of 200k rows/sec, and output a reproducible perf_report.json summarizing I/O stats before and after optimization.",,
7e3ecd21-2e81-4a59-884f-856e05fbcd8e,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose and fix a severe disk I/O bottleneck in a Python-based SQLite bulk loader that inserts rows individually (autocommit on), triggering per-row fsyncs and tiny writes. Optimize by batching transactions and enabling WAL with appropriate PRAGMAs (e.g., synchronous=NORMAL, page/cache tuning) to achieve a measurable speedup while preserving identical dataset contents.",,
5965df14-24fe-4901-a1c7-f1fda9612fe6,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose a Python log-processing CLI that is extremely slow because it writes output one line at a time with fsync after each write and a tiny buffer. Rework it to batch and buffer writes and use atomic rename on completion, remove unnecessary fsyncs, and verify at least a 5x speedup on the provided dataset with byte-for-byte identical output.",,
d79af8c3-f05e-4af4-a3a6-be9c3f5d9502,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose a Python ETL utility that writes hundreds of thousands of rows and is slowed by per-record os.fsync() calls; use strace or iostat to pinpoint excessive sync syscalls. Refactor the script to use buffered writes and batch fsyncs, then benchmark to confirm at least 5× throughput improvement.",,
edf7f1df-0014-4e49-917c-9f493cbc110c,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose a Python script performing bulk inserts into a SQLite database where unbatched transactions and default journaling cause excessive fsync calls, then optimize by batching inserts, tuning PRAGMA journal_mode and synchronous settings, and rewriting to use executemany to achieve at least a 3× throughput improvement on the provided benchmark harness.",,
5a95189c-f5e7-4de6-bfe1-a370d9da209e,Debugging & Troubleshooting,Performance & Resource Optimization,I/O & Disk Bottlenecks,"Diagnose a C-based log aggregator that is extremely slow due to 1-byte read() calls and an fsync/flush on every line. Refactor it to use buffered streaming and batched writes (e.g., setvbuf/FILE* or coalesced writev) and verify /app/bench.sh runs at least 5x faster without changing output.",,
0552b1b6-e643-4fa2-a674-feb1a34f080b,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose and optimize a gRPC microservice’s network stack under a simulated 80 ms RTT and 1% packet loss to cut p99 latency by at least 50% without reducing throughput. Apply and verify kernel- and app-level tuning (e.g., congestion control/qdisc, HTTP/2 flow-control windows, TCP keepalive/Nagle, MTU/MSS) using the provided load generator and report.",,
a9221318-48d3-484d-ad08-1bc430c35b4e,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose a severe throughput collapse and sporadic stalls across a VXLAN tunnel caused by an MTU black hole (broken PMTUD), using ping with DF and tcpdump to determine the effective path MTU. Apply a fix by setting appropriate interface MTUs and TCP MSS clamping so iperf3 throughput improves at least 3x without packet loss, and write the discovered MTU/MSS to /app/mtu_report.txt.",,
11c20a91-4167-4cf8-8e03-228dc784976b,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose and fix severely limited throughput between two containers on a high-RTT simulated link by identifying TCP window/buffer and congestion-control misconfiguration. Measure with iperf3 and ss/tcpdump, then tune sysctl (enable window scaling, raise rmem/wmem and tcp_rmem/tcp_wmem, switch to BBR with fq, adjust MTU/MSS if needed) and verify higher goodput with fewer retransmits.",,
024944e3-cc32-4470-a555-fda9d61a7725,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose and reduce tail latency in a Dockerized Go gRPC service under heavy concurrent load by analyzing tcpdump and pprof outputs, then optimize Linux TCP settings (socket buffers, congestion control, Nagle’s algorithm) and tune gRPC keepalive parameters. Validate sub-50 ms 99th-percentile latency using the provided load-test script and submit the adjusted sysctl configuration alongside benchmark results.",,
169c6aa5-7e34-4b96-b6b9-e491cf516d7f,Debugging & Troubleshooting,Performance & Resource Optimization,Network Performance Tuning,"Diagnose and resolve throughput issues in a Docker overlay network by identifying MTU mismatches and suboptimal socket parameters; tune sysctl TCP window sizes, container network MTU, and gRPC socket options to achieve a specified high-bandwidth target and validate with iperf3 tests.",,
ac0d3063-c9d0-431f-b508-63cb4ca3ceab,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose and fix a deadlock and goroutine leak in a Go fan-out/fan-in worker pool where misordered channel closes and blocking sends during cancellation stall the pipeline under load. Correct the synchronization (context propagation, channel buffering, and close/drain order) so the provided stress test finishes under the time limit and go test -race shows no leaks or races.",,
91460ea0-fc8b-40b4-84a4-98722e3e229f,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,Diagnose and fix a non-deterministic race condition in a C++11 multi-threaded file transformation service that intermittently corrupts output under high load. Introduce proper synchronization (mutexes or atomics) and ensure all provided concurrency stress tests pass without impacting single-threaded performance.,,
12628b09-93b7-45ef-85ec-d187a3be813b,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose and fix a race condition in a Go microservice that uses a shared in-memory cache across goroutines, replacing unsafe map access with proper synchronization (e.g., sync.Map or mutex sharding) to eliminate data corruption while preserving throughput. Provide a benchmark harness and verify 99th percentile request latency remains below 50 ms under simulated concurrent load.",,
a98b0755-c848-4504-9e5b-11874ad053f6,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose and fix an intermittent deadlock in a Rust Tokio service caused by holding a std::sync::Mutex across await points and doing blocking file I/O inside async tasks, leading to hangs under load. Refactor to use tokio::sync::Mutex/RwLock and spawn_blocking for I/O, add cancellation timeouts, and verify via a stress script, cargo test, and tokio-console traces.",,
ef3a32bc-f6d6-450c-a6dc-e665d6ec55cf,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose a deadlock and throughput collapse in a Rust Tokio-based pipeline where a Mutex is held across await points and a bounded mpsc channel backpressures a blocking file writer. Refactor to avoid cross-await locks and move blocking I/O to spawn_blocking or a dedicated thread pool, then verify no hangs under a provided stress script and achieve at least 3× higher throughput.",,
7ba28845-6bdc-475f-923c-2de6a8617864,Debugging & Troubleshooting,Performance & Resource Optimization,Parallelization & Concurrency Bugs,"Diagnose and fix a deadlock in a Go-based concurrent log processor where workers hold a mutex while sending to a results channel, creating a circular wait with the aggregator that acquires the same lock. Refactor to avoid holding locks across channel operations (e.g., copy before send or introduce a dispatcher) and verify under a stress harness that prior hangs disappear and throughput improves.",,
3f633404-3d3e-4dcd-bf96-8a5bc8dfcd75,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Audit a Dockerized Node.js microservice to detect silent dependency drift between declared semver ranges in package.json and actual versions in yarn.lock, identify which transitive updates introduced a runtime error in health-check endpoints, and implement resolution overrides or version pins to restore consistent behavior. Verify reproducibility by rebuilding the Docker image and running the provided end-to-end tests successfully.",,
c81c6732-8cba-4b2c-941e-b9d8580f146f,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Audit two provided Docker images by enumerating installed apt, pip, and npm packages, identify version mismatches and missing dependencies, and output a structured env_drift.json. Then generate a remediation_plan.sh script to synchronize the development environment with production based on the drift analysis.",,
7f67ecba-ac23-4415-b4f2-ab07d0300adc,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Diagnose why a Node.js project’s native addon (e.g., sharp or grpc) fails to load with errors like GLIBC_x.y not found or wrong ELF class inside the container. Audit Node ABI vs compiled binaries and system libc/libstdc++ versions, rebuild or pin a compatible binary with node-gyp and verify the addon loads in a minimal script.",,
03ddad07-9c29-4945-9c02-1209f9711978,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Diagnose why the prebuilt /app/server web binary exits on launch with “No such file or directory” and fix it by auditing dynamic library dependencies and environment drift (e.g., missing libsqlite3 due to CGO). Install or rebuild with the correct dependencies (or static linking), verify the /health endpoint responds, and write a brief postmortem to /app/POSTMORTEM.md.",,
cfa13688-5d5b-4feb-9dab-bbf7eb89ccb6,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Investigate a prebuilt C++ CLI tool that fails at startup with a “GLIBCXX_x.y not found” error inside the container. Identify the ABI mismatch between the binary and the system libstdc++/glibc, remediate by aligning runtime libraries or rebuilding, and verify the tool runs successfully end-to-end.",,
3a93c960-ec0b-45ae-8c66-b6bce2e25d34,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Investigate why importing a pip-installed C++ extension (e.g., scikit-learn) now fails with GLIBCXX/CXXABI symbol errors after a base image or compiler runtime change by auditing the system’s libstdc++/libgcc versus the wheel’s required ABI. Resolve by aligning the C++ runtime or installing compatible wheels/pins, then verify with a minimal script that imports and exercises the package.",,
3882ef92-ee8c-4fc4-9855-c90b929aee86,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Dependency & Environment Audit,"Audit a Python Flask app’s Docker-based environment by comparing pip freeze outputs in development and production containers to identify silent version mismatches causing intermittent 500 errors. Update the Dockerfile and requirements.txt to pin the correct dependency versions, rebuild images, and verify consistent behavior by running a predefined load-testing script.",,
3d69a0af-81b2-4f74-a7f1-e02ac87aca15,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,Design a load-testing harness in Docker to systematically reproduce an intermittent race condition in a Go HTTP server under concurrency. Then isolate and extract a minimal standalone Go program and test script that reliably triggers the data race without external dependencies.,,
6257cbed-5d4c-42ba-81cf-5f90372554c6,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"Reproduce an intermittent deadlock in a Go HTTP server that occurs only under specific GOMAXPROCS values and concurrent request patterns, then isolate a minimal single-file program and deterministic request sequence that triggers it. Capture the exact environment and commands used (race detector, pprof blocking profile, goroutine dumps) to demonstrate the deadlock reliably.",,
d766a87a-85eb-4397-a212-3185aaf6fa8c,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"Reproduce and isolate a CLI tool crash that emits 'Broken pipe' or exits non-zero when its stdout is piped to head/grep -m1, identifying the minimal code path that triggers SIGPIPE/EPIPE under controlled conditions. Implement graceful handling so the pipeline exits cleanly without stack traces or spurious errors.",,
4b9fc436-581f-48b2-a630-944410a1c053,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,Reproduce an intermittent timestamp parsing failure that occurs only during daylight-saving transitions by controlling TZ and the system clock inside the sandbox. Isolate the minimal failing input and code path by iterating across DST boundary timestamps and documenting the exact timezone/offset combination that triggers the error.,,
fa636fbd-101a-408c-9c77-d5c39bfe1d66,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"A Docker sandbox includes a multi-threaded C++ program that sporadically segfaults under concurrent std::map insert/erase operations. The task is to write a stress-test harness to reproduce the failure, iteratively reduce the code to isolate a minimal standalone example that reliably triggers the segfault, and document the narrowing process.",,
eeca33de-dffe-4e25-8319-9c89e7e42de9,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Error Reproduction & Isolation,"Reproduce a flaky 'Address already in use' failure by isolating the smallest script that deterministically triggers a TCP port reuse race (TIME_WAIT) during rapid server restarts. Build a tiny server/client and use only standard OS tools to narrow the failure to missing socket cleanup/options, yielding a minimal reproducible case.",,
73368045-611d-48c8-a63c-9e36b360bb4d,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Investigate a production failure where package installs and writes error with 'No space left on device' despite ample free disk space, trace the root cause to inode exhaustion from a runaway temp/log file generator, and validate via df -i and remediation. Produce a concise postmortem detailing impact, timeline, contributing factors, and preventive measures such as file-count monitoring, log rotation policies, tmp cleanup jobs, and quotas.",,
237d4275-fc9c-48da-9af8-0c1782267e94,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Investigate intermittent authentication failures (401/403) traced to JWT validation errors caused by container clock drift and misconfigured timezone/time sync. Write a postmortem detailing timeline, root cause, impact, detection gaps, and concrete preventive measures (time synchronization policy, startup time sanity checks, monitoring/alerts, and validation tolerances).",,
3dc694f4-2cf1-4113-b25f-e5166e963a45,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Analyze a simulated e-commerce checkout service outage by examining container logs, health check configurations, and deployment scripts to identify the root cause of continuous restarts and transaction failures. Compile a postmortem report at /app/postmortem.md detailing the incident timeline, impact, root cause, resolution steps, and recommended preventive measures such as improved monitoring and configuration validation.",,
5765ffec-9b64-4ecf-8bc8-2da658548495,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Investigate an incident where API requests intermittently returned 401 due to container clock drift causing JWT nbf/exp validation failures around a DST transition. Reconstruct the timeline from logs and metrics, identify the root cause, and produce a postmortem summarizing impact, detection, and preventive measures (time synchronization, validation leeway, targeted monitoring/alerts).",,
68893eaf-4de5-4cfb-998e-1f0544eef49b,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Postmortem Documentation & Preventive Measures,"Investigate why a nightly data export executed twice and produced corrupted partial uploads by reconstructing the timeline from cron logs, application logs, and a stale PID lock during a DST transition. Write a postmortem detailing root cause, impact scope, contributing factors, and preventive measures (timezone policy, idempotent runs, and robust lock hygiene).",,
5c014df5-0376-4ebf-8020-1e7fd55ebf5b,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,"Analyze a Rust Tokio-based service that panics with a long backtrace due to an unwrapped Option in nested async calls; trace through the stack frames to identify the faulty unwrap, then implement proper error handling to prevent the panic. Ensure the service starts and handles missing values gracefully under asynchronous workloads.",,
ba1cffa3-ffb2-4dae-9e1b-c30c01fd14ef,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,"Diagnose a Node.js microservice crash by analyzing its V8 heap snapshot and long-stack-trace to reconstruct the async call chain leading to an UnhandledPromiseRejectionError, locate the missing await causing context loss, and propose a minimal patch restoring correct error propagation.",,
5fef8bb7-5895-47cb-9016-7997f7e1a03f,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,"Analyze a Go HTTP server panic of 'invalid memory address or nil pointer dereference' by inspecting the panic stack trace to pinpoint an uninitialized map used in request handling. Fix the code by initializing the map and verify that no panics occur under load, documenting the root cause and resolution.",,
595e978f-b1e3-4d3b-8adc-6a4865b1d5d9,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,"Diagnose a Java service hang by capturing and analyzing multiple jstack thread dumps to trace a lock-order inversion deadlock (each thread waiting on the other’s monitor) and identify the exact code paths involved. Implement a fix by enforcing a consistent lock acquisition order or using tryLock with timeouts, rebuild, and verify the service remains responsive under concurrent load.",,
c0eb882b-94ba-410a-8052-937bf756c5dd,Debugging & Troubleshooting,Root Cause Analysis & Postmortem Debugging,Traceback & Stack Analysis,Investigate an intermittently crashing Go HTTP service by analyzing its panic log and full goroutine dump to trace the execution path to a 'concurrent map writes' failure and pinpoint the offending map and call sites. Implement a minimal synchronization fix and a stress test that runs with -race to verify the panic no longer occurs.,,
e1ec2f70-7562-452b-8c6e-086af7187282,Debugging & Troubleshooting,Security & Access Debugging,Access Policy & Role Misconfiguration,Diagnose and correct a MinIO S3 setup where a data-ingest user cannot list or upload objects due to conflicting bucket and user policies. Apply the least-privilege fix by adjusting the bucket and user policies so that aws s3 ls and multipart uploads succeed only within the intended bucket/prefix.,,
87e31f70-0cfb-4d78-9ff2-1bbe6d9c8498,Debugging & Troubleshooting,Security & Access Debugging,Access Policy & Role Misconfiguration,"Diagnose and fix a Redis ACL misconfiguration that blocks a non-default user from executing required commands (e.g., SET/GET) on a specific key prefix used by a sample app. Update the ACLs to grant least-privilege access for that user and verify the app completes successfully end-to-end.",,
a6fb3357-f867-46b0-a331-2ec5e02eb79a,Debugging & Troubleshooting,Security & Access Debugging,Access Policy & Role Misconfiguration,"Diagnose why a data-ingestion script receives 403 AccessDenied when uploading to an S3-compatible MinIO bucket due to a mismatched bucket policy and user credentials. Correct the bucket and user policies to grant least-privilege PutObject/ListBucket on the intended prefix, update the client configuration, and verify the script completes successfully with upload and listing.",,
c9f29cd3-b51f-4d92-bb74-36b46cfadebb,Debugging & Troubleshooting,Security & Access Debugging,Access Policy & Role Misconfiguration,Diagnose and fix an Azure Key Vault access issue where a service principal’s Conditional Access policy blocks secret retrieval. Provide the corrected JSON policy and a CLI-based verification script demonstrating least-privilege secret get/set operations.,,
24d44981-13e8-4969-b7e5-e812153b1e96,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,"Diagnose and fix a local PostgreSQL login failure for user 'app' where URI-based connections are rejected due to pg_hba.conf rule order, SCRAM-vs-MD5 password mismatch, and missing LOGIN/CONNECT privileges. Correct the configuration and role settings, reload PostgreSQL, and verify with psql postgresql://app:app@localhost:5432/appdb -c SELECT 1.",,
ac7133d1-5525-4e0a-a118-97f17398dcdc,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,"Diagnose and fix a broken HashiCorp Vault integration in a CI/CD pipeline where tokens are not renewing, policies are misapplied, and secrets cannot be fetched. Ensure the pipeline can authenticate, auto-renew tokens, and retrieve required secrets with correct Vault policies in place.",,
f2270d72-20cd-4860-83e0-3b92e1f80820,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,Diagnose and repair a Node.js Express service’s JWT authentication misconfiguration caused by an algorithm mismatch and missing environment secrets. Update the app’s config and .env keys so that POST /login issues a verifiable JWT (RS256) and GET /protected succeeds with a valid Authorization header.,,
ce16cf7e-8f6a-403c-948c-0dd4a68e35dd,Debugging & Troubleshooting,Security & Access Debugging,Authentication & Authorization Failures,Diagnose and resolve npm 401 Unauthorized errors when installing from a local Verdaccio registry by pinpointing bad/expired credentials or scope misconfiguration in ~/.npmrc and registry ACLs. Reauthenticate or correct token scopes/registry settings so installing a private package succeeds from the terminal.,,
7b1bbefa-7666-40d0-97b8-48d814ef37c2,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"Debug and repair a Node.js microservice that fails to authenticate to an external REST API due to missing or malformed credentials in its .env file and misconfigured AWS Secrets Manager integration. Implement an entrypoint script that retrieves Base64-encoded JSON secrets via aws-cli, validates and decodes them, exports the required environment variables with correct permissions, and proves authentication by calling the service’s /health endpoint with a valid Authorization header.",,
c8dbf6ca-00b2-4769-92b2-e4ba0d94ab09,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"Diagnose and fix a CI/container build that fails to fetch private npm packages and Git submodules due to mismanaged tokens (missing/misnamed env vars, malformed .npmrc, and SSH key permission issues). Repair the credential chain and config so npm install and git submodule update complete non-interactively.",,
d741b44e-0beb-490c-af33-5291056f25a3,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"Diagnose why sops cannot decrypt secrets.enc.yaml in the container because the AGE private key is provided as a base64, single-line environment variable that is never materialized as a key file. Reconstruct the PEM from the env var, set SOPS_AGE_KEY_FILE with correct permissions, and verify decryption by producing /app/secrets.yaml.",,
047e6885-1b25-4b53-bac9-9d94d9982d9b,Debugging & Troubleshooting,Security & Access Debugging,Environment Secrets & Credential Mismanagement,"A Node.js API service running in Docker Compose fails with missing API key and secret errors because its .env file is excluded by .dockerignore and not mounted via env_file. Fix the Dockerfile, docker-compose.yml, and application startup to include environment variables securely, enforce file permissions, and add graceful logging when credentials are absent.",,
272f50a7-ddea-4c75-aa20-494817c60257,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"A reverse proxy cannot connect to its backend via a Unix domain socket at /run/app.sock due to permission denied on the socket path. Diagnose and correct directory/socket ownership, mode bits, and group/ACL settings so the proxy user can connect, then verify a 200 OK from curl localhost.",,
e00a901d-2733-46cc-a84a-13fcf0e80382,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose and fix a Unix domain socket connection failing with 'Permission denied' by auditing the socket file and its parent directory ownership/modes and the creator’s umask. Implement a least-privilege solution (e.g., dedicated group, setgid directory, corrected socket permissions), then verify the client can connect and exchange data successfully.",,
d3fd7160-608b-4486-a7d4-f9c8499ae4b9,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose and fix a reverse proxy failing with 502 because nginx cannot access a backend UNIX domain socket (EACCES) due to incorrect ownership/permissions on the socket and its parent directories. Adjust ownership, mode, and directory execute bits or set ACLs, then make the fix persistent by updating the systemd .socket/.service or tmpfiles.d configuration, and verify that curl via nginx returns 200.",,
48151bba-a57f-4381-a82b-18e12a9fd1a5,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,Diagnose why a client fails to connect to a local service over a Unix domain socket (/run/app/app.sock) with EACCES and fix the underlying directory and socket ownership/permission and group-membership issues. Verify the repair by enabling the non-root client to connect end-to-end using the provided health-check script.,,
c936f828-7732-4b92-81df-6940c702925c,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose and fix file and directory permission issues preventing the Redis service from creating and binding its Unix socket at /var/run/redis/redis.sock by correcting ownership set by a faulty install script, adjusting the systemd unit’s RuntimeDirectory settings, and verifying that redis-cli can connect without sudo.",,
956ec99a-2e92-4414-853e-9fca243ca8f6,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose permission denied errors preventing a systemd-managed Go web service from creating its runtime directory (/var/run/goapp) and log file (/var/log/goapp/app.log). Update the unit file to use RuntimeDirectory, UMask, and correct ownership so the service and a non-root user can access its socket and logs properly.",,
a3292310-b1a9-4dd6-923f-cafe4b2acf44,Debugging & Troubleshooting,Security & Access Debugging,File & Directory Permission Errors,"Diagnose why a client receives 'Permission denied' when connecting to a Unix domain socket at /app/run/metrics.sock: the socket’s parent directory lacks execute permission for the client’s group and the daemon’s umask creates overly restrictive socket permissions. Implement a least-privilege fix by adjusting directory ownership/modes and the daemon’s umask or group, then verify bidirectional communication over the socket.",,
b994aa41-8175-4fd7-b6a9-e17ba446151c,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose why a systemd socket-activated Python HTTP service intermittently fails with 'Cannot assign requested address' by correcting network-online.target ordering, socket file cleanup, and ExecStart bindings. Deliver fixed .socket and .service units, a cleanup helper script, and proof of consistent HTTP responses after restarts.",,
62075f38-8c64-4d40-858f-136849efb268,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose a systemd timer-backed backup service that intermittently fails with SELinux permission denials by analyzing journalctl and audit logs. Restore correct file contexts, write a custom SELinux policy module, and update the unit file to ensure reliable, policy-compliant backups.",,
3eae9629-e441-44eb-8ef7-24837e1cfd7a,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose why a systemd-timer–driven daily log-rotation service skips or duplicates runs around daylight saving transitions; inspect journal logs and unit files, correct OnCalendar settings or add Persistent flag, reload systemd, and verify the next scheduled runs occur exactly once.",,
055b25b7-9b24-4b05-8344-e9f859a14a1d,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Investigate why a systemd timer’s backup.service succeeds when started manually but fails when triggered by the timer due to environment/working-directory differences and reliance on relative paths. Update the unit(s) to use absolute ExecStart, set WorkingDirectory and Environment (PATH/HOME), add logging, then verify the timer fires and completes successfully.",,
b5ce9afb-2425-4316-8588-b45a6970a803,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose a systemd socket-activated service that never starts on client connect due to mismatched unit names, incorrect ListenStream/ListenUnix path, and restrictive socket directory permissions. Correct the .socket/.service units (naming, ExecStart, WorkingDirectory, User), reload and enable socket activation, and verify the daemon spawns on demand and successfully serves a test request.",,
44f6f3f4-98ca-4100-ad4a-c65fd7d28465,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Investigate a systemd-managed daemon that immediately enters a restart loop because unit hardening (DynamicUser with ProtectSystem=full) prevents creation of its PID/log/state files. Use journalctl and unit inspection to diagnose and then update the unit to provision writable runtime/state paths (e.g., RuntimeDirectory/StateDirectory or ReadWritePaths) so the service starts and stays active, verified by a heartbeat file appearing.",,
6734c6bf-6507-455a-ba0f-0e88ea6dec8d,Debugging & Troubleshooting,System & Process Diagnostics,Background Service Failures,"Diagnose a systemd-managed Celery worker service that silently stops processing tasks by inspecting journal logs to uncover misconfigured broker URLs, missing virtualenv activation, and low file descriptor limits. Provide a corrected .service unit with proper ExecStart, EnvironmentFile, LimitNOFILE settings, and a health-check script to verify continuous task processing.",,
2ee3d744-e373-437a-bdaf-382455c3b965,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Diagnose intermittent restarts of a systemd-managed service by analyzing journalctl and kernel logs to detect OOM-killer and memory pressure events time-correlated with the service’s crashes. Implement a mitigation (e.g., adjust MemoryMax or service configuration) and verify stable operation with no recurring log anomalies.",,
9a5986c7-0631-41f8-b9f9-932e5685344a,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Correlate a recurring 2–3 minute outage by analyzing nginx access/error logs, systemd-journal logs, and cron logs while compensating for a deliberate 5‑minute clock skew between components. Identify that a misconfigured logrotate postrotate script intermittently sends SIGSTOP to the web app and apply a minimal fix so the outage ceases.",,
4cb4368f-febd-4b0a-8edd-3283dd8db8b5,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Scan syslog, auth.log, and NTP logs (including rotated .gz) to detect a surge in authentication errors and correlate it with a significant NTP time step, pinpointing the drift magnitude and window. Output a concise timeline report naming the triggering event and the impacted services (e.g., sshd, sudo) where errors align with the clock change.",,
fef1f0e3-ace8-4f90-b117-b5dc35325496,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Investigate intermittent TLS handshake failures by scanning journalctl/syslog and application logs for anomalies like “certificate not yet valid” alongside abrupt timestamp jumps, correlating them with NTP desynchronization events. Restore correct time sync (e.g., via systemd-timesyncd or chrony) and verify by re-running a TLS client to confirm error-free handshakes and aligned log timestamps.",,
6a26affa-f5a6-4785-9593-a142fdab17aa,Debugging & Troubleshooting,System & Process Diagnostics,Log Inspection & Anomaly Detection,"Analyze syslog and kernel logs to detect recurring disk I/O errors, SMART failures, and ECC correction events. Correlate timestamps to identify the failing device, count error occurrences, determine the failure window, and generate /app/disk_error_report.json with device details, error metrics, time window, and remediation suggestions.",,
1a2ed9e1-daa2-4151-8a68-70e940844e54,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,Analyze a core dump from a C-based JSON validator that crashes with a segmentation fault on long keys. Use gdb to pinpoint the buffer overflow in the key-handling function and patch the code to allocate buffers dynamically and safely copy strings.,,
2cbc448e-d36f-4232-bc28-2026808e3dbb,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Reproduce and analyze a core dump from a multithreaded C service that intermittently segfaults on SIGTERM due to a reentrant, non-async-signal-safe signal handler freeing shared memory twice. Enable core dumps, use gdb to pinpoint the crashing thread and double-free path, refactor the handler to defer work via a self-pipe and enforce single-ownership, rebuild, and verify stability under a stress harness.",,
5ec4b776-7294-4a95-83d5-dcf5a5d22b90,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,Analyze a core dump from a Node.js application crashing with SIGSEGV inside a custom C++ native addon by using llnode and gdb to reconstruct a JS backtrace and pinpoint misuse of v8::Persistent handles. Then update the addon source to correctly manage handle lifetimes and verify the fix under GC stress without further crashes.,,
b7b4667f-6e4c-4728-a5a5-b3293ea17168,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Analyze the core dump of a multithreaded C++ HTTP server that intermittently segfaults under load. Use gdb backtraces to pinpoint a use-after-free in the request parser, then implement proper ownership and synchronization to eliminate crashes under stress tests.",,
0f1f8d48-3f4e-4462-b792-7aa1f573f67c,Debugging & Troubleshooting,System & Process Diagnostics,Process Crashes & Core Dumps,"Investigate a Node.js service that segfaults when requiring a native addon, analyzing the generated core dump with gdb to pinpoint an ABI/version mismatch between Node and the .node binary. Rebuild the addon for the correct Node-API/ABI (e.g., via node-gyp or prebuilds), replace the artifact, and verify the service runs and responds to a simple request without crashing.",,
458d7bf7-553e-4215-a7db-dd1ee868471c,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose why package installs and temporary builds fail with 'No space left on device' by pinpointing which filesystem is full (/var or /tmp) and identifying the largest consumers (journald logs, apt/pip caches, orphaned artifacts). Reclaim space and implement mitigations (logrotate/journald limits, apt clean, TMPDIR relocation) so subsequent installs and builds succeed reliably.",,
d34c31d6-109f-47ac-b812-d37bb8213a50,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose a Node.js HTTP server leaking file descriptors under high load by analysing lsof outputs and system logs, then patch the code to close sockets properly and adjust systemd LimitsNOFILE. Validate stable FD usage below 1k under simulated 10k concurrent connections and provide patched server.js, updated unit file, and fd_report.json.",,
c152c71e-49b6-42c3-886a-d0982177d5d0,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose a backup job that aborts with ""No space left on device"" even though df shows ample free space, uncovering inode exhaustion from millions of stale temp/log files. Mitigate by reclaiming inodes and preventing recurrence (e.g., targeted cleanup, log rotation, and moving TMPDIR to a larger filesystem), then rerun the backup to complete successfully.",,
ab5fd16a-85f7-453b-93eb-811f08bffe4d,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose sporadic 'No space left on device' errors despite ample free disk by identifying inode exhaustion caused by millions of small files in /var/tmp/app-cache. Implement cleanup and a prevention policy (e.g., tmpfiles.d or a cleanup cron) and verify new files can be created successfully.",,
6df1af8a-ec99-43aa-b0c4-af8806293361,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose intermittent 'EADDRNOTAVAIL' and 'cannot assign requested address' errors in a service that spawns many short-lived outbound TCP connections, tracing the issue to ephemeral port exhaustion and sockets stuck in TIME_WAIT. Implement mitigations (e.g., enable connection pooling, tune the ephemeral port range and TIME_WAIT reuse via sysctl in the container), then rerun load to verify stable connectivity.",,
cf08737d-ea98-4c02-80a0-2f89c1bb1976,Debugging & Troubleshooting,System & Process Diagnostics,System Resource Exhaustion,"Diagnose and mitigate disk space exhaustion in a Dockerized logging service by identifying unbounded log growth under load, implementing log rotation with compression and retention policies, and freeing existing logs. Verify that no container runs out of space during a simulated high-traffic test and produce a cleanup_report.txt summarizing before/after disk usage statistics.",,
32ab428c-2fe3-48f3-b98c-469d05dbd987,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Git & Version Control Issues,"Recover from an erroneous force-push that wiped out recent commits and caused local-remote divergence. Use reflogs and remote refs to restore lost commits, reconcile branches and tags, and update the remote to a correct fast-forward state while preserving collaborator workflows.",,
4822773f-c827-4363-a5d3-2123b813bf89,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Git & Version Control Issues,"Diagnose and repair a misconfigured Git submodule setup where .gitmodules contains wrong URLs and submodules are stuck on detached HEADs, causing CI checkout failures. Update .gitmodules, fix each submodule’s branch tracking, remove stale submodule folders, and implement a reproducible script to clone and sync all submodules correctly so all tests in /ci pass.",,
91ed2df6-45b2-47dc-902c-1c74d8d32dc8,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Git & Version Control Issues,"Diagnose and repair a repository with nested Git submodules that fail to initialize due to incorrect URLs and detached HEADs; update .gitmodules, fix references, perform recursive initialization, and validate that the superproject and all submodules can be cloned and updated correctly.",,
b0e9eac7-8002-417f-9782-9152d36195b5,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Local vs Remote Environment Divergence,"Investigate a Python project whose tests pass locally but fail in the provided CI container due to differing default locale (C/POSIX vs en_US.UTF-8) and timezone (UTC vs local), affecting collation and datetime formatting. Make the test run deterministic by enforcing explicit locale/TZ and locale-independent sorting/parsing so the suite passes in both environments.",,
fc07e789-b20c-4511-b093-ca5dbe739b88,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Local vs Remote Environment Divergence,"Detect and reconcile discrepancies (Node.js versions, environment variables, dependency lockfiles, and file permissions) between local development and CI Docker environments for a Node.js microservice. Update the Dockerfile, .env configuration, and npm scripts so builds and tests pass identically in both contexts.",,
accbd531-5ac2-4b85-9361-7ef6cd54c38e,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Local vs Remote Environment Divergence,"Investigate Python tests that pass locally but fail in the provided CI-like container due to differences in locale and timezone affecting sorting, casing, and datetime parsing. Identify the mismatch (e.g., POSIX/C vs UTF-8 locale and non-UTC TZ) and reconcile it by standardizing environment settings and hardening code/tests to be locale- and TZ-independent.",,
a14a5612-d734-43ea-93ee-1b9eb87665eb,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Investigate a Python pytest suite that passes locally but fails in CI due to hidden timezone/locale assumptions (naive datetime comparisons and locale-dependent formatting). Make tests deterministic by enforcing UTC and a fixed locale in both code and pipeline (e.g., TZ=UTC, LC_ALL=C) and refactoring tests to use timezone-aware datetimes or freezegun, then verify consistent green runs.",,
338c51f4-79be-4de5-b5bb-d4058b17840e,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Diagnose and remediate intermittent test failures in a Node.js monorepo CI pipeline by pinpointing misconfigured Jest caches, inconsistent workspace dependency resolutions, and phantom registry URLs. Update workspace and CI configurations, regenerate the lockfile, tweak caching directives, and provide a reproducible validation script to ensure deterministic, flaky-free test runs.",,
c91311b0-abd4-46a3-9466-53a8f7fe5722,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Investigate why tests that rely on large sample assets fail in CI but pass locally, discovering that Git LFS-tracked files are checked out as pointer stubs in the CI environment. Initialize and configure Git LFS in the pipeline, fetch actual binaries, and rerun the suite until all tests pass.",,
fb94fa1a-5157-45d4-8686-2e54bba02e82,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Diagnose and repair a GitHub Actions workflow for a Node.js monorepo that intermittently fails due to caching issues and outdated lockfile conflicts. Implement automated steps to validate YAML, refresh dependency caches, lock Node versions, and ensure deterministic installation so all CI runs succeed reliably.",,
cec5d234-62f9-4448-9234-2e4162c496e9,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Diagnose a flaky GitHub Actions CI workflow for a Python project where parallel pytest jobs against a shared PostgreSQL service intermittently fail due to database lock contention and misconfigured environment variables. Update the workflow to ensure isolated test databases, proper service health checks, and effective caching, then verify five consecutive successful runs and document findings in /app/ci_diagnosis.md.",,
a960b220-897e-4949-9d90-c4ab858560af,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Reproduce and fix a CI-only failure in a React/Jest snapshot test that passes locally but fails in a headless CI container due to missing system fonts and locale/timezone differences. Identify the mismatches, install/configure the necessary fonts, set deterministic TZ/LC_* and rendering flags, and make the pipeline pass with consistent snapshots.",,
2c02e64c-dba4-4be2-abd5-98a014853daf,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Testing & CI/CD Failures,"Diagnose why a pytest suite passes locally but fails in CI where LANG=C and TZ=UTC cause Unicode encoding and time-format assertions to break. Make the pipeline and/or code locale- and timezone-stable (install a UTF-8 locale, set LANG/LC_ALL/TZ, and remove locale-dependent assumptions) and demonstrate a consistent green run.",,
48f9471c-dc0f-40ea-81c5-58a45d7152dd,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose and repair a broken Git pre-commit setup where hooks (e.g., black/isort/flake8/mypy) fail due to Python interpreter mismatches and outdated hook revisions. Update .pre-commit-config.yaml and environment so pre-commit install and pre-commit run -a complete successfully and reproducibly from the terminal.",,
6636f4c3-61f8-46a0-93d2-7c811cf06e2d,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose a Node.js monorepo where CI fails because the pipeline runs npm ci against a pnpm-managed workspace using pnpm-lock.yaml, breaking workspace links and dependency resolution. Reconfigure the workflow to use a pinned pnpm via corepack, install with pnpm in all jobs, regenerate the lockfile if needed, and verify that build and tests complete successfully.",,
50fece10-7cb0-4217-afee-c4a2071aaf78,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose a Rust workspace that fails in a simulated CI script due to dependency drift and toolchain mismatch (yanked versions in Cargo.lock, incompatible feature flags, and an unsupported rustc). Repair by pinning a compatible toolchain, updating/patching dependencies and regenerating the lockfile so cargo build and cargo test complete successfully.",,
ccd11bd1-5cff-4c20-8491-05f3d7ac838c,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose and repair a failing GitHub Actions CI workflow in .github/workflows/ci.yml caused by deprecated actions, misconfigured cache keys, and YAML syntax errors. Update action versions, correct cache configurations, adjust matrix definitions for Node.js (14/16) and Python (3.8/3.9), and validate the workflow completes successfully without cache misses.",,
451d3cbb-40b0-4944-98ae-3f4904e56de8,Debugging & Troubleshooting,Toolchain & Workflow Diagnostics,Tool Misconfiguration & Dependency Drift,"Diagnose and fix a broken GitHub Actions CI pipeline for a Yarn v2 monorepo where dependency drift across workspaces leads to mismatched lockfile states and test failures. Synchronize package.json versions, regenerate the PnP lockfile, configure proper caching steps, and verify that all /packages/* modules build and pass tests under the updated workflow.",,
327f83e2-60c1-4703-8fd9-15a0a4a89ddb,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Dynamic Difficulty Adjustment,"Build an agent that plays an adaptive Unix Pipe Gauntlet: a judge program presents level-by-level data-processing goals and allowed/forbidden tools; each success raises difficulty by tightening constraints (e.g., streaming-only, no temp files, limited forks) and larger inputs. The agent must clear at least 6 consecutive levels without invalid commands and then write the exact pipeline used for each level, in order, to /app/pipelines.txt.",,
6c3ab004-4cf8-4232-8083-4dd45ff6abf7,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Goal Discovery & Hidden Objective Games,"Use the interactive text-adventure harness at /app/harness.py to explore an enchanted ruin, inspect artifacts, and converse with spirits that drop cryptic hints. Infer and enact the unstated objective of reassembling the Celestial Orb by collecting and placing elemental shards in the correct order and write the action sequence to /app/solution.json.",,
2390a635-e82a-446a-a59a-98092abb254f,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Launch an adaptive Forensics Gauntlet CLI that presents a three-stage sequence of artifacts (e.g., pcap, stego-image, packed binary) whose exact types and hints change based on the agent’s prior actions and errors. Extract a token from each stage with appropriate terminal tooling, concatenate them into the final passphrase, and write it to /app/flag.txt.",,
d530fd45-cbcd-44d0-92ee-8402df9e0b8b,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Interact with a multi-stage network pentesting simulator—discover open services, craft and deploy exploits, escalate privileges, retrieve encrypted secrets, and purge audit logs under a strict command budget, with the environment adapting dynamically to your tactics. Produce /app/loot.txt containing recovered secrets and /app/timeline.txt logging each command executed.",,
c91b2d29-aa73-4c81-80b1-2e2c41cbc2d2,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"In a dockerized three-host network, enumerate services, brute SSH using a rotating wordlist to compromise a print server, pivot to a database host to retrieve a secret flag, and exfiltrate it via an HTTP POST to a simulated C2 endpoint. Host configurations, open ports, and credentials change on each run, requiring adaptive tool use and multi-step planning.",,
852470db-20bd-47f2-9929-128a5b4cb2c8,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Simulate a corporate network intrusion where the agent must sequentially perform reconnaissance, analyze compromised services, isolate infected hosts, and deploy patches via a CLI interface. The sandbox dynamically escalates threat complexity based on the agent’s successes or mistakes, demanding long-horizon planning and adaptive reasoning.",,
55dc23c6-d537-43f9-ac4c-823b9fd2ccb2,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Implement a multi-phase terminal treasure hunt game where the agent first navigates a hidden directory maze with shell commands to locate clue files, then deciphers those clues using UNIX text utilities and simple cryptography, and finally completes a simulated network handshake challenge by crafting and sending packets with netcat. The harness dynamically adjusts puzzle complexity based on the agent’s performance, enforces timeouts for each phase, and records all successful commands and answers to /app/results.json.",,
89685975-e62f-435a-808f-73f1776fd7b2,Interactive Challenges & Games,Meta-Challenges & Adaptive Tasks,Multi-Stage Interactive Scenarios,"Interact with a terminal-based adaptive market simulator that changes regimes (fees, tick-size, order throttles, volatility) in response to your PnL and risk. In phases, first probe and infer the current rules, then place exactly one legal order per tick to survive all rounds and finish above a target net worth, finally writing your ending equity and inferred parameters to /app/answer.txt.",,
49aaf64e-8d1f-4b27-ab5c-e6ffba5568bb,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Adversarial Game Environments,"Build a terminal client for a Tron-style light-cycle duel on a toroidal grid that receives per-tick state over a socket and must emit exactly one legal move under a strict per-turn deadline. To pass, the agent must outlast or trap the AI opponent across a best-of-N series while maintaining a target non-loss rate and zero invalid moves.",,
0f1c38c9-72d2-4e41-9089-49eee085a5da,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Adversarial Game Environments,"Create a terminal agent that plays an adversarial Battleship variant against a hidden AI where ships can legally drift one cell per turn after each round. With a limited number of probes and optional sonar sweeps, the agent must track probabilistic ship positions, anticipate evasive maneuvers, and achieve a target win rate over a best-of series.",,
1cb5eba8-e3cb-4ec6-af68-5442a4d4953a,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Adversarial Game Environments,"Create a terminal bot that plays Notakto (misère tic-tac-toe) on three simultaneous 3×3 boards against a provided adversarial engine via a simple text protocol. The bot must issue legal moves under a per-turn time limit, strategically closing boards to force a win across a best-of-five match and log the full transcript.",,
03b7e6d0-33a3-41ca-9752-41d02406b52b,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Collaborative Simulations,"Coordinate three simulated warehouse robots via provided CLI tools and TCP sockets to pick, carry, and deliver items on a 2D grid while avoiding collisions and respecting capacity and battery limits. Plan a joint schedule including charging stops, issue synchronized move/pick/drop commands, and write the final delivery ledger to /app/fulfillment.txt.",,
33e94781-5b93-493c-b633-80ff8f309c0e,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Collaborative Simulations,"Coordinate three autonomous spelunking drones in a fog-of-war cavern using the provided TCP JSON protocol: each drone has limited sensors, battery, and comm range, and some passages require synchronized two-drone actions to unlock. Implement a controller that schedules moves, plans rendezvous to sync maps, avoids collisions, and writes a globally merged ASCII map to /app/cavern_map.txt.",,
412a9133-415b-45c4-860f-1e1291062629,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Collaborative Simulations,"Implement a terminal controller that coordinates two cooperative agents—Scout and Carrier—over JSON via UNIX pipes in a partially observable 2D mine. Map hazards, schedule pickups, and deliver a target ore quota to base within a strict tick limit without collisions or invalid commands, then write the mission summary to /app/results.txt.",,
e75aa374-67b9-48ba-858b-8f2e80672ab4,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Collaborative Simulations,"Implement an agent that joins a turn-based, socket-driven cooperative pipe network repair simulation alongside a simulated teammate controlling a disjoint set of tiles. Using a 16-byte-per-turn radio channel, coordinate synchronized rotations and valve toggles to connect all sources to sinks without leaks within 250 turns, then output the final ASCII grid to /app/network.txt.",,
e877425c-af70-43a0-8bc0-8e3c35d6586a,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Use the provided market_sim CLI to negotiate concurrently with two competing suppliers that bluff, issue time-limited counteroffers, and adapt pricing to your messages. Secure a single bundled contract meeting target quantity, budget, and delivery constraints, then write the agreed terms to /app/contract.json in the required schema.",,
ad926719-62f7-46ab-b113-e3555db095af,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Implement an agent that conducts multi-attribute contract negotiations (price, delivery window, warranty) via a terminal CLI with three simulated vendors using an alternating-offers protocol, inferring each vendor’s hidden preferences from their counteroffers. The agent must secure at least two agreements under a global budget and write the finalized deals as JSON to /app/deals.json.",,
f85c695f-abd8-45c3-8924-8535d16ab5b8,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Build a Python negotiation agent at /app/deal_agent.py that interactively negotiates a multi-issue contract (price, warranty, delivery) with a simulated vendor via STDIN/STDOUT over a fixed number of rounds, adapting to opponent concessions to maximize joint utility. The test harness randomizes the vendor’s hidden utility weights and requires the agent to reach a normalized joint score ≥0.8 within 10 exchanges.",,
87620ef7-43d6-40e7-ae51-a3a1e1ac64c5,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Negotiate a cloud service contract with two simulated vendors over a JSON-lines CLI broker, adapting to counter-offers and surprise constraint changes (budget, latency SLO, and data residency) to reach a Pareto-feasible deal in ≤20 rounds. On success, write the agreed terms as valid JSON to /app/contract.json and the complete dialogue transcript to /app/transcript.log.",,
26964ebc-83b1-4621-8f36-81bf12537c07,Interactive Challenges & Games,Multi-Agent or Adversarial Simulations,Negotiation or Dialogue Simulations,"Negotiate a multi-item procurement contract with three simulated vendors over a CLI dialogue protocol, exchanging offers that vary unit price, lead time, and minimum-order constraints. Produce a single purchase order that fulfills the given BOM within budget and deadline while minimizing total cost.",,
dc1560d7-231d-4c1a-b67c-7b8110e3c1d2,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Create an agent that interacts with a terminal simulator to explore a partially observed 2D grid featuring toroidal wrap-around, paired teleporters, and one-way wind tiles that push the agent upon entry. The agent must output an exact ASCII map labeling S, E, walls, portal IDs, and wind directions, and a minimal-length path from S to E that respects these mechanics to /app/solution.txt.",,
88e7a3cf-dd88-4725-b66d-0d4b8463d784,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Explore a terminal-based grid with hidden paired portals and one-way conveyor tiles under partial observability, inferring teleport linkages and movement dynamics as you go. Reconstruct the exact ASCII map, list portal pairings, and compute the shortest S→E route that respects conveyors and teleports.",,
1cba6ca4-a978-4998-bb4d-035399cf9fe9,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Interact with a time-evolving grid simulator where hazards drift each turn; using only local scans and actions (up/down/left/right/wait/ping), explore to map the environment, collect two artifacts, and return to S. Write the final ASCII map and the time-indexed action sequence to /app/solution.txt.",,
36e285d9-1040-40b7-a0a4-5009d78f8fa3,Interactive Challenges & Games,Simulation & Virtual Environments,Environment Navigation Challenges,"Build an agent that explores a fog-of-war hex-grid rover simulation via CLI, where each move reveals neighbors, drains battery, and encounters dynamic hazards (e.g., shifting dunes or rockfalls). The agent must locate and collect two beacons, then reach the uplink before power depletion, outputting the discovered map and exact move sequence to /app/route.txt.",,
3b5f6c3f-5a55-4ddc-9a42-16063886a1c1,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Interact with a terminal-based 2D n-body gravity sandbox where a probe starts on an escape trajectory; issue one thrust command per tick under a fixed fuel budget to capture into and maintain a near-circular orbit around a specified body for 600 steps. On completion, write the measured semi-major axis, eccentricity, and mean motion to /app/orbit.txt.",,
856f9719-5342-479a-9d7b-2a149aff3ac3,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,Create a Python agent at /app/predator_prey_agent.py that interacts with a provided harness to control a predator–prey cellular automaton by issuing add/remove commands for wolves and sheep each generation and reading the updated grid. The agent must keep the predator-to-prey ratio within a target range for 100 consecutive turns using only the harness API and no external I/O.,,
14274b8e-39fd-46e6-ab74-dd4be289eb8f,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Pilot a spacecraft in a terminal-based 2D orbital simulator by issuing discrete thrust commands each tick to rendezvous and soft-dock with a moving satellite while conserving fuel. Parse telemetry, predict trajectories under gravity, avoid collision zones, and complete docking within time and distance/velocity tolerances.",,
3a1c4571-3aba-4da2-8721-1be5f8deeafa,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Pilot a capsule in a simplified 2D orbital dynamics simulator by issuing discrete thruster burns via a CLI to match position and velocity with a target module before fuel runs out. On successful dock, write the timestamp of docking and remaining fuel to /app/docking_report.txt.",,
8a3e5b65-56e4-46b1-a6eb-04cbb4caa5b0,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Probe an unknown 2D cellular automaton via a terminal interface that lets you seed patterns, step the simulation, and snapshot states under a fixed global step budget. From these experiments, infer the local update rule and implement a predictor that, given a fresh initial grid and K, writes the K-step future state to /app/answer.txt.",,
1b52da74-b648-4c39-8049-c9646796f2fd,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"Create a Python CLI agent that, given an N×N Conway’s Game of Life grid and a target pattern, interactively places up to K live cells each generation (or passes) to evolve the automaton into the goal shape within M steps, then outputs success or failure.",,
73ac681e-95a0-4f86-a549-4ff989bb1c39,Interactive Challenges & Games,Simulation & Virtual Environments,Interactive Physics or Cellular Simulations,"In a 2D heat‐diffusion sandbox with random initial temperatures, the agent selects one grid cell per timestep to activate a heater under a global energy budget and must drive the entire grid to a uniform target temperature within a fixed number of steps. The solution must interact via the CLI, reading the grid state each turn and outputting heater coordinates while respecting performance and budget constraints.",,
4088a2b5-ac52-47de-9504-98f4696ed1eb,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Operate a terminal-based power grid where you must schedule generators with ramp/warm-up constraints, shift energy via batteries, and buy/sell on a volatile spot market as demand and weather vary each tick. Survive a multi-day horizon with zero blackouts while minimizing total operating cost under emissions and maintenance limits.",,
b9c2fd74-1dc4-4289-9121-71483ed4a540,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Operate a simulated island microgrid via a terminal CLI—dispatch diesel gensets, curtail wind/solar, and charge/discharge a battery each tick—to meet demand and maintain a spinning-reserve margin without blackouts over a 24h scenario. Minimize total operating cost and emissions while surviving randomized weather dips and a forced-outage event, then write the final KPIs to /app/report.json.",,
74dbbe43-f190-4352-9783-8ee88ae20be0,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Use the /app/grid_sim.py CLI tool to deploy and configure generators, storage units, and transmission lines to meet dynamic 24-hour power demand across three zones under budget and emission limits. Aim to minimize total cost without causing any outages, then save the final configuration and metrics in /app/solution.json.",,
373ee238-ca44-41d0-bb31-efa123e7ec31,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Use a terminal microgrid-sim to manage solar, wind, battery, and diesel assets over 48 simulated hours, issuing per-tick dispatch commands to meet demand without blackouts. Minimize fuel use and battery wear amid stochastic weather and output a final KPI summary to /app/report.json.",,
e3edeaf2-4590-4b95-a597-8eaab5c4655c,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Operate a terminal-driven microgrid where each tick you dispatch generators, charge/discharge batteries, and optionally shed load amid stochastic demand and weather. Keep blackout events below a threshold and total operating cost under a budget for 500 ticks, then write the final cumulative cost and unmet-load percentage to /app/answer.txt.",,
81a60d51-f295-4aec-9713-4b69bf997404,Interactive Challenges & Games,Simulation & Virtual Environments,Resource Management Simulations,"Operate a terminal-based microgrid simulator by dispatching generators and scheduling battery charge/discharge each tick to meet demand under transmission constraints and variable renewable output. Survive 96 ticks without load shedding while minimizing fuel and carbon cost, then write final KPIs (cost, unserved energy, CO2) to /app/results.txt.",,
016eba79-1b40-444d-b799-2280f138fb69,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Build a Python controller script at /app/agent.py that uses the provided /app/harness.py to interact with a simulated microservice cluster where nodes randomly crash or partition. The agent must issue start, stop, and migrate commands to maintain at least three healthy replicas of each service and write a JSON recovery report to /app/deployment_report.json.",,
399b2def-5601-4895-b69b-c65d8299d2ca,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Operate a simulated three-tank industrial control system via a terminal CLI, reading sensor states and issuing bounded pump/valve commands under latency and sensor noise. Keep all tank levels within target bands for 500 ticks despite disturbances, then write the stability checksum to /app/answer.txt.",,
73a39e67-e20a-483e-bd4e-bcee9484faa1,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Using a provided Raft cluster simulator, bootstrap a 5‑node key-value store, write a test key, then induce controlled failures by stopping/restarting nodes to trigger leader elections while preserving linearizable reads. Verify consistency by reading the key from all nodes after recovery and write the observed leader IDs over time to /app/leader_log.txt.",,
c77ab31e-66d1-40dd-ae33-09b1ae3e1ce7,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Provision a three-node Docker network comprising a router, web server, and client; configure IP routing and iptables on the router to permit only HTTP traffic from client→web and MySQL traffic from web→db while blocking all other flows. Verify services with curl and mysql-client from the client node, and write a summary of passed connectivity tests to /app/answer.txt.",,
4cb79ca2-0bef-4a15-9e39-c3fcea16641c,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,Operate a terminal-driven Raft cluster simulator where nodes suffer leader flapping from mis-tuned timeouts and intermittent network partitions. Diagnose logs and adjust per-node settings and links to maintain quorum and consistency across hundreds of simulated ticks.,,
8fc5d3ea-a935-4121-86c4-f14720bfd6f3,Interactive Challenges & Games,Simulation & Virtual Environments,System or Network Simulations,"Pilot a simulated Software-Defined Network: use the provided controller CLI to install and update OpenFlow rules across six virtual switches so tenant networks stay isolated, service A is load-balanced, and failover occurs within 2s during injected link failures. Keep dropped-allowed-traffic under 1% as reported by the monitor and write the final rule set and metrics to /app/results.txt.",,
956d8a64-259b-4b32-8cf7-abf14e693b5d,Interactive Challenges & Games,Strategy & Reasoning Games,Board & Turn-Based Games,"Implement a fast Gomoku (five-in-a-row) agent module at /app/output/gomoku_agent.py that defines a GomokuAgent.select_move(board) method returning a valid (row,col) move using pattern-based heuristics or search. The agent must win at least 90% of games as first player and 80% as second against a provided basic opponent on a 15×15 board, averaging under 20 ms per move and fitting within 50 KB of code.",,
1b10bfda-d0cd-43a0-b92e-ebb5f9feba20,Interactive Challenges & Games,Strategy & Reasoning Games,Interactive Optimization Problems,"Develop a Python TSPAgent that, given the current tour and distance matrix via an interactive harness, proposes city‐swap moves to iteratively minimize total length. Within 2000 swaps it must reach ≤1.5% above the known optimum on a 100-city instance, using only numpy/numba, no external I/O, and staying under 25 KB.",,
d150d9fc-e51d-48c5-8f06-f25c393f8e36,Interactive Challenges & Games,Strategy & Reasoning Games,Probability & Randomized Challenges,"Build a terminal agent to play a non-stationary multi-armed bandit exposed via CLI/HTTP, choosing among 10 arms with stochastic rewards and occasional distribution shifts. Across 5,000 rounds, the agent must adapt online and complete with sublinear regret while writing final metrics to /app/results.json.",,
0fef431c-1356-469b-bf4a-ed4db70b94f5,Interactive Challenges & Games,Text-Based Games & Puzzles,Adventure & Exploration Games,"Play a terminal-based time-loop mystery where the facility resets every 10 in-game minutes, altering NPC schedules and door states. Across multiple loops, navigate rooms, cache items in persistent lockers, infer patterns from logs, and assemble a 6-symbol code to trigger the final shutdown and escape.",,
7b726ce4-932e-417e-aaec-2373128bad49,Interactive Challenges & Games,Text-Based Games & Puzzles,Escape Room & Challenge Scenarios,"Navigate a git-based escape room where each room is a branch and doors open by resolving crafted merge conflicts that conceal ciphered codes, with clues hidden in commit messages, tags, notes, and diffs. Progress through the repository to reach the final release tag, decode the ultimate passphrase, and write it to /app/answer.txt.",,
e20cb93e-75c0-4990-a0d1-738abdca9278,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Load the provided stripped ELF into gdb, set breakpoints to inspect the password-check routine (disassemble/step/examine memory) and recover the required passphrase or live-patch the check to reveal the computed token. Execute the program to its success state and write the exact success banner to /app/answer.txt.",,
83f2aa0c-ab74-42bd-9e69-af94cbc9774d,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Launch gdb on the provided 'vault' ELF, interactively identify the password check routine, patch the branch condition in-memory to bypass it, run the program to reveal the secret, and write the token to /app/flag.txt. Do not modify the binary on disk; all changes must occur live in the debugger.",,
96f41e47-b750-4ff0-b213-1b155aa12819,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive REPL Mastery,"Using the GNU Debugger (gdb) REPL, attach to and analyze the provided /app/lockbox binary, intercept its credential check (e.g., via breakpoints on strcmp) to recover the correct unlock token, then rerun the program to reveal the secret and write it to /app/flag.txt.",,
851ac4a3-226a-4bde-9849-d782a1a0d381,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive Tool Learning,"Use radare2 to recover a hidden passphrase from a deliberately obfuscated, stripped ELF in /app/bin using only r2’s analysis and debugging features. Consult r2’s help/man to identify the validation routine, step/trace to derive the correct input, then run the binary with that input and write the exact success banner to /app/flag.txt.",,
d4923f5d-c4dc-4d7a-8c71-d2dc06f2a54a,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Interactive Tool Learning,"Analyze an unknown ELF binary using radare2’s CLI (r2, pdf, afl, aec, izz, etc.) to locate the input check routine and recover the exact passphrase that reveals a secret when the program is run. Run the binary with the recovered input and write the secret output verbatim to /app/answer.txt.",,
e1a3a086-08f6-4a19-93ad-920bed84cb53,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"Recover a hidden release key by streaming through a labyrinth of nested archives and mixed-format shards, normalizing CSV/TSV/JSONL on-the-fly, key-joining records, and verifying order with checksums using a single shell pipeline. No intermediate files are allowed; write the final key to /app/results.txt.",,
c3faadcc-2f6f-4ec9-bfda-111dd2c2cbb3,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"Reassemble scattered base64-encoded, gzipped JSON fragments from numbered part files in nested hex-named directories, then decode and extract the JSON objects; filter those with prime 'id's below 1000, sum their 'value' fields, and write the total to /app/output/result.txt using only shell tools.",,
c15ebdd3-59d8-4013-84c3-80811771c0ed,Interactive Challenges & Games,Tool & CLI Mastery Challenges,Shell Puzzle Games,"Starting at /app/maze/start, traverse a symlink-based filesystem maze where each encountered file contains JSON giving a regex for the next filename plus a token fragment and sequence number. Using only shell tools (find, sed/awk, jq, sort), detect and avoid cycles, collect and order fragments, then base64-decode and gunzip the concatenated string to plaintext and write it to /app/answer.txt.",,
d2a9fdde-9c92-4984-aa1b-d508269855f2,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Using the visidata TUI, open /app/orders.csv and interactively create a pivot grouped by region and product_category for orders in 2023-Q4, calculating total_revenue and order_count, then sort by total_revenue descending and export the result to /app/summary.tsv. Also write the single top row of that pivot (tab-separated) to /app/top.txt.",,
d7722ad3-9ade-421f-8fdc-946982241984,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Use the ncurses-based websrv-config tool to configure a web server on port 8080 with SSL enabled and document root /srv/www via menu navigation and save the settings. Finally, verify the server returns a valid 200 OK response serving the expected test page.",,
7b7bde3a-310a-4184-bb32-bf320ea05a7d,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Use the tig ncurses Git interface to locate the first commit that introduced a target function signature and determine the first tag that contains it by navigating log, search, and blame views. Record the exact commit SHA and tag name to /app/results.txt as 'SHA TAG' after exiting the TUI.",,
0173c5be-d3b2-425d-bcef-168649ab9184,Interactive Challenges & Games,Tool & CLI Mastery Challenges,TUI (Text User Interface) Interaction,"Open the provided mixed CSV/JSONL dataset in the VisiData TUI, interactively filter to completed EMEA orders in Q3 2024, join users to orders, group by user, compute total spend, sort descending, and export a 2‑column TSV to /app/report.tsv. All data manipulation must be performed inside VisiData via keyboard-driven operations, then exit cleanly.",,
90fe463e-a963-40f7-80d9-25fb7b2c3764,Machine Learning & AI,Machine Learning Pipelines & Automation,Experiment Tracking & Logging,"Create a Python CLI that runs 5-fold cross-validation with hyperparameter search, using MLflow to record a parent run and nested child runs per trial and fold with parameters, metrics, and artifacts (ROC/PR plots, confusion matrices, and serialized models). The CLI must support resuming by skipping completed child runs, produce an aggregated leaderboard.csv, and register the best model with signature and input example in the Model Registry.",,
0cdd2e52-7b6b-4fec-82f3-9698717e4dfe,Machine Learning & AI,Machine Learning Pipelines & Automation,Model Registry & Versioning,"Create a Python CLI that publishes trained models as OCI artifacts to a local Docker registry (registry:5000), storing model weights and a metadata.json layer with code/data hashes, metrics, and dependency manifest. Support semver tags and aliases (staging/production), integrity verification by content digest, version comparison by a chosen metric, and atomic promote/rollback of the production alias.",,
ba14482f-1094-4350-a6fa-1f5ae7ccb93f,Machine Learning & AI,Machine Learning Pipelines & Automation,Pipeline Construction & Scheduling,"Build a Prefect 2.x flow and deployment that orchestrates an end-to-end ML pipeline with ETag-aware data ingestion, feature engineering, model training/evaluation, and conditional promotion; configure retries, result persistence/caching, and a cron schedule, ensuring re-runs skip unchanged tasks. Provide a CLI to register the deployment, start a worker, trigger a run, and emit versioned artifacts plus a run_report.json summarizing cache hits, timings, and the promotion decision.",,
44025c5e-e4a9-4ede-bf48-7f9c0eceaadc,Machine Learning & AI,Machine Learning Pipelines & Automation,Reproducibility & Environment Setup,"Create a Nix flake that defines a hermetic Python 3.11 environment with pinned NumPy, pandas, and scikit-learn, plus a CLI that trains a logistic regression on /app/data.csv with fixed seeds. Add a Makefile target that builds the flake and runs the training twice in fresh pure shells, asserting identical SHA256 hashes for model.pkl and metrics.json to confirm bit-for-bit reproducibility.",,
5a4596f0-5004-42ff-bf48-2c6b73788f48,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"Implement a CLI that applies three model compression techniques (structured pruning, post-training quantization, and knowledge distillation) to a pre-trained ResNet-18 on CIFAR-10, benchmarks accuracy, inference latency (CPU/GPU), and memory footprint, and outputs a comparison.json and an HTML report summarizing the trade-offs.",,
dd4a6ebd-c1a5-409e-a78b-8944e814287c,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"Create a reproducible benchmarking harness that trains five scikit-learn classifiers across four built-in datasets with repeated stratified k-fold, logging ROC-AUC, log loss, Brier score, per-sample latency, and model size to a results file. Run a Friedman test with Nemenyi post-hoc to rank methods, emit a critical-difference diagram, and pick a champion model that satisfies latency and size thresholds.",,
a1eb54d6-a5bb-42f3-9ed6-087ad52d0a2e,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"Create a reproducible CLI benchmarking harness that trains and evaluates at least three scikit-learn classifiers on every CSV dataset in /app/data using nested stratified k-fold CV, computing accuracy, ROC-AUC, F1, log-loss, Brier score, and calibration error with 95% bootstrap confidence intervals. Aggregate results across datasets with paired Wilcoxon tests and effect sizes to rank models, also measuring CPU inference latency on fixed batch sizes and exporting a single results.json with per-dataset metrics, CIs, significance, and an accuracy–latency Pareto summary.",,
8b41ef0d-2b1e-4313-9675-e31048e1b66c,Machine Learning & AI,Model Evaluation & Validation,Benchmarking & Comparison,"Implement a CLI tool that benchmarks varying pruning and quantization configurations on a pre-trained PyTorch image classification model by measuring top-1 accuracy, model size, and inference latency for each setup. The tool should output a JSON report ranking configurations across these trade-off metrics.",,
082e1cd5-2f54-430a-a05c-5b0c18c8e7f1,Machine Learning & AI,Model Evaluation & Validation,Cross-Validation & Statistical Testing,"Design a Python CLI that implements nested cross-validation with configurable inner hyperparameter search (grid or random) and outer k-fold evaluation, aggregating per-fold performance metrics for multiple models. After training, conduct paired Wilcoxon signed-rank and paired t-tests with multiple testing corrections to assess statistical significance, and emit comprehensive JSON and human-readable summary reports containing metric distributions, p-values, corrected alpha levels, and confidence intervals.",,
8c1a19eb-ffa7-4cda-9de5-c0d7937dea70,Machine Learning & AI,Model Evaluation & Validation,Cross-Validation & Statistical Testing,"Implement nested 5-fold cross-validation to tune logistic regression hyperparameters via grid search alongside a baseline random forest, record per-fold accuracies, and perform paired Wilcoxon signed-rank and McNemar’s tests to compare model performance. Generate fold_scores.csv, p_values.json, and confidence_intervals.txt with the exact schemas and formatting constraints.",,
f2a5ba62-8332-45c1-8bd3-814b9b14b56b,Machine Learning & AI,Model Evaluation & Validation,Error Analysis & Visualization,"Implement a Python CLI that loads a trained multi-class classifier and its test dataset, computes the confusion matrix to identify the top K most confused class pairs, and plots a heatmap along with per-class precision-recall curves and a reliability diagram. Then extract penultimate-layer embeddings for misclassified samples, apply UMAP to cluster failure modes, and save all visualizations as PNG files.",,
eae5b996-46ac-4d1a-bfe1-8d1f2764d2a4,Machine Learning & AI,Model Evaluation & Validation,Error Analysis & Visualization,"Implement a CLI tool that reads prediction and label CSVs, computes per-class confusion matrix, calculates expected and maximum calibration errors, and identifies the top-3 most confused label pairs. The tool must generate a normalized confusion heatmap PNG, a reliability diagram PDF, and write metrics.json, confusion_matrix.csv, and top_confusions.csv with the exact schemas and filenames.",,
520925cf-6497-4fde-bc11-0c027dd89f59,Machine Learning & AI,Model Evaluation & Validation,Error Analysis & Visualization,"Create a Python CLI that evaluates multivariate time-series forecasts against ground truth, computing per-horizon sMAPE, MASE, and prediction-interval coverage, and generates horizon-wise error heatmaps plus overlay plots of predictions vs. actuals for the worst 10 series by MASE. Write a metrics.json and PNG plots to /app/output while streaming to handle >1e6 points with numerically stable aggregations.",,
b1a69c2c-bd16-4a81-bac0-6ea31595ccf6,Machine Learning & AI,Model Evaluation & Validation,Metric Computation & Reporting,"Create a CLI that ingests a CSV of multiclass prediction probabilities and ground-truth labels, computes macro/micro F1, top-1/top-5 accuracy, per-class precision/recall, confusion matrix, and calibration metrics (ECE with adaptive binning, MCE, Brier), and writes a JSON summary plus per-class CSV. Include 1,000-sample bootstrap confidence intervals for scalar metrics and save a reliability diagram and normalized confusion matrix as PNGs.",,
d8716679-ad83-4867-aa94-62651dc799ce,Machine Learning & AI,Model Evaluation & Validation,Metric Computation & Reporting,"Develop a CLI tool that ingests ground-truth labels and probabilistic model outputs for a multi-class classifier, computes per-class and aggregate metrics (accuracy, precision, recall, F1, ROC-AUC), calibration measures (Brier score, expected calibration error), and emits a JSON report plus CSVs for confusion matrices and calibration curves.",,
50f20ca8-b5cc-4b94-ab80-f9ce76710bfd,Machine Learning & AI,Model Evaluation & Validation,Metric Computation & Reporting,"Create a CLI that ingests a Parquet file containing multilabel ground-truth indicators and model score columns, learns per-label thresholds on a validation split to maximize macro-F1, then evaluates the test split with those thresholds. Output a JSON report with per-label precision/recall/F1, micro/macro averages, LRAP, coverage error, Jaccard index, and the chosen thresholds, and write per-label 2x2 confusion matrices to CSV.",,
a078a83f-7de0-485e-bb2c-6d00d4e1978f,Machine Learning & AI,Model Inference & Serving,Batch & Online Inference,"Implement a Python CLI tool that loads a TorchScript-exported object detection model and processes images in adjustable batches from a given directory, applying non-max suppression to produce bounding box predictions. Generate a COCO-formatted predictions JSON and a metrics.json detailing average per-image latency and peak GPU memory utilization.",,
1e745a23-7f68-4658-b006-f18b28d2d1d8,Machine Learning & AI,Model Inference & Serving,Batch & Online Inference,"Create a Python CLI that loads a quantized ONNX transformer for sentiment analysis, processes text files in batch from /app/data/texts/ to emit a CSV of id, score, and label with GPU/CPU timing and memory logs, and supports an interactive REPL mode for single-sentence inference mixing CPU fallback.",,
c28e5380-fb60-47c1-b860-5f6a794946b1,Machine Learning & AI,Model Inference & Serving,Batch & Online Inference,"Build a CPU-only FastAPI inference service that loads a scikit-learn model from /app/model.pkl, performs dynamic batching by aggregating requests for up to 50 ms before a single model call, and hot-reloads the model when the file changes without dropping in-flight requests. Provide a batch_infer.py CLI that reads /app/input.csv, runs identical pre/post-processing for batched predictions, and writes results to /app/preds.csv including a model_version column.",,
1336ef8d-0374-4c96-9c18-51b70483d814,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Create a Dockerized FastAPI endpoint hosting a provided PyTorch sentiment-analysis model, measure baseline P95 latency and throughput under simulated concurrent requests (load config given), then apply ONNX dynamic quantization, server worker tuning, and request-level caching to achieve ≥2× throughput or reduce P95 by 50%. Save detailed profiling metrics (latency percentiles, throughput, CPU/GPU utilization) for both baseline and optimized setups in results.json following the provided schema for automated verification.",,
cb379f6a-c2ac-4aec-8418-ff6dcbbe74cf,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Export a pre-trained PyTorch vision transformer to TorchScript and ONNX, apply dynamic quantization, and integrate it into a FastAPI server supporting asynchronous batch requests. Profile the service’s latency and throughput under various batch sizes and thread configurations, and implement an automated tuning script to meet specified performance targets.",,
339dc3f9-b73a-440f-9bfe-36d009221b8c,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Build a CPU-only FastAPI service that serves a DistilBERT sentiment classifier via ONNX Runtime, then add three optimizations: static INT8 quantization with calibration, adaptive micro-batching (max batch 16, 10ms timeout), and an LRU cache of tokenized inputs keyed by content hash. Provide a benchmark script that drives concurrent requests and outputs a JSON report comparing p50/p95 latency and throughput before vs after, with a required ≥1.5× throughput and ≥25% p95 latency improvement to pass.",,
d350e2dc-3f14-415f-9d10-53e9cd88a180,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,Build a CPU-only FastAPI inference server for a torchvision ResNet-18 and implement a background queue that performs dynamic micro-batching (coalesce requests for up to 16 images or 10 ms) with a single forward pass using a TorchScript-compiled model and tuned num_threads. Provide a CLI load generator to compare baseline (no batching) versus micro-batched serving and write p50/p95 latency and requests/sec to /app/results.json.,,
4d0e0cae-0f5f-466b-8c7f-555fb77528af,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Containerize a FastAPI inference service for a small Transformer text classifier that implements a background request queue with dynamic micro-batching and an LRU tokenizer cache, and provide an ONNX Runtime int8-quantized variant. Use a load generator to measure QPS and p50/p95 latencies for fp32, int8, and 'int8+batching+cache' modes, writing a comparison summary to /app/bench.json.",,
d9c06643-8ff6-4bf2-826c-c973377a5646,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Build an async Python inference server for a small Hugging Face Transformer that adds micro-batching (time-windowed), dynamic int8 quantization, and a tokenizer cache. Provide a replay benchmark that outputs baseline vs optimized p50/p95 latency and throughput to a JSON report.",,
4f24d349-65e9-4cb9-a521-5c5ad09508cf,Machine Learning & AI,Model Inference & Serving,Latency & Throughput Optimization,"Create a CPU-only FastAPI inference server for a pretrained DistilBERT classifier that implements time-windowed dynamic batching, int8 dynamic quantization of Linear layers, and a content-hash response cache; include a short warm-up and pad inputs to multiples of 8 tokens. Supply a load generator that compares baseline vs optimized builds and outputs p50/p95 latency and throughput, with tests requiring at least 1.5x throughput improvement without violating a p95 latency SLA.",,
f6a65932-bdfa-4b85-a8cc-e31de3f46bd5,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Implement a CLI tool that converts a scikit-learn preprocessing and classification Pipeline (e.g., ColumnTransformer + RandomForest) to ONNX with dynamic batch dimensions, then runs ONNX Runtime inference on a test CSV and validates prediction parity (absolute difference ≤1e-6). The script must output model.onnx and a JSON report containing inference metrics and parity checks.",,
20836b84-4c31-4cdd-acef-64ec22def167,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Create a Python CLI that loads a trained PyTorch multimodal image-text model, exports it to both scripted and traced TorchScript as well as ONNX with dynamic axes for batch and sequence lengths, then validates output consistency within a specified tolerance on sample inputs and reports file sizes and inference latencies.",,
a794bc5c-52f7-4c41-bff6-fb522c9ac6cc,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Export a PyTorch sequence model to both TorchScript (scripted) and ONNX with dynamic axes and opset 17, saving weights in safetensors with strictly pickle-free serialization. Provide a CLI that loads the exported artifacts on CPU, runs onnxruntime and TorchScript inference on the same inputs, and asserts numerical parity within a tight tolerance.",,
b864608e-13d2-4708-b59d-43f6a6405630,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Implement a CLI that builds a variable-length batched BiLSTM tagger in PyTorch using PackedSequence, exports it to TorchScript and ONNX (opset 17) with dynamic batch and sequence length, and provides an ONNX-compatible unpacking path. Validate numerical parity across eager PyTorch, TorchScript, and ONNX Runtime on randomized inputs, saving all artifacts and a sample input under /app/export.",,
857ddd86-9828-43b3-9f1e-a19a8e80c7f0,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,Export a Hugging Face MarianMT translation model to ONNX with dynamic batch and sequence-length axes. Implement a Python CLI using onnxruntime to translate sample sentences and verify outputs match the PyTorch baseline within a specified tolerance.,,
cd5f1ac0-fb2e-4fcb-9f66-412c6f71c86a,Machine Learning & AI,Model Inference & Serving,Model Export & Serialization,"Export a scikit-learn Pipeline that includes a custom categorical encoder and a RandomForest model to ONNX by implementing a custom converter and shape calculator, then verify output parity against the original pipeline with onnxruntime on a mixed-type dataset. Save the portable ONNX and a small parity report summarizing numerical differences and opset/ir metadata.",,
fd48d907-fe4d-41aa-88af-31513dab7719,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Implement a FastAPI-based Docker microservice that hosts two versions of a fine-tuned Hugging Face BERT model for sentiment analysis, supports runtime model version selection via an HTTP header, and performs asynchronous batched inference. Include Prometheus-compatible endpoints for request metrics, latency breakdowns, and model load times, plus a CLI for health checks and graceful hot-reloading of models without downtime.",,
2d05c44c-06bc-44af-a5a3-ed77727174d3,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Deploy a FastAPI microservice that serves a small ONNX sentiment classifier via ONNX Runtime with async micro-batching (max batch size and wait time), concurrency-safe tokenization, and pydantic request validation. Provide Dockerfile and startup scripts, expose /predict, /healthz, and /metrics (Prometheus) endpoints, and implement a zero-downtime hot-swap endpoint that atomically loads and switches to a new model file.",,
b177f1f7-5293-49fa-8a4a-ac9d694b6fb1,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Package a CPU-only ResNet18 into a TorchServe .mar with a custom handler that performs torchvision preprocessing and returns top-5 class probabilities as JSON. Launch TorchServe on 0.0.0.0:8080, register the model, support both single and batched image requests at /predictions/resnet18 with proper 400 errors for invalid inputs, and expose /ping and Prometheus /metrics for health and monitoring.",,
955019b3-f7cd-4c80-84dd-ed39cae77562,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Package a pre-trained PyTorch ResNet18 into a TorchServe .mar with a custom handler that accepts base64-encoded images, applies preprocessing, and returns top-3 labels with probabilities. Launch TorchServe with dynamic batching (e.g., max_batch_size=8), register the model via the management API, issue batched requests, and write a latency/throughput summary to /app/serve_metrics.json.",,
246a9b2e-757b-4b05-8425-3fbd010e8d7d,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Implement a Python gRPC inference server that loads a CPU-only ONNX Runtime model and performs dynamic micro-batching (bounded by batch size and a 50 ms queue window), exposing the gRPC health checking service and a Prometheus /metrics endpoint. Provide a CLI load generator to issue concurrent requests and write a JSON report comparing latency/QPS in batched vs unbatched modes to /app/bench.json.",,
0e41513a-caeb-47da-8165-f41701c78506,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Deploy a quantized BART summarization model as a Dockerized FastAPI microservice that supports both REST and gRPC endpoints, asynchronous dynamic batching, JWT-authenticated requests, and emits Prometheus-compatible latency and throughput metrics. Provide a CLI tool to manage the server lifecycle (start, stop, reload) and include an example client script for end-to-end testing.",,
cfa43219-1a9f-40cc-b32e-c5eb575ae6b8,Machine Learning & AI,Model Inference & Serving,Serving & Deployment,"Implement a FastAPI-based microservice that loads both a TensorFlow Object Detection API model and a PyTorch segmentation model, dynamically routes requests based on a JSON flag, and falls back to CPU-only inference when GPU is unavailable. Include asynchronous request batching with configurable batch size and timeout, expose Prometheus-compatible metrics at /metrics, and provide a Typer CLI for bulk image scoring reusing the same service logic.",,
84469d46-a34c-48d3-8548-eaeef88a9eb2,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Fine-tune a GPT-Neo 2.7B model using PEFT’s LoRA adapters on a legal contracts summarization dataset, with configurable adapter rank, learning rate, and batch size via CLI. After training, quantize the adapter weights to 8-bit and package the model for efficient inference, reporting ROUGE scores on a held-out test set.",,
bfce7f82-557a-40b0-a69b-98d3f57a4a43,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Fine-tune a pretrained sentence-transformer (e.g., sentence-transformers/all-MiniLM-L6-v2) on provided positive/negative sentence pairs with a contrastive cosine-similarity loss to adapt it for semantic search. Provide a CPU-only CLI that trains, saves the fine-tuned encoder, and reports MRR@10 and Recall@10 on a held-out query set using exact cosine similarity over corpus embeddings.",,
defb78db-061d-467c-9685-1fa72d8f649d,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Fine-tune T5-small with parameter-efficient prefix tuning to translate English task descriptions into Bash one-liners on a provided dataset; evaluate exact match and BLEU on a held-out split, and save both the prefix adapter and a merged model plus predictions.json to /app.",,
8d4f7a93-4604-40f5-aef6-04d92d051a9e,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Implement parameter-efficient fine-tuning by inserting lightweight adapter modules into a pretrained DistilBERT for domain text classification, training only adapters with discriminative layer-wise learning rates and a slanted triangular schedule. Provide a CLI to train/evaluate, export adapter-only weights, verify the frozen base model hash is unchanged, and support hot-swapping different adapter checkpoints at inference.",,
788a5a1b-314f-470c-8fed-eb681c37e757,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,"Fine-tune a pretrained OpenAI CLIP model with lightweight adapter modules on a custom 10-class image dataset for zero-shot classification, providing a deterministic CLI that handles data preprocessing, adapter training with a frozen backbone, and outputs top-1/5 accuracy and confusion matrix metrics on held-out labels.",,
d9ce3928-db01-4044-a894-8f004f598a55,Machine Learning & AI,Model Training & Optimization,Fine-Tuning Pretrained Models,Implement a Python CLI to fine-tune a pretrained BART transformer on a dataset of long policy documents for abstractive summarization using mixed-precision training and early stopping; log metrics to Weights & Biases. Export the final model as a quantized ONNX file and evaluate using ROUGE scores on a held-out test set.,,
039571e4-dfab-4ccd-b130-f526007c0c9c,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Create a reproducible, multi-objective Optuna study that tunes a CPU-only PyTorch tabular classifier (layers, width, dropout, learning rate, weight decay, batch size) to simultaneously maximize ROC-AUC and minimize measured inference latency using ASHA pruning within a fixed time budget. Persist the study to a local SQLite DB, export the Pareto-optimal trials to /app/pareto.json, and save the fastest model meeting a target AUC threshold to /app/best_model.",,
1b438d12-7b47-4141-a4e8-ecd836b0599e,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Build an end-to-end Optuna pipeline using its NSGA-II sampler to tune AdamW weight decay, learning rate, and warmup ratio for fine-tuning BERT on SST-2, jointly optimizing validation accuracy and GPU training time under a fixed memory cap. Record the nondominated trials as a pareto_front.json with top hyperparameter sets and their two objectives.",,
d59b9aab-6dd6-4f2a-a4e1-68fa8904e722,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Implement a CLI pipeline that uses Optuna to perform multi-objective hyperparameter optimization of a given PyTorch model, balancing classification accuracy and inference latency on the provided dataset. The tool must support multi-fidelity pruning, cache trials for reproducibility, and export the Pareto front configurations as JSON.",,
38f9769c-54a5-4abd-9cd6-084ce00cfc51,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Build a CLI that performs multi-objective hyperparameter optimization with Optuna for a PyTorch CNN on Fashion-MNIST, maximizing validation accuracy while minimizing wall-clock time via ASHA pruning and a SQLite-backed study that can be resumed. After the search, pick the Pareto-optimal trial under a 30s time budget, deterministically retrain on the full training set, and export best_config.json, study.db, metrics.json, and best_model.pt.",,
c52f37f6-f681-455d-8904-8cd2f8ef403d,Machine Learning & AI,Model Training & Optimization,Hyperparameter Optimization,"Build a reproducible Optuna-powered multi-fidelity search (ASHA pruner) that tunes learning rate, weight decay, batch size, and transformer depth for a small text classifier on a provided CSV, persisting the study to SQLite. After the search, retrain the best trial and export the final model along with a Pareto front that balances validation accuracy against measured inference latency.",,
d56d132b-0cbc-4654-9318-2144ada5d39b,Machine Learning & AI,Model Training & Optimization,Resource Management & Parallel Training,"Create a Dockerized PyTorch pipeline-parallel training script that splits a ResNet-50 into two stages across two GPUs, uses torch.distributed RPC for microbatch scheduling and gradient checkpointing, handles automatic rollover to CPU memory when a GPU runs out of space, and logs per-step throughput, GPU utilization, and peak memory usage.",,
44344258-22bc-4e7c-99e3-1462b74f7f69,Machine Learning & AI,Model Training & Optimization,Resource Management & Parallel Training,"Implement a PyTorch DistributedDataParallel script that auto-detects available CPUs and multiple GPUs, spawns per-device processes, and trains a simple CNN with synchronized gradient reduction. The script should dynamically adjust per-GPU batch sizes based on free memory and log device-specific GPU utilization, memory usage, and per-epoch training throughput to a CSV file.",,
dcff2fc0-b4ae-4b12-9bba-bea765ff73d6,Machine Learning & AI,Model Training & Optimization,Supervised & Unsupervised Learning,"Train a sparse autoencoder in PyTorch on a numeric tabular dataset with early stopping and L1 activation regularization, saving the encoder to /app/encoder.pt. Freeze the encoder to generate embeddings and train a scikit-learn logistic regression on labels, reporting stratified 5-fold ROC-AUC and writing metrics and artifact paths to /app/results.json.",,
bc3559e5-94a6-4098-acc5-0be5a32cee24,Machine Learning & AI,Model Training & Optimization,Training Loop Implementation,"Implement a PyTorch training loop for a CNN on CIFAR-10 with gradient norm clipping, a one‐cycle learning rate scheduler, and early stopping. The script must checkpoint the best model, log training and validation metrics to JSON, and resume correctly from the latest checkpoint.",,
03f02971-558b-42ff-8db5-fa4961114657,Machine Learning & AI,Model Training & Optimization,Training Loop Implementation,"Implement a PyTorch training loop for a tiny character-level language model on a given corpus with truncated BPTT, gradient accumulation, global-norm gradient clipping, and early stopping on validation loss. Support rotating checkpoints (keep N), exact resume of optimizer/scheduler and RNG state after interruption, and deterministic results when a seed is provided.",,
2d4ffad4-aa8a-4b4b-9885-e54b8c0bc7dc,Machine Learning & AI,Model Training & Optimization,Training Loop Implementation,"Implement a PyTorch federated averaging training loop that simulates multiple clients each performing local training with gradient clipping and optional momentum, aggregates weights via FedAvg with dynamic client sampling per round, and supports checkpointing and resume functionality. Include early stopping based on global validation metrics and detailed per-round TensorBoard logging.",,
8c1dddab-7f75-4dc9-a24a-51059d2ed48f,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Custom Environment Setup & Curriculum Policy Training,"Implement and register a custom OpenAI Gym environment simulating a 2D robotic pick-and-place task with randomized object positions, sparse success rewards, and failure conditions. Then train a PPO agent via stable-baselines3 through a three-phase curriculum, logging per-episode returns, success rates, and training checkpoints to metrics.json.",,
2826f686-e7d8-45be-860f-3ffc81252e18,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Create a Dockerized Gym environment wrapper that applies domain randomization to CartPole’s physics parameters (mass, length, gravity), configure and train a Soft Actor-Critic agent using stable-baselines3 with a linear learning-rate schedule and TensorBoard logging, then export the saved policy. Validate the policy over 10 unseen physics seeds to achieve an average return ≥195.",,
68f9e62d-1d50-4979-9221-4d0ceb7a209f,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Create and register a custom Gymnasium environment 'ThermalControl-v0' whose dynamics (heat capacity, loss rate, actuator limits, and disturbance sequence) are loaded from /app/dynamics.yaml, and train a Soft Actor-Critic agent with stable-baselines3 (automatic entropy tuning) to keep temperature within a target band via domain-randomized episodes. Save the trained policy to /app/checkpoints and a 100-episode seeded evaluation log (time, state, action, reward) to /app/eval.csv for automated verification.",,
e82e442a-f53d-453b-b1ab-86068e4e6732,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Implement a custom OpenAI Gym multi-asset trading environment using /app/data/price_history.csv, with portfolio and risk-adjusted reward shaping. Configure RLlib to train a PPO agent for 200k timesteps, output training logs, Sharpe ratio and cumulative returns in metrics.json, and save the final policy checkpoint.",,
6062f9bc-1a32-4539-ab64-bb6ab2b97285,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Install Ray RLlib with PettingZoo and SuperSuit, configure the MPE simple_spread_v3 multi-agent environment, and train a shared-parameter PPO policy using vectorized parallel environments. Export the trained policy to TorchScript and run a seeded evaluation that writes per-agent rewards and coverage metrics to /app/mpe_eval.json.",,
482ec49a-8032-4f97-a0ea-d06c224a1cf4,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Environment Setup & Policy Training,"Create a Dockerized custom OpenAI Gym environment simulating a 2D gridworld with dynamic obstacles and moving goals, register it via gym.make(), and automate training a PPO agent with curriculum learning and reward shaping. Provide a deterministic CLI that seeds all randomness, launches training, logs TensorBoard metrics, saves the final policy, and runs evaluation episodes with aggregated performance output.",,
3412324f-afdd-4e3c-a6ec-545bae3d878a,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a Python CLI tool at /app/train_connect4.py that sets up an OpenAI Gym Connect Four environment for two DQN agents to learn via self-play with an epsilon-greedy schedule, periodically evaluating head-to-head performance. The script must save the best agent model as /app/models/best_agent.pt, record win rates over 100-episode evaluation windows in /app/metrics.json, and output a final payoff_matrix.csv documenting win/draw counts.",,
3b50270a-f515-4802-b6bd-8f49b952abe3,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a self-play training pipeline using the PettingZoo ‘simple_tag’ pursuit-evasion environment with PPO from stable-baselines3, periodically swapping chaser and evader policies. Log episodic team rewards, role-switch events, and save agent checkpoints once cooperative performance exceeds a threshold, then evaluate against random baselines and output metrics.json with per-agent and joint reward statistics.",,
908ba69b-2e25-46e5-81f4-a1cad26cdbad,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Train a near-Nash strategy for Kuhn Poker via self-play Counterfactual Regret Minimization (CFR/CFR+) using OpenSpiel (pyspiel), then serialize the average policy and compute exploitability. Produce a policy artifact and a metrics report demonstrating exploitability below a specified threshold.",,
ada92c7c-5d37-4f64-8724-ec6138a568d1,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,Implement from-scratch CFR+ self-play for Kuhn Poker with a CLI to train for N iterations and compute exploitability via an exact best response. Save the average strategy to /app/kuhn_policy.json and ensure the final policy’s exploitability is ≤0.05 chips.,,
e4de7787-4b00-4ab3-a58e-2e3f9ed14bcb,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a self-play Counterfactual Regret Minimization trainer for Kuhn Poker with a minimal game engine including chance nodes, information-set caching, and average-strategy export. The script should train to a low-exploitability policy verified by a best-response evaluator, be reproducible via seeding, and finish on CPU within tight time limits.",,
92ff6d83-aa4e-46c8-a359-9ea7cc5e04db,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Implement a Dockerized Python CLI project that defines a custom grid-world predator-prey environment for two agents, configures self-play with Stable Baselines3’s PPO including curriculum difficulty scaling and periodic opponent parameter swapping, and supports automatic checkpointing. After training, run 200 headless evaluation episodes and produce a JSON report with win rates, average episode length, and policy entropy.",,
5abd49cf-e743-422e-9d64-ffc0c3945d58,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Multi-Agent & Self-Play Training,"Create a gridworld capture-the-flag environment using PettingZoo, train two competing agent teams via Stable Baselines3 PPO in self-play with parameter sharing, log episodic win rates and cooperation metrics, and export the best team policies and training curves.",,
bc7ef49f-3e4e-4df4-a9ce-5f765d77d9b6,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"In a 2D gridworld with a key, a locked door, and a fragile vase, implement and compare three rewards: sparse goal-only, potential-based shaping with step penalty, and a side-effect avoidance term that penalizes action impact relative to an inaction baseline using object-position L1 distance. Train a fixed PPO agent under each reward, detect reward hacking like key pick/drop loops, and produce a summary of goal success, vase collisions, loop frequency, and sample efficiency.",,
42542e5b-3910-49d1-8d17-6b843192891f,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Augment Gymnasium’s LunarLander-v2 with a configurable multi-objective reward balancing landing accuracy, fuel efficiency, and leg-contact stability, then sweep at least 32 coefficient sets where each trains a lightweight PPO agent for a fixed budget. Compute and save the Pareto frontier and knee-point selection with CSV/plots of episodic return, crash rate, and fuel use to verify the chosen reward balances competing objectives.",,
4fc46959-8f65-49e1-a8fa-271dec78720d,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Implement a custom Gymnasium GridWorld with a sparse goal reward, time penalty, and stochastic hazard tiles, then compare two rewards: potential-based shaping via Manhattan-distance potential and a naive per-step progress bonus. Train PPO under both and report success rate, hazard contacts, and path optimality gap to highlight shaping invariance vs reward hacking.",,
7ce72b3e-9f64-424f-8067-bb665f1dc459,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Design and implement a multi-objective reward function in a custom gym-based logistics simulation that balances delivery time, fuel consumption, and fairness among multiple agents, and evaluate trade-offs by plotting Pareto frontiers of performance metrics across varying weight configurations.",,
fddab346-f2c4-49e6-9ac6-1e22bfc87919,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Design and evaluate multi-objective rewards for Gymnasium’s Taxi-v3 by augmenting the sparse reward with penalties for illegal pickup/dropoff and a discomfort cost proportional to action changes, implementing both scalarized (lambda-weighted) and Lagrangian-constrained formulations. Train a tabular Q-learning agent across a sweep of coefficients and report the Pareto frontier between episode length and discomfort with a baseline comparison to the original sparse reward.",,
28b77aa4-22c5-4792-86d7-e66df1b721ad,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"In a simulated warehouse navigation environment, design and implement reward functions that balance path efficiency, collision avoidance, and battery consumption; then evaluate how different reward weightings affect the agent’s learning speed, policy robustness, and trade-offs among objectives.",,
5ff21f55-e252-40ff-9c7e-98dcc47b4516,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Reward Design & Evaluation,"Implement and compare multiple reward functions combining extrinsic goal completion with intrinsic curiosity bonuses in a procedurally generated maze environment, training an OpenAI Gym agent under various reward-weight schedules. Automate runs for each schedule, collect path efficiency and state coverage metrics, and output a Pareto-front analysis in JSON.",,
acc236c8-85b5-43ad-abe8-6aa81f926374,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a Python CLI that collects rollouts from the OpenAI Gym CartPole-v1 environment into a disk-backed prioritized experience replay buffer using a SumTree, supports proportional priority updates and both uniform and prioritized minibatch sampling, and writes buffer statistics and sampled indices to JSON files.",,
abd711d4-0eb1-4e41-897f-8ebcc789b12d,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a goal-conditioned 2D grid environment and generate large-scale rollouts to an on-disk replay buffer supporting Hindsight Experience Replay, n-step returns, and prioritized sampling with importance weights. Train a lightweight DQN for several thousand updates from this buffer and output success-rate curves and sampling diagnostics derived from the stored trajectories.",,
47ac2a0d-24bd-45ed-95e6-6f6a198df1f3,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a multiprocessing rollout + learner system that generates goal-conditioned episodes and stores them in a segment-tree prioritized replay buffer with n-step returns and on-the-fly Hindsight Experience Replay relabeling. The buffer must support batched append/sample/update with importance-sampling weights, be mmap-backed to handle 10M+ transitions, and a training script should reach a target success rate while validating sampling distribution and bias correction.",,
10862da4-27c2-4b86-9fd5-8dd2a1478b3d,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a memory-mapped, Zarr-backed replay buffer for Gymnasium Dict/Box spaces with prioritized experience replay, n-step returns, and sequence sampling for RNN policies (burn-in, overlap, zero-padding). Provide a CLI to run vectorized rollouts to populate the store, then deterministically sample batches under a fixed seed and output a JSON report verifying priority distributions, importance-sampling weights, and crash-safe resume behavior.",,
76538d90-c15e-4027-a196-bfb0b5703959,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a Python CLI that executes OpenAI Gym rollouts using both random and heuristic policies to collect n-step trajectories stored in a prioritized replay buffer with proportional and rank-based sampling via segment trees. Include commands to generate trajectories, sample mini-batches as Torch tensors, purge stale experiences, and log buffer statistics (priority distribution, average returns) to JSON.",,
aba66aee-ba00-4791-9b3f-42c88721be78,Machine Learning & AI,Reinforcement Learning & Simulation-Based Training,Simulation Rollouts & Replay Buffers,"Implement a disk-backed prioritized replay buffer daemon that ingests CartPole-v1 transitions from multiple local producer scripts over TCP, computes n-step returns across episode boundaries, and persists state for crash-safe restart. Provide a client to sample mini-batches with PER (alpha/beta) and importance weights, with a test harness that verifies sampling distribution, deterministic checksums for sampled batches, and replay continuity after restart.",,
9e2fb891-354d-420b-a689-cc40b0097aea,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Create a Python pipeline that uses TextAttack to craft adversarial text examples against a BERT sentiment classifier under semantic and grammatical constraints, logs attack success rates and similarity metrics, then fine-tunes the model on the adversarial examples and outputs pre- and post-defense robustness reports in JSON.",,
61bc22bb-461b-46db-88ca-602960cc80d4,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Train a small CNN on MNIST (CPU) and implement FGSM and PGD-Linf attacks. Add a feature-squeezing detector (bit-depth reduction + median smoothing) and an adversarially trained variant, then report clean/robust accuracy at eps=0.3 and ROC-AUC for detection, saving metrics and checkpoints.",,
cde85dee-1de4-49ad-8a26-7cc359dc2db0,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Implement a CPU-only Python CLI that loads a provided CIFAR-10 model, wraps it with a non-differentiable defense (bit-depth reduction plus randomized resizing), and evaluates robust accuracy under FGSM, PGD, and BPDA+EOT-PGD. Save per-attack metrics to /app/robust_metrics.json and 32 adversarial samples per attack to /app/adv/{attack}/, demonstrating that BPDA+EOT meaningfully reduces reported robustness compared to naive PGD.",,
943ac041-04a1-4110-a8aa-ed1db97bf7c3,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Create a CLI pipeline that attacks a pretrained image classifier with EOT-PGD over random crops, rotations, and Gaussian noise, then reports robust accuracy and worst-case loss. Implement a defense via randomized smoothing with calibrated sigma to compute per-sample certified radii and write a CSV summarizing clean/robust accuracy and certificates for a test subset.",,
503551a7-7be4-4144-8a11-abea2c2a904e,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Implement a CLI to load a pretrained CIFAR-10 classifier and generate FGSM, PGD, and CW adversarial examples at user-specified perturbation levels. Then apply adversarial training and randomized smoothing defenses to compute robust accuracy curves, per-sample certified radii, and save artifacts and plots in a reproducible format.",,
fec512ab-5691-404c-a919-0c4c5244f990,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Implement a randomized smoothing defense by wrapping a pretrained PyTorch CIFAR-10 classifier to produce certifiably robust predictions under Gaussian noise, computing per-sample certified radii and robust accuracy at multiple thresholds, and saving both detailed certificates and an aggregate JSON report.",,
eb323c8a-6ddd-4950-b036-ef7854f696dd,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,Implement a randomized smoothing defense wrapping a pretrained CIFAR-10 ResNet18 with configurable Gaussian noise to certify predictions under L2 adversarial budgets. The CLI must also generate PGD adversarial examples to measure empirical robustness and write certified and empirical accuracy metrics to results.json.,,
fa54768d-53c4-4b06-8861-0c7fc96cf184,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Implement a randomized smoothing certification pipeline that wraps a pretrained CIFAR-10 PyTorch classifier to compute and report per-sample L2 robustness radii and average certified accuracy, saving results to cert_results.json and radii.csv with specified schema.",,
67100375-6784-4304-add2-1bda8f310b88,Machine Learning & AI,Responsible AI & Model Robustness,Adversarial Robustness & Defense,"Train a small CNN on MNIST, implement FGSM and multi-step PGD (with Expectation-over-Transformation for stochastic defenses) to craft adversarial examples at multiple L∞ epsilons, and report clean/robust accuracies with saved adversarial image grids. Add PGD adversarial training and a randomized smoothing inference defense, then re-evaluate and output a JSON metrics report plus a file of estimated certified radii for 100 test samples.",,
c68bd706-7925-4128-b595-c08285175ee4,Machine Learning & AI,Responsible AI & Model Robustness,Bias Detection & Mitigation,"Implement a Dockerized Python CLI that audits classification bias on a dataset with protected attributes by computing demographic parity, equalized odds, and disparate impact metrics, outputs JSON reports and plots, then applies a reweighing-based preprocessing to retrain a fair logistic regression and produces updated metrics and model artifacts.",,
f4200f4a-2697-49f7-924c-2481958d8981,Machine Learning & AI,Responsible AI & Model Robustness,Bias Detection & Mitigation,"Implement in PyTorch an adversarial debiasing pipeline using a gradient reversal layer to train a neural classifier that removes sensitive attribute information from learned representations on a tabular dataset. Compute and save pre- and post-debiasing fairness metrics (such as demographic parity, equal opportunity difference, and disparate impact) along with classification performance to /app/metrics.json.",,
29648b82-9dde-4906-8c3d-6913bff7e075,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Build a CLI pipeline that scans a raw text corpus, detects PII (emails, phones, names, addresses) via regex+NER, applies consistent pseudonymization, and produces both a redacted dataset and a provenance ledger with SHA-256 hashes, source URLs, and SPDX license IDs. Then evaluate a fine-tuned text generation model for privacy compliance by running canary extraction and membership inference tests, emitting a JSON report of leakage metrics and pass/fail flags against given thresholds.",,
97dc219e-c094-4084-a095-7258006b7c57,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Create a Python CLI tool that scans a JSONL dataset of customer interactions, automatically detects and redacts PII (names, locations, phone numbers, and email addresses) using regex patterns and a spaCy NER model, and outputs a sanitized dataset plus a compliance report summarizing redaction counts by type. Ensure the tool logs any records with missed or ambiguous redactions, maintains an audit trail, and exits with a non-zero code if validation checks fail.",,
4057a216-3879-4431-89e8-2809d458b1f3,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Implement a Python CLI that scans an input CSV with free-text fields, detects PII using regex patterns and spaCy NER, redacts each entity with a type-specific placeholder, and writes the sanitized CSV. Generate a JSON compliance report detailing counts per PII category and exemplar redacted snippets for audit.",,
234421b3-850f-460f-8191-44cf96c3bdf7,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Build a Python CLI that scans /app/data/{train,test} and /app/logs/inference.log for PII (names via a bundled dictionary, emails, phones, IPs, street addresses, government IDs) and validates that each record has provenance in /app/metadata.jsonl with a source, timestamp, and SPDX license from an allowed list. Automatically redact violations, emit a tamper-evident audit to /app/compliance_report.json with SHA-256 hashes and a redaction map, and exit non-zero if any unredacted PII or disallowed licenses remain.",,
df43241a-62ee-44fa-9a9c-356ca44134a3,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Build a streaming Python CLI that ingests a large CSV of free-text training data plus a whitelist of permitted licenses, detects and redacts PII (names, emails, phone numbers, addresses, SSNs) via regex and spaCy NER, and validates each row’s provenance against a provided source-to-license map. Output a JSONL compliance report with SHA-256 hashes of raw and redacted text, per-row PII categories found/redacted, license verdicts, and exit non-zero if any violation exceeds configured thresholds.",,
8e5b43e6-42ad-48fe-814e-12358747ee12,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Create a terminal CLI that validates a dataset’s licensing and provenance for model training by parsing per-file metadata and SPDX identifiers, verifying cryptographic hashes against a manifest, and checking compatibility with a specified usage policy (e.g., commercial use). The tool should emit a machine-readable compliance report and a symlinked approved/ subset, failing with clear diagnostics for missing, incompatible, or conflicting licenses.",,
b157750b-e7d5-47ff-a4f9-09a87f0f54e6,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Build a CLI that audits a JSONL training dataset and a local text-generation model for policy compliance by verifying data provenance (required source_url and license in an allowed whitelist) and detecting/redacting PII (emails, phones, addresses, SSNs) with deterministic hashing. Run a fixed red-teaming prompt suite against the model to flag PII leakage and disallowed content, then emit a compliance_report.json with per-rule counts, sample snippets, thresholds, overall pass/fail, and a sanitized_data.jsonl output.",,
d825ac2d-0f53-40b0-8426-84ece5e78816,Machine Learning & AI,Responsible AI & Model Robustness,Ethical & Policy Compliance Validation,"Implement a Python CLI that scans /app/data/text_corpus.jsonl to detect and redact PII (emails, SSNs, phone numbers) using a combination of regex and named‐entity recognition. The tool must output a sanitized.jsonl and a compliance_report.json summarizing PII counts by type, redaction recall/precision, and ensure ≥99% recall on a held‐out validation sample.",,
41bea51e-f8d6-4967-8200-f5e1bd452e75,Machine Learning & AI,Responsible AI & Model Robustness,Explainability & Interpretability,"Implement a CLI that explains predictions of a pretrained HuggingFace sentiment model on a text file using both SHAP and LIME, repeating each method over multiple random seeds to quantify stability (Kendall tau of token-importance ranks and top-k Jaccard overlap). Write a JSON summary of stability metrics, a CSV of per-example attributions, and HTML token heatmaps for the most unstable cases.",,
d661ebec-cb76-4fe1-981c-b207e1b5bea9,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Build a Python CLI that ingests a theoretical CMB angular power spectrum (Cl) file, uses healpy.synfast to generate a full-sky synthetic CMB map, then computes its angular power spectrum via healpy.anafast, compares it to the input Cl, and writes out the map as a FITS file plus a JSON summary of residuals and basic statistical diagnostics.",,
43c4cd09-dbd5-469e-9f0f-82e0f3a9252a,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Implement a Python CLI that constructs a Barnes–Hut octree for 3D gravitational N-body simulations and integrates positions and velocities using a symplectic leapfrog scheme with adaptive time-stepping. Validate energy and momentum conservation, compute radial density profiles at specified intervals, output periodic CSV snapshots of particle states, and write a summary JSON of diagnostics.",,
39e224b5-1b0a-42bf-8ca2-c79aa9cfd2a9,Scientific Computing & Analysis,Domain-Specific Computation,Astronomy & Astrophysics Computation,"Create a terminal tool that reads UVFITS visibility data, performs convolutional gridding and FFT to generate a dirty image and point-spread function. Implement the Hogbom CLEAN algorithm to deconvolve and restore the sky brightness, then output cleaned, residual, and model FITS images along with imaging quality metrics in JSON.",,
c5bf29fa-81c7-418a-8853-d7ed10f7fdbf,Scientific Computing & Analysis,Domain-Specific Computation,Climate & Environmental Modeling,"Build a CLI tool that reads CF-compliant NetCDF files of monthly precipitation and potential evapotranspiration, computes the 12-month SPEI per grid cell via log-logistic fitting with robust handling of missing values, and writes a CF-compliant NetCDF of SPEI. Additionally, produce a CSV time series of global land-area fraction in drought (SPEI <= -1) for each month.",,
246a5f56-456a-4a57-ba0e-35def7ad46c3,Scientific Computing & Analysis,Domain-Specific Computation,Climate & Environmental Modeling,"Implement a two-box global energy balance model (mixed-layer plus deep ocean) driven by a provided radiative forcing time series to simulate global-mean temperature and ocean heat uptake. Calibrate feedback, heat capacities, and exchange parameters against historical GMST and OHC data, then output ECS, TCR, fitted parameters, and scenario projections.",,
223f0174-2db9-4e71-8adb-cb10dfd69614,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Implement a Python CLI that reads an SBML model from /app/model.xml, parses the reaction network via libSBML, and performs multiple Gillespie algorithm stochastic simulations over a user-defined time. The tool should aggregate species concentration trajectories to compute mean and variance, output /app/trajectories.csv and /app/stats.json, and optionally generate time-course plots.",,
a35b8476-208e-4c1a-8b27-50d4edae7534,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Using COBRApy, load the provided SBML metabolic network, configure exchange reactions to model aerobic minimal media with glucose, and maximize biomass to compute the optimal growth rate. Then perform a single-gene deletion screen to identify essential genes under these conditions and write the growth rate and the sorted essential gene IDs to output files.",,
eb40ebe2-b02c-422b-8d82-a37215d97f08,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Create a Python CLI that reads a JSON list of SMILES, uses RDKit ETKDG and UFF to generate and optimize up to N 3D conformers per molecule, computes basic molecular descriptors (MW, logP, TPSA, rotatable bonds), clusters conformers via RMSD (e.g., Butina), and selects cluster centroids. Write per-molecule JSON with descriptors, cluster counts, and centroid SDF files under /app/output, plus a Markdown report summarizing the molecular library properties.",,
417e85ed-f421-42ac-9ac0-c05ed4ffbdb7,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Create a Python CLI tool that ingests a list of SMILES strings, generates and energy-minimizes 100 3D conformers per molecule using RDKit’s ETKDG and MMFF94 force field, then clusters them by RMSD with the Butina algorithm. Output a representative conformer for each cluster in /app/representatives.sdf and a JSON summary of cluster sizes, average energies, and RMSD distributions.",,
5aa02538-fa46-4301-8493-6a6b83700e9b,Scientific Computing & Analysis,Domain-Specific Computation,Computational Chemistry & Biology,"Create a Python CLI that loads a metabolic network SBML (/app/model.xml), builds the stoichiometric matrix, and performs flux balance analysis to maximize a specified biomass reaction using linear programming. Validate mass balance and bounds, identify exchange reactions, then write the optimal flux vector and dual shadow prices to CSV files.",,
e3b35e19-77c8-4b09-a35b-be76d2db0a68,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a CLI that solves the 1D compressible Euler equations for Sod’s shock tube using a finite volume scheme with Roe’s approximate Riemann solver and user-specified CFL number, grid resolution, and final time. It should output CSV files of density, velocity, and pressure profiles at defined timesteps and generate corresponding plots.",,
d71a8216-fb03-4b50-9160-dc75c61584b4,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,Implement an Euler–Bernoulli beam finite element solver for a uniform clamped–clamped beam that assembles mass and stiffness matrices and computes the first three natural frequencies and mode shapes. Validate the frequencies against closed-form solutions within 2% and save frequencies and mode shapes to specified output files.,,
fb120c18-e722-4ec8-96e3-d30c1df8f87d,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a 1D compressible Euler solver to simulate the Sod shock tube using a finite-volume Godunov scheme (e.g., HLLC) with CFL-controlled timestepping and positivity preservation. Output density, velocity, and pressure profiles at specified times and report L1 error against the analytic solution.",,
18e514df-89c5-40b6-aee1-71d048460056,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Build a 1D compressible gas dynamics solver for the Sod shock tube using a conservative finite-volume scheme (MUSCL-Hancock with HLLC flux and CFL control) from Riemann initial data, and write density/velocity/pressure profiles at specified times. Include a check that total mass and total energy are conserved to within a small tolerance.",,
5e54abf4-99ce-46da-bb2b-9b40373a6dcc,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a 1D finite-volume solver for the compressible Euler equations to simulate the Sod shock tube using an HLLC Riemann solver with a TVD slope limiter, exposing a CLI to set grid size and CFL and writing CSV profiles of density, velocity, and pressure at a target time. Validate conservation of mass/momentum/energy and achieve a small L1 error versus an exact Riemann solution computed by a provided routine.",,
43cdd1ef-dc03-4d55-b453-c678323396bc,Scientific Computing & Analysis,Domain-Specific Computation,Physics & Engineering Simulation,"Implement a Python CLI that solves the 2D shallow water equations on a rectangular grid with variable bathymetry using a finite-volume Godunov scheme with HLL flux and MUSCL reconstruction. The program reads initial conditions and simulation parameters from /app/config.json, applies reflective boundaries, integrates to a final time, and writes depth and velocity fields plus gauge time series to /app/output.",,
0cc13cbf-fb2f-47b8-a584-decac0a212b9,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Write a Python script that loads a sparse SPD matrix A from /app/A.mtx and a vector b from /app/b.npy, then solves Ax=b using preconditioned conjugate gradients with an incomplete factorization (ILU/IC) or Jacobi fallback. Save x to /app/x.npy and a JSON with iteration count, final relative residual, and wall time, ensuring ||A x − b||2 / ||b||2 ≤ 1e-8.",,
63faffeb-352c-46a6-bd8b-ecc8d340272c,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Implement a randomized low-rank SVD with oversampling and configurable power iterations to compute the top-k singular values and vectors for large dense or sparse matrices via a CLI, benchmarking accuracy and runtime against NumPy/SciPy baselines. Validate orthonormality of U and V and relative reconstruction error, writing standardized outputs to files.",,
3fb4234c-8624-4409-8940-dea6452f050e,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Implement a randomized SVD (Halko algorithm) with configurable rank, oversampling, and power iterations to compute a low-rank approximation of a large dense or sparse matrix loaded from disk. Compare to a deterministic truncated SVD by reporting singular values, relative Frobenius reconstruction errors, and timings in a results JSON, also saving the U,S,V factors.",,
469e0e7e-45d6-4f79-a97b-debf8117a8c1,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Implement a Python CLI that loads A, B, C from /app/*.npy and solves A X B = C for X using factorization-based linear solves without forming the Kronecker product (e.g., via LU/QR and column/row reshaping), with an option for Tikhonov regularization. Save X to /app/output/X.npy and a metrics JSON including relative residual (target ≤ 1e-8) and simple condition estimates.",,
e9a2077d-3ed5-4737-9237-ec0d833c31f4,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Matrix & Vector Operations,"Implement a Python CLI that loads a large sparse matrix from /app/matrix.npz and applies a randomized SVD algorithm with user-defined oversampling and power-iteration counts using only scipy.sparse and numpy operations. Output the top-k singular vectors and values as U.npy, S.npy, Vt.npy and record the spectral norm reconstruction error in /app/output.json.",,
34375d21-9384-4d75-8d6c-65b7a2521725,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement a Python tool that loads a parameterized ODE and scalar loss from a problem module, integrates forward to produce state samples at given eval_ts, then computes dL/dθ via a reverse-time continuous adjoint solve with accurate interpolation of the forward trajectory. Output the trajectory and gradient along with a verification report that checks the adjoint gradient against central finite differences within a specified tolerance.",,
815c9669-7a3f-4f45-a8cf-83d64eafc30f,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement a Python CLI that performs 1D integration using tanh-sinh (double-exponential) quadrature with adaptive node refinement and error control to handle endpoint singularities. Use it to evaluate the integral of x^(-1/2) * log(x) over [0, 1] to at least 12 correct digits and write both the result and the function-evaluation count to /app/answer.json.",,
cb547e33-f529-432e-bd5c-948f364a6393,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Create a Python CLI that generates Chebyshev nodes and differentiation matrices to solve second-order boundary–value ODEs under Dirichlet conditions using spectral collocation. The tool should also perform Clenshaw–Curtis quadrature for user-specified functions, outputting nodal solutions, quadrature results, and error estimates in JSON.",,
32a27c91-c704-4f67-b486-8f24b6e72b1e,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement a Python CLI that performs adaptive multi-dimensional integration over hypercubes using the Smolyak sparse grid method, providing hierarchical error estimates and supporting arbitrary user-supplied integrand functions. The tool should output the integral result, estimated error, and evaluation metrics in a structured JSON format.",,
d3c4e58f-477b-467f-b814-c9e2d11e7498,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Build a Python CLI that integrates systems of ODEs defined by a JSON spec using an adaptive Dormand–Prince 5(4) solver with dense output and event/root detection, automatically switching to an implicit BDF method when stiffness is detected via step-rejection heuristics. The tool should write solution snapshots and event times to files and include a test harness that verifies accuracy and performance against SciPy.integrate on provided nonstiff and stiff problems.",,
62241141-49ed-413c-bd15-76bdd6c3c3cf,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement an adaptive tanh-sinh (double-exponential) quadrature that handles endpoint singularities and infinite limits, returning integrals to specified absolute/relative tolerances while tracking function-evaluation counts. Provide a CLI that reads multiple integrals and intervals from input, computes results without external integration libraries, and writes both values and convergence traces.",,
ba551f4a-a736-4133-a1db-6f66041e5d5f,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Numerical Integration & Differentiation,"Implement an adaptive Gauss–Kronrod 21/10 quadrature with a best-first error priority queue that handles infinite limits and endpoint algebraic/log singularities via variable transformations, enforcing absolute/relative tolerances and a cap on function evaluations. The CLI loads an integrand from /app/integrand.py and a JSON spec of intervals and tolerances, then writes the integral, error estimate, and evaluation statistics to /app/output.json.",,
177488a5-0915-4565-9edd-8ba6fcae67cf,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Build a Jacobian-free Newton-Krylov solver with backtracking line search to find the steady state of the 2D Bratu (nonlinear Poisson) equation on an N×N grid. The CLI should accept N and lambda, converge to a specified residual tolerance using GMRES with simple preconditioning, and write the solution field and an iteration/residual log to disk.",,
6df9042b-4033-4c85-a1dd-bb9a1cc24d8d,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Create a Python CLI implementing the Aberth–Ehrlich method from scratch to simultaneously find all complex roots of a high-degree polynomial provided via JSON, writing the root estimates with residuals and convergence metrics to /app/roots.json and a Markdown summary report.",,
3e37a629-3502-42f2-baa6-4a2bcc7cfa05,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Implement a primal-dual interior-point solver (Mehrotra predictor–corrector) for dense convex quadratic programs that reads H, f, A, b, G, h, and bound vectors from /app/problem.npz, uses a safeguarded line search with regularization, and drives the KKT residual below 1e-6. Output the primal and dual solutions, final duality gap, and residual norms to /app/output/solution.json.",,
c0f35790-cdfe-49cb-9130-306540c7f008,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Implement a Python CLI that performs nonlinear least-squares curve fitting via the Levenberg–Marquardt algorithm: it reads a CSV data file and a JSON-defined model (with initial parameter guesses), computes Jacobians by finite differences, iterates to convergence, and writes best-fit parameters, covariance matrix, χ², reduced χ², uncertainties, and iteration history to JSON.",,
868cc7d2-db0b-4876-818f-b82963aaa332,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Implement a command-line tool that computes the minimax (L-infinity) polynomial approximation of a given function on [a,b] using the Remez exchange algorithm, with optional weighting. Output the polynomial coefficients, the achieved uniform error, and the final set of alternation points to a results file.",,
164ddf68-5362-45bc-8e05-42e08cd58e04,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Optimization & Root Finding,"Build a terminal tool that solves a system of nonlinear equations using a Jacobian-free Newton–Krylov method (Newton-GMRES with backtracking line search), loading residual(x) and an initial guess from /app/problem.py. Stop when the 2-norm of the residual is ≤1e-8 or the time budget is hit, and write the solution vector plus iteration and GMRES stats to /app/solution.json.",,
6ef53c4d-61d7-4c74-ba8e-440effe560a3,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Build a CLI tool that estimates logdet(A) for large sparse SPD matrices via randomized trace estimation of log(A) (Hutch++ with Chebyshev/Lanczos polynomial approximation), using reproducible seeds and batched probes to deliver a 95% confidence interval within a target relative error. The program must read Matrix Market files, validate against exact small cases, and emit a JSON report with estimate, CI, probe count, and timings.",,
457b4646-1165-44d7-88a8-d96656b62acc,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Create a Python CLI that performs a Monte Carlo simulation of the 2D Ising model on an L×L periodic lattice using the Metropolis algorithm, sweeping a user-specified temperature range to compute magnetization, susceptibility, and specific heat. Support JSON-configured parameter batches, reproducible seeding, per-temperature CSV outputs, and a summary JSON reporting the estimated critical temperature via finite-size scaling.",,
0f40ac5b-90a3-4601-b5a9-142f8bd791d2,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Create a Python CLI that reads a JSON config defining a high-dimensional integrand over [0,1]^d, then approximates the integral using both pseudorandom Monte Carlo and Sobol quasi-Monte Carlo sampling across increasing sample sizes, computes convergence rates and error estimates, and writes a JSON summary plus a CSV of RMSE vs sample count.",,
e56b0223-d28c-41d8-8fc2-28c9850d7eea,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Implement a Python CLI that estimates the volume of a 10-dimensional hypersphere using both standard Monte Carlo and Sobol Quasi-Monte Carlo sampling to compare convergence rates. The tool should read dimension and sample counts from a JSON config, compute error estimates for each method, and output results and a convergence plot under /app/output.",,
35dea734-908a-4328-b10a-930b264f961f,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Implement a CLI tool that, given a symmetric positive definite sparse matrix A (Matrix Market), estimates trace(log A) via stochastic Lanczos quadrature with Hutchinson probes, supporting Rademacher, Gaussian, and Owen‑scrambled Sobol sequences. The tool adaptively increases probes to hit a target relative 95% CI, reports estimate/CI/probe count/RNG/timing to /app/results.json, and validates on small cases against a Cholesky-based exact computation.",,
da8e3e71-8793-401a-bdd3-6be2cde2baf5,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Implement a stochastic Lanczos quadrature estimator for trace(log(A)) (i.e., log det A) of a large sparse SPD matrix using Hutchinson probes (Rademacher with optional antithetic pairing), reporting the mean, standard error, and 95% CI as functions of probe count and Lanczos steps. Provide a CLI that loads a Matrix Market .mtx, runs with a reproducible seed, and writes per-probe estimates and the final summary to CSV.",,
e57d3d07-9a5c-48c8-899a-98dca12e46eb,Scientific Computing & Analysis,Numerical Computation & Linear Algebra,Random Number Generation & Monte Carlo Methods,"Create a terminal script that loads a symmetric positive-definite matrix from /app/A.npz and estimates log(det(A)) by approximating trace(log A) via stochastic Lanczos quadrature with Hutchinson (Rademacher) probes using a reproducible RNG seed. The tool should adaptively increase probes to meet a target confidence interval and write the estimate, probe count, and CI to /app/answer.json within a time budget.",,
a96e5e13-c5a7-4d9b-bb36-d58bf051c16c,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Create a SLURM workflow that runs a parameter sweep as a job array reading /app/params.csv, stages per-task inputs to node-local scratch, and records stdout/stderr per index. Implement automatic failure handling that requeues only failed array tasks once with doubled time/memory and a dependent postprocessing job that uses sacct to write state, runtime, and MaxRSS for all indices to /app/output/summary.csv only after all tasks succeed.",,
17232145-e9fb-44ed-92fa-8e527351a8ba,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Build a CLI that reads a YAML parameter grid, generates and submits a resilient SLURM array job with a launcher mapping SLURM_ARRAY_TASK_ID to parameters, and monitors progress via squeue/sacct until completion. It must auto-requeue failed indices with increased time/memory, throttle or add dependencies based on pending reasons, and produce a CSV with per-index status, exit code, runtime, and MaxRSS.",,
96531448-c37f-4fce-b184-bd8e8a97c506,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Create a SLURM workflow that shards a large input into 200 parts, submits a fault-tolerant job array with per-task time/memory requests that traps SIGTERM to checkpoint and automatically retries failed elements, then resumes from partial results upon requeue. Monitor progress via squeue/sacct and submit an afterok aggregation job that verifies all shards, computes per-task runtime/memory statistics, and writes a consolidated JSON report to /app/summary.json.",,
13f7ee2e-7f34-40c7-8295-36a02d543dbc,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Build a CLI tool that reads a JSON-defined workflow of interdependent SLURM batch jobs, submits them with appropriate dependency flags and resource requests, polls their statuses, and upon completion aggregates stdout/stderr logs and key output metrics into a consolidated report, with configurable retry policies for failed tasks.",,
b1d0c75c-f5fc-4b41-b262-83229d09a561,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Build a SLURM workflow manager that submits a 3‑stage pipeline (preprocess → job array → reduction) with dependency chaining, monitors via squeue/sacct, and automatically requeues only failed array tasks (e.g., preempted or OOM) with adjusted resources and retry limits. It must handle SIGTERM for checkpointing and produce a final JSON/CSV report of exit status, retries, elapsed time, and MaxRSS per task.",,
b9994309-b117-45bd-bb38-1717262816ef,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Build a SLURM-driven workflow that launches a job array for a parameter sweep, enforces job dependencies (build -> stage data -> array -> postreduce), detects and auto-recovers preempted/failed tasks via sacct, and aggregates per-task elapsed time and GPU allocation into results.json. Provide scripts to submit, monitor, and checkpoint outputs so requeued runs resume without redoing completed work.",,
dbca6134-937c-4200-a590-72ed55e202f8,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Cluster & Batch Job Management,"Create a Python CLI that reads a JSON config of parameter sets and auto-generates SLURM job array scripts to run a hybrid MPI+OpenMP application with specified CPU, GPU, and module environment loading per task. The tool must submit jobs with dependencies, monitor their status via sacct, automatically retry failures, and aggregate per-task logs and resource usage into a final summary JSON after completion.",,
2f67a170-4856-4394-905e-26c3659c55a6,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement an MPI-based 3D Poisson solver on a structured grid using domain decomposition and a conjugate gradient method with Jacobi preconditioning, with each rank maintaining ghost cells and performing halo exchanges each iteration. Validate against an analytical solution by reporting L2 error and residual reduction, and write per-rank timing/scaling metrics and a representative solution slice to output files.",,
aa22161b-967e-4997-89f0-df4042fcae62,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement a distributed Conjugate Gradient solver for large sparse SPD matrices using MPI (mpi4py) with row-wise partitioning and halo exchanges for sparse matrix–vector products; solve Ax=b from provided Matrix Market and NumPy inputs and write the solution residual, iterations, and per-rank timing to files. Validate against a serial SciPy reference on small cases and demonstrate strong scaling across multiple processes.",,
40f9546c-2e50-44d1-b967-99b2ba4a38d1,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Build an MPI-based distributed PageRank solver for sparse graphs that partitions the adjacency matrix by rows, performs power iteration with teleportation and dangling-mass handling via collective reductions, and outputs the top-k ranked nodes and convergence metrics. Provide a CLI to read an edge list, configure alpha/tolerance, verify correctness by matching NetworkX PageRank on small graphs within 1e-6, and report weak-scaling efficiency.",,
707bfdf2-f1b4-491e-8854-88565506b954,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Create an MPI-based CLI that solves the 3D Poisson equation on a structured grid via domain-decomposed finite differences and Conjugate Gradient with ghost-cell halo exchanges, then writes the solution field and strong/weak scaling metrics to /app/output.json.",,
018a423d-8383-44f2-a0bc-9662a34834a9,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement an MPI-based 3D Poisson solver on a uniform grid using 3D Cartesian domain decomposition with nonblocking halo exchanges and Jacobi/CG iteration, writing per-iteration residuals, timings, and a central solution slice to standardized outputs. The harness runs at 1, 2, and 4 ranks to validate against a manufactured sinusoidal solution (error threshold), ensure monotonic residual decrease, and assess near-ideal weak scaling.",,
ac0d76a4-bc14-4c95-a6b2-daab533ad707,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement a distributed 2D Poisson/heat equation solver using MPI with domain decomposition and ghost-cell halo exchanges alongside a serial baseline sharing a common CLI to control grid size, iterations, and tolerance. Save residual history and the final field to standardized outputs, validate convergence and agreement with the serial solution within a set error, and demonstrate strong-scaling across process counts.",,
9e1234ab-a24b-43a4-95b4-c3bba555d174,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement a distributed block-Lanczos algorithm using mpi4py to compute the top-k eigenvalues and eigenvectors of a large sparse symmetric matrix loaded from /app/matrix.mtx, partitioning rows across MPI ranks for parallel matrix–vector products. Gather the Ritz values, eigenvectors, and timing metrics on rank 0 and write them to /app/eigs.json.",,
34289011-ad2a-489f-b12c-1f88fc544bc5,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Distributed Numerical Computation,"Implement a Python-based distributed solver (using Dask or MPI) for the 3D Gray–Scott reaction–diffusion system on a large grid with periodic boundaries, writing time‐step field snapshots to NetCDF and performing strong/weak scaling benchmarks. Include automatic error estimation against a reference solution and a CLI to configure domain size, time step, and diffusion parameters.",,
ab48a32b-f0c9-48ec-b013-587fd188d79e,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Create a GPU-accelerated 3D FFT-based Poisson solver using CuPy that computes the potential from a density field under periodic boundary conditions, with a CPU fallback using NumPy/SciPy. The CLI should load a .npy volume, compute potential and total energy, verify relative error ≤1e-6 vs CPU on a test case, and print device info and achieved GPU speedup.",,
88ea3523-5d26-45e4-a7d4-d757e9daf587,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a GPU-accelerated 2D Poisson solver on a large grid using a CuPy/Numba-CUDA stencil (Jacobi or Red–Black Gauss–Seidel), and compare its runtime to a NumPy CPU baseline. The script must reach a specified residual tolerance, validate against an analytic solution, and write residual, iterations, and GPU speedup to /app/metrics.json.",,
f9d9cce3-0e2f-4823-8c02-7b5b67fc2f3f,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a GPU-accelerated 3D Lattice Boltzmann Method fluid solver using CuPy that reads a VTK geometry, applies D3Q19 update kernels on the GPU, and enforces periodic or no-slip boundaries. The CLI should run for specified timesteps, output velocity and pressure fields as VTK files, and produce a JSON summary of performance metrics including timing and GPU memory usage.",,
8d2192ca-d3d8-40ba-b9ad-4a529b3e7833,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Develop a command-line tool that uses CUDA/CuPy to run a GPU-accelerated Metropolis–Hastings MCMC sampler for Bayesian logistic regression on large datasets, producing posterior samples, convergence diagnostics, and GPU versus CPU execution time comparisons.",,
2db94bb6-e4c2-4d7e-9253-233a9a053d65,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a 3D heat diffusion solver using CuPy with a custom CUDA RawKernel (7-point stencil) alongside a NumPy CPU reference, then run both on provided initial conditions to the same final time and validate the GPU field against CPU within 1e-6 max error while saving the final array, device name, and per-backend timings/speedup. Enforce the stability constraint dt <= dx^2/(6*alpha) and use shared-memory tiling with coalesced accesses in the GPU kernel.",,
e713ecd7-4425-40fe-9fd5-ac8676a4138b,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a CUDA-accelerated spectral Poisson solver that uses cuFFT via CuPy to solve the 3D Poisson equation ∇²φ=ρ on a periodic grid. The CLI should accept JSON-configured density fields, output the potential in VTK and a JSON performance report including runtime, GFLOPS, and L∞ error against an analytic solution.",,
56a9aa9f-9df0-428d-8d39-97d56101ea96,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a Python command-line tool using CuPy that runs a 3D Lennard-Jones molecular dynamics simulation on the GPU with periodic boundary conditions, GPU-based Verlet neighbor list construction, and velocity-Verlet integration for a user-specified number of steps. The tool must compute and record the total energy and temperature time series, write final positions and velocities to /app/final_state.npz, and export the radial distribution function as /app/rdf.csv and metrics as /app/output.json.",,
34cac5df-f210-4b43-a6be-22efd2518daa,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),GPU & Accelerator Utilization,"Implement a 3D FFT-based Poisson solver with periodic boundaries accelerated on GPU using CuPy/cuFFT, supporting batched right-hand sides and single/double precision. Provide a CLI that validates against a manufactured analytic solution and reports accuracy plus speedup versus a NumPy/FFTW CPU baseline.",,
8e821cbf-d965-4c81-883d-70de91f997f6,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a Conjugate Gradient solver for large SPD sparse matrices in CSR format with both serial and OpenMP-threaded paths for SpMV and vector reductions, selectable via a CLI. Load a provided matrix/vector, solve to a tolerance, and output solution, residual norm, and per-iteration timing to validate correctness and speedup across thread counts.",,
ee348e00-ff14-4d69-b341-60c1d26fee40,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement serial and OpenMP-parallelized Conjugate Gradient for large SPD sparse matrices in CSR loaded from Matrix Market files, with optional Jacobi preconditioning and fused parallel reductions. Provide a common CLI to solve Ax=b, write residual histories and solution summaries, verify the parallel solution matches serial within tolerance, and report timing-based speedups across thread counts.",,
df34c07c-d818-4783-82e5-a08fe905c558,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Build a multi-threaded Smith–Waterman local sequence alignment engine that parallelizes anti-diagonals (wavefront) with OpenMP alongside a serial baseline, exposing a CLI to align FASTA pairs and emit alignment score and traceback. Include correctness checks against a known-good implementation and a benchmark that reports GCUPS and thread-scaling.",,
a011b7f8-1144-4e62-a25c-b6caefc56a20,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a Python MPI-based solver for the 2D heat diffusion equation using an explicit finite-difference scheme, distributing grid rows across ranks with ghost-cell exchanges. Accept grid size and time steps from a JSON config, write the final temperature field to /app/output.npy, and report total runtime and per-rank timing metrics.",,
bc88264c-619a-4b15-a271-0f8c18b9ca90,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a Python CLI that reads initial positions and masses of N bodies from /app/bodies.csv, constructs a Barnes–Hut octree, and computes gravitational forces in parallel across CPU cores using multiprocessing, then integrates motion via a symplectic leapfrog scheme. Output trajectories as time-stamped CSV files and a JSON performance report showing speedup and scaling for varying core counts.",,
f5432d22-9e82-421f-9243-4d44d54d4bb4,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Develop a Python CLI that runs a parallel N-body gravitational simulation using multiprocessing to distribute pairwise force calculations and Velocity Verlet integration, supporting configurable number of bodies and time steps. The tool must compute and log energy/momentum conservation metrics and output trajectories and summary statistics in JSON format.",,
8a964256-76b1-441d-9912-80cb2da724b9,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a multithreaded Python CLI that runs parallel Monte Carlo simulations of the 2D Ising model across a range of temperatures, dividing the lattice into thread-owned blocks and performing concurrent Metropolis sweeps. Output per-temperature time-series CSVs of magnetization and energy plus a summary JSON with average observables, heat capacity, susceptibility, and thread scalability metrics.",,
37a865e1-c676-42ea-bfaf-ec9f0502ab1b,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement a 2D steady-state Poisson solver on a large grid using Jacobi iterations, providing both a single-threaded baseline and a multi-threaded version (OpenMP or multiprocessing). The CLI must accept grid size and thread count, iterate until a residual threshold, and write the final field plus a convergence/timing summary that demonstrates speedup with ≥4 threads.",,
29ea492a-f234-4de5-96cc-113a722e273d,Scientific Computing & Analysis,Parallel & High-Performance Computing (HPC),Multi-Threaded & Parallel Programming,"Implement serial and shared-memory parallel PageRank for a large sparse graph loaded from disk, using thread-partitioned sparse matvec and residual-based convergence. Output the top-ranked nodes and detailed timings to demonstrate speedup over the serial baseline.",,
d4e0ffb5-d578-4803-b56e-ba2db422ac5d,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Create a reproducible time-travel runner that checks out dataset revisions (e.g., tags data/v1 and data/v2) with DVC, resolves the exact environment via conda-lock, executes a Snakemake pipeline, and writes a provenance manifest listing git SHAs, DVC object IDs, lockfile hash, and output checksums. Generate a metric-drift report comparing the two runs and fail if any data or dependency is not pinned.",,
42d607b0-b6e0-4eae-9b5b-a5f7700a713a,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Initialize a Git+DVC project tracking /app/data.csv with a local remote and a two-stage, params.yaml-driven pipeline (preprocess -> analysis) that produces metrics.json and commits the resulting dvc.lock. Pin Python dependencies via a generated lockfile (e.g., pip-tools) and run in a fresh venv; then modify the data to create a second version, check out the original DVC tag to reproduce identical metrics and checksums, and write the original data hash and metric to /app/answer.json.",,
644c5b12-9429-45d2-9f69-b3c4e12fcced,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Build a DVC-managed analysis pipeline that versions two dataset revisions in a local DVC remote and runs a metrics script inside a conda-lock pinned environment. The run must write /app/results.json with metrics and provenance (dataset DVC hash, lockfile digest, git commit, script checksum) and reproduce bit-for-bit identical outputs across reruns.",,
682b0fa3-1a14-4e6f-b033-caefe0c32d4c,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Build a DVC-backed pipeline (local remote) with dvc.yaml stages to fetch, preprocess, and analyze a dataset while pinning Python dependencies with pip-tools to a requirements.lock. Prove reproducibility by switching between two Git tags and using dvc checkout so that metrics.json and output file checksums exactly match each tag’s recorded state.",,
88bd1ec5-b983-4af4-87d2-5ce95a328e63,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Create a DVC-based pipeline in /app that version-controls raw and processed datasets, with stages for data cleaning, analysis, and result generation, and employs a hash-locked requirements.txt plus environment.yml to pin dependencies. Provide CLI commands to checkout past experiment versions, install exact environments, rerun pipelines reproducibly, and output checksums for all artifacts.",,
afce8ce1-7e30-4255-9c34-fd3651573688,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Data Versioning & Dependency Control,"Implement a DVC-managed pipeline (preprocess → train → evaluate) with two local dataset versions and lock Python dependencies via pip-tools so reproducing on v1 yields identical artifact and metrics hashes across runs, while switching to v2 triggers only minimal stage recomputation. The run must emit an output manifest with dataset version, DVC stage checksums, and exact pip freeze, and validate at startup that installed packages match the lockfile.",,
282861b7-a463-417d-ba4e-248cf15b680e,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Develop a CLI pipeline tool that ingests a YAML workflow specification to orchestrate data preprocessing, model training, and evaluation, automatically versioning datasets with DVC and logging code commits, Conda environments, hyperparameters, and metrics to MLflow. Upon completion, generate an interactive provenance graph tracing data, parameters, and artifacts across runs for end-to-end auditability.",,
e18e4633-b4e7-434d-8f4b-294ec6587175,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Build a small ML experiment pipeline (data → preprocess → train → eval) that uses DVC to version data and stages and MLflow (file backend) to log params, metrics, artifacts, code version, and environment. Provide a CLI to run a parameter sweep and emit a single provenance.json that links each produced model and report to its DVC hash, MLflow run ID, Git commit, code diff, and random seed, enabling exact reruns.",,
f7bfcadb-d67a-4b57-bfcf-dee30bad6f70,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Create a DVC-tracked pipeline (preprocess → train → evaluate) for a small scikit-learn task, and instrument each run with MLflow to log parameters, metrics, artifacts, git commit, and DVC data hashes. Prove reproducibility by rerunning dvc repro to obtain byte-identical outputs and emit a provenance report linking MLflow run IDs to the exact DVC stage versions used to produce the final metrics.",,
8b83766a-c491-4fcf-bec8-b356f3a81f46,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Create a DVC-driven workflow (data → preprocess → model) that logs parameters, metrics, and artifacts to MLflow, and emits a provenance.json capturing dataset checksums, code commit, DVC stage graph, environment snapshot, and MLflow run IDs. Provide a CLI to reproduce any past run from only an MLflow run ID by restoring DVC versions and the environment, then verify artifact byte equality and write a reproducibility report.",,
97aeebfc-3d41-432a-b0f2-cd549adde78f,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Experiment Logging & Provenance Tracking,"Implement a Dockerized CLI that uses DVC to version raw and processed data, Git to snapshot code, and MLflow to log parameter sweeps, metrics, and artifacts, then generates an HTML provenance report showing data lineage, experiment comparisons, and diffed commit history. Ensure that invoking the CLI with a --reproduce flag can recreate any logged experiment end-to-end using the tracked artifacts and parameters.",,
8434eef3-682e-4512-abef-e41bff0739e3,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Implement a reproducibility runner that provisions a fresh Conda environment from environment.yml, executes each Jupyter notebook in /app/notebooks headlessly via nbconvert, and extracts JSON metrics embedded via papermill. The tool must compute SHA256 checksums of outputs, compare them against stored baselines, and output a consolidated pass/fail report indicating any divergences across runs.",,
30ccecd9-85e4-475f-a94e-f91e6ab95641,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Implement a Snakemake pipeline that parses a mixed Python–R Jupyter notebook, auto-generates conda environment.yml and renv.lock files, executes the notebook headlessly, and validates output cell SHA256 hashes against a provided manifest for reproducibility. Finally, bundle the notebook, lockfiles, and execution logs into a deployable archive.",,
f55d619f-8a2a-48a8-a3dd-efecbfda7ce9,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Convert a provided Jupyter notebook into a deterministic, headless analysis pipeline by parameterizing randomness, extracting it to a Python script, and orchestrating execution with a Makefile that builds a fully pinned, hashed environment (e.g., pip-tools) and runs papermill to regenerate results. The pipeline must yield byte-identical CSV/PNG outputs across reruns and emit a manifest.json capturing package lock hashes, data checksums, seeds, and system info for verification.",,
c7d59433-73c9-422b-8604-e4cb08737864,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Create a CLI pipeline that executes /app/analysis.ipynb with papermill using explicit parameters (including a fixed RNG seed), producing deterministic metrics, tables, and plots in /app/outputs and verifying bit-for-bit identical artifacts across two consecutive runs via SHA256 checksums. The run must also emit a locked requirements file and environment manifest (Python, OS, and package versions) alongside the outputs to ensure re-execution fidelity.",,
7930b1d2-4e38-40f8-b1d4-ea74578e5cce,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Refactor a provided Jupyter notebook with stochastic analyses into a deterministic, parameterized workflow that runs in a locked Python environment and produces byte-for-byte identical outputs on repeated runs. Expose a single terminal entrypoint that pins dependencies, executes the notebook (via papermill or a jupytext-converted script) with fixed seeds and constrained BLAS threads, and writes results.json plus a reproducibility checksum.",,
acb1faab-8f24-4d44-87b8-e2c6fda3a523,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Develop a script and environment specification that uses Papermill to parameterize and execute /app/analysis.ipynb with a given data CSV and random seed, captures outputs to /app/output, and verifies reproducibility by comparing SHA256 checksums of the generated HTML report and metrics JSON across repeated runs.",,
451315f7-4729-47d8-9e11-4d21f818e1c6,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Notebook & Script Reproducibility,"Convert a geospatial analysis notebook that reprojects a provided shapefile and computes polygon areas under two CRSs into a headless, reproducible CLI executed via papermill/nbconvert, pinning GDAL/PROJ and setting deterministic env vars (e.g., PROJ network/grid settings and single-threaded BLAS). The run must produce identical CSV/PNG artifacts and a results.json with area summaries and SHA256 hashes across repeated clean-container executions.",,
91bd85b0-8e2d-4e2f-af34-a20e004e1ea0,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Report Generation & Automation,"Build a Makefile-driven pipeline that ingests experiment CSVs, computes grouped summaries with bootstrap CIs, renders figures/tables, and compiles a templated Markdown into a standalone HTML (and optional PDF) report via Pandoc with embedded assets. The workflow must support incremental rebuilds and include a provenance appendix (git commit, CLI args, pip freeze), writing /app/report/index.html and a machine-readable /app/results.json.",,
4b3b8861-8782-4c57-82a8-62768b10ff49,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Report Generation & Automation,"Implement a Snakemake workflow that cleans raw datasets, performs statistical analyses and generates publication-quality plots, then automatically compiles a Markdown report to PDF via Pandoc with embedded tables, figures, software versions, and runtime logs. Ensure full reproducibility by capturing environment specifications (e.g., conda YAML) and Git commit metadata within the report.",,
b86776d0-8b2a-486f-943d-47d1a3b953cf,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Report Generation & Automation,"Implement a CLI that runs a parameter sweep for a numerical model, collects output metrics and plots, then uses a Pandoc template to compile a PDF report with methodology, results tables, convergence plots, and embedded input/output hashes to ensure full reproducibility.",,
abddac5a-e255-406c-b179-1bbcd08e8296,Scientific Computing & Analysis,Reproducible Research & Workflow Automation,Report Generation & Automation,"Build a CLI pipeline that performs a seeded analysis on a provided dataset, exports figures and tables, and assembles a fully self-contained HTML report (embedded images, no external assets) plus a manifest with SHA256 checksums and environment metadata. Orchestrate with Makefile/Snakemake so unchanged inputs trigger cached steps and reruns produce byte-identical outputs.",,
dabd28b1-f5fe-481f-acdf-8bf7183ddffb,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Implement a Python CLI that ingests an HDF5 file of nested oceanographic CTD casts, flattens the station/profile hierarchy into a tidy tabular structure, standardizes timestamps to ISO-8601, imputes missing salinity and temperature via nearest-neighbor interpolation, applies depth-based smoothing and min-max scaling, and exports the result as Parquet with a JSON metadata summary.",,
40cce994-7bb7-428b-a0ed-5e7901e22f14,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Build a CLI that ingests a folder of heterogeneous NetCDF climate model files, maps variables to CF-standard names, converts units to SI, reprojects to a target grid, and aligns time onto a unified daily calendar with gap filling. Output a consolidated chunked Zarr store and a manifest CSV documenting provenance, unit conversions, and optional baseline-normalized anomaly fields.",,
df4b2dda-f533-40a5-a9d7-a6f2a3c7cdf5,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Create a Python CLI that ingests a directory of daily CF-NetCDF climate files, harmonizes variable names/attributes, converts units to a specified target, stitches a continuous time axis over a given range, and repairs single-day gaps via flagged interpolation. Compute per-calendar-month climatology over a baseline and standardized anomalies, then write a CF-compliant compressed NetCDF of the cleaned series plus a CSV of the monthly climatology.",,
03a7a2c7-624a-4704-b57c-1bc8bdba00ab,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Create a CLI that ingests a directory of daily CF-netCDF climate files, harmonizes units (e.g., K→°C), decodes mixed time units/calendars, merges along time, masks fill values, removes outliers, and resamples to monthly means. Compute 1991–2020 per-gridcell climatology and z-score anomalies, then export a chunked, compressed Zarr dataset with consolidated metadata and a Parquet summary index.",,
abdb95f4-55f0-4228-bdfe-314f4ea268be,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Create a CLI tool that ingests a DICOM CT series, converts pixel data to Hounsfield Units via RescaleSlope/Intercept (handling per-slice calibration), clips to [-1024, 3071], and resamples to 1 mm isotropic voxels while preserving spatial metadata. Write a single 3D NIfTI (.nii.gz) with correct RAS affine and a JSON summary of original/resampled spacings, dimensions, and any slices skipped due to corruption.",,
47e7f52a-7f64-40bb-b0c1-8000efceed93,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Build a CLI that ingests a directory of environmental sensor CSV/TSV files with mixed time zones and units, converts all measurements to SI using declared metadata, aligns timestamps to UTC, resamples to uniform 1-minute intervals, flags/removes outliers, and imputes short gaps. Write a single tidy, columnar Parquet dataset with standardized NaNs and stable column order, plus a JSON file summarizing QC metrics and unit conversions applied.",,
3ab8bc03-605c-4490-bd71-27377eff0ee7,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Develop a Python CLI that ingests a set of NetCDF climate model outputs, regrids variables to a common resolution using xESMF, computes seasonal anomalies against a climatology baseline, and fills missing data via spatiotemporal interpolation. The tool must write cleaned NetCDF files with standardized metadata and a CSV summary of seasonal anomaly statistics by region.",,
c785a399-e492-49c8-b5fd-3e2e0db48efe,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Data Cleaning & Transformation,"Create a Python CLI that ingests multiple netCDF climate datasets, aggregates daily data to user-specified temporal resolutions, computes anomalies against a defined baseline period, performs spatial regridding to a target grid using bilinear interpolation, and writes out a consolidated Zarr store and regional anomaly summary CSV. Implement gap-filling for missing data via temporal and spatial interpolation and enforce CF metadata conventions throughout the pipeline.",,
22874c08-08e4-441f-889a-d43e8854c996,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Implement a Python CLI that reads a directory of LiDAR .las files, bins points to generate a raster DEM, computes hillshade and slope rasters, and extracts contour lines at 10m intervals as GeoJSON. Finally assemble a standalone Leaflet HTML map overlaying the DEM, hillshade, slope colormap, and contours with interactive toggles.",,
f22172b2-c14e-481d-ae93-8c3d72a2b37e,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Implement a Python CLI that ingests a directory of multispectral GeoTIFFs, masks clouds using a threshold-based algorithm, computes NDVI/SAVI indices, and spatially aligns them over an AOI defined by a GeoJSON. Generate time-series mosaicked GeoTIFFs and an interactive Folium HTML map highlighting seasonal vegetation changes.",,
a7dc9322-a30f-4828-8185-429ecda427eb,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Implement a Python CLI that ingests a GeoTIFF DEM and a GeoJSON LineString, reprojects the path to the DEM CRS, and samples elevations at uniformly spaced intervals. Compute local slope and aspect via finite differences and output a CSV profile (distance,elevation,slope,aspect) plus a Matplotlib PNG plot of elevation and slope versus distance.",,
3f95ae32-2def-423c-b68f-14e653c9bab9,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Implement a CLI that reads two multi-band GeoTIFF satellite images from different dates, warps and aligns them to a common CRS, computes per-pixel NDVI difference, and applies Otsu thresholding to extract significant vegetation changes. Output a GeoTIFF of change magnitude, a vector shapefile of change polygons, and a JSON summary with area statistics.",,
5547c3b1-5422-40e8-89de-be9942ff655f,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Build a Python CLI that ingests a time-series of multispectral GeoTIFFs and a polygon ROI, decodes per-pixel cloud masks from QA bands, harmonizes projection/resolution, and computes a cloud-free median NDVI composite. Output a cloud-optimized GeoTIFF with overviews, a quicklook PNG with ROI outline and scale bar, and a CSV of per-ROI summary statistics.",,
af7689d1-163c-48f1-873d-64a7a51ce980,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Create a CLI that loads two co-registered GeoTIFF satellite images from different dates, computes per-pixel NDVI change, thresholds significant vegetation loss/gain, and vectorizes affected regions into a GeoJSON with area metrics. It must reproject inputs to a common CRS, generate a change-overlay PNG map, and output a summary JSON report with region statistics.",,
1b4bbbb3-34d3-4686-be38-a7dc5fbbf4db,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Build a Python CLI that ingests a multi-band satellite GeoTIFF (with NIR and Red), computes NDVI with nodata handling, reprojects to EPSG:3857, and writes a colorized XYZ tile pyramid into an MBTiles database with correct bounds and metadata. Additionally, vectorize pixels where NDVI exceeds a threshold into simplified GeoJSON polygons and export a PNG quicklook map.",,
29de4ed3-528d-4aba-a9dd-7a89fee1b473,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Create a Python tool that reads a folder of multi-date satellite GeoTIFFs with varying CRSs and resolutions plus an AOI polygon, reprojects and clips them to a common grid, and builds a cloud-robust medoid mosaic across dates using RGB+NIR bands. Write the mosaic as a Cloud-Optimized GeoTIFF, a PNG quicklook with AOI overlay, and a JSON report of per-band mean/std and fraction of valid pixels.",,
08ecaadb-7f50-4f73-993d-a8b2af152935,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Create a CLI that georectifies an unreferenced aerial image using provided ground control points (pixel ↔ lon/lat), warps to a target CRS, and outputs a tiled, compressed Cloud-Optimized GeoTIFF with correct nodata and overviews. Also produce a quicklook PNG, a GeoJSON footprint of the warped image, and a JSON report of per-point residuals and overall RMSE.",,
7c8fc36f-7574-4160-a26b-5adc2571085a,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Image & Geospatial Data Handling,"Create a Python CLI that mosaics multispectral GeoTIFF tiles, reprojects to EPSG:3857, clips to polygons in a GeoJSON ROI, computes NDVI from specified Red/NIR bands while honoring nodata and an optional cloud mask, and saves a color-mapped NDVI PNG plus a Cloud-Optimized GeoTIFF. Also compute per-polygon zonal statistics (mean, median, std, pixel count) and write them to a GeoJSON output.",,
8439f17f-572d-48cd-9f1a-2ec0d0083722,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Implement a Python CLI that loads a multichannel time series, applies adaptive notch filtering at mains and harmonics plus a zero-phase bandpass, then computes multitaper PSDs and magnitude-squared coherence; it must detect and report dominant peaks, band powers, spectral entropy, and a coherence matrix to /app/results.json and save publication-quality PSD/coherence plots. Include a test mode that synthesizes known signals to validate peak frequencies within ±0.2 Hz and coherence above 0.9.",,
763fa1e2-bdcc-4660-a573-8f78d5f5f70b,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Implement a matched-filter detector for transient chirp signals: read a 1D noisy time series and a template waveform, estimate the noise PSD via Welch, whiten both, and compute the matched-filter SNR time series using FFT-based convolution. Write the peak detection time and SNR to a results JSON and save plots of amplitude spectral density (pre/post whitening) and the SNR time series.",,
09660539-85c5-4e7b-8493-4421749f7e24,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Create a CLI tool that computes a multitaper (DPSS) power spectral density of a 1-D signal and automatically detects narrowband line components above a robust noise floor. Apply notch filtering at detected lines and save the cleaned signal, PSD before/after, and a figure highlighting the peaks removed.",,
2e28fccb-3a54-43b1-930f-25608bb34cdf,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Develop a Python CLI that ingests a time-series CSV, performs continuous wavelet transforms with user-selectable wavelets, extracts and reconstructs signal components via ridge detection, and outputs JSON summaries plus annotated scalogram images.",,
1a36d7e4-a653-4333-bcb3-421c829ff5be,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Implement a Python CLI that loads a multichannel time-series CSV, applies discrete wavelet denoising and designs Butterworth bandpass filters to isolate user-specified frequency bands, then computes Welch power spectral densities and pairwise magnitude-squared coherence across channels. The tool must output a JSON summary of dominant peaks and coherence maxima and save spectrogram PNGs for each channel and band.",,
2ba35e03-c23c-439b-8563-2bb85a772947,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Spectral & Signal Processing,"Create a CLI tool that computes power spectral density estimates for multichannel signals using both Welch and multitaper (DPSS) methods, saving PSDs and 95% confidence intervals to CSV plus comparison plots. Validate normalization via Parseval’s theorem by requiring the PSD-integrated variance to match the time-domain variance within 2% and report any channels that fail.",,
4fda1c36-20ac-49e1-8481-f7aea46e1318,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Implement a Python CLI that loads a 3D volumetric dataset (e.g., a .npy array), extracts iso-surfaces at multiple user-specified thresholds using skimage.measure.marching_cubes, and renders them in an interactive Plotly HTML with sliders for threshold and opacity control. The tool should support large volumes via optional downsampling and annotate surface area and volume metrics on the plot.",,
054da7a4-04e3-451f-ad2c-470ce3d7475f,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Build a Python tool that loads a gridded NetCDF climate dataset, computes a 1981–2010 monthly climatology and anomalies for a chosen year, and generates a publication-quality, three-panel figure: (1) a global Robinson-projection contour map of annual-mean anomaly with coastlines and significance hatching, (2) an equatorial Hovmöller diagram (time vs longitude), and (3) a zonal-mean anomaly profile, all using a shared color normalization. Save both PNG and PDF outputs with consistent, colorblind-safe styling and embedded metadata.",,
107b65ae-a451-44a2-9733-c86276a60d0a,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Build a Python CLI that loads a gridded NetCDF atmospheric dataset (temperature on lat–lon–pressure), computes a zonal-mean latitude–pressure cross-section and derives the tropopause pressure using the WMO lapse-rate criterion, then plots a publication-quality contour/contourf figure with an inverted log-pressure axis, labeled isotherms, and an overlaid tropopause line using Matplotlib. Save both PNG and SVG figures and export the zonal-mean fields and tropopause profile to specified output files.",,
a4537e6a-0b75-41a5-b158-d6cebc1dc673,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Create a Python script that loads a 2D velocity field (u, v) from /app/velocity.npy, computes speed and vorticity, and generates a two-panel Matplotlib figure: left panel shows a pseudocolor speed heatmap with overlaid streamlines and a sparsified quiver; right panel shows filled vorticity contours with contour lines. Save the figure as /app/flow_figure.png and /app/flow_figure.pdf with labeled colorbars, equal aspect ratio, consistent fonts, and grid-aligned axes.",,
1c878dc9-fef7-45a6-b574-21220ec7f204,Scientific Computing & Analysis,Scientific Data Processing & Visualization,Visualization & Plotting,"Create a Python CLI that loads a global surface temperature netCDF4 file, computes monthly anomalies relative to a baseline period, and generates a multi-panel Matplotlib PDF containing a time-series of global mean anomaly, a world map contour of a selected month, and a zonal mean contour plot.",,
9e0922e5-157f-442d-84f9-45259a269138,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a Chebyshev collocation spectral solver in Python to solve the 1D Poisson equation -u''=f on [-1,1] with Dirichlet boundary conditions, using numpy and scipy.linalg to construct differentiation matrices and solve the linear system. Validate spectral accuracy by solving for f(x)=sin(pi x), computing L2 and max errors for N=16,32,64 grid sizes, and output a JSON summary of errors and estimated convergence rates.",,
8226cdb2-d2ed-4aeb-8738-5f7b8c2d8f76,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a 1D finite-volume solver for the linear advection equation u_t + a u_x = 0 on [0,1] with periodic boundaries, supporting both first-order upwind and second-order MUSCL-Hancock schemes with CFL-controlled time stepping and CLI selection. Validate against the exact traveling-wave solution for a smooth periodic initial condition by outputting solutions at requested times and reporting L1/L2 errors that demonstrate first- vs second-order convergence over at least three uniform grid refinements.",,
66b8d07e-1173-47ed-ae50-86573d40ba8e,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a 1D heat equation solver using the Crank–Nicolson scheme with a Thomas tridiagonal solver on a uniform grid with Dirichlet boundaries. Validate by comparing to the analytical solution u(x,t)=exp(-pi^2*t)*sin(pi*x) (alpha=1), reporting max and L2 errors at specified times and demonstrating near second-order convergence under grid refinement.",,
940d389c-088c-4d1b-bc2f-d215679fd203,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a 2D Poisson solver on the unit square using a geometric multigrid V-cycle with red-black Gauss–Seidel smoothing and second-order finite differences, with CLI options for grid size and cycle parameters. Validate via a manufactured solution (e.g., u(x,y)=sin(pi x) sin(pi y)) to demonstrate O(h^2) convergence and quantify residual reduction per cycle versus a plain Gauss–Seidel baseline.",,
483c66d2-2772-4a00-9b3b-566150901b47,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a Gauss–Legendre quadrature generator using the Golub–Welsch algorithm to compute nodes and weights for arbitrary n (e.g., up to 2048) and provide a CLI to write them to disk. Validate by integrating polynomials up to degree 2n−1 over [-1, 1] and reporting the maximum absolute error against exact values, ensuring it stays below a specified tolerance.",,
25954180-cbf4-4c5a-af53-c88cbfbec8ae,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Create a Python CLI that implements a two-dimensional Laplace Fast Multipole Method (FMM) using quad-tree decomposition and multipole/local expansions to evaluate potentials for N sources and targets read from JSON. Validate accuracy against direct O(N^2) summation for small N, report error and complexity metrics, and output potentials in JSON.",,
3fdcff1b-47ba-485f-b3b4-a543251e98fa,Scientific Computing & Analysis,Scientific Software Engineering,Algorithm Implementation & Validation,"Implement a 2D Poisson solver on the unit square with Dirichlet boundaries using second-order finite differences with at least two solvers (e.g., Gauss-Seidel and Conjugate Gradient) exposed via a CLI. Validate against the analytical solution u(x,y)=sin(pi x)sin(pi y) by grid refinement (e.g., N=32,64,128), reporting L2/L∞ errors and observed order to a results file and failing if order < 1.9 or residual tolerances are unmet.",,
752a4df9-1afb-45c4-9b85-64c809d7ba7e,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,Profile a naive finite-element stiffness-matrix assembly for a 2D Poisson problem on triangular meshes and optimize the hotspot by vectorizing element computations and constructing the global matrix in CSR with preallocated buffers or Numba. Validate numerical equivalence within tolerance across provided meshes and emit timing and speedup metrics.,,
32162f32-ca05-4036-8438-2e580ee354c1,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Create a CLI tool with a Python-based explicit finite-difference solver for the 2D heat equation, profile hotspots using cProfile and line_profiler, then optimize the core time-stepping loop via NumPy vectorization, memory blocking, and Numba JIT compilation, finally comparing pre- and post-optimization runtimes, memory footprints, and speedup metrics.",,
ac2a9431-f5b2-48a2-8b09-ac1ba4d1bd9f,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Profile a naive pure-Python 3D heat equation explicit solver stepping 100 iterations on a 128^3 grid, then vectorize the stencil update, optimize memory access, and accelerate with Numba (parallel) to achieve ≥10× speedup while keeping max absolute error ≤1e-6 versus the baseline. Provide a CLI benchmark that runs pre/post-optimization versions, captures timing and max error, and writes a JSON report to /app/bench.json.",,
98122940-5b4f-48d8-a873-65c32d1c83a2,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Profile and optimize a naive 3D 7-point Jacobi solver for the Poisson equation on a uniform grid, transforming a triple-nested loop baseline into a high-performance version via cache blocking/tiling, vectorized memory access, and optional Numba or OpenMP. The CLI should run solves on several grid sizes, verify residual reduction against a reference solution with fixed boundary conditions, and print a profiling report that shows at least a 5× speedup over the baseline.",,
a68f3cb7-80b3-416b-8d44-98e71d66d382,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Optimize a naive Python finite-element stiffness matrix assembly for a 2D Poisson problem that performs incremental CSR updates inside nested loops by profiling hotspots and refactoring to a vectorized batch COO (I,J,V) build with a single CSR conversion. Verify numerical equivalence of the assembled matrix and improved end-to-end solve time, and emit a JSON report of timings and speedups.",,
6f410144-95c6-412c-a3cd-387e70941233,Scientific Computing & Analysis,Scientific Software Engineering,Code Optimization & Profiling,"Profile a naive Python N-body Lennard–Jones force computation with cProfile to identify loop hotspots, then refactor using NumPy broadcasting or Numba JIT and memory blocking to achieve at least a 10× speedup while verifying forces and energy remain accurate within 1e-6.",,
c706fccc-2499-4a13-ab1a-1e27c8139f09,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a typed Python library for uncertainty propagation via Polynomial Chaos Expansions, supporting Gaussian/Uniform inputs, sparse regression and quadrature fitting, and computing means/variances plus first/total Sobol indices. Provide a CLI that loads a black-box model from a Python module and a JSON distribution spec to write a results JSON, and include unit tests and Sphinx docs with API and examples.",,
23b07447-1b15-4f73-88d5-caf5f0ce226b,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a C++ library providing high-accuracy special functions (Bessel, Gamma, incomplete Beta) via Chebyshev expansions with Python bindings through pybind11 and Julia wrappers. Include a CMake build, Doxygen-generated API docs, Sphinx integration for Python, example notebooks, comprehensive unit tests, CI pipelines, and packaging recipes for PyPI and Conda Forge.",,
5cef89b1-428b-4c3e-8bef-6e0f2a82fad3,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a Python package providing a suite of astrophysics-focused probability distributions (e.g. broken power-law, truncated log-normal) with vectorized PDF/CDF evaluation, parameter estimation routines, and optional JAX acceleration. Include Sphinx-generated API documentation, example Jupyter notebooks covering common astronomy use cases, a comprehensive test suite, and PyPI-ready packaging with continuous integration.",,
c39b5a3b-3657-40b1-bf87-3de313331127,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a Cython-accelerated Python library for multi-dimensional interpolation of scattered scientific data (linear, cubic spline, barycentric), backed by a KD-tree spatial index, complete with unit tests, CI pipelines, Sphinx API docs, example notebooks, and PyPI packaging.",,
16295396-b028-4a0d-ae3e-52621ff78d19,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Design a Python package that provides a unified API for propagating uncertainties through numerical models via linear Taylor expansion, Monte Carlo sampling, and polynomial chaos expansions. Include complete Sphinx documentation with usage examples, unit tests, CI configuration, and PyPI-ready packaging.",,
a6972976-346b-439e-a35e-81a6e064e71b,Scientific Computing & Analysis,Scientific Software Engineering,Library Development & Documentation,"Develop a Python interval arithmetic library that guarantees enclosure for elementary functions using outward rounding and vectorized NumPy operations, with a clean API, type hints, and Sphinx docs driven by doctests. Include a CLI to evaluate expressions over named intervals and a test suite that verifies inclusion properties and monotonicity on randomized cases.",,
a08da7a0-23bb-4e05-b72f-c65c76c081f7,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Create a pytest + Hypothesis test harness that ingests a finite-difference PDE solver and verifies second-order accuracy via manufactured solutions, conservation and boundary-condition compliance, and monotonic error reduction under grid refinement. The suite must emit JUnit XML and a JSON convergence report and fail if the estimated order falls below 1.8 on any tested problem.",,
0a02206d-9826-400e-bd7d-23e94343ae2f,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Create an automated test/CI harness that runs a provided 1D PDE solver across successively refined grids on manufactured solutions, computes L2 errors, fits the empirical convergence order, and fails if it falls below a set tolerance. Include metamorphic tests for boundary-condition transformations and a discrete conservation check, and emit JSON and JUnit XML summaries.",,
38ac1d0d-2759-451c-833f-327e99f5a7e6,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Build a metamorphic and property-based test harness for a 2D Poisson solver that generates randomized periodic RHS fields, asserts exact recovery on single Fourier modes, checks symmetry/conservation invariants, and differential-tests against an independent finite-difference reference with convergence and error thresholds. Provide a CLI to run the suite and a CI workflow that records metrics and fails on tolerance regressions.",,
76ca303b-95fd-4bc4-82c2-26700ba83a4d,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Set up a GitHub Actions CI pipeline for a Python finite‐difference PDE solver package that automatically runs pytest suites verifying second‐order convergence against analytic Poisson and heat equation solutions via parameterized tests, checks gradient consistency, tracks performance benchmarks, enforces code coverage ≥90%, and integrates linting/formatting checks.",,
48794712-9dda-4e5e-be18-3061fb16513d,Scientific Computing & Analysis,Scientific Software Engineering,Testing & Verification Frameworks,"Build a pytest + Hypothesis metamorphic testing suite for a time-integration library (explicit/implicit Runge–Kutta) that verifies order of accuracy via step-halving, checks conserved quantities on canonical systems (harmonic oscillator, Kepler), and validates A-stability on the Dahlquist test equation. Provide a CLI to run the suite with numeric tolerance gates, enforce coverage thresholds, and emit JUnit XML and coverage artifacts suitable for CI.",,
e7819bc9-7043-4f33-82ae-e250f4e48273,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Create a Python CLI that solves the 2D FitzHugh–Nagumo reaction–diffusion system on a unit square using finite-difference spatial discretization and an implicit–explicit (IMEX) time-stepping scheme with SciPy’s sparse solvers. The tool must read initial conditions and model parameters from /app/config.json, produce solution snapshots and figures, and report wave propagation speed and mass-conservation error in /app/output.json.",,
b9c67c76-3001-4531-9bf9-5cd1ee3e1d44,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Implement a Python CLI that solves the 1D Fisher–KPP reaction–diffusion PDE on [0, L] with Neumann boundaries via method-of-lines (finite differences) using SciPy’s stiff integrator from a compact initial condition. Estimate the traveling wave speed from the simulation and verify it is within 5% of the theoretical minimum 2*sqrt(D*r), writing the estimated speed and error to /app/answer.json.",,
16f4099d-3aa2-4381-a89a-23f12b5c9120,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Create a Python CLI that uses FiPy to solve the 2D Gray–Scott reaction–diffusion PDE system with configurable feed and kill rates, grid size, and time-stepping scheme, exporting concentration snapshots and pattern metrics. Support batch JSON-driven parameter sweeps to generate multiple pattern outputs and a summary report of morphology statistics.",,
29a6e8d8-6bbc-4bb2-acbe-985352aa3a8e,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Build a Python CLI that performs adjoint-based parameter estimation for an ODE by integrating both the forward system and its continuous-time adjoint to obtain exact gradients of a least-squares misfit. Apply it to fit the Lorenz system’s (sigma, rho, beta) to a provided noisy trajectory, and report recovered parameters along with adjoint–finite-difference gradient agreement.",,
5c10cbcb-72f6-416e-adbe-a5234d7ca4ba,Scientific Computing & Analysis,Simulation & Modeling,Differential Equation Solvers,"Implement a 1D heat-equation solver with time-dependent source and mixed (Robin) boundary conditions using second-order finite differences in space and Crank–Nicolson time stepping, solving the per-step tridiagonal system via the Thomas algorithm. The CLI should ingest problem parameters and output snapshots at requested times to CSV and additionally run a mesh-refinement check to confirm ~O(Δx^2 + Δt^2) convergence.",,
8196fde1-e327-4c34-bfe6-d3994c1f2ebe,Scientific Computing & Analysis,Simulation & Modeling,Finite Element & Numerical Methods,"Implement a 2D finite element solver for -∇·(k∇u)=f on a Gmsh triangular mesh with mixed Dirichlet/Neumann boundaries, assembling a sparse system and solving with Conjugate Gradient and a basic preconditioner. Validate via a manufactured solution by reporting L2 and H1-seminorm errors across at least two mesh refinements, and write both the nodal field and error summary to output files.",,
389ad966-5499-41b2-b8d7-624e0e4778b8,Scientific Computing & Analysis,Simulation & Modeling,Finite Element & Numerical Methods,"Create a Python CLI that loads a 2D composite material mesh from /app/mesh.msh, assembles and solves the transient non-linear heat equation with temperature-dependent anisotropic conductivity using linear finite elements and implicit Euler time stepping, applies Newton–Raphson iterations with Zienkiewicz–Zhu error estimation for adaptive mesh refinement at each step, and outputs VTK field files along with a JSON report of time-step convergence metrics and mesh statistics.",,
7a1314e7-5866-4c5d-b252-a8ce81488e9a,Scientific Computing & Analysis,Simulation & Modeling,Finite Element & Numerical Methods,"Implement a 1D discontinuous Galerkin solver for linear advection with periodic boundaries, selectable numerical flux (upwind/Rusanov), and SSPRK time stepping; expose CLI options for polynomial order, CFL, and final time. Output field snapshots and L2 error versus the exact shifted solution, and verify k+1 convergence across mesh refinements.",,
b3e5da9a-b912-4aaf-a8aa-bf2237176a10,Scientific Computing & Analysis,Simulation & Modeling,Finite Element & Numerical Methods,"Implement a sparse finite element modal analysis tool for 2D trusses: parse nodes and bar elements with A, E, and ρ, assemble global stiffness and consistent mass matrices, apply fixed DOFs, and compute the first k natural frequencies and mode shapes via eigsh. Write frequencies to an output text file and mode shapes to a mesh-compatible format (e.g., VTK/CSV).",,
4c7f8933-6faa-497b-9b4c-90fb4b46a514,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Build a CLI tool that runs a stochastic SIR epidemic simulation (Gillespie SSA) and performs a Sobol global sensitivity analysis over R0, mean infectious period, and initial infected fraction, reporting first- and total-order indices for peak prevalence, time-to-peak, and final size. Use Saltelli sampling with a fixed seed, parallelize simulations, and write indices and summary metrics to CSV/text outputs.",,
3e22b584-1b8d-44a4-b766-fd771b7569e4,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Build a 1D heat-equation simulator (explicit FTCS with Dirichlet boundaries) that sweeps spatial resolution and timestep to explore CFL stability and convergence, comparing against an analytic solution. For each (dx, dt), record stability, L2 error at a fixed final time, and estimate order-of-accuracy across resolutions in a summary CSV.",,
9b133bd6-cf3d-4309-9b95-dc2904d4d511,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Implement a Python CLI that integrates the Lorenz '63 system and, for a grid of (sigma, rho) values at fixed beta, computes the largest Lyapunov exponent to map chaotic vs non-chaotic regions, writing a CSV heatmap and the estimated boundary. Assess numerical sensitivity by rerunning a subset with stricter solver tolerances and reporting deviations in the exponent.",,
10774d4e-5893-4b15-81e3-a984b745dae3,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Implement a Python CLI that sweeps the Lorenz system over ranges of σ, ρ, and β, numerically integrates each parameter set to compute the largest Lyapunov exponent for chaos detection, and writes out a JSON-formatted sensitivity matrix, convergence diagnostics, and representative phase-space snapshots.",,
ef5a60e6-6536-44b5-ba9d-8d5c955b4007,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Build a Monte Carlo simulator for the 2D Ising model with periodic boundaries, sweeping temperature across a range and multiple lattice sizes to compute ensemble magnetization, energy, specific heat, susceptibility, and Binder cumulant. Estimate the critical temperature by locating the susceptibility peak and Binder cumulant crossing, saving the full per-temperature statistics and Tc estimate to outputs.",,
9db8fc47-98a5-4b12-b29d-31e7a4bbc602,Scientific Computing & Analysis,Simulation & Modeling,Parameter Sweeps & Sensitivity Analysis,"Build a Python CLI that simulates the Lotka–Volterra predator–prey ODE across thousands of parameter samples (birth, predation, mortality, efficiency) drawn via Sobol or Latin hypercube designs, recording summary metrics such as final populations, peak amplitudes, and oscillation period per run. Compute and save first-order and total Sobol sensitivity indices for each metric, along with a CSV of runs and a JSON report of indices.",,
0c9db30d-652e-4c1d-87bc-5a6e18752969,Scientific Computing & Analysis,Simulation & Modeling,Stochastic Differential Equation Solvers,"Implement a Python CLI that uses the Euler–Maruyama method to integrate a system of coupled stochastic differential equations modeling a double-well potential with additive Gaussian noise, generate Monte Carlo sample paths, estimate mean first-passage times and the stationary distribution histogram, and write trajectories to CSV and metrics to JSON.",,
5fb8c643-698c-4541-8b48-e2ac07eb2cf7,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Develop a command-line tool that reads a JSON configuration for a 2D grid predator-prey model with random-walk movement, birth, death, and predation rules, executes multiple stochastic runs, and records time-series population counts. The tool should output JSON summary statistics along with spatial distribution snapshots (e.g., PNGs or CSVs) for each realization.",,
9cc5f790-e71d-4baa-a8a6-ba41a0db774f,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a discrete-event simulator for an M(t)/M/c/K queue with two priority classes (preemptive-resume) and impatient customers (reneging), supporting reproducible random seeds and multi-run parameter sweeps via CLI. For each run, write CSVs with time-series queue lengths and per-class summary metrics (utilization, mean/95th-percentile wait, abandonment rate).",,
f1350dc7-4622-4435-b144-1baff7ec8bfa,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a discrete-event simulator for an open Jackson queueing network (2–4 M/M/1 nodes) with configurable arrival/service rates and routing probabilities, running multiple replications with independent RNG seeds to estimate steady-state throughput, utilization, mean queue lengths, and waiting times. For provided test cases, compare simulated metrics and 95% CIs to analytic formulas and fail if discrepancies exceed 5%, writing standardized CSV/JSON outputs.",,
8d152cdb-696f-41b0-a797-40ad45f82fda,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Build a discrete-event simulator for an M/M/c/K queue with balking at full capacity and exponential reneging, using a fixed RNG seed and automatic warm-up detection before collecting statistics across multiple replications. Output per-replication and aggregated 95% CI estimates for throughput, loss probability, mean queue length, and waiting time to standardized CSV/JSON files.",,
4820acf7-38ef-4f7c-b9ea-ce98a0ee44ad,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a stochastic chemical kinetics simulator that loads a reaction network from a simple JSON schema and runs both exact Gillespie SSA and an adaptive tau-leaping variant across multiple random seeds. Save ensemble trajectories and checkpointed means/variances, and report agreement metrics between the two methods within specified tolerances.",,
bd41f126-69dd-4399-9e6c-b4ebf955306d,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a discrete-event simulation of a priority M/M/c/K queue with balking and reneging, reading parameters from /app/scenario.yaml, and run batched replications with fixed RNG seeds to estimate per-class throughput, mean wait, and server utilization with 95% CIs to /app/results.json. Include a test mode that sets K→∞ and a single class to validate against the analytical M/M/c steady-state formulas within a specified tolerance.",,
650ba307-14d9-4c6b-b8c1-acc284a79ff9,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a Python CLI that reads ant colony foraging parameters (grid size, nest and food source locations, agent counts, pheromone deposition/evaporation rates) from /app/config.json and simulates an agent-based foraging model on a 2D lattice with seeded random exploration and pheromone-biased movement over discrete time steps. The tool must write /app/results.json summarizing food collected and efficiency metrics, /app/pheromone.npy for the final pheromone field, and /app/trajectories.csv logging individual agent positions per step.",,
3bee9dea-9c1a-48f5-9170-d9d287ca482a,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Implement a Python CLI that reads a chemical reaction network definition (species, stoichiometry, rate constants) from JSON and runs Gillespie’s stochastic simulation algorithm for multiple trajectories. Compute ensemble means and variances over time for each species, and output both time-series data and histogram summaries in JSON format.",,
12a003ac-ac27-4773-a8e5-29f2bae2a102,Scientific Computing & Analysis,Simulation & Modeling,Stochastic or Agent-Based Simulations,"Create a CLI that loads a social contact network from CSV, runs a stochastic agent-based SIR epidemic with configurable vaccination and quarantine policies, and outputs per-timestep compartment counts as CSV plus a JSON summary of peak infection, final attack rate, and estimated R₀. Ensure all randomness is seedable, support batch runs via JSON config, and report policy comparison metrics.",,
79abef51-a281-4381-b2dd-b7a6a17e532e,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Descriptive Statistics & Summarization,"Create a CLI that reads a CSV of mixed numerical and categorical columns, auto-detects types, computes numeric summaries (count, mean, median, std, skewness, kurtosis, quantiles) and categorical frequency tables, and outputs a JSON report plus histogram/bar-chart PNGs for each column.",,
db15ad90-2491-4b15-a7ac-1eb8a11afe26,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Create a Python CLI that reads a CSV with multiple treatment groups, performs a permutation-based one-way ANOVA by Monte Carlo resampling to compute an empirical p-value, then runs pairwise permutation tests with Holm–Bonferroni correction and outputs F-statistic, p-value, effect sizes, and significant group comparisons in JSON format.",,
7adfdb7c-70e3-4904-a2cf-4eb5e025c6be,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Create a CLI tool that ingests per-study effect sizes and standard errors, runs a random-effects meta-analysis (DerSimonian–Laird with optional Hartung–Knapp adjustment), and tests for overall effect and heterogeneity (Cochran’s Q, I²). Write combined estimates, p-values, per-study weights, and a leave-one-out influence summary to standardized output files.",,
72bfe312-a8fa-40e0-9832-56fcbd819878,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Implement a Python CLI that reads a CSV with one numeric outcome and one categorical group factor, runs Shapiro–Wilk and Levene tests to decide between one-way ANOVA or Kruskal–Wallis, then performs the chosen omnibus test plus all pairwise post-hoc comparisons (Tukey HSD or Dunn’s test) with Holm correction, outputting test statistics, p-values, adjusted p-values, and effect sizes in JSON.",,
d82b0fdc-3069-4544-bf9a-cd081352b784,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Build a CLI tool that reads a CSV with a grouping factor and numeric response, runs Shapiro–Wilk for normality and Levene’s test for homogeneity, then performs one-way ANOVA or Welch’s ANOVA as required, computes effect sizes and conducts post-hoc pairwise tests with Holm–Bonferroni correction, and emits a JSON summary plus diagnostic plots.",,
34c2152b-5e32-4155-882c-5d71fea4b40b,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Hypothesis Testing & Inference,"Create a script that ingests stratified 2x2 contingency data (A/B by success/failure with a stratum identifier), performs a Cochran–Mantel–Haenszel test to estimate a common odds ratio with 95% CI, and reports its p-value. Additionally run the Breslow–Day test for homogeneity across strata and write the common OR, CI, and both p-values to an output JSON file.",,
64dc4e6b-bd8b-4b9d-ac1d-671f606e5c1d,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Implement a Python CLI that loads concentration–response data from /app/data.csv, fits a four-parameter logistic dose–response model via scipy.optimize.least_squares with automatic initial guesses, computes covariance-based parameter uncertainties, AIC, and R², then writes fit_params.json, residuals.csv, and a high-resolution fitted_curve.csv under /app.",,
1ed2caf8-f925-4624-8257-497ab4795ffa,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Create a CLI tool that fits a bi-exponential decay model y(t)=a1*exp(-k1 t)+a2*exp(-k2 t) using the variable-projection method: optimize k1,k2 via nonlinear search while solving a1,a2 by linear least squares at each step, enforcing a1,a2>=0 and k1,k2>0. Report parameter estimates, bootstrap 95% CIs, and predicted values at specified eval times without using high-level curve-fitting helpers.",,
e3945558-d0b9-4e53-8f2d-67c5eb8e357e,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Build a CLI tool that fits an errors-in-variables Deming regression for method-comparison data, estimating the error variance ratio from replicate measurements and optionally applying Huber M-estimation to orthogonal residuals for robustness. Output slope, intercept, their 95% CIs (bootstrap), the variance ratio estimate, and a CSV of fitted values and orthogonal residuals.",,
d4e4c09f-5e32-493e-9715-66d3887908b4,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Build a CLI tool that fits piecewise linear (segmented) regression with an unknown number of change-points on a noisy 1D dataset, selecting the number and locations via BIC-penalized dynamic programming (e.g., PELT). Save breakpoint positions, segment slopes/intercepts, fitted values and residuals, and bootstrap confidence intervals for parameters to standardized output files.",,
6492f935-289d-4e2d-83c4-f25287b5a0e1,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Build a terminal script that reads /app/series.csv (time,y) and fits a piecewise linear regression with 1–3 unknown changepoints under Huber loss using dynamic programming (or equivalent), selecting the segment count by BIC. Output /app/results.json with changepoint times, segment slopes/intercepts, BIC per model, and residual diagnostics.",,
b831fb16-dcf5-4490-8221-0b1e8d93b171,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Regression & Curve Fitting,"Fit Planck's law to a measured spectral radiance dataset (wavelength vs intensity), jointly estimating temperature and a gray-body emissivity factor with bounds and optional instrument-response correction from a calibration file. Save parameter estimates with bootstrap confidence intervals and residual diagnostics to standardized output files.",,
00552fca-25b8-4da7-9fbc-f7e4f0ec45ee,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Build a CLI tool that ingests an irregularly timestamped sensor series, resamples to hourly, and fits a Basic Structural Model (local level + local trend + 24-hour seasonality) using a from-scratch Kalman filter/smoother with maximum-likelihood estimation of noise variances while natively handling missing points. Output the decomposed components, the seasonally adjusted series, and 48-hour forecast quantiles (5/50/95%).",,
38a1e98b-ba87-4e11-8b61-c22b15ca6e6d,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Implement a Python CLI that loads a multivariate time-series CSV from /app/data.csv, applies STL decomposition to extract trend, seasonal, and residual components, and uses Welch’s method to estimate the power spectral density of the residuals, identifying dominant periodicities. Flag anomalies based on residual z-scores, then output a JSON summary of decomposition metrics, dominant frequencies, and anomaly timestamps, and save diagnostic CSVs and plots under /app/output.",,
70b528ae-1349-407c-a678-a085af6c62d4,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Create a CLI that reads a univariate time-series CSV (with timestamp and value), performs seasonal-trend decomposition via STL, fits a Holt–Winters Exponential Smoothing model with multiple seasonal periods to forecast the next horizon, and outputs forecast.csv and a metrics.json (including MAE, RMSE, and prediction intervals) based on a holdout period.",,
7cb8899a-7ee7-435e-b425-3784fe7dbee7,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Create a CLI that ingests an irregularly sampled multivariate time series, estimates dominant seasonal periods via Lomb–Scargle and multitaper spectral analysis, then fits a seasonal state-space/SARIMAX model with Fourier terms to forecast a specified horizon. The tool must impute missing values, run rolling-origin backtesting, and write forecasts with 80/95% intervals and per-horizon error metrics to standardized output files.",,
114ebc9b-14ca-4cd9-8b8a-df6dd347f0e7,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Create a CLI tool that ingests an irregularly sampled univariate time series with optional exogenous variables, resamples to a target frequency, applies a Box–Cox transform, and selects a SARIMAX model via stepwise AIC under stationarity/invertibility constraints. Perform multi-fold rolling-origin backtesting and output n-step forecasts with 95% intervals, residual Ljung–Box diagnostics, selected (p,d,q)(P,D,Q)s, and MASE/sMAPE metrics to standardized files.",,
66e23a93-0f92-4752-a466-53e099170979,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Implement a CLI that ingests an irregularly sampled univariate time series, estimates dominant seasonal periods via Lomb–Scargle spectral analysis, and performs STL decomposition using those periods. Fit a SARIMA model to the deseasonalized component to generate 30-step forecasts with 95% intervals, saving detected periods, decomposition components, and forecasts to disk.",,
ccbd0405-e99c-4e5b-9d25-740134ab57b9,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Implement a Python CLI that reads a multivariate time-series CSV, automatically selects the optimal VAR lag order via AIC/BIC, fits the VAR model, performs Granger causality tests for each variable pair, computes impulse response functions and forecast error variance decomposition for a user-specified horizon, and writes JSON summaries of model parameters, p-values, IRFs, FEVDs, and diagnostics.",,
dd8ec0d2-94ed-40e0-9d21-bcced3607835,Scientific Computing & Analysis,Statistical Analysis & Data Modeling,Time Series Analysis,"Create a CLI tool that ingests an irregularly sampled time series with gaps, detects dominant seasonal periods via a Lomb–Scargle periodogram, and performs robust STL decomposition after appropriate resampling/imputation. Fit an ARIMA model to the seasonally adjusted component to generate a 7-day forecast with 95% intervals, and write the detected periods, decomposition components, and forecast to standardized CSV outputs.",,
06b4e8c2-5063-4900-81b1-df187f793bc7,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Build a CLI tool that performs hierarchical Bayesian calibration of a Michaelis–Menten kinetics model across multiple temperatures, linking Vmax(T) via an Arrhenius law to jointly infer activation energy, pre-exponential factor, Km, and per-experiment noise with MCMC. Write posterior parameter summaries and posterior predictive trajectories with 95% credible intervals for each experiment to designated output files.",,
20b2f39a-cf7b-495f-8127-396cc46a8a3c,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Create a CLI tool that loads epidemiological time–series data (S, I, R) from CSV and runs Metropolis–Hastings MCMC to infer SIR model parameters β and γ under user-specified priors, outputting posterior samples, credible intervals, and trace plots. Include automated computation of Bayes factors for alternative compartmental models and support batch processing of multiple outbreak scenarios with JSON summary reports.",,
7e977ad7-4df3-4270-b955-995964630bbb,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Create a Python CLI that loads noisy predator–prey time-series from /app/data.csv, defines a Lotka–Volterra ODE model with prior distributions, and runs NUTS sampling via PyMC3/TensorFlow Probability to infer posterior parameter distributions. The tool must output /app/output.json containing posterior summaries (means, 95% credible intervals) and a set of posterior predictive trajectories with credible bands.",,
0a97ec94-eaca-48f3-a643-fec64970a558,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Create a Python tool that fits a stochastic SIR model to a provided daily incidence CSV using Particle Marginal Metropolis–Hastings with a bootstrap particle filter, jointly inferring β, γ, initial I0, and a reporting rate under Negative Binomial observation noise. Output posterior samples and 95% credible intervals for parameters plus posterior predictive incidence trajectories to standardized JSON/CSV files.",,
f3efb591-ce31-4e3d-9dd2-cdfc24bf87b2,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Calibrate an SIR epidemic ODE model to noisy incidence data using Bayesian inference (e.g., PyMC/NumPyro with NUTS), estimating transmission and recovery rates and R0. Run multi-chain MCMC to produce posterior credible intervals and posterior predictive trajectories and save a concise summary artifact.",,
614f6820-207d-4174-b4c8-e7457a17a799,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,Build a CLI tool that performs Bayesian inference for a stochastic SIR model using ABC-SMC to estimate transmission and recovery rates from observed daily case counts with an adaptive tolerance schedule. The program outputs weighted posterior samples and posterior predictive simulations for a fixed forecast horizon as standardized CSV files.,,
5502edda-b1b9-43cf-96e8-19772b7f1551,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Bayesian Parameter Estimation,"Implement a CLI tool that calibrates an SIR ODE model to noisy daily incidence via Bayesian inference (PyMC NUTS), estimating beta, gamma, initial infections, and a reporting rate under a Negative Binomial likelihood. The program must run MCMC, compute R0 and posterior predictive trajectories with coverage metrics, and write diagnostics and posterior summaries to standardized output files.",,
cbeb471c-c12a-419c-aab9-670183a0db4c,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Create a Python CLI that ingests a CSV of measurements x, y and their standard deviations, fits an orthogonal distance regression for a linear or nonlinear model, and computes 95% confidence intervals on each parameter using both analytical covariance and bootstrap resampling. The tool must output best-fit parameters, confidence limits, and propagated error bands for predictions in JSON and CSV, plus optional Matplotlib diagnostic plots.",,
50d3f04e-fe80-4a33-9db6-58084a09ed7d,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Implement a Python CLI that reads a CSV containing concentration vs time with measurement uncertainties and fits a Michaelis–Menten kinetic model via weighted least squares. Use Monte Carlo error propagation to compute 95% confidence intervals for the model parameters and predicted concentration curves, then output a JSON summary and a plot with confidence bands.",,
e5caa526-33a6-4785-96a0-ceca5db78077,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Implement a CLI that reads a CSV of 4-parameter Hill dose–response data with uncertainties on both concentration and signal, fits the model via total-least-squares, and computes parameter confidence intervals using bootstrap and Fisher information approaches. Output JSON with fitted parameters, 95% CI bounds, and generate PDF plots of dose–response curves with shaded confidence bands and residual error histograms.",,
95ff534f-5297-43f3-9e76-bbf678adddff,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Create a Python CLI that fits an Arrhenius reaction‐rate model to CSV temperature–rate data via nonlinear regression, estimates parameter uncertainties using both Hessian‐based approximations and bootstrap resampling, propagates these to 95% confidence intervals on predicted reaction rates at user‐specified temperatures, and outputs a JSON summary plus Matplotlib error‐bar plots.",,
b374e907-4abe-41e4-afb9-d79ab3d64068,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Fit a nonlinear Michaelis–Menten model with weighted least squares to enzyme kinetics data, then compute 95% profile-likelihood confidence intervals for Km and Vmax. Propagate parameter uncertainty to a specified substrate level to produce a 95% prediction interval for the reaction rate and emit all interval endpoints in a results file.",,
a6f87fbe-3ee0-4e26-a058-1f0050c931cb,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,Fit a nonlinear Michaelis–Menten model to concentration–rate data and compute 95% confidence intervals for Vmax and Km using both an asymptotic (Fisher information/delta) method and a residual bootstrap. Propagate uncertainty to a prediction at a specified substrate level and write point estimates and interval bounds to a standardized results file.,,
6fd0e8a4-d8cb-4619-981f-64d84688f0f0,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Create a Python script that estimates a 95% confidence interval for the half-life parameter in an exponential decay experiment by fitting a non-linear model with heteroscedastic Gaussian noise and performing both profile likelihood and parametric bootstrap, then propagates the parameter uncertainty to predicted counts at specified times. Load data from /app/data/decay.csv and write a JSON summary with the CI endpoints, bootstrap distribution diagnostics, and predicted interval bands to /app/output/results.json.",,
40ef039a-f829-4989-959b-2b3eb294910b,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Error Analysis & Confidence Intervals,"Implement a CLI tool that propagates uncertainty in Steinhart–Hart temperature estimation: given correlated coefficient estimates (A,B,C with covariance) and a CSV of resistance readings with standard uncertainties, compute 68%/95% confidence intervals for T using both the delta method and Monte Carlo sampling with correlation, and write per-sample intervals plus a JSON summary. Include a simulation mode that generates synthetic datasets from a known ground truth to estimate empirical coverage for both methods.",,
0eb4b9b5-a770-4a06-aa9e-8ab2bd8ab306,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Develop a CLI that loads a time-dependent Python model and parameter ranges from JSON, generates Saltelli samples to compute first-, second-, and total-order Sobol indices at each time step in parallel, and writes time series of indices to JSON and PNG plots. Ensure support for arbitrary model callables, convergence diagnostics, and configurable sampling sizes.",,
0d14c428-5ac7-4530-91cf-8cfed75dfd0f,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Create a Python CLI that estimates Shapley sensitivity indices for arbitrary black-box models using Monte Carlo sampling with user-defined correlated input distributions (via copulas), outputs main, interaction, and total Shapley effects in JSON, and ranks parameters by influence. Support parallel evaluation and allow reproducible sampling via a seed flag.",,
4e8e558a-5068-42fe-b0f9-0df3c76113e9,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Create a Python CLI that loads a black-box model f(x) from model.py and parameter bounds from bounds.json, then computes Sobol first- and total-order indices via Saltelli sampling alongside derivative-based global sensitivity measures (DGSM) via finite-difference gradients. The tool should adaptively increase samples until 95% bootstrap CI widths for S_i fall below a threshold and write indices, CIs, and a consolidated parameter ranking to /app/results.json.",,
b360294b-52ba-4968-a54a-3c1a5dbc9e54,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Create a CLI tool that loads a black-box model from /app/model.py and input distributions from /app/inputs.json, then computes first-order and total Sobol indices via Saltelli sampling and performs Morris screening for comparison. Output a ranked CSV of parameters by influence with bootstrap 95% confidence intervals, and save the exact sample matrices and RNG seed to /app/artifacts.npz for reproducibility.",,
2c417a35-ab30-4035-a676-e95bad45cec3,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Create a CLI tool that loads a black-box model f(x) from /app/model.py (optionally stochastic via a seed argument) and computes first- and total-order Sobol’ indices using a Saltelli design with Owen-scrambled Sobol sequences and common random numbers under a fixed evaluation budget. Output a CSV of indices with bootstrap 95% CIs and a parameter ranking by total-order effect, and include an automated self-test that recovers Ishigami indices within ±0.02.",,
481267c4-3eef-48aa-929c-1104541ab04a,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Implement a Python CLI that loads a differentiable JAX model f: R^d -> R, computes derivative-based global sensitivity measures (DGSM) via automatic differentiation on quasi–Monte Carlo samples, and converts them into provable upper bounds on total Sobol indices using Poincaré constants for Uniform/Normal inputs. Write a JSON file with per-parameter DGSM, total-effect bounds, and a ranking by the bounds.",,
b632ea52-88b6-4750-b4f1-9027c24f201d,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Sensitivity Metrics & Ranking,"Build a CLI tool that computes first- and total-order Sobol indices (Jansen estimator with Saltelli sampling) for a stochastic black-box model f(x, seed) in /app/model.py under independent Uniform priors, using replicate runs and bootstrap CIs to produce a ranked list of influential parameters. The script must be robust to NaNs/infs in model outputs, respect a configurable time budget, and write both the indices with 95% intervals (JSON) and the parameter ranking (TXT).",,
9ba4534f-fa26-4782-9d5f-0bea36aefc2f,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Time-dependent Sobol Indices,"Create a Python CLI that takes a user-defined dynamic model, generates Saltelli sample sets, runs the model across a specified time grid, computes first-order and total-order Sobol sensitivity indices at each time point, and writes JSON metrics and time-series index plots to /app/output.",,
1e4c9e3e-6955-4df9-91e3-0f49bd1310d8,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Build a polynomial chaos expansion (total order 3) using Smolyak sparse Gauss-Hermite quadrature to propagate a 5-D Gaussian input uncertainty through a provided black-box function, returning mean/variance estimates and a surrogate evaluator. Compare the PCE estimates against a Sobol low-discrepancy Monte Carlo reference and report relative errors and sample efficiency.",,
b89acb08-ff7d-4db8-904e-9bd6296e7a6e,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Build a CLI tool that loads a black‑box Python model and a JSON of input uncertainties (marginals plus optional correlation) and propagates them to outputs using both Latin Hypercube Monte Carlo and a sparse Polynomial Chaos Expansion. Report mean, variance, 5th/95th percentiles, and KL divergence between methods, and save the fitted PCE surrogate for reuse.",,
2a43422d-1963-45a9-915a-92fe3dc5a136,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Create a script that reads a JSON file describing correlated lognormal uncertainties for R and C in an RC circuit, then propagates them through the step-response V(t)=V0*(1-exp(-t/(R*C))) to estimate the mean and variance of V(t) over a given time grid using both Monte Carlo sampling and a third-order polynomial chaos expansion. Write per-time statistics and the maximum absolute discrepancy between the two methods to /app/results.json with a fixed random seed for reproducibility.",,
98f7c2f5-51bc-4e4d-b77d-c92445cab660,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Create a Python CLI that ingests a JSON configuration of distribution parameters (mean, variance, type) for a damped harmonic oscillator and performs Latin-hypercube Monte Carlo sampling to numerically integrate the ODE for each sample. Compute statistical moments and 95% confidence intervals for peak displacement and oscillation period, then write a JSON summary and a CSV of selected sample trajectories.",,
2cde2559-b852-4226-ae21-8badfb0c31b4,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Implement a Python CLI that reads nominal parameters and uncertainty distributions for an SIR compartmental model from JSON, propagates these uncertainties through the ODE solver using both Monte Carlo sampling and the Unscented Transform to compute 95% credible bands for S, I, and R time series. It should write time-step quantiles to /app/output/trajectories.csv, summary statistics to /app/output/summary.json, and produce Matplotlib plots of the predicted bands.",,
968f931a-751a-4759-a455-a61dec2b9381,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Create a Python CLI that reads a config of input distributions and a black‐box model in /app/model.py, then builds a sparse polynomial chaos expansion using Smolyak collocation to compute expansion coefficients, propagate uncertainty, and estimate output PDFs. The tool should also calculate variance‐based Sobol indices and cross‐validate results via Monte Carlo sampling, writing all outputs and convergence diagnostics to /app/results.json and /app/log.csv.",,
cea50f44-fe9d-476b-8ea0-1d6dbe67e262,Scientific Computing & Analysis,Uncertainty Quantification & Sensitivity Analysis,Uncertainty Propagation,"Implement a non-intrusive polynomial chaos pipeline that reads a YAML describing independent input distributions and a black-box model CLI, then builds a sparse Legendre/Hermite PCE via stochastic collocation to propagate uncertainty and estimate the output mean, variance, and 5th/95th percentiles. Validate the PCE by comparing its moments against a fixed-seed Monte Carlo baseline and report relative errors.",,
c4ad31f6-602c-4b5f-b293-97d369e162ba,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Cipher Cracking & Weak Encryption Analysis,"Implement a Python CLI tool that recovers text encrypted by an unknown monoalphabetic substitution cipher through simulated annealing over English quadgram fitness, writing the decrypted plaintext to /app/plain.txt and the recovered key mapping as JSON to /app/key_map.json.",,
183a87f3-d349-4f9b-9e8f-2f15e6ac62b6,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,Analyze a stripped x86-64 ELF that validates input using a custom stack-based bytecode VM and simple anti-debug checks. Reconstruct or emulate the VM to recover the exact passphrase that yields 'ACCESS GRANTED' and write it to /app/flag.txt.,,
087716af-222d-487c-b30e-d192082028b9,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,"Reverse-engineer a stripped Linux ELF that embeds a WebAssembly module inside a custom section and validates input by interpreting that WASM; locate and extract the module, reconstruct the check algorithm from its bytecode, and compute the input that makes the program reveal FLAG{...}. Write the recovered flag to /app/secret.txt and note the byte offsets used for the extraction.",,
b08403cb-7599-423e-83b5-bf042b2b16cf,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,"Analyze a stripped x86-64 ELF that embeds a custom bytecode virtual machine for license verification; extract the bytecode and reimplement the VM in Python to compute the correct license without running the binary, writing it to /app/license.txt.",,
3099848a-d3fb-4dbb-81c8-c9979dab4e24,Security & Cryptography,Applied Cryptanalysis & Reverse Engineering,Reverse Engineering Binary Artifacts,"Reverse engineer a stripped x86_64 ELF that decrypts a payload using AES-CTR, where the key and nonce are constructed at runtime from several obfuscated constants. Recover the exact key/nonce and write a CLI tool that decrypts /app/secret.enc to /app/secret.txt without modifying the binary.",,
97762c20-6153-4cfb-a09b-5b210a3aa2a7,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Create a Python CLI tool that implements the OAuth 2.0 Device Authorization Grant against the supplied mock server: fetch and display device/user codes, poll the token endpoint with exponential backoff, handle approval, denial and expiration, securely persist access and refresh tokens, and finally fetch a protected resource, writing the result to /app/output.json.",,
307e6c13-6d38-4d2f-9ac4-cbafa068b4ed,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Patch a vulnerable web API that currently accepts JWTs with alg=none and HS/RS key confusion by enforcing strict RS256 verification against a local JWKS endpoint, validating iss/aud/exp, and implementing key rotation with cache invalidation. Provide CLI scripts that mint a valid token to access a protected endpoint and demonstrate that forged tokens (none, HS-using-public-key, wrong aud/iss, expired) are rejected, writing results to /app/verification.txt.",,
5e756f11-1507-4077-b39d-a17f265482bd,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Create a shell script that installs and configures libpam-google-authenticator for a designated user, updates the SSH PAM configuration to require both a static password and a TOTP code, and generates a provisioning URI plus ASCII QR code in the output directory. Then use pamtester (or expect) with a generated valid one-time password to simulate and verify an SSH login, producing a JSON summary with the provisioning URI, test credentials, and authentication result.",,
362a6d09-e5fd-4ebf-8db1-725069ff51b7,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,Configure OpenSSH in the sandbox to require dual authentication: Ed25519 public key plus a TOTP code derived from /app/mfa_seed.txt via keyboard-interactive PAM. Implement a non-interactive client script that computes the current TOTP and successfully scp’s /secure/flag.txt to /app/result.txt as proof of access.,,
16462757-679a-409a-b431-8a4c6084a100,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Configure an OpenSSH server to require dual authentication: a CA-signed user certificate and a TOTP code via PAM. Generate a user keypair, sign it with a provided SSH CA, seed a TOTP secret for the test user, and prove that SSH access succeeds only with a valid cert plus current OTP while plain keys or incorrect codes are rejected.",,
60852d76-d0ac-4913-ae8d-cc57c23f8928,Security & Cryptography,Authentication & Access Control,Multi-Factor & Token-Based Authentication,"Implement a mock OAuth2 authorization and resource server in Docker, then write commands to register a PKCE client, perform the authorization flow to obtain and refresh a JWT access token, and call a protected endpoint. Save the final greeting JSON response to /app/output.json.",,
210d1b16-4d73-46b2-bfb1-60d89d748be4,Security & Cryptography,Authentication & Access Control,Password Management & Hashing,"Create a shell-based migration utility that converts legacy SHA-1 or MD5 password hashes in a provided shadow-style file to Argon2id with per-user random salts and configurable parameters, writing the updated shadow file and verifying each hash upgrade by simulating user authentication using a provided password list. The script must preserve user metadata, handle unsupported hash formats, and produce a structured JSON report detailing migration successes, failures, and performance metrics.",,
1e713960-d23c-4c07-8937-b13d6b1e6b06,Security & Cryptography,Authentication & Access Control,Role-Based & Policy Enforcement,"Implement UNIX RBAC for a project workspace by creating dev, qa, and ops roles, enforcing a permission matrix with POSIX ACLs (including default ACL inheritance), and adding a sudoers.d rule that lets only ops run a specific appctl restart command without enabling shell escapes or env-based escalation. Provide a verifier that impersonates sample users to confirm read/write/execute behavior, ACL inheritance on new files, and denials for unauthorized sudo or file operations.",,
4ecbd492-e92e-422c-9206-03374033de49,Security & Cryptography,Authentication & Access Control,Role-Based & Policy Enforcement,"Provision role-based access on a Linux host by creating dev, ops, and audit roles with UNIX groups, POSIX ACLs, and sudoers.d policy. Enforce that devs can write to /srv/app/releases but cannot restart services, ops may only sudo systemctl restart app@* without shell escapes or env-based escalation, and auditors can read /var/log/app but not secrets, with default ACLs applied to new files.",,
b2e4b4c0-5161-4dd9-b749-f96546dd2175,Security & Cryptography,Authentication & Access Control,Role-Based & Policy Enforcement,"Develop a Bash script that reads a YAML policy file defining user-to-role mappings and role-based permissions on specified directory hierarchies, then applies and enforces POSIX ACLs with default inheritance under /app/projects. The script must recursively validate current ACLs against the policy, remediate violations, and output a compliance report summarizing each path’s effective permissions.",,
8c14c34a-0417-406f-b358-9c4bbe8d01e5,Security & Cryptography,Authentication & Access Control,Role-Based & Policy Enforcement,"Create a tool that reads a JSON mapping of Unix user groups to allowed systemctl service operations (start, stop, restart) and generates corresponding polkit rule files in /etc/polkit-1/rules.d/. Then run an automated test harness that impersonates each group and verifies enforcement by attempting both permitted and prohibited service commands.",,
1e123cd6-baf8-45a2-b415-de80fb0fad6d,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Implement refresh-token rotation with reuse detection and a centralized, Redis-backed revocation list for a JWT-based API, propagating revocations to all workers via pub/sub. Verify that using a stolen refresh token revokes its entire chain and that rotating the JWKS signing key invalidates only old-key tokens while unaffected sessions continue.",,
15142d11-357d-40cf-a30d-b675bf9bdce1,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Extend a JWT-based FastAPI authentication service to implement session-level revocation using per-token jti entries in Redis with TTL and refresh-token rotation with reuse detection that triggers immediate user-wide logout. Provide a CLI/endpoint to revoke all sessions for a username and verify that revoked access tokens return 401 while new logins succeed, with revocation instantly propagated via Redis pub/sub.",,
7970d045-dce6-427a-b3b0-cdcf9d016949,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Implement a Python CLI that issues HMAC-signed JWT access and refresh tokens stored in a SQLite database, provides commands to list active sessions, revoke specific tokens or all sessions for a user, automatically purges expired tokens, and supports key rotation without invalidating still‐valid sessions.",,
52304d6e-e522-4423-a39e-349287c208f9,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Configure an OpenSSH service to support key-based session revocation by adding a revoke-key command that, given a public key or fingerprint, updates the RevokedKeys file, reloads sshd, enumerates and terminates any active sessions established with that key, and emits a machine-readable report. Verify that future logins with the revoked key are refused while unaffected users remain connected.",,
8fd31457-c3a6-4356-9ae8-cce812d382fc,Security & Cryptography,Authentication & Access Control,Session Management & Revocation,"Develop a Python Flask microservice that issues RS256-signed JWT access and refresh tokens, persists refresh tokens in an SQLite-backed store, and implements an endpoint to revoke sessions by blacklisting token identifiers. Include an automated test script that simulates login, token refresh, logout, and verifies that revoked or expired tokens are rejected with HTTP 401.",,
9382a7d4-1abf-4834-a8dc-0b903eaf7515,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Create a Python script that performs RSA blind signatures: it should blind each message in /app/messages.txt using the provided public key, call /app/signer.py to obtain blind signatures, unblind them, and verify the signatures against the original messages. Finally, output valid and invalid message lists to /app/results/valid.txt and /app/results/invalid.txt.",,
cf9c70d5-b1e3-43d4-b6db-c4ce5c042e53,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Create a Bash script that imports provided GPG public keys and verifies detached .sig signatures for all .tar.gz release archives in /app/releases; do not modify input files. The script must produce /app/report.json listing each archive, signer key ID, and verification status.",,
9b77ca7f-5efa-4f60-8e57-5e760e1d9615,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Implement a CLI tool that verifies OpenPGP cleartext-signed messages (RFC 4880) with correct canonical text handling (CRLF normalization, dash-escaping, and trailing whitespace) against a provided public keyring. The tool scans /app/messages for .asc files and outputs a per-file validity report to /app/verification.json.",,
c4bf7893-cc3e-44d3-a18c-ab0bbcb3eafd,Security & Cryptography,Cryptographic Operations,Digital Signatures & Verification,"Create a terminal CLI that signs artifacts with Ed25519 producing detached .sig files and verifies downloads against a local trust store using a configurable threshold policy (e.g., require 2-of-3 maintainer signatures). Output a JSON report detailing key IDs verified, failures, and overall status, and support key rotation by marking old keys as retired while still validating past releases.",,
d370b5e4-4f5f-47f5-8fb9-993b90378704,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Implement an envelope decryption tool that processes all *.enc files under /app/data: each file begins with a base64 JSON header containing an RSA-OAEP-wrapped AES-256-GCM key and 12-byte nonce, followed by raw ciphertext and tag. Use the PEM private key at /app/keys/priv.pem to unwrap keys, decrypt outputs to /app/dec preserving directory structure, and write a decrypt.log listing any files that fail authentication.",,
be064583-f843-4455-bc7f-0a09e87078cc,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Implement a Python CLI tool for hybrid RSA-OAEPad RSA-OAEP and AES-256-GCM file encryption that takes an input file and an RSA public key, generates a random AES key and IV, encrypts the file with AES-GCM, wraps the AES key with the public key, and outputs a single binary containing the RSA-ciphertext key, IV, tag, and encrypted data. It must also decrypt such bundles with the corresponding RSA private key, verify the GCM tag, and restore the exact original file to a specified path without any extra bytes or metadata.",,
998ca654-7119-4fb8-94d3-0ce0efd027cb,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Build a CLI that performs envelope encryption of a directory using a hybrid RSA-OAEP (recipient key) + AES-256-GCM (data) scheme in a streaming fashion (tar -> encrypt) to produce a single archive.enc with a minimal JSON header. Provide a decrypt command that uses the recipient’s RSA private key to recover the data key, verify integrity, and reconstruct the directory byte-for-byte, failing on any tag or SHA-256 manifest mismatch.",,
131877a7-f792-4780-b99c-7b4c4faadb60,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Create a CLI that performs hybrid envelope encryption for a directory: each file is encrypted with a fresh AES-256-GCM key and nonce, and the key is wrapped for multiple recipients using RSA-OAEP (SHA-256), emitting a per-file JSON manifest with wrapped keys, nonce, and tag. Implement a decrypt mode that accepts any matching recipient private key, verifies tags before writing, reconstructs paths and permissions, and aborts on any authentication failure.",,
b9354cbb-aca1-4819-af20-ea8b286ed47c,Security & Cryptography,Cryptographic Operations,Encryption & Decryption,"Use OpenSSL CMS to implement multi-recipient envelope encryption of a file with AES-256-GCM using both an RSA and an EC certificate, then demonstrate that either private key can decrypt while tampering triggers authentication failure. Automate key/cert generation, encryption, per-recipient decryption, and produce the recovered plaintext and an audit log of verification steps.",,
894abdcb-2690-4777-95fc-3c8c93159fb8,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Create a tool that chunks files under /app/data into fixed-size blocks, computes SHA-256 hashes for each block, and assembles a Merkle tree in a JSON manifest with leaf and internal node hashes. Provide a verification mode that loads the manifest and reports any mismatches, missing files, or tampering.",,
64f7fc06-6590-459f-ba21-2fd88d6397ff,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Build a CLI that creates a chunked SHA-256 Merkle-tree manifest for a directory (e.g., 4 KiB chunks), emitting a root hash and inclusion proofs, and a verifier that can validate a specific file or chunk without re-hashing the entire dataset. The verifier must pinpoint tampered chunks and output a minimal diff (paths and chunk indexes) with expected vs actual hashes.",,
6f9d0379-f709-4eab-a643-75abb2e2e92b,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Implement a Python CLI that loads /app/manifest.json containing file paths, expected SHA-256 hashes, and an HMAC-SHA256 signature, verifies the manifest’s authenticity using the key in /app/key.txt, then computes each /app/data/* file’s SHA-256 and compares it to the manifest. Produce /app/integrity_report.json summarizing verified, missing, modified, and unexpected files.",,
0441ca00-4c3f-4066-88a8-e8ab7439bbd8,Security & Cryptography,Cryptographic Operations,Hashing & Integrity Verification,"Create a Bash or Python script that recursively scans a target directory and splits any file larger than 1 MiB into fixed-size blocks, computing SHA-256 for each block and recording offsets and hashes in a manifest. Provide a verify mode that reads the manifest, recomputes block hashes in the directory, and reports any missing or corrupted blocks per file.",,
9efb5e63-65ae-40a3-b47d-930aedbd81ba,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Set up an SSH Certificate Authority that issues both user and host certificates, configure a local sshd to trust the CA, and prove access requires a signed user cert and a valid host cert signature. Rotate the CA by generating a new key, re-signing credentials, publishing a Key Revocation List for the old CA/host certs, and demonstrate that old certs are refused while new ones succeed.",,
edbca895-df60-47de-a158-6f2a8cf3779f,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Create an offline GPG primary certification key and add dedicated signing, encryption, and authentication subkeys; export a revocation certificate and relocate the primary key to an “offline” store. Implement a rotation that replaces the encryption subkey, updates the public keyring, and proves functionality by signing, encrypting, and decrypting test data using only the subkeys.",,
2a2696b1-b07b-4f38-b094-beae3ff5e52d,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Develop a Bash script that uses OpenSSL to create a root CA and intermediate CA, issue and sign TLS certificates for specified hostnames, revoke a chosen certificate by updating a CRL, and verify certificate chains and revocation status. All keys, certs, CRLs, and verification reports must be organized under /app/pki.",,
bad6c4fa-970a-4cb3-9cf3-06eabe2389cf,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Develop a CLI tool that generates an RSA key pair, uses Shamir’s Secret Sharing to split the private key into N shares with a threshold of M, then reconstructs and verifies the key from provided shares. Store the original keys, all shares, the reconstructed key, and a verification log under /app.",,
9ab3ceed-9364-439a-8e96-5d9e4c648310,Security & Cryptography,Cryptographic Operations,Key Generation & Management,"Build a Bash script that bootstraps a three-tier PKI (root CA, intermediate CA, server certificates) using OpenSSL, issues and signs CSRs for a list of hostnames from a YAML file, generates a CRL and OCSP responder, and rotates the intermediate CA and all leaf certificates on demand. Include tests that validate the full certificate chain, CRL and OCSP stapling responses with openssl commands.",,
d4e950f7-2ccd-48ed-a573-23519d8ed6b2,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Implement a ChaCha20-based DRBG CLI seeded exclusively via Linux getrandom, with a timing-jitter collector for periodic reseeding and online health tests (FIPS continuous test and SP 800-90B repetition/adaptive proportion). Generate 512 KiB of random data to /app/out.bin and a JSON health report with reseed events and PASS/FAIL to /app/health.json.",,
b9a945bf-89ff-4f1f-aaa8-11f277de8fdd,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Implement a user-space entropy collector in Python that samples high-resolution timestamp jitter and per-CPU interrupt counters, pools and whitens the bits via a SHA-512 based extractor, then uses HKDF to expand the seed into a ChaCha20 keystream of N bytes. The script must accept a byte length argument, emit hex-encoded output, and pass a reference SHA-256 hash check on a fixed test vector.",,
1751cafb-fb06-4fe7-ab88-93acc57cfc4e,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Develop a Go CLI tool that collects entropy from at least three distinct system sources (e.g., rdtsc jitter, disk I/O latency, and /dev/urandom), mixes them via a SHA-512–based entropy pool, seeds an HMAC-DRBG per NIST SP800-90A, and writes 4096 bytes of random data to /app/random.bin. It must also produce a JSON report estimating the min-entropy contributed by each source.",,
29b86c07-6fc8-4f97-b444-f85274b6d583,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Build a user-space entropy combiner and CTR-DRBG that gathers timing jitter and kernel getrandom(), applies SP 800-90B on-line health tests to raw samples, and derives output via HKDF + AES-CTR. Provide a CLI that emits N bytes, supports reseed, blocks until a configurable entropy threshold is met, and refuses to reuse state across fork unless reseeded.",,
e73b8a2e-27bc-4f8a-a786-743404278139,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Implement a CLI entropy-mixer that collects bits from getrandom(), optional RDRAND, and CPU timing jitter, combines them via HKDF-SHA256 into a seed, and drives a ChaCha20-DRBG with fork detection and periodic reseeding to emit N bytes. Provide a health subcommand that performs basic randomness sanity checks and refuses to run if only a single untrusted source is present.",,
7391deb5-39b4-4c63-8c90-c2f355016218,Security & Cryptography,Cryptographic Operations,Randomness & Entropy Generation,"Implement a user-space entropy collector that samples CPU timing jitter and other non-blocking sources, conditions them with SHA-256, and seeds a ChaCha20-based CSPRNG with a CLI to emit N bytes to /app/output/random.bin. Include basic health tests (repetition count and adaptive proportion) and persistent reseed state to avoid output reuse across restarts.",,
5e41fb9b-5fe2-421e-b62b-2000cb1b7343,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Given a Linux process core dump produced during an active ransomware run, carve the ChaCha20-Poly1305 master key and per-file nonces from memory and use them to decrypt all samples under /app/encrypted to /app/recovered. Output a machine-readable incident report including the recovered key material, originating PID/command line, and hashes of the decrypted files.",,
ff3fd97c-b009-47aa-9a2e-31f0c9826eb0,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Analyze a Linux RAM dump to locate a shared object mapped from a deleted path or memfd that indicates code injection. Carve the ELF from the dump, save it to /app/output/evil.so with its SHA-256, and report the hosting PID and the suspicious VMAs involved.",,
4a181056-ac64-47fe-a5c9-c5a3db8303c7,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Write a non-interactive script to analyze the provided Windows memory dump, locate the in-memory OLE stream of a malicious Word process, extract its embedded VBA macro to /app/macro.vba and any decoded shellcode to /app/payload.bin. Produce /app/report.txt summarizing extraction offsets, payload sizes, and the method used for discovery.",,
c340770e-de93-4186-8141-d3fbf1fe3491,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Given a Linux process core dump and an AES-CTR–encrypted blob, recover the 32-byte AES key from memory artifacts (e.g., key schedule structures or contiguous hex bytes) and use it to decrypt the blob to plaintext. Validate success by matching the plaintext’s checksum against a provided reference.",,
4136c335-87ee-419d-86a6-a2c6028ed35e,Security & Cryptography,Forensics & Incident Analysis,File & Memory Forensics,"Analyze a Linux memory image to locate a ChaCha20-Poly1305 key and nonce left in a suspected process’s heap, reconstruct them from little-endian 32-bit words, and decrypt /app/capture.enc into /app/plaintext.out. Record the PID and virtual address where the key was recovered in /app/findings.txt.",,
4ea4b856-bac6-400b-ba58-a7b6fa419ffd,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Implement a terminal tool that ingests DNS resolver logs and network flow summaries to detect DNS tunneling exfiltration via heuristics (label entropy, query length uniformity, periodicity) and correlate suspicious domains to source hosts. Output a ranked alert list, a chronological incident timeline, and a JSON file of IOCs (domains, client IPs, first/last seen, estimated bytes).",,
4c5b900c-a23e-4648-a379-2ab0e38af223,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Parse DNS resolver logs (e.g., BIND/Unbound) to detect DNS tunneling by flagging high-entropy, long subdomains with abnormal query/NXDOMAIN rates. Attribute offending client IPs and reconstruct the exfiltrated payload by decoding base32/base64 subdomain chunks into /app/exfiltrated.txt.",,
075f5c82-1e7b-4330-a299-83d895cb9e43,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Develop a script that consolidates and normalizes auth, syslog, and firewall logs, detects SSH brute-force patterns (e.g., ≥5 failed login attempts within 10 minutes) followed by a successful access, then extracts subsequent shell commands and outbound connections, outputting a structured incident timeline and summary of suspicious activity.",,
68358721-240b-49f7-9f57-c11844a4b482,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Analyze BIND9 query logs and system auth logs to detect DNS tunneling via long high-entropy subdomains and elevated NXDOMAIN rates, then identify the tunneling domain, originating client IP, and time window. Write findings to /app/output/report.json and provide a CLI that prints the top 5 suspicious FQDNs with counts based on your heuristics.",,
71930ca4-f050-4228-b633-b2c55bfb5cb4,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,Analyze Suricata EVE JSON and SSH auth logs to detect a DNS TXT-based tunneling session followed by lateral movement via successful SSH login from the same source IP. Output the exfiltration domain and compromised username to /app/findings.json.,,
89a7b728-b20f-4aba-b881-524f0fe1be59,Security & Cryptography,Forensics & Incident Analysis,Log Analysis & Intrusion Detection,"Correlate nginx access.log, /var/log/auth.log, /var/log/cron.log, and syslog to detect a webshell-driven intrusion: identify the initial exploit request and source IP, enumerate compromised accounts via SSH, and reconstruct the timeline through persistence installation and data exfiltration. Write the attacker IP(s), first compromise timestamp, compromised usernames, path and SHA256 of the dropped payload, and the exfil destination to /app/incident_report.txt.",,
b2dfe363-0752-420e-ad2b-c31ee673622e,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Statically and/or dynamically analyze an obfuscated Linux ELF dropper at /app/samples/dropper to recover its behavior and configuration, including persistence mechanism and C2 endpoints. Decrypt the embedded config (XOR key stored in the .note.sec_key section) and write the persistence artifact path, targeted exfiltration globs, and C2 domain:port as JSON to /app/iocs.json.",,
df99c36c-2b10-4baf-8340-91971dc4362d,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,Inspect an obfuscated Linux ELF dropper that persists via /etc/ld.so.preload and exfiltrates data using DNS TXT queries. Recover and decode its embedded C2 domain (XOR+base64) to /app/iocs.txt and cleanly remove the persistence without breaking legitimate binaries.,,
a040d085-ad26-45c8-9407-041bd8303fd0,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Instrument the provided Linux ELF sample under strace to capture file, network, and process syscalls, then reverse-engineer its custom XOR-based C2 protocol by decoding network payloads to extract hardcoded command domains and decrypted beacon messages; output the domains to /app/c2_domains.txt and beacons to /app/beacons.json.",,
4e68152e-0132-421b-99b1-4231ebd4a8c8,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Create a Bash script that executes the provided ELF malware sample under strace and tcpdump in a Docker sandbox to capture all filesystem operations, network connections, and spawned processes. Parse the resulting strace logs and pcap file to produce a JSON timeline of suspicious syscalls, extracted C2 domains, and created or modified file artifacts at /app/report.json.",,
914350d5-c981-405b-92d4-a1e56290c556,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Create a script that takes a Linux ELF malware sample, unpacks it if packed (e.g., UPX), performs static analysis (objdump or readelf) to list imported functions and strings, then runs the binary in a sandbox under strace to capture file, process, and network syscalls. Correlate static and dynamic findings to identify suspicious behavior—such as dropped files, execve calls, and outbound connections—and output a structured JSON report summarizing these indicators.",,
45bb7a55-e6c7-41ef-bbe9-483e5a9ea598,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Perform static and controlled dynamic analysis of a packed Go-based Linux ELF dropper that decrypts its configuration at runtime. Without contacting external hosts, recover and write its decoded C2 endpoints, mutex/campaign ID, and installed persistence artifacts (e.g., systemd unit/timer names or crontab entries) to /app/iocs.txt, and extract the embedded payload to /app/payload.bin.",,
6e0612db-7e43-4745-84f2-74fcf6c6713f,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Perform hybrid (static and controlled dynamic) analysis of a suspicious Linux ELF dropper that conceals its configuration via XOR+Base64 and establishes persistence via a systemd user service, using tools like objdump, strings, strace, and a local network namespace to observe behavior safely. Recover and save the decrypted config, enumerate all IOCs (C2 endpoints, file paths, service names), and produce a concise YARA rule that identifies the sample while minimizing false positives.",,
1d0db37f-dbf3-42ff-bf8d-cb8226658acc,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Analyze a Linux ELF malware sample embedding XOR-obfuscated strings: statically extract the XOR key and deobfuscate to reveal C2 domains and commands. Then dynamically execute it under strace in a sandbox to capture its filesystem modifications and network connections, and output a JSON report summarizing all artifacts.",,
c51adb3f-786c-4b64-ad78-beec2b7b8b7b,Security & Cryptography,Forensics & Incident Analysis,Malware Behavior Analysis,"Create a terminal-based workflow that unpacks a multi-stage Linux dropper (bash + ELF), statically recovers its C2 configuration by deobfuscating an XOR+Base64 blob, and dynamically confirms behavior by tracing syscalls and outbound DNS/HTTP. Output a JSON report listing decrypted C2 domain(s), beacon interval, persistence mechanisms (e.g., ld.so.preload or cron edits), files touched, and any exfiltration paths.",,
6108696c-a523-4dd6-b4bc-cd9fc7287dba,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Correlate Linux auth logs, web server access logs, Docker daemon/container JSON logs, and shell history with partial clock skew to reconstruct a unified UTC timeline of a short-lived breach from initial credential reuse through containerized payload execution to data exfiltration and a log-tampering attempt. Produce a machine-readable CSV including timestamp, event label, actor/IP, and source file, noting any time-skew adjustments applied.",,
f2341e68-f1a8-40ac-95b2-cc4b82f3757a,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Create a CLI that parses rotated nginx access logs, SSH/auth logs, and Linux auditd logs from multiple hosts, auto-normalizes timestamps (timezones, DST changes, and a known 7-minute skew), and reconstructs a single UTC incident timeline from initial web hit to privilege escalation. Output a CSV with sequence numbers, unified timestamps, actor (IP/user), correlated PIDs, and flags for suspected timestomping when file MAC times conflict with process execution events.",,
c9881ff2-5227-4b92-bbf2-6428b6281b8f,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Correlate Apache/Nginx access logs, SSH auth logs, Zeek HTTP/conn logs, and a small pcap with mixed time zones to reconstruct the compromise timeline from first exploit to data exfiltration. Output a UTC-normalized CSV of events and a brief report identifying attacker IPs, exploited endpoint, privilege escalation, persistence, and exfiltration channel.",,
c9b04cb6-29b3-4009-9171-1118ebfd1b1b,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Reconstruct a minute-by-minute timeline of a supply-chain compromise by correlating auditd, apt/dpkg logs, pip metadata, systemd journal, and netflow/pcap artifacts from initial package install to persistence and exfiltration. Output a sorted timeline.csv and a findings.txt naming the malicious package, the first persistence write path, and the exfiltration destination IP.",,
1a883669-d735-4109-b030-54bc237bef62,Security & Cryptography,Forensics & Incident Analysis,Timeline Reconstruction,"Parse /app/logs/auth.log, /app/logs/syslog, and a mounted disk image (/app/disk.img) to extract SSH login attempts, sudo commands, and file creation/deletion timestamps, then correlate these events into a single chronological sequence. Output the reconstructed timeline as JSONL sorted by timestamp to /app/timeline.jsonl.",,
210a6c73-4894-4b9b-9f1f-bdd526e07645,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Compile the provided vulnerable network service and write a Python pwntools-based exploit to perform a buffer overflow with a ROP chain that spawns a shell, then connect to the service, deliver the payload, and retrieve the flag from /app/flag.txt.",,
c713c508-69b2-4562-8ac7-2f34b942909a,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,Exploit a misconfigured JWT verification flow vulnerable to HS/RS algorithm confusion by crafting a forged admin token to access a protected API and read /app/flag.txt. The task validates payload delivery by confirming elevated access and can be extended with a code/config hardening fix.,,
00b3990b-6ed1-404e-849d-60f2dac8f558,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Against a sandboxed Flask web app, identify a server-side template injection sink in a preview endpoint and craft an obfuscated Jinja2 payload that writes /tmp/mark_ssti.txt and exfiltrates http://127.0.0.1:8081/flag to /app/result.txt despite a naive WAF blocking common tokens. Success is validated by the presence of the marker file and the exact flag content.",,
3068fd20-41d2-4887-83b0-f3fc8269b153,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Assess a misconfigured Docker Engine API exposed on localhost by deploying a minimal containerized payload that mounts the host filesystem read-only to retrieve a designated secret. Copy the secret to /app and then cleanly remove all created containers, images, and networks to restore the environment.",,
f31bb7a0-1534-4009-ad1c-48a6d014b3d4,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Exploit a Shellshock vulnerability in a CGI-enabled web service by sending a crafted HTTP header that executes a controlled payload to create /app/pwned.txt and print the effective UID. Then harden the server (e.g., CGI config or shell update) and verify the payload no longer executes.",,
376fea5f-efb0-4884-8b4a-9a0a442ae325,Security & Cryptography,Network & System Penetration Testing,Exploit Simulation & Payload Delivery,"Exploit an unsafe YAML deserialization endpoint in a Python microservice that uses yaml.load on user input to achieve remote command execution. Craft and deliver a payload from the terminal that writes /tmp/pwn1, /tmp/pwn2, and /tmp/pwn3 and verifies their creation.",,
ef864d29-2387-47cd-a582-fea3aafd5cf3,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,"Scan node1 and node2 for open TCP and UDP ports using masscan or nmap, then perform service enumeration (nmap -sV/-sC plus banner grabs with netcat/curl) to capture service names, versions, HTTP titles, TLS certificate CNs, and SSH key fingerprints. Produce a deduplicated, host-and-port-sorted JSON report at /app/scan_results.json summarizing all discovered endpoints and metadata.",,
9bf447aa-010e-4323-92d9-f2983b1fa715,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,Design a command-line workflow that uses masscan for fast discovery and nmap (with select NSE scripts) for deep enumeration to build a complete inventory of open TCP/UDP ports and service metadata across a provided 172.20.0.0/24 sandbox network. The tool should fall back to netcat banner grabs when NSE is inconclusive and write a normalized JSON report to /app/scan.json plus a brief human summary to /app/REPORT.md.,,
9bd5a85f-cf0d-4a66-8cfb-4c4f0f5f3ff6,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,"Create a Bash script that reads CIDR ranges from /app/targets.txt and runs masscan at a user-defined rate to scan the top 500 TCP ports, then parses JSON output to launch nmap service/version scans with default NSE vulnerability scripts. Aggregate all findings into /app/scan_results.json and cross-reference discovered service versions against a provided /app/cve_db.json to generate /app/vulnerability_report.csv listing host, port, service, version, and matched CVEs.",,
e8611445-0649-4099-a8c3-70269a518c97,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,"Scan the provided lab subnet to discover an HTTP service on a non-standard TCP port, an SNMP agent on UDP 161, and a custom binary service on an unknown port. Use nmap (including relevant NSE scripts) and netcat/openssl to enumerate and write the HTTP title, SNMP sysName, and the custom service’s banner to /app/enum.txt.",,
f9adbd14-6587-400a-9039-19bf9f3b9bbf,Security & Cryptography,Network & System Penetration Testing,Port Scanning & Enumeration,"In a dual-stack (IPv4/IPv6) sandbox with multiple interfaces, perform comprehensive TCP/UDP scanning to enumerate open ports, service versions, and TLS SNI/ALPN-based virtual hosts using nmap, masscan, and netcat. Extract a port-knocking sequence from a discovered banner to temporarily expose a hidden management port and produce a structured report of all findings.",,
ae72954f-725c-4725-87a5-874f1685b48d,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Investigate a compromised Linux host to enumerate and validate stealth persistence mechanisms (e.g., a malicious systemd drop-in, cron.d @reboot job, LD_PRELOAD via /etc/ld.so.preload, and an SSH authorized_keys forced-command backdoor), safely neutralize each, and produce a machine-readable report at /app/persistence_report.json. Ensure legitimate services and user access remain unaffected while removing only malicious artifacts.",,
5d87ce3d-b88c-46a3-9b14-de35c4827db4,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Create a Python script that enumerates post-exploit persistence artifacts on a compromised Linux host—scanning systemd services and timers, system and user cron/at jobs, login/profile scripts, and loaded kernel modules—and generates /app/persistence_report.json with metadata (artifact path, type, schedule/trigger, owner) and mitigation recommendations. The script must then safely disable or remove each identified entry idempotently and log all actions to /app/persistence_audit.log.",,
17264c9a-6944-44c2-ad07-ab87728661cd,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"After an authorized compromise of a Linux host, enumerate and analyze multiple persistence footholds including a masqueraded systemd unit, an SSH authorized_keys entry with a forced-command, and a cron job carrying a base64-encoded payload. Decode each mechanism, map it to its on-disk artifacts and startup triggers, generate a JSON report with indicators of compromise, and disable the persistence so it does not survive reboot.",,
b8086ed9-8ca6-407b-a2ef-5f8b5c4dbe03,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Analyze a compromised Linux host that employs layered persistence—a PATH-hijacked systemctl shim, a systemd service drop-in masquerading as a core daemon, an /etc/ld.so.preload hook, and a cron self-healer using immutable files—to identify, validate, and eradicate each mechanism. Produce a machine-readable IOC report (paths, hashes, service/timer names, environment changes) and a verification script that proves persistence does not return after service restarts.",,
c1a9bd92-ea63-4af5-b794-11d25daa865e,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"On a compromised Linux host, locate and neutralize multiple persistence mechanisms (a masqueraded systemd service, an LD_PRELOAD backdoor, and a cron-based beacon) without disrupting legitimate services, then produce /app/findings.json detailing each artifact, removal steps, and verification evidence. Confirm remediation by showing the backdoor no longer injects into sshd and that no malicious systemd timers or cron entries remain.",,
6571ffc6-83d0-4361-9290-9d42c69aa440,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Identify all persistence mechanisms—including hidden cron jobs, tampered systemd unit files, and malicious PAM modules—in the provided compromised Linux sandbox, disable them, and regain a clean shell. Produce a markdown report listing each discovered artifact with its filesystem path, the commands used to neutralize it, and recommended remediation steps.",,
de8fa07d-73bb-4650-90b8-ddf4f297cad0,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"Design an idempotent Bash script that scans a Linux sandbox for seeded post-exploitation artifacts—malicious cron jobs, hidden systemd unit files, rc.local tweaks, and unauthorized SSH authorized_keys entries—and outputs a structured JSON report at /app/persistence_report.json listing each artifact’s type, path, and SHA256 hash. The script must only read from /app_target or container root and must not alter any system files.",,
3a261da6-d5a3-4651-bccc-dbdd7363e4c1,Security & Cryptography,Network & System Penetration Testing,Post-Exploitation & Persistence Analysis,"After a simulated compromise, build a CLI triage tool that hunts for stealthy Linux persistence (systemd timers/units, cron spools, SSH authorized_keys options, and /etc/ld.so.preload), disables any malicious entries safely, and emits a machine-readable remediation report. Validate by proving the planted persistence no longer triggers while legitimate services remain functional.",,
5802ae5e-0d61-4040-b3a6-3077b27f9674,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,"Starting from an unprivileged user, enumerate the host to discover a root cron job that uses tar against a writable directory and exploit tar’s wildcard/--checkpoint-action behavior to execute code as root and write a proof file. Then remediate by correcting permissions and hardening the backup command to use absolute paths and safe options so the escalation path is closed.",,
2c756166-4aa1-4d49-b153-1598ecdd2a6c,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,A sandboxed Linux host includes a misconfigured systemd service that executes a binary from a user-writable directory. Exploit this weakness to escalate to root and write the contents of /root/flag.txt to /app/output/flag.txt.,,
01bb3e61-4fe4-4fa6-9066-a05742744550,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,Provision a Docker sandbox with a misconfigured sudoers rule allowing passwordless execution of a root-owned backup script that uses an insecure TMPDIR and unvalidated PATH. Exploit these flaws to escalate privileges to root and read /root/root.txt.,,
4d86b51a-9dbe-4f6a-b564-b96e3eb2d7f3,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,"Simulate a scenario with a root-owned cron job executing scripts in /app/cron.hourly, where that directory is writable by the user; exploit this misconfiguration by injecting a malicious shell script to obtain root privileges and write the flag to /app/flag.txt.",,
ff6434e6-7e18-46cb-b5c6-8d0d09faea31,Security & Cryptography,Network & System Penetration Testing,Privilege Escalation Simulation,"Develop a Bash script that exploits an insecure root cron job writing logs to a world-writable /tmp path by atomically creating a symlink to overwrite /usr/local/bin/pwn with a root shell payload, then triggers the cron execution and runs the planted script to capture /root/flag.txt into /app/flag.txt.",,
1b195010-4674-43fb-b8bb-042072d62bbe,Security & Cryptography,Network & System Penetration Testing,TCP Idle Scan,"Develop a Python script that performs a TCP Idle scan by selecting an idle “zombie” host, verifying its predictable IPID sequence, then probing a target’s TCP port range and inferring open, closed, or filtered ports from IPID increments. The tool must output a JSON report listing each port’s status and the zombie host’s IPID data used to derive results.",,
b0a78975-16b7-4042-89d4-d384f4cdd1ea,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Harden a Docker Compose application by rewriting its services to run as non-root with read-only root filesystems, drop all capabilities (add back only what’s required), enable no-new-privileges, apply a strict seccomp profile, and set memory/PIDs limits. Validate that the app still functions while attempts to perform privileged actions (e.g., mounting, ptrace, writing to root-owned paths) fail within the containers.",,
7c5d6477-cfd6-43d9-a13e-c136b5c5460a,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Write an idempotent Bash script that hardens the Docker daemon by updating /etc/docker/daemon.json to enable user namespace remapping, set default read-only root filesystem, drop all capabilities except NET_BIND_SERVICE, and enforce seccomp and log rotation policies. The script must restart Docker, launch a test container to verify each setting, and generate a JSON compliance report.",,
8d1a4a32-1024-4878-9571-f8a460898b47,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Develop a CLI utility that audits Kubernetes manifests for insecure PodSecurity configurations—such as containers running as root, missing resource limits, or unbounded hostPath volumes—and produces a hardened YAML with enforced securityContext settings, generated NetworkPolicy templates, and admission annotations, then validates compliance via kubectl dry-run and kubeval.",,
bc088864-bba9-4acb-b17a-cfb161418236,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Harden a Dockerized service to run rootless with user-namespace remapping, read-only rootfs and tmpfs overlays, minimal capabilities (e.g., only NET_BIND_SERVICE), no-new-privileges, custom seccomp/AppArmor profiles, and strict ulimits/cgroup constraints while preserving functionality. Provide a docker-compose setup that blocks 169.254.169.254 and non-whitelisted egress, denies hostPath mounts and Docker socket access, and verifies the container cannot write outside its volume or invoke ptrace/keyctl/mount syscalls while health checks pass.",,
c5968513-3fec-4d40-aba6-b5b07dfeca7a,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Create a Bash tool that ingests a Docker Compose file and emits a hardened override by applying resource constraints, dropping all Linux capabilities, enforcing seccomp and AppArmor profiles, non-root user namespaces, and read-only service filesystems. Finally, run Docker Bench for Security and output the CIS compliance results as JSON to /app/compliance.json.",,
f820d943-7f9d-46eb-843c-df6ec9c3d40e,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Build a CLI that hardens a Docker Compose project by enforcing least-privilege defaults (non-root user, read-only filesystem, dropped capabilities, no-new-privileges, seccomp/AppArmor profiles, CPU/memory limits, and read-only mounts unless whitelisted) and rewrites compose.yaml in place. Provide a verification script that launches the stack and uses docker inspect to confirm each service satisfies the required constraints.",,
f3220ee1-693f-4deb-84c8-fbf2f158d320,Security & Cryptography,Secure Configuration & Hardening,Container & Cloud Hardening,"Harden a Docker Compose-based microservice by running containers as non-root, dropping unnecessary capabilities, enabling no-new-privileges, read-only root filesystems, strict seccomp/AppArmor profiles, and segmented networks with egress allowlists. Implement a policy-as-code linter (e.g., OPA/conftest) that validates the Compose file against these controls, and ensure the project passes the checks.",,
ea5a8641-894e-4d48-82c0-c224c5c66103,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Implement a non-interactive Bash script that scans /usr/local/bin for SUID and SGID executables, verifies each file’s SHA256 checksum against a provided whitelist manifest, and reports any mismatches in JSON format. The script must automatically strip unauthorized SUID/SGID bits and restore tampered binaries from a trusted reference directory under /app/reference.",,
ddb44dc5-3a47-46b5-af90-d34dc1843c51,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Identify and remediate a symlink race in a root-run log rotation script that compresses and moves files from /var/log/app, where an attacker can swap a log for a symlink to clobber or exfiltrate arbitrary files. Harden the rotation by rejecting symlinks/hardlinks and using O_NOFOLLOW-safe moves, then tighten permissions (logs 600, log dir 700) and emit a change report to /app/rotation_hardening_report.json.",,
809ebd0c-a14a-415e-a4f9-15dcf4dd0499,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Audit a multi-user workspace to detect world-readable secrets and symlink-based write-escape hazards in shared paths (e.g., /tmp and a build cache), then implement a fix script that enforces least-privilege permissions and blocks symlink traversal. The solution must harden SSH/GPG key directories and files, set sticky-bit and ownership on shared directories, and ensure artifact writes cannot escape the intended workspace.",,
6a17f0d5-f98b-472b-93f4-0fcd790433a1,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Audit a containerized service for insecure file permissions and symlink misuse: find world-readable secrets and an uploads directory that permits symlink-based writes, then harden by correcting ownership/modes, adding sticky bits where needed, and enforcing least-privilege with POSIX (default) ACLs for the service user. Demonstrate remediation by showing unprivileged users can no longer read the secrets or redirect writes via symlinks.",,
2594fba8-2553-4c25-a8f0-dad37a0bf0b5,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Implement a policy-driven filesystem hardener that reads a YAML policy of expected owners, groups, and modes for specified paths, then audits and enforces them while stripping unsafe SUID/SGID bits and setting sticky bits on designated temp directories. It must detect and refuse symlink/hardlink escapes, correct insecure world-readable/writable permissions on secrets, and emit a machine-readable before/after report of all changes and blocks.",,
f5feee22-f568-4735-8a34-028e59dede46,Security & Cryptography,Secure Configuration & Hardening,Filesystem & Permission Security,"Build a hardening utility that audits and remediates PATH hijacking and temp-dir permission issues: locate world-writable or non-root-owned directories in $PATH, detect user-writable shadow binaries preceding system utilities, and ensure /tmp and /var/tmp have the sticky bit. It must fix ownership/permissions or remove unsafe entries, reorder PATH safely, and emit a before/after compliance report proving that no PATH entry is writable by non-root and that core tools resolve to system binaries.",,
6b493f86-7ef0-465a-b526-72ff725db9b5,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Implement host egress hardening using nftables: redirect all outbound TCP/80 to a local transparent proxy on 127.0.0.1:3128, allow only DNS and HTTPS to the Internet, block cloud metadata IP 169.254.169.254 and RFC1918 destinations, and set default-drop for everything else. Include a verification script that demonstrates allowed and blocked paths and writes a concise report to /app/firewall_report.txt.",,
11f4e2e0-c717-41ae-bf48-bf665632000a,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Using nftables, implement a default-deny egress policy that only allows DNS to the system resolver and HTTPS to a domain whitelist managed as an IP set resolved from /app/allowed_domains.txt, with all other outbound connections rate-limited logged and dropped. Persist the rules in /etc/nftables.conf and provide /app/update_whitelist.sh to refresh the IP set so curl to allowed domains succeeds while others are blocked.",,
0367e0f0-195f-4a26-a0c6-0b7636a75548,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Harden a Linux host with nftables by implementing a default-deny, stateful firewall that permits inbound HTTPS on 8443 to a sample service, rate-limits SSH (5/s, burst 10), blocks all IPv6, and enforces an egress allowlist (DNS/HTTPS) for both the host and a container bridge subnet. Provide a persistent ruleset and a verification script that proves container isolation, denied outbound ports, and rule survival after a ruleset reload.",,
e5d05e25-b0a9-4d95-b58a-e7b3c003a39a,Security & Cryptography,Secure Configuration & Hardening,Network Security Configuration,"Configure a stateful nftables firewall implementing a three-packet port-knocking sequence that temporarily opens SSH (port 22) for the knocking source IP, with automatic timeout and rate-limited logging of denied traffic. Provide idempotent scripts to install and persist the rules, and verify that incorrect sequences or scans never open the port and that access reverts after the timeout.",,
16602a21-e5e2-46da-bc5c-b55baa05f610,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Given an insecure systemd unit file at /app/service/app.service, generate and install a hardened override file under /etc/systemd/system/app.service.d/ that enforces security directives (PrivateTmp=yes, ProtectSystem=full, ProtectHome=read-only, NoNewPrivileges=yes, CapabilityBoundingSet) and applies a basic seccomp syscall filter. Reload systemd, start the service, and write its active status (active/inactive) to /app/output/status.txt.",,
e3c0e7ee-576d-4a1a-9da3-164f29351603,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Create a script that audits all installed systemd service unit files, applies sandboxing directives (NoNewPrivileges, PrivateTmp, ProtectSystem, ProtectHome, etc.) to essential services, disables or masks unused ones, and reloads the daemon. The tool must backup originals, validate service health post-hardening, and output a JSON compliance report with before/after settings.",,
36e735e5-9770-4cf3-b6e0-7c57c9e417d6,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Develop a Python tool that profiles a specified systemd service at runtime (via strace or audit logs) to generate and compile a minimal AppArmor profile, applies and enforces it, and validates enforcement by detecting blocked operations during a controlled test run.",,
ac549346-ae38-4952-97f3-b46e9aaeec77,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Develop an idempotent Bash script to apply CIS-level hardening to a mock LAMP stack under /app by securing Apache (enforcing TLS 1.2+, HSTS, disabling unused modules), tightening php.ini (disabling dangerous functions), removing default virtual hosts, and hardening systemd unit files with dropped capabilities and ProtectHome settings. The script must only modify files within /app, log each action with timestamps, and generate a concise summary report of all applied changes.",,
233ff48e-aaa7-4f55-9858-9ccdf299a659,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Install and harden OpenSSH by creating a non-root deploy user, disabling root and password authentication, enforcing Ed25519 key-only access with modern Ciphers/MACs/KexAlgorithms, and restricting logins to that user via AllowUsers. Prove hardening by successfully logging in to localhost with the key while root/password logins fail, and write the final sshd_config and test results to /app/output.",,
44e2f808-ea81-4bfe-beb2-13fee514e751,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Harden a provided systemd-managed file-sync service by applying systemd sandboxing and least-privilege features (DynamicUser, capability bounding, filesystem and network/address-family restrictions). Verify the service still syncs files while being unable to write outside /var/lib/sync, read /etc/shadow, spawn a shell, or bind to privileged ports.",,
0a4f53d5-2d78-4aea-a5d9-86741c119f0a,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Harden a provided systemd unit for a demo HTTP service to enforce least privilege by using DynamicUser, dropping all capabilities, enabling NoNewPrivileges, sandboxing with ProtectSystem=strict/ProtectHome/PrivateTmp, restricting writable paths, and applying a strict SystemCallFilter. Demonstrate the service still functions on localhost while reads of /etc/shadow, execution of new binaries, and writes outside the allowed directory are denied, then output the final unit and a validation log to /app/result.",,
fb854a74-d297-40ec-bbd6-3e852bb11143,Security & Cryptography,Secure Configuration & Hardening,System & Service Hardening,"Harden a provided systemd service via a drop-in override that runs it as a dedicated user and applies systemd sandboxing (NoNewPrivileges, CapabilityBoundingSet, ProtectSystem=strict, PrivateTmp, ReadOnlyPaths, RestrictAddressFamilies, SystemCallFilter) while preserving its core UNIX-socket functionality. Tests confirm the service still works but cannot read /etc/shadow, write outside its working directory, bind TCP sockets, or retain elevated capabilities.",,
03ee2c89-29b3-482b-a8db-bed18f0d8726,Security & Cryptography,Secure Software Development,Input Validation & Sanitization,"Enhance the provided Node.js Express application by integrating a schema-driven validator to enforce strict type checks, length limits, and disallow prototype-polluting keys on all JSON bodies and query parameters. Supply a suite of malicious and edge-case payload tests verifying that the server rejects or sanitizes inputs correctly without any injection or object overwrite vulnerabilities, and outputs consistent error responses.",,
f7562c37-3310-4f8e-9324-47a8c01d5922,Security & Cryptography,Secure Software Development,Input Validation & Sanitization,"Given a vulnerable C HTTP server that builds SQL queries and file paths directly from user input, patch the code to implement prepared SQLite statements, whitelist allowed file paths, and add robust bounds checking on all buffers. Ensure the modified server compiles without warnings and passes provided tests for SQL injection and directory traversal prevention.",,
409e6daa-ca9e-4f52-a619-4d44bf1eaf9b,Security & Cryptography,Secure Software Development,Input Validation & Sanitization,"Refactor a FastAPI + SQLite microservice that currently builds SQL from query parameters to enforce strict validation and sanitization using parameterized queries and Pydantic validators (types, length limits, regex whitelists), returning 400s for disallowed input. Include a CLI verifier that exercises endpoints to prove SQLi payloads are neutralized while valid requests still return correct results.",,
83de18e0-3d54-4003-8b5b-50f2afff4717,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Identify hardcoded OAuth client secret and JWT signing key in a Node.js service, migrate them to Docker Compose secrets and a .env file with properly generated replacements, and refactor the code and compose config to consume them securely. Add a git pre-commit hook that blocks future secret leaks and demonstrate the app still authenticates and issues tokens using the rotated keys.",,
8122d9b8-7f4f-4b60-b194-60d7582bb0fe,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Create a Git-aware remediation tool that scans the working tree and full history for hardcoded credentials (provider patterns + entropy), migrates them to environment-driven config backed by a local dotenv/JSON store, and rewrites code to use lookups. The script must purge secrets from history, install a pre-commit hook to block future leaks, and emit a machine-readable report verifying no secrets remain and the app runs with injected env vars.",,
95470edd-95d0-4fec-bbde-b15970d9d8c4,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Develop a Bash script that scans the /app codebase for hardcoded AWS or GCP credentials and rotates compromised keys by generating new short-lived tokens via AWS CLI or gcloud. Store the new tokens in HashiCorp Vault, update source files to retrieve credentials from environment variables and configure the CI pipeline (e.g., GitHub Actions) to fetch secrets at build time, then remove all plaintext secrets from the repository.",,
2dc62600-01a3-4791-bad0-674b5afdcda0,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Scan the repository (including full Git history) to locate hardcoded secrets, rewrite history to purge them, and migrate the values into a SOPS-encrypted secrets.yaml secured with an AGE keypair while refactoring code to read from environment variables. Verify by showing the application runs using decrypted env at runtime and that a secret scanner reports no findings in the working tree or history with only the encrypted file tracked.",,
608d0c87-9c99-45d6-ab2e-c5611d5cd7cc,Security & Cryptography,Secure Software Development,Secrets & Key Management in Codebases,"Implement a CLI tool that scans a Git repo (current files and history) for hardcoded secrets matching configurable regexes, extracts them into a JSON vault file, and purges them from history using git-filter-repo. Replace all in-code occurrences with environment variable references, update config loaders, and run the provided test suite to ensure no plaintext secrets remain and secret-loading behavior still passes.",,
5ea054f6-817e-4bc9-9fae-82013d916060,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Implement a non-interactive Bash script that generates a CycloneDX SBOM for a Node.js project, scans its dependencies using npm audit and Snyk, then automatically upgrades any vulnerable packages to the nearest safe release and produces a deterministic JSON report of all detected CVEs and applied updates. The script must also verify each package’s integrity against the checksums in package-lock.json and exit with an error if any integrity mismatch or unresolved high-severity vulnerability remains.",,
1763391d-c61f-40c5-90e8-785c1d869801,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Create a Bash script that audits a Go module for known CVEs using go list -m -u all and go vulncheck, automatically updates dependencies to the lowest non-vulnerable versions, runs go mod tidy, then re-scans to ensure no vulnerabilities remain. Output a summary report detailing each upgrade, the CVEs resolved, and the final vulnerability status.",,
73967541-b97f-427d-aee0-20aa181df35d,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Implement a Bash pipeline that clones a given Git repository, generates a CycloneDX SBOM with syft, scans for high-severity CVEs using grype, auto-updates the dependency manifest to the nearest patched versions, rebuilds and runs the project’s tests, and produces a JSON report comparing baseline vs. remediated vulnerability counts along with the list of upgraded packages.",,
c65a805f-7ec5-4e44-b379-b38eb14d6fb6,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Implement a shell script that uses Syft to generate a CycloneDX SBOM for a Go project, scans for vulnerabilities with Grype, automatically bumps vulnerable module versions in go.mod and go.sum to the latest semver-compatible secure releases, rebuilds the binary, and outputs a summary report of patched modules and any remaining issues.",,
d4a60c04-6a87-4d94-8525-880e702bff61,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Implement a Bash script that generates a CycloneDX SBOM for a Python project using Syft, scans it with Grype against a provided severity policy to identify and filter high-risk CVEs, then pins safe dependency versions via pip-tools and regenerates requirements.txt. The script must output a JSON vulnerability report, the updated requirements.txt, and a Markdown compliance summary.",,
c7c4620f-ea56-4209-bf9b-0fac92fdbe6d,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Scan a Python + Node monorepo with pip-audit and npm audit, then apply minimal safe upgrades via constraints.txt and npm overrides to remove all High/Critical findings and regenerate lockfiles. Output a unified JSON diff of vulnerabilities before/after and enforce deterministic installs with pip --require-hashes and intact npm integrity fields.",,
06cea5da-8b17-4b73-80fe-6b55653f6142,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Audit a Python package that includes a Rust extension (built with maturin) using pip-audit and cargo-audit, then apply minimal semver-safe upgrades via constraints.txt and Cargo.toml updates/patches to eliminate all high/critical advisories without altering CLI behavior. Rebuild the wheel, regenerate lockfiles/SBOM, ensure tests pass, and write a JSON report of remediated CVEs to /app/vuln_report.json.",,
e0fc5d19-30d3-465b-ba21-49ea3115fef0,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"Build a CLI that scans a monorepo’s Python (pip) and Node (npm) dependencies with OSV/pip-audit/npm audit, applies minimal non-breaking upgrades to eliminate high/critical CVEs, and regenerates lockfiles with hash/integrity pins. It must emit pre/post CycloneDX SBOMs, run the project tests to validate the upgrade, and fail the run if vulnerabilities persist or the build is not reproducible.",,
a5456293-28ab-45d6-86f7-096aa274701d,Security & Cryptography,Secure Software Development,Secure Build & Dependency Management,"In a polyglot monorepo (Python, Node.js, and Rust), audit dependencies with pip-audit, npm audit, and cargo audit, then apply the minimal safe upgrades and regenerate lockfiles with hashes. Emit a consolidated CycloneDX SBOM and JSON advisory report, wire a CI script to fail on new critical CVEs, and verify builds and tests still pass.",,
e59e701d-79ea-413f-af68-abce938090ea,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Create a Semgrep taint-mode rule pack that detects flows from Flask request inputs to sqlite3 query execution (SQL injection) and to filesystem access (path traversal), outputting findings in SARIF. Run the scan on a provided Flask app, then refactor to parameterize queries and normalize/whitelist file paths, and re-scan to verify zero findings.",,
a47ebd00-c2c1-4f85-bbd9-67d61f80a278,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Install and run Bandit and Semgrep on a deliberately vulnerable Python microservice, and author custom Semgrep rules to detect ECB mode, static IVs, weak hashes, and subprocess calls with shell=True, then refactor the code to remove all findings. Produce before/after SARIF reports and a CI-failing script that exits non‑zero if any critical issues remain.",,
bf691216-c049-485b-86f2-62937c8a822e,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Run Semgrep (community security rules) and Bandit on a mixed Python/Node codebase to detect command injection, unsafe YAML loading, path traversal, and insecure temp-file/cookie settings. Fix the findings with minimal behavioral change, add a pre-commit and CI configuration that fails on reintroduction, and emit a before/after SARIF or JSON report to /app/output/findings.json.",,
8ddcb3b4-cbdd-4472-a6d6-fbeecbfd3a94,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Build a CLI script that runs Bandit on Python, SpotBugs on Java, and ESLint security rules on JavaScript within a provided multi-language project, converting each report into SARIF format and merging them. Deduplicate findings by file path and CWE ID, then output a prioritized CSV listing severity, location, and suggested remediation steps.",,
90debcb5-2993-458a-b1eb-7b69f7bf17d0,Security & Cryptography,Secure Software Development,Static Code Analysis & Vulnerability Detection,"Author a custom Semgrep rule set that models taint flow across a mixed Python/Node.js codebase to detect untrusted input reaching command execution, SQL queries (string interpolation), and unsafe path joins (zip-slip). Run the rules to produce a SARIF report, refactor the code to remediate all high-severity findings, and re-run to confirm zero remaining issues.",,
1062e2e8-c6e1-4a51-a7d8-ac019906efe0,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Build a lightweight fail2ban-style responder that tails a custom service log, detects credential-stuffing/401-flood patterns via a regex filter, and posts JSON alerts to a local webhook endpoint. On threshold breach, automatically quarantine offending IPs by appending to a persistent blocklist enforced by a provided mock-firewall script, with tests that simulate attacks and benign traffic to verify correct alerting and no false positives.",,
d4e485c0-18cc-4b82-9b96-20601c0bf5a4,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Implement a real-time incident responder that tails auth and HTTP logs, loads YAML rule files defining thresholds over sliding windows, and on matches emits HMAC-signed JSON alerts while executing mapped actions (append IP with TTL to /app/blocked_ips, lock a user, or disable a service) and producing a triage bundle with relevant logs, process tree, and socket info. Validation simulates brute-force SSH and repeated 403s, expecting alert files in /app/alerts, auto-expiring IP entries, and timestamped incident report directories with captured evidence.",,
763f4792-a1a0-4c76-bab9-b1a3b96f4073,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Build a correlation-driven incident responder that tails auth and web access logs to detect account takeover patterns (failed logins from IP A, success from IP B, then privileged action within 5 minutes) and, upon detection, automatically disables the user, revokes sessions, writes a firewall block, and emits both JSON and human-readable alerts with a timeline. Provide an executable CLI to replay logs from files for testing and a stateful deduplication mechanism with auto-expiry of blocks.",,
145d94fb-d48d-4515-afe1-9cdb02448ecd,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Configure auditd to log reads of files under /app/secrets and any subsequent outbound network connection by the same PID, then build a responder that correlates events within 10 seconds, quarantines the executable and blocks its egress via nftables. The responder must also POST a JSON alert to a local webhook and write a detailed incident record to /app/incidents/incident-*.json.",,
d653cf93-071c-4be6-bfb5-8b89a0f6d006,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Create a Python daemon that continuously tails a mock authentication log in /app/var/log/auth.log, detects patterns of repeated failed SSH logins, queries a provided IP reputation REST API, updates a simulated firewall rule file (/app/firewall.rules) to block flagged IPs, and sends alert emails via a fake SMTP server.",,
f760a0e9-ef6d-40d3-9105-cc8ac0f00aeb,Security & Cryptography,Security Monitoring & Compliance,Alerting & Incident Response Automation,"Create a Bash-based incident response tool that watches /var/log/auth.log for SSH authentication failures and aggregates events to detect brute-force attacks, then automatically blocks offending IPs via iptables. The tool must send formatted alerts to a configured Slack webhook and log each incident as a JSON entry in /app/incidents.json with timestamp, source IP, and action taken.",,
3580fee5-9554-4d5f-bdfe-657bd5223b96,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Configure auditd with rules to log modifications to /etc/passwd, user login/logout and Docker exec events, and set up rsyslog to forward these logs securely to a remote server. Run the supplied event generator and verify correct entries were logged and forwarded, outputting a JSON summary of event types and counts.",,
e00b0e8c-712a-4c3b-8720-3ac981f6bea4,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Create an idempotent Bash script to configure auditd with rules for user authentication events, file changes in /etc, and network socket creations, forwarding logs in JSON format over TCP to a local syslog server. Include a test harness that simulates representative events, captures the forwarded logs, and verifies they conform to the expected schema and content.",,
77e47780-d4ca-4d75-87c3-b23b6dbd341b,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Enable persistent journald storage and configure auditd rules to log all execve by uid 0, any chmod that adds setuid/setgid bits, and writes under /app/secure. Validate by triggering events and generate /app/audit_report.json summarizing counts and the latest five matching events from both audit logs and the journal.",,
a1074c0f-bdf5-4827-9845-83eb74f78f01,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Write an idempotent Bash script that configures auditd to log all file access events under /etc, sets up daily rotation for /var/log/audit/audit.log, and enables rsyslog forwarding of audit logs to localhost:514/udp. Simulate an /etc/passwd modification and verify the resulting audit event appears on the remote log endpoint.",,
448955fd-ff07-40f4-81ab-363054d8f1aa,Security & Cryptography,Security Monitoring & Compliance,Audit Logging & Monitoring Setup,"Automate the configuration of auditd to capture execve, file access, and user authentication events, then set up rsyslog to forward these logs over TLS to a remote SIEM endpoint. Generate sample events to validate end-to-end delivery and integrity by querying the centralized log store for the injected entries.",,
202f2ba5-f973-4c48-b372-bd7730ef5a31,Security & Cryptography,Security Monitoring & Compliance,Security Policy Compliance,"Develop a Python script that loads Docker image tarballs under /app/images and evaluates each against the CIS Docker Benchmark v1.2 controls—verifying root user usage, privileged mode, dropped capabilities, read-only root filesystem, seccomp profile, and SELinux labels. The script should output a UTF-8 CSV with columns for image name, control ID, description, and pass/fail status.",,
b641a1c2-b0b4-4d38-9ee7-6ab6f26cb9e1,Security & Cryptography,Security Monitoring & Compliance,Security Policy Compliance,"Build a terminal-based compliance scanner/remediator that evaluates a Debian/Ubuntu image against a small set of CIS Level 1 controls (SSH configuration, password/PAM policy, world-writable files, and root PATH safety), emitting a deterministic JSON report to /app/output/report.json. When invoked with --fix, apply compliant changes idempotently and record a rollback plan at /app/output/rollback.sh.",,
28d7b1b8-89d6-4c9a-9ea1-7b39559c85a4,Security & Cryptography,Security Monitoring & Compliance,Security Policy Compliance,"Build a lightweight compliance tool that gathers Linux system facts to JSON and evaluates them with OPA/Rego policies implementing a subset of CIS Linux controls, emitting both JUnit XML and a human-readable report in /app/report. Provide idempotent remediation scripts for failing checks (e.g., SSH root login, file permissions, password aging), re-run to reach at least 90% passing, and archive before/after evidence.",,
6559562d-fcf2-4337-a721-2fb722c27aff,Security & Cryptography,Security Monitoring & Compliance,Security Policy Compliance,"Implement a Python CLI that validates a minimal CIS Ubuntu Server baseline by auditing password/PAM policy, SSH hardening, key sysctl settings, and world-writable permissions, emitting a structured JSON pass/fail report with remediation guidance. Provide an idempotent --fix mode that backs up affected files and applies compliant configurations where safe.",,
45e08750-7d29-41c6-9b01-a2850f9e1be7,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Implement a Bash script that runs Nmap with version and vulnerability NSE scripts against targets listed in /app/targets.txt, parses the XML output to extract host:port, service/version, and detected CVEs, then produces a JSON report grouped by host and a Markdown remediation guide including issue descriptions and patch links.",,
d8dad229-dd78-4ec9-9f1c-2d19c0eb3318,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Create a script that scans a list of Docker images and live hosts using Trivy and Nmap, deduplicates and correlates vulnerabilities and open ports by CVSS severity, and outputs a consolidated JSON report. Additionally, generate a remediation guide with suggested package upgrade or container base-image update commands for all high and critical issues.",,
2e0d446c-69ce-4aa2-871d-f0051d10163a,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Build a CLI that generates an SBOM for a local project, scans it with Trivy and Grype in offline mode, de-duplicates CVEs, and emits both SARIF and an HTML dashboard. Enforce a YAML-defined policy to suppress known issues and fail on configurable severity thresholds, including recommended fixed versions and dependency paths in the report.",,
c2f1ae62-28b4-4de8-af7d-194d69aa2e7f,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Create a CLI that scans a provided Docker image and its source tree with both Trivy and Grype, merges and deduplicates CVE findings, and emits SARIF plus a concise markdown summary with severity counts and fix-available mapping before/after remediation. Update the Dockerfile and dependency manifests with minimal pinned upgrades to reduce all Critical findings with fixes to zero, then prove compliance by rescanning and writing pass to /app/gate.status.",,
aaa14846-297a-459a-b5f0-115f3ab4a6ed,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Scan a provided Docker image with Trivy, output a CycloneDX SBOM (/app/report/sbom.json) and SARIF findings (/app/report/trivy.sarif), then refactor the Dockerfile and dependency pins to remediate all HIGH/CRITICAL vulnerabilities. Add a .trivyignore entry for a documented vendor-backported CVE, rebuild and rescan to verify zero remaining HIGH/CRITICAL except the ignored CVE, and write a concise remediation summary to /app/report/summary.txt.",,
2a30d8c7-9b9a-416a-acd9-27da92ea136d,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Scan the provided container image tarball at /app/images/webapp.tar using Trivy, output a SARIF report and a CSV listing only fixable High/Critical CVEs sorted by CVSS. Then create /app/output/Dockerfile.patched that updates the base image and pinned packages to remediate all fixable findings without altering the container’s entrypoint or command.",,
f7a50c70-11ae-4c1d-af71-f839e0b2643b,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Scan a provided container image and its running service with Trivy and nmap to generate a consolidated SARIF report, then refactor the Dockerfile and service configuration to remediate all Critical findings and close an inadvertently exposed admin port. Rebuild and re-scan to verify the report shows zero Critical/High CVEs and the admin port is unreachable, saving before/after reports in /app/reports.",,
11f18e54-b73b-45e3-92b1-1c50e80bf9a3,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Develop a Bash or Python script that uses Trivy to scan the supplied Docker image for vulnerabilities, parses the JSON results to extract all high and critical CVEs, and generates a CSV report listing package names, installed and fixed versions, and severity counts. The script should then update the Dockerfile to reference the latest patched base image tag, handle private registry authentication, and log all operations to /app/scan.log.",,
33709d39-90ee-4ab8-becc-78abb240e267,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Create a terminal pipeline that runs Nmap, Trivy, and Nikto scans against a supplied Docker-Compose service, normalizes and filters vulnerabilities by CVSS score, correlates findings with CWE IDs, and outputs both a unified JSON report and a Markdown summary with prioritized remediation guidance.",,
18370c0a-2b4e-4113-8742-8febb825db61,Security & Cryptography,Security Monitoring & Compliance,Vulnerability Scanning & Reporting,"Automate building the provided Docker image and running vulnerability scans with both Trivy and Grype. Merge and deduplicate findings into a unified JSON report sorted by severity, including summary statistics and remediation URLs.",,
20f16c8b-67e4-49ee-8a1d-e50219735343,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Provide a C source for a small application that naively calls printf on user input without a format string and includes a hidden get_flag() function. The agent must compile the binary, craft a format-string payload to leak a stack guard value and then overwrite the return address to invoke get_flag(), writing the recovered flag to /app/flag.txt.",,
98b283da-f4f5-46d2-8b7b-cb0b24f2c6b5,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Provide a C binary with an unsafe printf() call allowing a format-string vulnerability; write a pwntools exploit to leak a libc address, compute libc base, overwrite the GOT entry of exit() with system(), trigger a shell, and write /app/flag.txt contents to /app/pwned.txt.",,
4da51148-a061-461a-89ea-0921ce321aff,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,Exploit JWT algorithm confusion in a Node.js API that mistakenly accepts HS256 for tokens intended to be RS256 by using the server’s public key as the HMAC secret to forge an admin token and retrieve the admin-only secret to /app/secret.txt. Then harden the authentication middleware to strictly enforce RS256 with the correct key material while preserving normal login behavior.,,
eb515b21-ef14-4ad8-adc9-43ba015b234c,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Investigate a C logging daemon with a format-string vulnerability in printf that allows leaking stack memory; craft an input to extract FLAG{...} and write it to /app/flag.txt, then patch the code to use fixed format strings and recompile, confirming normal logging still works.",,
c21686b6-7a6b-4c4b-b1b8-e9101996b0c9,Security & Cryptography,Vulnerability Demonstration & Exploitation,Common Vulnerability Reproduction,"Provide a precompiled C binary with a format string vulnerability in its untrusted printf call and write an automated exploit script that first leaks stack data, then uses the %n specifier to overwrite a GOT entry to invoke system('/bin/sh'), finally reading the flag from /app/flag.txt and writing it to /app/output/flag.txt.",,
161df2d8-205e-434d-b348-c55dd774ac8c,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Provide a vulnerable C server binary exhibiting a format-string bug and stack canary; write a Python pwntools exploit to first leak the canary and libc base, then build a ROP chain calling system(""/bin/sh"") over the network. Include an automated test harness that verifies a remote shell is obtained and the flag.txt is read successfully.",,
a8a0db0d-136b-47fd-8c1a-36e14e1125ad,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,Develop a Python exploit that performs a CBC padding oracle attack against a provided local HTTP service to recover the plaintext of an encrypted session token and forge a valid admin token to access a protected endpoint. Include a concise analysis of the oracle behavior and implement a mitigation that removes the side-channel while preserving normal application behavior.,,
afacca99-c31d-4029-8f06-533994ca632d,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Develop a proof-of-concept exploit for the provided 64-bit Linux ELF binary (with NX, PIE, and stack canary enabled) by first leaking a libc address via a format string bug and then building a ROP chain to spawn a shell. Write the exploit in Python using pwntools to connect to localhost:9001 and output a confirmation token upon success.",,
e90ee934-c464-4a44-9bb6-545ff7cfe949,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Develop a PoC exploit against a sandboxed 64-bit Linux ELF service with a format-string bug in its logging path: leak the stack canary and libc base, then craft a ret2libc/ROP payload that creates three marker files to prove control. Provide an automated script that launches the target, derives offsets under ASLR with NX enabled, delivers the exploit reliably, and verifies the markers.",,
c751a392-d64b-4a03-a69e-24e76e7512a9,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Analyze a hardened 64-bit ELF service to locate a format-string vulnerability, then craft a multi-stage exploit that leaks stack/libc addresses and overwrites a GOT entry to redirect execution to a hidden print_secret() routine. Write the recovered secret to /app/flag.txt after successful exploitation.",,
7dd8a1bf-142d-4d5e-9e85-a49d0abdb560,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,Develop a proof-of-concept that exploits JWT algorithm confusion in a local API by re-signing an RS256 token as HS256 using the service’s RSA public key to forge an admin token and trigger a privileged action that writes /app/pwned.txt. Add brief inline analysis of the root cause and mitigations (algorithm whitelisting and key-type separation).,,
399c3f23-0d3b-4a25-8ecc-105488b63bc4,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Develop a Python pwntools exploit for a remote TCP service with a format-string vulnerability that lets you leak the stack canary and libc base, then craft a ROP chain to spawn a shell, read /app/flag.txt, and write its contents to /app/pwned.txt.",,
6da46b90-93c1-4847-ae0c-90f0d254803f,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Develop a Python exploit script using pwntools to attack a 64-bit ELF binary with NX, PIE, and stack canary. The script must leak the canary and libc address via a format string, build a ROP chain via ret2csu to call system('/bin/sh'), and capture the flag, writing it to /app/output/flag.txt.",,
a2e732c9-2e61-4508-83dc-87be734a51a8,Security & Cryptography,Vulnerability Demonstration & Exploitation,Exploit Development & Analysis,"Analyze a custom C-based CLI notes service with a heap use-after-free bug and develop a minimal exploit that achieves arbitrary read to extract a secret from /app/secret.bin without crashing the process. Then implement and rebuild a hardening patch (e.g., pointer invalidation and allocator checks) that eliminates the bug while preserving normal functionality.",,
6171b9c6-3bfa-4a7c-a36c-65e5e73ec713,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Implement an idempotent Bash script that compiles a provided x86-64 ELF vulnerable to GOT overwrite twice—once unprotected and once with full RELRO and immediate binding—automatically runs the original exploit against both binaries, and writes a JSON report to /app/mitigation_results.json indicating which version is exploitable.",,
f673ebbd-246e-4127-ba57-0d88e041b20d,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Develop a Bash test harness that compiles a supplied buffer-overflow vulnerable C program under varying hardening options (RELRO, PIE, NX, stack canaries) and automatically runs a provided exploit against each binary to detect success or failure. The script should produce a concise report mapping each mitigation flag combination to exploitation outcome (prevented or not).",,
36d53948-c89c-449c-92b1-f05be8b05e69,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Rebuild a provided overflow-vulnerable C service with hardening (stack canaries, PIE, full RELRO, NX) and enable ASLR, then verify each mitigation via ELF/Procfs inspection. Demonstrate that the supplied working exploit succeeds pre-harden and reliably fails post-harden, recording evidence to a verification file.",,
bb605da8-915c-45c0-a87f-8ff6a0fd214b,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Compile and run a vulnerable C program that attempts to execute stack-injected shellcode and a companion probe that records memory addresses across multiple executions. Verify NX and ASLR are effective by confirming the shellcode attempt crashes without code execution and that address layouts vary significantly across ≥20 runs, then output a machine-readable mitigation_report.json in /app.",,
6e59d5e9-e36a-49eb-bd5e-fcf9a9da2bf5,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Build a deliberately vulnerable C service and an automated harness that compiles it twice (unhardened vs hardened with stack canaries, NX, PIE, full RELRO, and FORTIFY), verifies each mitigation via readelf/sysctl, and runs a supplied overflow input. The report must show the exploit succeeds only on the unhardened build while the hardened build safely aborts, failing the task if any mitigation is missing or ineffective.",,
efb21ec2-5c91-49a9-836d-13923f0ffb40,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Build a deliberately vulnerable C binary with a stack buffer overflow, exploit it to achieve code execution on an unprotected build, then rebuild with hardening (ASLR, NX, stack canaries, PIE, full RELRO) enabled. Programmatically verify mitigations via ELF inspection and /proc/sys checks, rerun the exploit to confirm it fails, and output a concise pass/fail report.",,
c105b818-9298-4be3-82ea-09c19551172a,Security & Cryptography,Vulnerability Demonstration & Exploitation,Patch Verification & Mitigation Testing,"Create an automated harness that compiles a deliberately vulnerable C program under four builds (no mitigations, stack canary, NX/DEP, PIE+ASLR), runs a provided overflow exploit, and verifies exploitation only succeeds when the relevant mitigations are absent. The script must also assert mitigation presence via binary introspection (e.g., readelf/objdump symbols, GNU_STACK, PIE) and system checks (/proc/sys/kernel/randomize_va_space), outputting a machine-readable report of flags detected and exploit outcomes.",,
e6f342bf-6ff5-42c3-b73b-ec36097d1486,Security & Cryptography,Vulnerability Demonstration & Exploitation,Privilege Escalation Demonstrations,"Locate a world-writable root cron job script in /etc/cron.d, inject a malicious payload to escalate privileges, and extract the contents of /root/flag.txt. Your exploit should automate modifying the cron script, triggering its execution, and saving the recovered flag to /app/output/flag.txt.",,
36463b63-c17d-437b-acfc-62c2fd1f5cf4,Security & Cryptography,Vulnerability Demonstration & Exploitation,Privilege Escalation Demonstrations,"Simulate a misconfigured SUID C binary in /app/vuln/bin with a world-writable home directory; craft and compile an LD_PRELOAD shared library to hook execve and spawn a root shell, then read /root/flag.txt and write its contents to /app/pwned.txt.",,
fb85ef30-1718-47eb-8b86-07215221b28a,Security & Cryptography,Vulnerability Demonstration & Exploitation,Privilege Escalation Demonstrations,"Starting as an unprivileged user, exploit a sudoers misconfiguration that permits passwordless tar to escalate via --checkpoint-action=exec (or crafted wildcard injection), then prove root by creating /root/owned.txt. Mitigate by tightening the sudoers rule to a safe, argument-pinned form so the exploit is no longer possible.",,
327df3a4-1027-4c0c-b3ce-87ede24f37c8,Software Engineering & Development,Debugging & Issue Resolution,Runtime Error Debugging,"Debug a C++ network daemon that consistently segfaults on the second configuration reload (SIGHUP) due to a use-after-free of a shared configuration object. Reproduce the crash, inspect the core with gdb and run under AddressSanitizer to pinpoint the invalid access, then fix ownership/lifetime and verify that multiple consecutive reloads complete without crashes or leaks.",,
cfc4bc43-abe5-42c5-b412-c1ae17dce573,Software Engineering & Development,Debugging & Issue Resolution,Runtime Error Debugging,"Diagnose and fix an intermittent segmentation fault in a multithreaded C++ application handling JSON parsing, using AddressSanitizer and GDB to uncover data races or use-after-free bugs, then submit a patched version with thread-safe modifications and a brief root-cause report.",,
fc4a9169-f5ef-4176-a03b-ebdbbed815d3,Software Engineering & Development,Development Tooling & Workflow Automation,Build Tool Configuration,"Create a CMake build for a C++ library that generates a version header from git metadata, fetches fmt via FetchContent, and installs exportable targets with both a CMake package config and a pkg-config .pc file for downstream consumption. The harness should build out-of-tree, run ctest, install to /app/dist, then compile a separate consumer using find_package or pkg-config, and verify incremental builds are no-ops and the reported version matches the latest git tag.",,
87874037-b3ff-487a-81ae-14704c4d9ea6,Software Engineering & Development,Development Tooling & Workflow Automation,Continuous Integration (CI) Pipelines,"Write a GitLab CI configuration that first builds a Rust library crate and pushes it to a mock local registry service container, then runs a Python tox test matrix (3.7–3.10) to build and validate a ctypes-based wrapper wheel with a minimum coverage gate and cached dependencies. Finally, on protected branches only, publish generated Sphinx documentation to GitLab Pages.",,
7e768001-145e-43ef-b228-b01e6dd755e0,Software Engineering & Development,Development Tooling & Workflow Automation,Developer Environment Setup,"Write a Dockerfile and VSCode DevContainer configuration that provisions a reproducible x86_64 container capable of cross-compiling and emulating ARM64 binaries via QEMU binfmt support, preinstalled with build-essential, CMake, Ninja, and Git. The environment should automatically register QEMU, compile a sample ARM64 HelloWorld program, and verify it runs correctly under emulation.",,
52b7dc7f-392f-42aa-a473-40bc99466b03,Software Engineering & Development,Development Tooling & Workflow Automation,Developer Environment Setup,"Create a hermetic polyglot developer environment using Nix Flakes that exposes a dev shell with pinned Python (Poetry), Rust (cargo), and Node (pnpm), plus pre-commit and reproducible caches. Provide flake.nix and a Justfile so `nix develop` drops into a non-root shell where `just lint` and `just test` execute the configured tooling.",,
a8b60f64-083f-4e97-8541-c3b04e2e7e5c,Software Engineering & Development,Development Tooling & Workflow Automation,Toolchain Customization & Extensions,"Build a custom clang-tidy module that implements a check (e.g., modernize-avoid-raw-new) to flag and auto-fix uses of new/delete by suggesting std::make_unique/make_shared, and integrate it into a CMake project with a .clang-tidy config and a script to run it on the codebase. Include unit tests for the check and ensure the plugin builds and runs entirely within the sandbox.",,
e4e4aa20-f579-4ca9-9aa3-44fb75f2f3e5,Software Engineering & Development,Feature Implementation & Algorithm Development,Algorithm Implementation,"Implement a KLL streaming quantile sketch with configurable error (epsilon) that supports insert, merge, serialize/deserialize, and percentile queries, exposing both a small library and a CLI that reads floats from stdin and returns requested quantiles. Provide deterministic tests verifying accuracy bounds against exact quantiles on synthetic and adversarial streams.",,
08a44022-5a36-4aec-b2e5-a16aecc775e2,Software Engineering & Development,Feature Implementation & Algorithm Development,API Design & Integration,"Implement an HTTP gateway that exposes a REST+SSE API on localhost:8080 and transparently bridges to a local gRPC service at 127.0.0.1:50051, translating unary and streaming RPCs into JSON and server-sent events. Ensure consistent gRPC→HTTP error mapping, request deadlines via headers, idempotency keys for POSTs, and auto-generate an OpenAPI spec for the REST facade.",,
326a3386-bcfa-43bd-af42-254c11b4bbaf,Software Engineering & Development,Feature Implementation & Algorithm Development,Code Generation & Automation Utilities,"Implement a Node.js CLI named api-scaffold that reads an OpenAPI 3.0 JSON spec and generates Express.js route handlers with Joi validation, corresponding EJS-based controller stubs, a Dockerfile, and a GitHub Actions CI workflow. The tool must support custom template overrides via a --template-dir flag and output a manifest of generated files with checksums.",,
cad24160-0880-423f-8464-9dc4916668e1,Software Engineering & Development,Feature Implementation & Algorithm Development,Code Generation & Automation Utilities,"Create a CLI tool that scans a repository for Dockerfiles and generates a GitHub Actions workflow YAML that builds and pushes a multi-architecture image matrix for each Dockerfile (respecting ARG defaults and build contexts). The tool must validate the YAML, support dry-run and overwrite modes, and output both the workflow at .github/workflows/build.yml and a machine-readable summary report.",,
128a21f6-ff18-443a-ad20-4aa7257f4909,Software Engineering & Development,Feature Implementation & Algorithm Development,Code Generation & Automation Utilities,"Build a CLI that scans a polyglot monorepo (Python, Node.js, Go) to detect service roots and generate optimized multi-stage Dockerfiles and matching .dockerignore files using lockfiles for deterministic caching and stable layer ordering. Provide a validate subcommand that builds each image and outputs a summary of image sizes, cache efficiency, and hadolint violations.",,
1a49683b-971e-4cc8-8a90-54a6445af0c9,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Build a CLI tool that verifies a release artifact by validating a signed checksums manifest (detached OpenPGP signature against a pinned keyring) and, if present, a Minisign/Signify signature, confirming digests across multiple algorithms (SHA-256/512, BLAKE2b), and emitting a fail-closed JSON report with signer identities, algorithms, and timestamps. Handle revoked/expired keys, ambiguous filenames, and newline/whitespace normalization, and return non-zero on any verification failure.",,
d11a5249-8d98-4c32-b57d-d38e813670c7,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Build an offline CLI that signs deployment tarballs with Ed25519 and emits a DSSE JSON attestation (including SHA-256, builder ID, and timestamp), with a keygen and public keyring export. Implement a verifier that enforces a JSON trust policy (allowed keys per release channel, expiry window, and revocation list) and fails on any tampering or policy violation.",,
d220e167-5bf4-4d59-a081-7e791d39eb3d,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Code Signing & Verification,"Build a minimal TUF-secured release flow: generate root, targets, snapshot, and timestamp metadata with a 2-of-3 threshold for targets, sign a target artifact, and implement a client that downloads and verifies the artifact enforcing expiry and key rotation. The verifier must fail on expired metadata, insufficient signature threshold, or tampered targets, and exit 0 only when all checks pass.",,
ff4bcaab-881a-4e9d-ab1e-9e83b08a686a,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Build a CLI that ingests a polyglot repo (npm, pip, and Cargo), parses their lockfiles to map dependencies to SPDX license IDs, and emits a unified SPDX 2.3 SBOM at /app/sbom.spdx.json. Enforce a policy.yaml with allow/deny lists and per-package exceptions plus OSV vulnerability thresholds, verify each dependency’s LICENSE presence or resolvable URL, produce /app/compliance_report.json with remediation suggestions, and exit non-zero on any violation.",,
8b44d798-78ff-4c9c-96ae-36400404753c,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Build a CLI that scans a polyglot monorepo (Python/Poetry, Node/pnpm, and Go modules), resolves all transitive dependencies, normalizes their SPDX license expressions, and enforces an allowlist/denylist with per-package exceptions. The tool must output an SPDX 2.3 SBOM and a deterministic THIRD_PARTY_NOTICES.md with license texts and source URLs, run offline from lockfiles, and ship a CI workflow that fails the build on violations.",,
11a0e7b7-ac24-464b-b5aa-2b2311d9fdcb,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Set up a polyglot repo (Python, Node.js, Rust) with a CI-like script that generates an SPDX SBOM, scans for CVEs and license terms, enforces a policy banning copyleft licenses and high-severity vulnerabilities, and fails if violations are found. Remediate by pinning or replacing flagged dependencies, regenerate lockfiles, and produce a machine-readable compliance report under /app/compliance/report.json.",,
2dc81eaf-8199-4b5c-bd35-cfee9297fc0a,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Implement a shell script at /app/license_checker.sh that loads allowed license identifiers from /app/policy.json; scans Python requirements.txt (using pip-licenses) and Node package-lock.json (using license-checker) to detect any disallowed or unknown licenses. The script must output a colorized compliance summary, emit an SPDX SBOM to /app/dependency.spdx, and exit with a non-zero status on any policy violations.",,
8377c823-c7c2-4c44-b6bc-0b4346794f2a,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Dependency & License Compliance,"Implement a CLI that audits a polyglot repo (Python/Node/Rust) by parsing poetry.lock, package-lock.json, and Cargo.lock to resolve all transitive dependencies offline, extracting SPDX license identifiers from local metadata. It must generate a CycloneDX SBOM and a consolidated THIRD_PARTY_NOTICES.txt, enforce a policy forbidding AGPL/SSPL/GPL-3.0-only and unknown licenses unless explicitly allowlisted, and exit non-zero on violations.",,
f5b9a9aa-92ab-4dfd-b37a-97bcd1dec211,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a Python ResilientKVClient that connects to two Redis instances with idempotent get/set methods, applying exponential backoff with jitter on network errors and automatically failing over to the secondary after five retries while logging each attempt to /app/logs/client.log. Provide a CLI script that reads batch operations from /app/ops.txt, skips malformed lines gracefully, and include a Docker Compose setup to simulate Redis node failures for automated testing.",,
7f522043-b113-4538-a9f8-5e8917474d9c,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Create a resilient HTTP proxy that fronts multiple flaky upstreams, implementing bounded retries with exponential backoff and jitter, a circuit breaker with half-open recovery, and request hedging; when all upstreams fail, serve stale cache entries (cache-aside) and surface structured errors. Add idempotency-key handling for POST requests and a /metrics endpoint exposing success/failure counts so tests can inject chaos and verify graceful degradation and self-healing.",,
3ba41cf3-9336-475e-8f90-a9d22ffa7671,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a crash-safe transactional outbox for a toy Orders service using SQLite and a background dispatcher: persist orders and outbox records atomically, then reliably deliver them to an append-only mock broker with idempotency keys, exponential backoff with jitter, and a retry budget. After simulated crashes and restarts, the system must guarantee at-least-once delivery without duplicate observable publishes and reconcile any in-flight work.",,
db1a1c7a-6678-4555-aa2c-9d048d9d3072,Software Engineering & Development,"Security, Compliance & Reliability Engineering",Reliability & Fault Tolerance,"Implement a Python HTTP client wrapper using the circuit breaker pattern with per-endpoint failure tracking, adaptive exponential backoff with jitter, and half-open recovery trials, emitting structured metrics. Provide a Docker-based Toxiproxy test harness that simulates latencies, timeouts, and failures to automatically validate retry and failover behaviors under load.",,
0922cd72-f1dc-44f0-9b3b-fe8f538d3825,Software Engineering & Development,Software Architecture & Design Patterns,Codebase Architecture Documentation,"Given a polyglot microservices monorepo with docker-compose, build a tool that parses source imports and compose files to generate a cross-service architecture diagram and per-language package dependency graph, emitting Graphviz artifacts and a Markdown overview. The tool must detect cycles and boundary violations and fail CI when found, with tests verifying required nodes/edges and report contents.",,
cc9584b4-b3d6-41c4-a8d3-e8cd32070f15,Software Engineering & Development,Software Architecture & Design Patterns,Codebase Architecture Documentation,"Build a CLI that analyzes a polyglot monorepo (Python, Go, Node) to generate a cross-language dependency graph and a C4 Container diagram, writing docs/architecture.md and SVG diagrams with components annotated by primary git authorship and service boundaries. Include a CI mode that fails on new dependency cycles or components missing ADR links, and provide a deterministic make target to regenerate all artifacts.",,
9c509685-fc23-41d7-8e4d-82b4059ce8ad,Software Engineering & Development,Software Architecture & Design Patterns,Codebase Architecture Documentation,"Create a script that scans a polyglot repo (Python and Node) to generate /app/docs containing a C4-style container diagram inferred from docker-compose.yml, per-service module dependency graphs, and a consolidated architecture README. The script must be idempotent, detect and list circular dependencies, and output diagrams in both Mermaid and PlantUML formats.",,
b87cad9d-d47e-46a1-ad7e-c7d3129757b2,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Create a Python ETL framework with separate modules for extractors, transformers, and loaders, each defined by abstract interfaces in interfaces.py. Implement plugin classes (e.g., CSV and JSON extractors, filter and map transformers, SQLite loader), dynamically assemble pipelines from a YAML config, and verify data flow correctness via unit tests.",,
fb9e1f83-6351-4a6b-b1d3-20123aef8dac,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design a hexagonal architecture (ports and adapters) for a feature-flag evaluation service. Define the domain module and interfaces (FlagStore, TargetingRuleEngine, Evaluator), implement separate adapters for JSON-file persistence and an HTTP query endpoint, and a composition root that wires dependencies while keeping the domain free of I/O or framework dependencies.",,
79a4b5af-5e60-436f-830c-33103e633365,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design and implement a Python-based plugin-driven data processing pipeline with clearly defined modules: a core engine, plugin interface definitions, dynamic loader, and configuration manager, ensuring inversion of control and separation of concerns. Provide a module dependency graph and enforce initialization and teardown order for plugins loaded from /app/plugins.",,
a709b827-3828-4bbd-9523-9c010e00b85b,Software Engineering & Development,Software Architecture & Design Patterns,System & Module Design,"Design a pluggable feature-flag evaluation engine with clean module boundaries: Strategy (targeting/rollout), Store (flag/state persistence), and AuditSink (decision logging) wired via dependency inversion. Define interfaces and data flow, load implementations from a TOML config at runtime, and provide a CLI that evaluates flags for user contexts without the core depending on concrete classes.",,
deaa2d3c-3639-4a28-bea0-268bcc5d1281,Software Engineering & Development,"Testing, Validation & Quality Assurance",End-to-End (E2E) & Regression Testing,"Build a Dockerized E2E and regression test harness that launches a three-service sample app (frontend, API, Postgres) via docker-compose, seeds test data, and runs headless Playwright tests against localhost. Include golden JSON and visual snapshot assertions, collect screenshots/HAR/logs on failure, and provide a single CI-friendly script that exits nonzero on any diff.",,
eafbfb74-2b0b-47d6-a85c-ad370f559eab,Software Engineering & Development,"Testing, Validation & Quality Assurance",End-to-End (E2E) & Regression Testing,"Create a regression harness that runs the same Playwright E2E suite against two app versions (baseline vs candidate) via docker-compose, capturing API response snapshots and page screenshots, then producing semantic diffs and visual diffs in /app/artifacts. Implement retry-based flake detection with automatic quarantine list generation and emit a JUnit XML summary suitable for CI.",,
a8c0d3fd-14c1-442e-a394-9a72226a19e0,Software Engineering & Development,"Testing, Validation & Quality Assurance",End-to-End (E2E) & Regression Testing,"Design an automated cross-version E2E regression harness that spins up vN and vN-1 of a sample service (HTTP + gRPC) with docker-compose, replays recorded interactions, and validates API responses, protobuf/JSON schemas, DB state, and log invariants. Integrate OpenAPI/Buf breaking-change checks and emit JUnit and HTML reports to fail the pipeline on incompatibilities.",,
0ed054b1-03c0-40e6-b96e-ca8cb379bf05,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Create a spec-driven mock HTTP service that reads an OpenAPI 3.0 spec from /app/spec.yaml and deterministically generates synthetic responses from schema examples and constraints, with toggles for error injection, pagination, and rate limits. Include fixtures and a test harness that validate a client’s handling of boundary values, idempotency keys, and retry/backoff behavior using only the mock service.",,
ffe49138-0b6b-4360-bedc-cbf0cbc070c8,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Implement a Dockerized mock payment gateway service that reads a YAML config defining transaction success/failure rates, latency distributions, and error codes, exposing a REST API compatible with Stripe’s charge and refund endpoints. The service should support dynamic behavior profiles and record all request-response logs for integration tests.",,
07ea6a18-584d-4593-84a8-a73c4e1888c0,Software Engineering & Development,"Testing, Validation & Quality Assurance",Mocking & Test Data Simulation,"Implement a Python-based mock HTTP streaming service that simulates an external IoT sensor endpoint by emitting configurable JSON Lines events at a defined rate, supporting custom JSON Schema definitions, timestamp offsets, and injection of controlled anomalies (e.g., missing fields, out-of-range values, or malformed payloads). Provide a CLI that loads schema and anomaly schedules from YAML, writes static fixtures to /app/data/fixtures/, and validates all outputs against the loaded schemas with detailed error reports.",,
10c3a45c-9913-45ea-a455-3db603d91135,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Implement a custom Flake8 plugin that flags calls where the return value of any function decorated with @must_use is ignored, emitting code MUU100 at the call site. Register the plugin and provide a script that runs flake8 on /app/src and writes a SARIF report to /app/lint.sarif.",,
5766aa18-13d0-4c6f-9f9b-f7c2780a3124,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Create a Dockerized CLI tool that scans the /app/src directory with flake8 (using a provided flake8.ini), mypy (strict mode), and a custom regex-based linter for banned patterns (e.g., TODO comments or print statements), then aggregates and classifies all findings into /app/report.json with per-file, per-tool violation counts and severities. The script should exit with code 0 if no violations are found or with the total count of violations otherwise.",,
7aa66e6b-b740-4f81-b0ed-15faf05c7d1f,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Create a custom Flake8 plugin that identifies Python functions using mutable default arguments, package it as an installable module, configure .flake8 to enable the rule, and run the linter on a sample codebase to produce a JSON-formatted report of all violations.",,
49e4384d-fc73-4fa3-a1f7-8da412868133,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Implement a custom flake8 plugin that flags functions and methods using mutable default arguments (lists, dicts, sets, and comprehensions), supporting per-line noqa and exemptions for dataclasses field(default_factory=...). Integrate it via setup.cfg, run it over a small Python package with seeded violations, and make the codebase pass with a combination of fixes and justified ignores.",,
aabfa929-e0d7-450b-89e5-8b9629cc9348,Software Engineering & Development,"Testing, Validation & Quality Assurance",Static Analysis & Linting,"Create and integrate a custom Flake8 plugin that flags timezone-naive datetime usage, mutable default arguments, and broad exception handlers in a small Python repo. Configure pyproject.toml so flake8 (with the plugin) and mypy --strict both run clean after refactoring the code to satisfy all checks.",,
0bfd1a83-20c7-4a21-8dce-1e3b659f0728,Software Engineering & Development,"Testing, Validation & Quality Assurance",Unit & Integration Test Implementation,"Write a comprehensive pytest + Hypothesis suite for an existing Python CRDT library (e.g., LWW-Element-Set and OR-Map) that verifies merge algebra (commutativity, associativity, idempotence), serialization round-trips, and tombstone semantics. Tests should generate randomized concurrent operation sequences across multiple replicas, simulate partitions and merges, and assert eventual consistency and order-independence in end-to-end scenarios.",,
c4aa144c-109e-4cb0-b365-089b5e05507a,Software Engineering & Development,"Testing, Validation & Quality Assurance",Unit & Integration Test Implementation,"Implement unit tests for a timezone-aware recurring event scheduler to verify next_occurrence and occurrences_between across DST forward/back transitions, month-end rollovers, and timezone changes using IANA zoneinfo and frozen time. Add integration tests that run the provided CLI against a fixtures.yaml of recurrence rules to assert deterministic outputs and round-trip serialization across multiple timezones.",,
287c3a89-6997-42aa-90dc-92a9ad155c10,System Setup & Configuration,Filesystem & Storage Management,Backup & Snapshot Management,"Configure borgbackup to create encrypted, deduplicated incremental snapshots of /etc and /home to a remote SSH repository, schedule backups with a systemd timer, and implement automatic pruning per hourly/daily/weekly retention policies. Verify backup integrity by performing test restores and logging checksums of restored files.",,
bd94ead8-01a3-4b03-9f0e-a82880ed7c3c,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Provision a 3 GiB loopback disk image and partition it with GPT into: 512 MiB EFI System (vfat, label EFI), 2 GiB Linux filesystem (ext4, label DATA), and the remainder as Linux swap. Format and label each partition, mount EFI at /mnt/efi and DATA at /mnt/data, enable swap, and persist the setup using PARTUUID-based entries in /etc/fstab so all mounts reattach correctly after unmounting and remounting.",,
6e480bdd-208b-42e5-be16-078b6db251c9,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Provision an encrypted LVM-on-LUKS volume backed by a sparse loop device: create a GPT partition on the loop device, initialize it with LUKS using a keyfile, build a VG with two LVs (data and logs), format, and mount at /srv/secure/{data,logs}. Persist the setup via /etc/crypttab and /etc/fstab using UUIDs so it can be unlocked and mounted non-interactively and verified with mount -a after reattaching the loop device.",,
9fd87047-ef14-487d-b9e2-e2af0b5ac889,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Simulate two new block devices with loopback files and create an mdadm RAID1 array, then partition it into /boot and /root ext4 filesystems, mount them under /mnt, and persist in /etc/fstab. Next, simulate a disk failure, remove and re-add the failed device, rebuild the array, and verify filesystem integrity post-recovery.",,
eb6fc5eb-d33e-4e22-9157-68a176047207,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Create a 3 GiB sparse file as a loop device, partition it with GPT into two volumes (512 MiB ext4 labeled DATA and the remainder as a LUKS-encrypted XFS labeled SECRET) and set proper labels/UUIDs. Configure /etc/crypttab and /etc/fstab to unlock and mount them at /mnt/data and /mnt/secret by UUID, then verify persistence by detaching/reattaching the loop device and remounting without using device paths.",,
142e2dda-b1b9-4bde-b827-d598f6a26a91,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"On a blank block device, create a GPT partition layout with a BIOS boot partition, an EFI system partition, and an LVM physical volume; format and mount the /boot and EFI partitions, initialize LVM to create separate root and swap logical volumes, then configure /etc/fstab using UUIDs and activate swap. Verify that partitions, LVs, and mounts persist across simulated reboots within the Docker sandbox.",,
edcf8b8e-4263-4459-a455-3fff222f7c2b,System Setup & Configuration,Filesystem & Storage Management,Disk Partitioning & Mounting,"Simulate two disks using loopback files, build an mdadm RAID1 array, partition it into a small ext4 boot and larger XFS data slice, format and mount them under /mnt/boot and /mnt/data, add persistent UUID-based /etc/fstab entries, and verify mounts on reboot. Then simulate a drive failure by detaching one loop device, rebuild the array, and confirm recovery and data integrity.",,
029d5c66-f132-48ec-87fe-24489ae31052,System Setup & Configuration,Filesystem & Storage Management,Filesystem Permissions & Quotas,"Create a loopback-backed XFS volume mounted at /mnt/projects with project quotas enabled, defining project IDs for team-a (200 MiB) and scratch (50 MiB) and enforcing hard limits. Configure a shared dir with setgid and default POSIX ACLs for group inheritance, a scratch dropbox with the sticky bit, and a logs dir marked append-only via chattr, then verify quota and permission behavior with automated writes.",,
df5b593a-49a7-4f37-9826-0274fe96296b,System Setup & Configuration,Filesystem & Storage Management,Filesystem Permissions & Quotas,"Enable XFS project quotas on /mnt/shared to limit each project group to 10 GB with 80% and 9 GB warning thresholds, apply default POSIX ACLs for group inheritance, and automate daily quota reports via cron. Verify enforcement by simulating over-quota writes, capturing error messages, and reviewing generated reports.",,
207aa28b-9150-40a9-98f0-b4867209bde7,System Setup & Configuration,Filesystem & Storage Management,Filesystem Permissions & Quotas,"Create a loopback-backed XFS filesystem mounted at /mnt/projects with pquota enabled and configure project quotas for two directories (/mnt/projects/build-cache and /mnt/projects/datasets) via /etc/projid and /etc/projects, setting soft/hard limits of 500MB and 1GB with a 7-day grace period. Apply setgid and default ACLs so group 'research' has rwx on both trees, then verify quota enforcement with xfs_quota reports and writes that exceed the limits.",,
4373f014-8fe7-453a-a5c9-a81c4e74be7d,System Setup & Configuration,Filesystem & Storage Management,Filesystem Permissions & Quotas,"Enable and configure project quotas on an XFS partition mounted at /srv/projects to enforce a 10G limit per team directory. Set default POSIX ACLs so new files grant rwx to the ""developers"" group and apply the immutable attribute via chattr to archived logs, verifying quota usage, ACL inheritance, and immutability with CLI tools.",,
1fd00472-e5d5-4c39-bed0-02b4b8e3a10d,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Configure nftables to enforce a default-deny host firewall with stateful rules. Allow loopback/established traffic, port-forward 80→8080 to a local service, restrict SSH on 2222 to 10.0.0.0/24 with rate limiting, block outbound SMTP except to smtp.example.net, log drops with prefix TB-FW, ensure persistence across reboots, and verify behavior over IPv4/IPv6 with curl/nc tests.",,
bd7b02ae-4269-4fb9-99e4-040de5aa83bf,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Implement a dynamic nftables-based firewall that integrates with ipset to automatically fetch and apply daily blocklists from an external threat feed via a systemd timer, dropping all incoming traffic from malicious IPs. Configure rules to allow HTTP/S and SSH with rate limiting, log dropped packets, rotate logs via logrotate, and verify blocklist updates and traffic enforcement.",,
3d98e563-13cd-48cc-98c3-7af15136e402,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Configure firewalld with three zones (trusted, dmz, public), assign interfaces eth0 and eth1 appropriately, allow SSH and HTTPS-mTLS only in trusted, allow DNS in dmz, block all in public, and add a rich rule to rate-limit HTTP to 20 connections per minute. Enable info-level logging for dropped packets and verify the configuration using firewall-cmd status checks and simulated traffic with curl and netcat.",,
c86ca43f-0916-4fae-9d23-009390d6fcc4,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Configure nftables to enforce a host firewall with default drop on inbound traffic, allowing established/related and loopback, permitting HTTP/HTTPS to a local nginx, and opening SSH only after a correct 3-step UDP port-knock (1111→2222→3333 within 10s) with rate-limited access. Make the rules persistent across reboots and include a verification script that demonstrates SSH is closed before knocking, opens for 30 seconds after the sequence, then automatically closes again.",,
196bf81f-401f-4f8b-a2db-89dd90266f7b,System Setup & Configuration,Networking & Connectivity,Firewall & Security Rules,"Configure a host-wide nftables firewall with default-drop policy using inet and ip6 tables: allow established/related, loopback, necessary ICMP/ICMPv6 (ND, RA, RS, PTB), and open SSH (22) and HTTP (8080) only on IPv4, with rate-limited new connections. Make the rules persistent across reboots and enable logging of dropped packets to /var/log/nftables-drop.log; verify IPv4 HTTP works while IPv6 HTTP is blocked and ICMPv6 neighbor discovery still functions.",,
d2d54798-1a7e-4591-b30c-a2aa0ff03b63,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Configure a multi-homed Linux host with two network interfaces, each assigned a static IP and default gateway, then implement policy-based routing using ip rule and ip route so traffic from each source address uses its respective gateway. Configure per-interface DNS servers via systemd-resolved or netplan and validate correct routing and name resolution with traceroute and dig tests.",,
133f7c2e-6b3c-4d4e-a0f5-3126ffcbf3ab,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Create three network namespaces (ns1, rtr, ns2) connected by veth pairs, assign dual-stack IPv4/IPv6 addresses, enable forwarding and policy routing on the router, and run dnsmasq to provide DHCPv4, SLAAC/DHCPv6, and DNS. Verify both hosts obtain leases, resolve a custom domain, and reach each other through the router.",,
944595c0-1a1f-41f6-ba10-31e4c9d7a9d5,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Using iproute2 and network namespaces, build a routed lab with three namespaces (hostA, router, hostB): create veth links, assign static IPv4/IPv6, configure per-namespace DNS via a dnsmasq bound to the router, add policy-based routing and default routes, enable IPv4 forwarding/NAT on the router, and verify end-to-end connectivity and name resolution.",,
0f3e983b-da8d-4f24-904b-c4d729226568,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Configure two Ethernet interfaces into an active-backup bond with static IPv4 and IPv6 addresses, create a VLAN-tagged bridge on top for a VM network, add custom routing tables for policy-based routing, and verify connectivity using ping and traceroute.",,
ae61f5a1-f80d-4f71-8731-216ce3f7ce67,System Setup & Configuration,Networking & Connectivity,Interface & IP Configuration,"Configure a Linux bonded network interface (bond0) in active-backup mode using two physical NICs, assigning a static IPv4 address and default route. Simulate NIC failure by toggling link state, verify uninterrupted connectivity via ping, and extract syslog entries confirming failover events.",,
7eb31b56-ab48-4016-9822-fdccbfc2e2c7,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Create a three-namespace topology (client-router-server) where the router drops ICMP Fragmentation Needed, producing a PMTU blackhole that causes HTTPS requests to hang. Use ping with DF, traceroute, and tcpdump to confirm the issue, then fix it by enabling TCP MSS clamping (or lowering MTU) on the router and verify curl completes successfully.",,
2b665dea-1931-4c3e-b6d0-f8a8eb6529de,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Simulate a Path MTU black‐hole by creating two Linux network namespaces connected via a veth pair with ICMP fragmentation-needed messages dropped, then use ping, tracepath, and tcpdump to detect the MTU mismatch and restore connectivity by adjusting MTU or enabling ICMP responses.",,
169545f2-c1c5-4af3-a3b4-b1a2d1ec9eb2,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Create two Linux network namespaces connected by a veth pair with mismatched MTUs, then diagnose failed ICMP and TCP traffic using ping, tracepath, and tcpdump to identify fragmentation issues. Adjust MTU and apply TCP MSS clamping to restore end-to-end connectivity and verify resolution.",,
d01fd323-0d75-4d67-a15e-8d6ed6b1ec94,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Diagnose and fix stalled large file downloads caused by PMTU blackholing: use tcpdump, tracepath, and curl to confirm ICMP “Fragmentation Needed” is being dropped and that the interface MTU is misconfigured. Restore connectivity by allowing the required ICMP through iptables and/or clamping TCP MSS, then verify the transfer completes.",,
f1eff590-26f5-4ab9-b3c1-05dc6b91d885,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Simulate and diagnose a path MTU black hole using Linux network namespaces by creating a multi-hop topology with mismatched MTUs and blocking ICMP “Fragmentation Needed,” causing large TCP transfers to stall. Use ping with DF, traceroute, tcpdump, and curl to pinpoint the issue, then fix it by allowing ICMP or applying TCP MSS clamping and verify sustained transfers succeed.",,
780e2d0c-c0ce-435b-be5b-737e448b66f7,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Build a three-namespace topology (client–router–server) with mismatched MTUs and ICMP “Fragmentation Needed” filtered, then diagnose a stalled TCP connection using tracepath/ping and tcpdump to pinpoint a PMTU blackhole. Fix the issue by permitting ICMP or enabling TCP MSS clamping and verify successful HTTP transfer end-to-end.",,
5573c684-54e7-4aa0-9648-187a616d47ac,System Setup & Configuration,Networking & Connectivity,Network Diagnostics & Debugging,"Create three network namespaces (client, router, server) linked by veth; drop ICMP 'Fragmentation Needed' on the router to simulate a PMTU black hole that causes HTTP transfers to hang. Diagnose with ping -M do, traceroute, ss, and tcpdump, then fix by enabling TCP MSS clamping on the router and verify a large curl from client to server succeeds.",,
08aad376-2611-4650-8703-4add474778e8,System Setup & Configuration,Operating System Configuration,Environment Variables & Profiles,"Create a unified environment manager that reads variables and PATH entries from ~/.config/envvars.yaml and generates shell-agnostic snippets sourced by both Bash and Zsh for login, non-login, interactive, and non-interactive sessions. Provide an envsync command to rebuild the snippets and verify PATH precedence, LANG/LC_ALL, and HTTP(S)_PROXY/NO_PROXY persist across new shells and subprocesses.",,
d6fa2944-e3fa-4b51-b308-e32fa0109432,System Setup & Configuration,Operating System Configuration,Environment Variables & Profiles,"Use direnv and Mozilla SOPS to implement per-directory encrypted environment variables: when entering a project directory, the .env file is decrypted and loaded into the shell automatically, and unloaded on exit. Provide a bootstrap script to install and configure direnv in the user’s shell profile, import the GPG key, and verify that decrypted secrets are never stored on disk in plaintext.",,
5764305d-f3c2-4f75-b765-605fed2a610f,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Define two custom systemd slices with distinct CPU and memory cgroup v2 limits, then assign a long-running batch job and an interactive shell to each slice. Validate resource isolation by executing stress tests and monitoring usage via systemd-cgtop.",,
5f49833d-16d3-47e2-9a11-7bee51c68cd0,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Define and enable a custom systemd slice (bench.slice) with cgroup v2 limits (CPUQuota=40%, MemoryMax=512M) and a service (bench-workload.service) bound to it that runs a CPU/memory stress script with Restart=always and hardened sandboxing. Add a systemd timer to schedule the workload every 5 minutes, log output to /var/log/bench-workload.log, and verify enforcement by inspecting cgroup stats for CPU throttling and memory limits.",,
902f9a89-7fe4-41fd-9405-602f9cb61b95,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Create a sandboxed systemd service and timer that runs a worker script under cgroups v2 with CPUQuota=40%, MemoryMax=200M, CPUAffinity pinned to one core, TasksMax, and hardening options (NoNewPrivileges, PrivateTmp, ProtectSystem=strict), logging to both the journal and /var/log/worker.log. Enable and verify the limits by starting the unit, inspecting cgroup metrics, and demonstrating the timer’s persistence and randomized delay.",,
e0f98e9b-29a3-46b3-8ea8-70011b714d34,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Create a cgroups v2-backed systemd slice (tb-limited.slice) enforcing CPUQuota and MemoryMax, run a resource-hungry service (e.g., stress-ng via tb-hog.service) within it, and schedule it with a systemd timer that adds a randomized delay. Verify enforcement by observing throttling/OOM-kill behavior, automatic restarts, and corroborating logs via journald and systemd-cgtop.",,
d05b1315-2326-4510-9431-d360946531bb,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Create a dedicated cgroup v2 slice (batch.slice) and a templated systemd service (batch@.service) that runs a CPU/memory-intensive script under strict limits (CPUAffinity to specific cores, CPUQuota=25%, MemoryMax=150M, TasksMax=32) with automatic restart on OOM. Trigger it via a systemd timer every 2 minutes and verify via cpu.stat/memory.events that throttling and OOM handling occurred, with logs persisted to /var/log/batch/.",,
11802224-fc07-4300-86fd-906c1cc785fe,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Configure two systemd slices named high-priority.slice and low-priority.slice with distinct CPU and memory share settings. Migrate selected long-running processes into each slice, simulate load with stress-ng, monitor resource allocation via systemd-cgtop, and generate a report demonstrating enforced isolation.",,
77d29579-db9e-4403-88ba-2c70f5d29d78,System Setup & Configuration,Operating System Configuration,Process & Resource Management,"Create a systemd slice and templated service constrained by cgroup v2 (e.g., CPUQuota and MemoryMax) and trigger it via a Persistent=true systemd timer to run periodic batch jobs. Verify scheduled execution, enforced resource limits, automatic restart-on-failure behavior, and logs accessible with journalctl.",,
62f21a46-fc60-4a31-b7fa-38008f66e763,System Setup & Configuration,Operating System Configuration,System Parameters & Kernel Settings,Configure persistent kernel core dump handling by setting kernel.core_pattern to pipe to a custom collector script that stores and compresses cores under /var/lib/cores with metadata. Create and enable a systemd service that runs a small crashing test binary with LimitCORE=infinity to verify capture and persistence across reboots.,,
772dfc83-de7c-4c47-b0ce-a884e79983fc,System Setup & Configuration,Operating System Configuration,System Parameters & Kernel Settings,"Configure system-wide core dump handling by setting kernel.core_pattern to pipe crashes into a custom /usr/local/bin/core_collector that compresses dumps under /var/cores with metadata, and disable systemd-coredump while enforcing fs.suid_dumpable=0. Persist ulimit core=0 for all users except a dedicated systemd service that overrides to unlimited, then verify by crashing a test binary from both contexts and confirming only the service produces a compressed core in /var/cores.",,
4b436016-0623-4573-9625-9d0e9f32a817,System Setup & Configuration,Operating System Configuration,System Parameters & Kernel Settings,"Configure kernel boot parameters and sysctl to isolate CPU cores and enable real-time scheduling for low-latency workloads, set ulimit and cgroup limits for RT priority, then benchmark with cyclictest to verify reduced latency and produce jitter statistics.",,
3cbd9e77-56bd-4dc9-b009-180991591b91,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Create a sample memory-leaking C service managed by systemd, configure persistent journald storage and rate limiting, then simulate high load to trigger an OOM kill. Use journalctl and coredumpctl with GDB to analyze the cause, and update the unit file with watchdog and auto-restart directives to demonstrate automated recovery.",,
88d601ca-e940-4baf-b50a-948bcd031fba,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Create a socket-activated systemd service (myapp.socket/myapp.service) for a simple HTTP server that initially fails to start, enable persistent journald storage, and use journalctl to pinpoint the root causes (bad WorkingDirectory and missing RuntimeDirectory). Correct the unit (User/Group, WorkingDirectory, RuntimeDirectory, LimitNOFILE), set journald rate limiting, and verify the socket serves 127.0.0.1:8080 with clean, non-repeating logs.",,
28322208-14f4-4b84-b222-f497bd3ba883,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Debug a crash-looping systemd service 'img-resizer.service' by inspecting journald and its app logs to pinpoint failures caused by PrivateTmp and a missing RuntimeDirectory (socket at /tmp/img.sock and unwritable log path). Fix the unit to use /run/img-resizer via RuntimeDirectory=, correct User/Group and dependencies, reload systemd, and confirm the service stays active and the UNIX socket handles a test request.",,
b0cb7a54-fc6f-40bc-aea4-329e421c53c4,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Debug a systemd unit 'imgsvc.service' that crash-loops on startup: journald reveals 'listen tcp :80: bind: permission denied' and write failures due to DynamicUser=yes. Update the unit to grant AmbientCapabilities=CAP_NET_BIND_SERVICE and define a RuntimeDirectory with correct permissions, then verify it binds to 0.0.0.0:80 and runs cleanly with logs visible in journald.",,
074016bf-330d-43be-9c9f-c675d18771ec,System Setup & Configuration,Service & Daemon Management,Log Monitoring & Service Debugging,"Create a systemd service and timer that runs a backup script every minute, where the initial run fails due to a missing WorkingDirectory and permission errors. Use journalctl to diagnose the failures, fix the unit (User/Group, WorkingDirectory/RuntimeDirectory, ExecStart), and verify via logs that subsequent timer invocations complete successfully with stdout/stderr captured in journald.",,
eda3564f-7558-4ee7-8e37-91dd23dedc3e,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure the Mosquitto MQTT broker with plaintext (1883) and TLS (8883) listeners, password-based authentication, and persistence managed via systemd. Generate a self-signed certificate, enable the service on boot, and verify pub/sub functionality using mosquitto_pub and mosquitto_sub over both transports.",,
30466ab1-ae22-4af1-8dda-a6b085a001ef,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure OpenLDAP (slapd) with a base DN (dc=tb,dc=local), enabling StartTLS on 389 and LDAPS on 636 with a self-signed certificate, plus the memberOf/refint overlays and proper indexing. Create an OU and a test user with a salted hashed password, run slapd in the background, and verify authenticated ldapsearch/ldapmodify operations over TLS return expected entries.",,
3fcc4f40-f8ab-49fe-973a-8ee18a8e9156,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure an Apache Kafka cluster with systemd-managed Zookeeper and brokers across three nodes, secured with TLS encryption and SASL authentication. Create a topic and perform producer and consumer tests to validate end-to-end messaging and cluster health.",,
6cdedb2b-4d60-478a-a818-89fd494ae388,System Setup & Configuration,Service & Daemon Management,Service Installation & Setup,"Install and configure WireGuard as a systemd‐managed VPN service on a Linux host: generate server and two client keypairs and configs, apply firewall rules, enable the wg-quick service, and verify secure tunneling by exchanging traffic between the clients.",,
fb0cf31d-0df0-49c6-8114-7e564545945c,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Define a systemd.path and associated .service to watch /opt/secure-drop for new files. The service should encrypt dropped files with a GPG key under an unprivileged user, move encrypted outputs to /opt/secure-archive, remove the plaintext, and include proper dependencies, Restart policy, and resource controls; verify by dropping a test file.",,
1e095ff0-7824-4029-9623-b8c314641059,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Create a socket-activated, templated systemd service (echo@.socket/echo@.service) for a tiny Python HTTP echo server that runs as an unprivileged user and starts on-demand when connections arrive, with instances bound to ports via the instance name. Enable sockets for ports 8081 and 9091, ensure After=network-online.target with basic hardening, and verify curl requests trigger the service and return a response while logs appear in journald.",,
c738a0ff-aff1-4170-b882-b15ca3f419f6,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Implement a socket-activated, per-connection systemd service (using a .socket and a templated .service) that runs a minimal HTTP echo server bound to 127.0.0.1:8085 with DynamicUser and strict sandboxing. Validate that a curl request triggers on-demand startup, serves a response, then the service stops after an idle timeout while the socket remains listening.",,
22f00248-9e5d-4d74-b837-8975090b037a,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Implement a systemd path and service unit pair that watches a directory (e.g. /opt/uploads) for new files and automatically runs an archiving script to compress them into dated tarballs under /var/backups/uploads with journald and file logging. Enable and test by simulating file creation events, then verify the archive tarballs and corresponding log entries are produced as expected.",,
0286c8a8-8408-43e8-bc3c-9caee689987b,System Setup & Configuration,Service & Daemon Management,Systemd & Init Configuration,"Create a socket-activated, templated systemd service that spawns per-connection instances of a tiny Python HTTP responder via Accept=yes on port 8080 using the inherited socket (fd 3). Verify on-demand activation with curl, that each instance exits after one request, and enable the socket to start at boot.",,
cc7d1125-755c-47e7-bfde-dab4d105ab10,System Setup & Configuration,Software & Package Management,Dependency Verification & Repair,"Recover a Debian/Ubuntu system from an interrupted apt upgrade that left dpkg in a broken state by repairing the package database, clearing partial installs, and resolving held/unmet dependencies with correct version pinning. Validate the fix by installing and running a provided CLI that initially fails due to missing libssl/libffi SONAMEs, ensuring compatibility libraries are installed properly without manual symlinks.",,
371a35a3-626b-47d5-8694-7d399e55b227,System Setup & Configuration,Software & Package Management,Dependency Verification & Repair,"Resolve a C++ runtime symbol version mismatch by installing a compatible libstdc++ (e.g., GLIBCXX_3.4.26+) on a Debian-based system where a precompiled binary fails with 'version GLIBCXX_3.4.26 not found'. Configure apt pinning/backports to upgrade only libstdc++6 and required dependencies without a full dist-upgrade, then validate the binary runs and ldd shows no unresolved symbols.",,
7bf8af15-01ba-46b0-b8b4-ced4d963a6b2,System Setup & Configuration,Software & Package Management,Dependency Verification & Repair,"Diagnose and repair missing 32-bit runtime libraries for a provided 32-bit ELF binary (/app/bin/hello32) by enabling i386 multiarch on Debian/Ubuntu, installing required :i386 packages (e.g., libc6, libstdc++6, libgcc-s1), and refreshing the linker cache. Prove the fix by ensuring ldd shows no ""not found"" entries, the binary executes successfully, and saving the resolved ldd map to /app/output/ldd-hello32.txt.",,
9f8f5c55-f0d6-4e01-9426-fce2fa820e08,System Setup & Configuration,Software & Package Management,Dependency Verification & Repair,"Simulate a Debian system with mixed stable, backports and experimental repositories causing package conflicts and unmet dependencies; the agent must identify conflicting packages, adjust /etc/apt/sources.list and /etc/apt/preferences.d/, run apt-get update, apt-get -f install and dpkg --configure -a to fully repair the system, then produce a report detailing conflicts detected and resolution steps taken.",,
8ff7ada5-e665-4ec6-a79c-4c5010651cd6,System Setup & Configuration,Software & Package Management,Package Installation & Removal,"On a Debian Bullseye sandbox, configure apt pinning to selectively install a backported version of PostgreSQL 14 alongside stable packages, install it, then adjust pin priorities to downgrade to PostgreSQL 13 from the main repo. Verify by querying 'psql --version' before and after downgrade and ensuring no residual 14 packages remain.",,
6d0848a6-f131-4670-8712-452fc59e4d11,System Setup & Configuration,Software & Package Management,Package Installation & Removal,"Set up a custom Debian package repository using reprepro or aptly, generate and GPG-sign a sample .deb, and serve it over HTTP. Configure a client to trust the repo key, then automate installation, upgrade, holding, downgrading, and removal of the package via apt, verifying logs and package states after each operation.",,
1e0166e9-0ab4-4f20-9700-c42e1aa4269a,System Setup & Configuration,Software & Package Management,Repository Configuration,"Create a local APT repository at /repo, serve it over HTTPS via nginx, and sign its Release/InRelease files with a newly generated GPG key; publish and index a minimal hello-world .deb. Add the repo to apt sources using signed-by, confirm apt update and package installation succeed, then demonstrate that altering the signed metadata causes apt to refuse the repo until the correct signature/key is restored.",,
58582822-3a5d-4f33-a098-bbb1792487fa,System Setup & Configuration,Software & Package Management,Repository Configuration,"Create a locally hosted, GPG-signed APT repository (served on localhost) containing a provided .deb, add it to sources using the signed-by option with a keyring in /usr/share/keyrings, and install the package from it. Demonstrate that apt rejects the repo before the key is configured and succeeds after the correct keyring is installed and referenced.",,
2c13380d-cafb-478f-a8b8-bbd98158b2cf,System Setup & Configuration,Software & Package Management,Repository Configuration,"Deploy an internal Debian APT repository using aptly and Nginx: initialize and sign the repo with GPG keys, publish snapshots over HTTP with basic authentication. Configure a client container to trust the repository key, install a custom .deb, update the package in the repo, refresh the snapshot, and verify the client can upgrade to the new version.",,
c1c7b87c-3d13-4260-8432-972285c03148,System Setup & Configuration,System Monitoring & Diagnostics,Log Analysis & Troubleshooting,"Develop a Bash/AWK utility that scans rotated /var/log/auth.log and journalctl entries from the last 48 hours, identifies SSH brute-force attempts by grouping failed logins per IP, enriches each IP with offline GeoIP country data, and outputs both a CSV timeline and an ASCII world map highlighting attack origins. Configure it as a systemd timer to run hourly and validate by simulating login failures from multiple virtual hosts to ensure the report updates correctly.",,
2b2ce0fc-16cc-4486-9cf3-ba9ee017723c,System Setup & Configuration,System Monitoring & Diagnostics,Log Analysis & Troubleshooting,"Develop a shell script that parses syslog, auth.log, and kernel logs for the past 24 hours, counts kernel OOM events, high load warnings, and SSH authentication failures hourly, and outputs a CSV summary and JSON alert report. Schedule the script via a systemd timer and configure email notifications to be sent when any metric exceeds defined thresholds.",,
b68720a2-2894-4742-be8e-89865362ac3d,System Setup & Configuration,System Monitoring & Diagnostics,Log Analysis & Troubleshooting,"Configure persistent journald storage and custom logrotate rules for /var/log/syslog. Develop a script that parses syslog and journalctl logs to identify and correlate OOM kills, kernel panics, and service crashes over the past week, producing a CSV report of timestamps, event types, and counts.",,
3080f96c-4ff3-42e9-a77b-0307369109cc,System Setup & Configuration,System Monitoring & Diagnostics,Log Analysis & Troubleshooting,"Analyze log file sizes under /var/log to identify the top three services generating the most log data over the past week, then update the rsyslog configuration to drop DEBUG-level messages from the highest-volume service, reload rsyslog, and confirm log volume reduction via new growth statistics.",,
6c5b8f89-9e96-4a23-86aa-6149f558f6e1,System Setup & Configuration,System Monitoring & Diagnostics,Performance Tuning,"Configure a Linux system to maximize NVMe SSD performance by tuning the I/O scheduler, block device queue depth, and filesystem mount options, and by pinning fio workload threads to dedicated CPU cores. Benchmark sequential and random read/write workloads with fio before and after tuning, then produce a report comparing IOPS, throughput, and latency improvements.",,
28b601f4-709f-4d13-98c6-e108448bbcff,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Install and enable sysstat, then create a monitor.sh that samples CPU (user/system/iowait), memory (free/swap), and disk I/O (%util, await) every 5s for 3 minutes using vmstat, iostat, and ps, logging to /var/log/bench-monitor/. After completion, emit a summary.txt flagging thresholds (CPU >85%, iowait >10%, disk %util >80%), listing top 5 CPU and memory processes, and providing brief tuning recommendations.",,
3c74ff12-3957-4d94-a08b-3c5b5bfe8e5a,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Create an automated profiler that runs a short, reproducible workload and samples top, ps, iostat -x, and vmstat at 1-second intervals for 60 seconds, writing CSV logs and a human-readable summary. Based on thresholds (CPU idle, iowait, swap-in/out, disk util/await), classify the bottleneck as CPU-, memory-, or disk-bound and emit one concrete tuning recommendation (e.g., adjust vm.swappiness or revisit the I/O scheduler).",,
bdc841e1-1ede-40cc-8c11-5922628a62c9,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Create a shell-based monitor that induces CPU, memory, and disk load, samples vmstat and iostat at 1s intervals for 60s, captures top/ps snapshots, and writes /app/metrics.jsonl plus /app/resource_report.txt. The script must auto-classify the host as CPU-, memory-, or I/O-bound (verifying an injected I/O-bound scenario) and include at least one actionable tuning recommendation.",,
2fffb1ee-1b04-47b0-a73b-3f2880a22428,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Create triage.sh that concurrently samples vmstat 1, iostat -xz 1, pidstat/top in batch mode for ~30s, computes averages, classifies the dominant bottleneck (CPU, memory, or I/O) using clear thresholds, and writes both a human-readable report and summary.csv of key metrics. Validate by reproducing three synthetic loads (stress-ng for CPU and memory; fio for disk) and ensure the script labels each correctly and prints tuning hints (e.g., swappiness/read-ahead adjustments) for the detected bottleneck.",,
72e0db8b-2dc0-471f-92b3-cecf48ec5c07,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Install and configure sysstat to record system metrics every minute with one-week retention. Simulate CPU, memory, disk, and network load, then use sar to generate and parse hourly CPU, memory, IO, and network utilization reports into JSON, verifying that induced load periods match peaks.",,
b4744535-e49c-43cb-a4f4-d816beadb1a5,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Develop a shell script that collects CPU, memory, and disk I/O metrics every 30 seconds for 24 hours using vmstat and iostat, outputs results to a CSV file, and then uses gnuplot to generate time-series plots highlighting utilization trends and peak load periods. Provide the script, sample CSV data, generated graphs, and a brief report identifying the top three resource bottlenecks observed.",,
6ba03973-be02-4b8f-8b65-822d56e4c7f4,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Configure sysstat's sar to collect CPU, memory, and I/O statistics at one-minute intervals for a 12-hour period; then generate and parse sar reports to determine the hour with the highest average CPU usage, memory pressure, and disk utilization. Supply the sar logs, generated reports, and a concise summary highlighting these peak periods and recommending basic tuning steps.",,
113bc7c0-1f0f-420b-a672-5303668a34e2,System Setup & Configuration,System Monitoring & Diagnostics,Resource Monitoring,"Develop a Bash script that gathers CPU, memory, and disk I/O metrics via vmstat, iostat, and free at 1-second intervals over a two-minute window, then parses the data to compute average, peak, and 95th percentile values for each metric and outputs both a CSV file and a human-readable summary report.",,
7a5ffe07-c27b-4909-ab95-356bf6f62c90,System Setup & Configuration,User & Access Management,Authentication & Access Control,"Configure OpenSSH to require certificate-based user authentication using a locally generated OpenSSH CA, with TrustedUserCAKeys set and PasswordAuthentication/PubkeyAuthentication disabled. Create one valid signed client cert and one revoked cert via RevokedKeys, then verify only the non-revoked certificate can log in.",,
42addd8c-4691-48af-b2ab-53d9a0166d29,System Setup & Configuration,User & Access Management,Authentication & Access Control,"Configure OpenSSH to use an internal user CA for certificate-based logins, creating and trusting a CA key, generating and signing a client key for a new devops user, and disabling password and plain public-key authentication for that account via a Match block on port 2222. Add a least-privilege sudoers policy so devops can run only systemctl status and journalctl without a password, and verify both successful cert login and expected failures for password/unsigned keys.",,
e3b93aa2-b923-4361-9942-105ae2719dae,System Setup & Configuration,User & Access Management,Authentication & Access Control,"Set up OpenSSH to use a user certificate authority for authentication: generate a CA keypair, sign a user’s key with a principal, configure sshd with TrustedUserCAKeys and AuthorizedPrincipalsFile, and disable password/non-cert public key logins. Verify the user can SSH to localhost using the signed certificate while ordinary keys and passwords are rejected.",,
9f5dc599-13d8-43b1-aa17-d9bd0cbc75a7,System Setup & Configuration,User & Access Management,Authentication & Access Control,"Set up OpenSSH certificate-based authentication by creating a local SSH CA, signing both the server host key and a user key, and configuring sshd to trust the CA via TrustedUserCAKeys while disabling raw public-key logins. Define two principals (admin and deploy) with per-principal restrictions (e.g., ForceCommand for deploy and full shell for admin) and verify that only a signed certificate with the correct principal can log in while unsigned or wrong-principal attempts are denied.",,
8b1a9e63-8de0-4f59-a09c-0126c0f35d7b,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Create a multi-purpose project area at /srv/projects/acme with three subdirectories using POSIX ACLs: incoming as a write-only 'blind dropbox' (root:submitters, 1733, sticky bit) where only file owners and the reviewers group can read their own uploads; shared as a setgid devs workspace where new files inherit devs:rwx and qa:r-x; and secrets owned by svc-ci where only svc-ci has rwx and leads have r-x, others denied. Ensure inheritance with default ACLs and mask tuning, verify effective permissions with getfacl and by creating test files as representative users.",,
605796b6-d162-4ab1-9eca-5edf5a3f2f15,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Configure a shared /opt/shared directory owned by root:devops with the setgid bit and default ACLs granting alice and bob full rwx, auditors read-only, and no access to others, ensuring all new files and subdirectories inherit these settings. Verify by creating test files as each user and inspecting permissions using getfacl and access attempts.",,
63dbcd84-7726-437c-8035-ac8ef4231287,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Create a collaborative workspace at /data/projects owned by group dev with setgid, where POSIX ACLs grant dev rwX on all current and future content and interns r-X only, while a subdirectory /data/projects/secret explicitly denies user bob all access regardless of group membership. Ensure default ACLs and the mask preserve intended permissions and inheritance for newly created files and directories.",,
7e7e749a-263c-48f7-a5a7-7661db5e2404,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Provision a collaborative workspace at /srv/projects/alpha with users (alice, bob, charlie) and groups (dev, qa), enforcing via POSIX ACLs and setgid that dev has rwX, qa has r-X, while a secrets subdirectory is accessible only to alice. Configure default ACLs so new files inherit these rights, set the sticky bit on an uploads subdirectory, and validate effective permissions with getfacl and test file operations.",,
d54e3371-71a0-4dbb-a38d-84c477a0a014,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Create a multi-tenant /data/workspace with subdirectories shared, dropbox, and pii using POSIX ACLs plus setgid/sticky bits to enforce role-specific access (dev/audit/intern): shared RWX for dev+audit with interns read-only, dropbox write-only for interns with sticky, and pii RWX for dev, read-only for audit, no access for interns. Configure default ACLs so new content inherits correctly and adjust the ACL mask to demonstrate effective permission reduction where required.",,
e3610beb-79b3-44ba-bcaa-6967ed8e3cab,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Create a multi-team workspace in /srv/work using POSIX ACLs, default ACLs, setgid directories, and sticky bits so new files inherit the correct group and permissions: alpha/ and beta/ are rwX for their teams, read-only to the other team, ops has rwX everywhere, dropbox/ is write-only for all except owners and ops, and secrets/ is ops-only. Validate effective rights and inheritance by creating test files as alice, bob, carol, and an ops user via su, and confirming expected access with getfacl and targeted read/write attempts.",,
d8ebf4fd-d2ea-4173-b7f4-3837b14f0ff8,System Setup & Configuration,User & Access Management,File Ownership & ACL Management,"Provision a drop-box directory at /srv/dropbox owned by root with group “dropbox” granted only write/execute (no read) permissions via POSIX ACLs and the sticky bit so members can upload but cannot list directory contents. Create sample dropbox users to test file uploads, verify listing restrictions, and perform root retrieval to confirm ACL enforcement.",,
06f783d5-7aea-4e47-a2d8-c0abc1bfac0e,System Setup & Configuration,User & Access Management,User & Group Administration,"Enable per-user and per-group disk quotas on the /home ext4 filesystem by configuring soft and hard limits with a grace period. Create test users, consume disk space to trigger warnings and hard-limit enforcement, verify quota reports, enforcement behavior, and any notification emails.",,
c8ae7872-33a8-4779-a1d3-0965f7c9f18b,System Setup & Configuration,User & Access Management,User & Group Administration,"Provision users dev-amy and dev-bob with private groups and homes under /srv/home (0750) from a custom /etc/skel, create groups eng and contractors, and configure /srv/eng/share setgid with default ACLs so eng has rwx and contractors r-x (inherit). Require both users to change passwords on first login and set dev-bob’s account to expire in 30 days.",,
803482fd-3001-46ec-b546-68c57dd6ae75,System Setup & Configuration,User & Access Management,User & Group Administration,"Bulk onboard users from /app/new_hires.csv by creating accounts with per-user private groups, specified shells, home directories seeded from /etc/skel, and installed SSH authorized_keys; enforce password expiry on first login and set default umask to 027 for new users. Create dev and ops groups with least-privilege sudo rules in /etc/sudoers.d and emit a JSON report summarizing each user’s UID, group memberships, home permissions, and sudo access.",,
0a015ece-1292-4592-aa0b-29beef09b797,System Setup & Configuration,User & Access Management,User & Group Administration,"Create a new 'deploy' UNIX group and add three users with SSH key–based authentication and customized home directories via /etc/skel. Configure default and directory ACLs on /var/www/app to grant the 'deploy' group read/write permissions with inheritance, enforce a global umask of 027, and verify access and ACL propagation for both existing and newly created users.",,
bcd706c3-2c2c-43b6-b3dd-bcc699b38975,System Setup & Configuration,Virtualization & Containerization,Container Setup & Management,"Deploy and configure a private Docker registry secured with a self-signed TLS certificate and HTTP Basic Auth, then configure the Docker daemon to trust its CA. Build a multi-stage Go service image, enable Docker Content Trust to sign and push the image, verify a secure pull, and demonstrate that pulling an unsigned image fails.",,
4f5c0518-d0ab-4e6b-865b-45b73aca9ce7,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,"Build a bootable Debian 12 cloud-init image from scratch by creating a minimal rootfs with debootstrap, adding kernel/initramfs, OpenSSH, and cloud-init, then installing GRUB into a qcow2 disk and compressing it to /app/images/debian12-cloud.qcow2.zst with a sha256 checksum. Generate a NoCloud seed ISO that provisions user tb with an SSH key, and verify by booting the qcow2 in QEMU with host port 2222 forwarded and successful SSH login.",,
74158136-e469-4d9e-b4eb-f8b3c6cb7463,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,"Use debootstrap to assemble a minimal Ubuntu root filesystem, chroot in to install and configure SSH, cloud-init, and a non-root user, then convert the directory into a QCOW2 disk image and validate it boots successfully under QEMU.",,
0b719755-06be-44b9-9e9b-c45097602dc7,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,"Create a minimal Debian qcow2 VM image from scratch using debootstrap, configuring fstab, GRUB for serial console, a non-root tb user with SSH access, and cloud-init. Export the qcow2 and a cloud-init seed ISO, then boot with QEMU to verify SSH connectivity via host port forwarding.",,
d65b9cb8-e388-4623-9041-e889e63204fb,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,Use Docker Buildx with QEMU emulation to build and push a multi-architecture (amd64 and arm64) Docker image for a Go HTTP server via a multi-stage Dockerfile; register it under a manifest list in a local registry and verify pulls and container runs on both architectures.,,
7b036ad1-c5bf-47c8-9862-8652a34166f9,System Setup & Configuration,Virtualization & Containerization,Image Building & Exporting,"Assemble a minimal Debian-based cloud image from scratch using debootstrap, package it into a bootable qcow2 with ext4 and GRUB, and enable cloud-init. Export the image to /app/images/debian-cloud.qcow2 and verify it by booting with QEMU using a NoCloud seed that creates a known user and hostname.",,
820a9eb7-273a-4fa5-830c-917d9fbc5d78,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Provision an Ubuntu cloud-image VM with QEMU and cloud-init (NoCloud) to create a tb-admin user with a provided SSH public key, preinstall nginx, and serve a custom index.html reachable via host port 8080. After verifying SSH and HTTP access, create a named external qcow2 snapshot, change the site, then revert to the snapshot to demonstrate full VM state rollback.",,
88a24a17-cc4e-41e7-b185-9ab356c33098,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Provision an Ubuntu cloud-image VM with libvirt/KVM using cloud-init to create user 'tb' (password 'benchmarkpass'), inject an SSH public key, set hostname tb-vm, and enable qemu-guest-agent. Create an isolated libvirt network with a static VM IP and host port-forwarding 2222->22, autostart the VM, and verify SSH connectivity and hostname via a test script.",,
d0edb295-612c-4716-93a8-74df2659ab78,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Use Vagrant with the libvirt provider to provision three VMs: one running dnsmasq as a combined DHCP and DNS server, and two clients obtaining static leases. Configure an isolated network, verify clients receive the correct IPs and hostnames, and ensure DNS resolution between all machines.",,
2964c9a5-97c7-469f-b0dd-a8312bace525,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Using Vagrant and the libvirt provider, provision a PXE‐boot TFTP/HTTP server VM serving a custom Kickstart for CentOS 8 network installation, then spin up a second VM that boots via PXE to perform the automated install. Validate by retrieving the Kickstart file at /vagrant/ks.cfg, confirming the guest completes installation and boots to shell, and logging its assigned IP to /vagrant/guest_ip.txt on the host.",,
2b43d2af-36c5-48d6-ad6e-85d411630186,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Provision an Ubuntu 22.04 VM using libvirt and virt-install with cloud-init to configure a sudo user with SSH key access, assign a static IP, format and mount an attached second disk, and install Docker. Verify SSH connectivity, network settings, disk mount, and that `docker run hello-world` succeeds.",,
9f797d3c-3f06-460a-8a89-346b1388e7cc,System Setup & Configuration,Virtualization & Containerization,Virtual Machine Provisioning,"Provision an Ubuntu cloud-image VM with QEMU/KVM using a NoCloud cloud-init seed that creates a tbuser with an SSH key, enables the qemu-guest-agent, and runs a first-boot script to install and start Nginx serving a custom index.html. Forward host ports 2222->22 and 8080->80, verify SSH and HTTP from the host, and store the qcow2 disk and seed ISO under /app/vm.",,
